
@inproceedings{10.1145/3210240.3210334,
author = {Lentz, Matthew and Sen, Rijurekha and Druschel, Peter and Bhattacharjee, Bobby},
title = {SeCloak: ARM Trustzone-based Mobile Peripheral Control},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210334},
doi = {10.1145/3210240.3210334},
abstract = {Reliable on-off control of peripherals on smart devices is a key to security and privacy in many scenarios. Journalists want to reliably turn off radios to protect their sources during investigative reporting. Users wish to ensure cameras and microphones are reliably off during private meetings. In this paper, we present SeCloak, an ARM TrustZone-based solution that ensures reliable on-off control of peripherals even when the platform software is compromised. We design a secure kernel that co-exists with software running on mobile devices (e.g., Android and Linux) without requiring any code modifications. An Android prototype demonstrates that mobile peripherals like radios, cameras, and microphones can be controlled reliably with a very small trusted computing base and with minimal performance overhead.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {1–13},
numpages = {13},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210338,
author = {Ying, Kailiang and Ahlawat, Amit and Alsharifi, Bilal and Jiang, Yuexin and Thavai, Priyank and Du, Wenliang},
title = {TruZ-Droid: Integrating TrustZone with Mobile Operating System},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210338},
doi = {10.1145/3210240.3210338},
abstract = {Mobile devices today provide a hardware-protected mode called Trusted Execution Environment (TEE) to help protect users from a compromised OS and hypervisor. Today TEE can only be leveraged either by vendor apps or by developers who work with the vendor. Since vendors consider third-party app code untrusted inside the TEE, to allow an app to leverage TEE, app developers have to write the app code in a tailored way to work with the vendor's SDK. We proposed a novel design to integrate TEE with mobile OS to allow any app to leverage the TEE. Our design incorporates TEE support at the OS level, allowing apps to leverage the TEE without adding app-specific code into the TEE, and while using existing interface to interact with the mobile OS. We implemented our design, called TruZ-Droid, by integrating TrustZone TEE with the Android OS. TruZ-Droid allows apps to leverage the TEE to protect the following: (i) user's secret input and confirmation, and (ii) sending of user's secrets to the authorized server. We built a prototype using the TrustZone-enabled HiKey board to evaluate our design. We demonstrated TruZ-Droid's effectiveness by adding new security features to existing apps to protect user's sensitive information and attest user's confirmation. TruZ-Droid's real-world use case evaluation shows that apps can leverage TrustZone while using existing OS APIs. Our usability study proves that users can correctly interact with TruZ-Droid to protect their security sensitive activities and data.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {14–27},
numpages = {14},
keywords = {Android, TrustZone},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210330,
author = {Li, Wenhao and Luo, Shiyu and Sun, Zhichuang and Xia, Yubin and Lu, Long and Chen, Haibo and Zang, Binyu and Guan, Haibing},
title = {VButton: Practical Attestation of User-driven Operations in Mobile Apps},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210330},
doi = {10.1145/3210240.3210330},
abstract = {More and more malicious apps and mobile rootkits are found to perform sensitive operations on behalf of legitimate users without their awareness. Malware does so by either forging user inputs or tricking users into making unintended requests to online service providers. Such malware is hard to detect and generates large revenues for cybercriminals, which is often used for committing ad/click frauds, faking reviews/ratings, promoting people or business on social networks, etc.We find that this class of malware is possible due to the lack of practical and robust means for service providers to verify the authenticity of user-driven operations (i.e., operations supposed to be performed, or explicitly confirmed, by a user). We design and build the VButton system to fill this void. Our system introduces a class of attestation-enabled app UI widgets (called VButton UI). Developers can easily integrate VButton UI in their apps to allow service providers to verify that a user-driven operation triggered by a VButton UI is indeed initiated and intended by a real user. Our system contains an on-device Manager, and a server-side Verifier. Leveraging ARM TrustZone, our system can attest operation authenticity even in the presence of a compromised OS. We have implemented the VButton system on an ARM development board as well as a commercial off-the-shelf smartphone. The evaluation results show that the system incurs negligible overhead.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {28–40},
numpages = {13},
keywords = {Attestation, Mobile platform, TrustZone, User-driven security},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210317,
author = {Khan, Hassan and Hengartner, Urs and Vogel, Daniel},
title = {Augmented Reality-based Mimicry Attacks on Behaviour-Based Smartphone Authentication},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210317},
doi = {10.1145/3210240.3210317},
abstract = {We develop an augmented reality-based app that resides on the attacker's smartphone and leverages computer vision and raw input data to provide real-time mimicry attack guidance on the victim's phone. Our approach does not require tampering or installing software on the victim's device, or specialized hardware. The app is demonstrated by attacking keystroke dynamics, a method leveraging the unique typing behaviour of users to authenticate them on a smartphone, which was previously thought to be hard to mimic. In addition, we propose a low-tech AR-like audiovisual method based on spatial pointers on a transparent film and audio cues. We conduct experiments with 31 participants and mount over 400 attacks to show that our methods enable attackers to successfully bypass keystroke dynamics for 87\% of the attacks after an average mimicry training of four minutes. Our AR-based method can be extended to attack other input behaviour-based biometrics. While the particular attack we describe is relatively narrow, it is a good example of using AR guidance to enable successful mimicry of user behaviour---an approach of increasing concern as AR functionality becomes more commonplace.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {41–53},
numpages = {13},
keywords = {Augmented reality, Authentication, Behavioural biometrics, Mimicry attacks},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210348,
author = {Kang, Bumsoo and Hwang, Inseok and Lee, Jinho and Lee, Seungchul and Lee, Taegyeong and Chang, Youngjae and Lee, Min Kyung},
title = {My Being to Your Place, Your Being to My Place: Co-present Robotic Avatars Create Illusion of Living Together},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210348},
doi = {10.1145/3210240.3210348},
abstract = {People in work-separated families have been heavily relying on cutting-edge face-to-face communication services. Despite their ease of use and ubiquitous availability, experiences in living together are still far incomparable to those through remote face-to-face communication. We envision that enabling a remote person to be spatially superposed in one's living space would be a breakthrough to catalyze pseudo living-together interactivity. We propose HomeMeld, a zero-hassle self-mobile robotic system serving as a co-present avatar to create a persistent illusion of living together for those who are involuntarily living apart. The key challenges are 1) continuous spatial mapping between two heterogeneous floor plans and 2) navigating the robotic avatar to reflect the other's presence in real time under the limited maneuverability of the robot. We devise a notion of functionally equivalent location and orientation to translate a person's presence into another in a heterogeneous floor plan. We also develop predictive path warping to seamlessly synchronize the presence of the other. We conducted extensive experiments and deployment studies with real participants.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {54–67},
numpages = {14},
keywords = {Robotic avatar, co-located interaction, co-presesnce, telepresence},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210313,
author = {Liu, Luyang and Zhong, Ruiguang and Zhang, Wuyang and Liu, Yunxin and Zhang, Jiansong and Zhang, Lintao and Gruteser, Marco},
title = {Cutting the Cord: Designing a High-quality Untethered VR System with Low Latency Remote Rendering},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210313},
doi = {10.1145/3210240.3210313},
abstract = {This paper introduces an end-to-end untethered VR system design and open platform that can meet virtual reality latency and quality requirements at 4K resolution over a wireless link. High-quality VR systems generate graphics data at a data rate much higher than those supported by existing wireless-communication products such as Wi-Fi and 60GHz wireless communication. The necessary image encoding, makes it challenging to maintain the stringent VR latency requirements. To achieve the required latency, our system employs a Parallel Rendering and Streaming mechanism to reduce the add-on streaming latency, by pipelining the rendering, encoding, transmission and decoding procedures. Furthermore, we introduce a Remote VSync Driven Rendering technique to minimize display latency. To evaluate the system, we implement an end-to-end remote rendering platform on commodity hardware over a 60Ghz wireless network. Results show that the system can support current 2160x1200 VR resolution at 90Hz with less than 16ms end-to-end latency, and 4K resolution with 20ms latency, while keeping a visually lossless image quality to the user.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {68–80},
numpages = {13},
keywords = {60GHz, High-quality, Low latency, Untethered, Virtual Reality},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210319,
author = {Qiu, Hang and Ahmad, Fawad and Bai, Fan and Gruteser, Marco and Govindan, Ramesh},
title = {AVR: Augmented Vehicular Reality},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210319},
doi = {10.1145/3210240.3210319},
abstract = {Autonomous vehicle prototypes today come with line-of-sight depth perception sensors like 3D cameras. These 3D sensors are used for improving vehicular safety in autonomous driving, but have fundamentally limited visibility due to occlusions, sensing range, and extreme weather and lighting conditions. To improve visibility and performance, not just for autonomous vehicles but for other Advanced Driving Assistance Systems (ADAS), we explore a capability called Augmented Vehicular Reality (AVR). AVR broadens the vehicle's visual horizon by enabling it to wirelessly share visual information with other nearby vehicles, but requires the design of novel relative positioning techniques, new perspective transformation methods, approaches to isolate and predict the motion of dynamic objects in order to hide latency, and adaptive transmission strategies to cope with wireless bandwidth variability. We show that AVR is feasible using off-the-shelf wireless technologies, and it can qualitatively change the decisions made by autonomous vehicle path planning algorithms. Our AVR prototype achieves positioning accuracies that are within a few percent of car lengths and lane widths, and is optimized to process frames at 30fps.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {81–95},
numpages = {15},
keywords = {Autonomous Cars, Collaborative Sensing, Extended Vision},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210339,
author = {Li, Toby Jia-Jun and Riva, Oriana},
title = {Kite: Building Conversational Bots from Mobile Apps},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210339},
doi = {10.1145/3210240.3210339},
abstract = {Task-oriented chatbots allow users to carry out tasks (e.g., ordering a pizza) using natural language conversation. The widely-used slot-filling approach for building bots of this type requires significant hand-coding, which hinders scalability. Recently, neural network models have been shown to be capable of generating natural "chitchat" conversations, but it is unclear whether they will ever work for task modeling. Kite is a practical system for bootstrapping task-oriented bots, leveraging both approaches above. Kite's key insight is that while bots encapsulate the logic of user tasks into conversational forms, existing apps encapsulate the logic of user tasks into graphical user interfaces. A developer demonstrates a task using a relevant app, and from the collected interaction traces Kite automatically derives a task model, a graph of actions and associated inputs representing possible task execution paths. A task model represents the logical backbone of a bot, on which Kite layers a question-answer interface generated using a hybrid rule-based and neural network approach. Using Kite, developers can automatically generate bot templates for many different tasks. In our evaluation, it extracted accurate task models from 25 popular Android apps spanning 15 tasks. Appropriate questions and high-quality answers were also generated. Our developer study suggests that developers, even without any bot developing experience, can successfully generate bot templates using Kite.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {96–109},
numpages = {14},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210327,
author = {Farooq, Umar and Zhao, Zhijia},
title = {RuntimeDroid: Restarting-Free Runtime Change Handling for Android Apps},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210327},
doi = {10.1145/3210240.3210327},
abstract = {Portable devices, like smartphones and tablets, are often subject to runtime configuration changes, such as screen orientation changes, screen resizing, keyboard attachments, and language switching. When handled improperly, such simple changes can cause serious runtime issues, from data loss to app crashes.This work presents, to our best knowledge, the first formative study on runtime change handling with 3,567 Android apps. The study not only reveals the current landscape of runtime change handling, but also points out a common cause of various runtime change issues -- activity restarting. On one hand, the restarting facilitates the resource reloading for the new configuration. On the other hand, it may slow down the app, and more critically, it requires developers to manually preserve a set of data in order to recover the user interaction state after restarting.Based on the findings of this study, this work further introduces a re starting-free runtime change handling solution -- RuntimeDroid. RuntimeDroid can completely avoid the activity restarting, at the same time, ensure proper resource updating with user input data preserved. These are achieved with two key components: an online resource loading module, called HotR and a novel UI components migration technique. The former enables proper resources loading while the activity is still live. The latter ensures that prior user changes are carefully preserved during runtime changes.For practical use, this work proposes two implementations of RuntimeDroid: an IDE plugin and an auto-patching tool. The former allows developers to easily adopt restarting-free runtime change handling during the app developing; The latter can patch released app packages without source code. Finally, evaluation with a set of 72 apps shows that RuntimeDroid successfully fixed all the 197 reported runtime change issues, meanwhile reducing the runtime change handling delays by 9.5X on average.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {110–122},
numpages = {13},
keywords = {Android, Event Handling, Runtime Configuration Change},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210331,
author = {Kim, Wonjung and Choo, Kenny Tsu Wei and Lee, Youngki and Misra, Archan and Balan, Rajesh Krishna},
title = {Empath-D: VR-based Empathetic App Design for Accessibility},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210331},
doi = {10.1145/3210240.3210331},
abstract = {With app-based interaction increasingly permeating all aspects of daily living, it is essential to ensure that apps are designed to be inclusive and are usable by a wider audience such as the elderly, with various impairments (e.g., visual, audio and motor). We propose Empath-D, a system that fosters empathetic design, by allowing app designers, in-situ, to rapidly evaluate the usability of their apps, from the perspective of impaired users. To provide a truly authentic experience, Empath-D carefully orchestrates the interaction between a smartphone and a VR device, allowing the user to experience simulated impairments in a virtual world while interacting naturally with the app, using a real smartphone. By carefully orchestrating the VR-smartphone interaction, Empath-D tackles challenges such as preserving low-latency app interaction, accurate visualization of hand movement and low-overhead perturbation of I/O streams. Experimental results show that user interaction with Empath-D is comparable (both in accuracy and user perception) to real-world app usage, and that it can simulate impairment effects as effectively as a custom hardware simulator.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {123–135},
numpages = {13},
keywords = {accessibility, distributed user interfaces, empathetic design, mobile design, multi-device, virtual reality},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210324,
author = {Erd\'{e}lyi, Viktor and Le, Trung-Kien and Bhattacharjee, Bobby and Druschel, Peter and Ono, Nobutaka},
title = {Sonoloc: Scalable positioning of commodity mobile devices},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210324},
doi = {10.1145/3210240.3210324},
abstract = {We present Sonoloc, a mobile app and system that allows a set of co-located commodity smart devices to determine their relative positions without local infrastructure. Sonoloc enables users to address each other based on their relative positions at events like meetings, talks, or conferences. This capability can, for instance, aid spontaneous communication among users based on their relative position (e.g., in a given section of a room, at the same table, or in a given seat), facilitate interaction between speaker and audience in a lecture hall, and enable the distribution of materials, crowdsensing, and feedback collection based on users' location. Sonoloc can position any number of devices within acoustic range with a constant number of chirps emitted by a self-organized subset of devices. Our experimental evaluation shows that the system can locate up to hundreds of devices with an accuracy of tens of centimeters using up to 15 audio chirps emitted by dynamically selected devices, in actual rooms and despite substantial background noise.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {136–149},
numpages = {14},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210316,
author = {Chen, Kongyang and Tan, Guang},
title = {BikeGPS: Accurate Localization of Shared Bikes in Street Canyons via Low-Level GPS Cooperation},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210316},
doi = {10.1145/3210240.3210316},
abstract = {The past few years have seen a surge of stationless bike sharing services in many modern cities. The service allows the bikes to be dropped off freely, and to be found through GPS localization. For maximum convenience, the bikes are often parked in close proximity to the buildings, where GPS may perform poorly, making bike search a challenging task. This paper proposes a novel approach to addressing this problem. Inspired by multi-antenna systems, our method tries to collect GPS signals from multiple distributed bikes, by organizing a group of bikes into a network, called the BikeGPS. Formed by pedestrian users who opportunistically measure interbike distance via radio sensing and step tracking, the generated network permits one to map all the nodes' satellite range measurements into a single lead node's view. By considering both signal and geometry properties of satellite raw measurements, and using an asynchronous coarse time navigation algorithm, the lead node can accurately derive the locations of all the network nodes. Real-world experiments show that BikeGPS significantly improves the localization performance, in terms of both accuracy and solution availability, compared with the naive GPS approach and a high-level cooperative localization method.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {150–162},
numpages = {13},
keywords = {GPS, Localization, Shared Bikes, Street Canyons},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210343,
author = {Liu, Xiaochen and Nath, Suman and Govindan, Ramesh},
title = {Gnome: A Practical Approach to NLOS Mitigation for GPS Positioning in Smartphones},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210343},
doi = {10.1145/3210240.3210343},
abstract = {Accurate positioning in urban areas is important for personal navigation, geolocation apps, and ride-sharing. Smartphones localize themselves using GPS position estimates, and augment these with a variety of techniques including dead reckoning, map matching, and WiFi localization. However, GPS signals suffer significant impairment in urban canyons because of limited line-of-sight to satellites and signal reflections. In this paper, we focus on scalable and deployable techniques to reduce the impact of one specific impairment: reflected GPS signals from non-line-of-sight (NLOS) satellites. Specifically, we show how, using publicly available street-level imagery and off-the-shelf computer vision techniques, we can estimate the path inflation incurred by (the extra distance traveled by) a reflected signal from a satellite. Using these path inflation estimates we develop techniques to estimate the most likely actual position given a set of satellite readings at some position. Finally, we develop optimizations for fast position estimation on modern smartphones. Using extensive experiments in the downtown area of several large cities, we find that our techniques can reduce positioning error by up to 55\% on average.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {163–177},
numpages = {15},
keywords = {GPS, Localization, Mobile Computing, NLOS Mitigation},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210318,
author = {Yin, Zhimeng and Li, Zhijun and Kim, Song Min and He, Tian},
title = {Explicit Channel Coordination via Cross-technology Communication},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210318},
doi = {10.1145/3210240.3210318},
abstract = {Under significant coexistence in the ISM band, the impact of cross-technology interference (CTI) has become a major threat to low-power IoT. This paper presents ECC that uniquely enables explicit channel coordination among heterogeneities via cross-technology communication (CTC) introduced in the latest studies, while maintaining full compatibility to commodity devices. Unlike any implicit coordination designs adopting statistical models to probabilistically predict white spaces, ECC generates the white space using WiFi CTS, which is then explicitly notified to ZigBee through CTC for immediate use. Technical highlight of ECC lies in ensuring ZigBee communication under CTI, without disrupting WiFi operation. This is effectively achieved by the dynamic adjustment of CTS duration with respect to traffic amount and spectrum availability, which essentially enables ECC to be generally applied to various scenarios without prior knowledge. Lastly, ECC significantly reduces delay and energy in low duty cycled ZigBee, by waking them up upon channel availability (via CTC). We evaluate ECC on commercial platforms: Atheros AR2425 WiFi card and TelosB motes. Experiment results show that ECC achieves 1.8x ZigBee packet reception ratio, and cuts down delay and energy by 98.6\% and 51\% under the low duty cycle.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {178–190},
numpages = {13},
keywords = {Internet of Things, WiFi, ZigBee},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210329,
author = {Zhao, Jia and Gong, Wei and Liu, Jiangchuan},
title = {Spatial Stream Backscatter Using Commodity WiFi},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210329},
doi = {10.1145/3210240.3210329},
abstract = {Backscatter WiFi offers a novel low-cost and low-energy solution for RFID tags to communicate with existing WiFi devices. State-of-the-art backscatter WiFi solutions have seldom explored advanced features in the latest WiFi standards, in particular, spatial multiplexing, which has been the cornerstone for 802.11n and beyond. In this paper, we present MOXcatter, a WiFi backscatter communication system that works with spatial streams using commodity radios, while keeping the ongoing data communication unaffected. In MOXcatter, a backscatter tag can embed its sensing data on ambient spatial-stream packets, and both the sensing data and the original packets can be decoded by commodity WiFi devices. We have built a MOXcatter prototype with FPGAs and commodity WiFi devices. The experiments show that MOXcatter achieves up to 50 Kbps throughput for a single stream and up to 1 Kbps for double streams with a communication range (tag-to-RX) up to 14 m. We discuss the tradeoffs therein and possible enhancements, and also showcase the applicability of our design through a sensor communication system.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {191–203},
numpages = {13},
keywords = {Internet of Things, Spatial Stream, WiFi Backscatter},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210346,
author = {Li, Yan and Chi, Zicheng and Liu, Xin and Zhu, Ting},
title = {Chiron: Concurrent High Throughput Communication for IoT Devices},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210346},
doi = {10.1145/3210240.3210346},
abstract = {The exponentially increasing number of heterogeneous Internet of Things (IoT) devices motivate us to explore more efficient and higher throughput communication, especially at the bottleneck (i.e., edge) of the IoT networks. Our work, named Chiron, opens a promising direction for Physical (PHY) layer concurrent high throughput communication to heterogeneous IoT devices (e.g., wider-band WiFi and narrower-band ZigBee). Specifically, at the PHY layer, Chiron enables concurrently transmitting (or receiving) 1 stream of WiFi data and up to 4 streams of ZigBee data to (or from) commodity WiFi and ZigBee devices as if there is no interference between these simultaneous connections. We extensively evaluate our system under different real-world settings. Results show that Chiron's concurrent WiFi and ZigBee communication can achieve similar throughput as the sole WiFi or ZigBee communication. Chiron's spectrum utilization is more than 16 times better than the traditional gateway.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {204–216},
numpages = {13},
keywords = {Concurrent Communication, Internet of things (IoT), Wireless},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210341,
author = {Das, Tanmoy and Chen, Lu and Kundu, Rupam and Bakshi, Arjun and Sinha, Prasun and Srinivasan, Kannan and Bansal, Gaurav and Shimizu, Takayuki},
title = {CoReCast: Collision Resilient Broadcasting in Vehicular Networks},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210341},
doi = {10.1145/3210240.3210341},
abstract = {Reliable and timely delivery of periodic V2V (vehicle-to-vehicle) broadcast messages is essential for realizing the benefits of connected vehicles. Existing MAC protocols for ad hoc networks fall short of meeting these requirements. In this paper, we present, CoReCast, the first collision embracing protocol for vehicular networks. CoReCast provides high reliability and low delay by leveraging two unique opportunities: no strict constraint on energy consumption, and availability of GPS clocks to achieve near-perfect time and frequency synchronization.Due to low coherence time, the channel changes rapidly in vehicular networks. CoReCast embraces packet collisions and takes advantage of the channel dynamics to decode collided packets. The design of CoReCast is based on a preamble detection scheme that estimates channels from multiple transmitters without any prior information about them. The proposed scheme reduces the space and time requirement exponentially than the existing schemes. The system is evaluated through experiments with USRP N210 and GPS devices placed in vehicles driven on roads in different environments as well as using trace-driven simulations. It provides 15x and 2x lower delay than 802.11p and OCP (Omniscient Clustering Protocol), respectively. Reliability of CoReCast is 8x and 2x better than 802.11p and OCP, respectively.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {217–229},
numpages = {13},
keywords = {CoReCast, Preamble detection, Vehicular Networks},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210321,
author = {Razeen, Ali and Lebeck, Alvin R. and Liu, David H. and Meijer, Alexander and Pistol, Valentin and Cox, Landon P.},
title = {SandTrap: Tracking Information Flows On Demand with Parallel Permissions},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210321},
doi = {10.1145/3210240.3210321},
abstract = {The most promising way to improve the performance of dynamic information-flow tracking (DIFT) for machine code is to only track instructions when they process tainted data. Unfortunately, prior approaches to on-demand DIFT are a poor match for modern mobile platforms that rely heavily on parallelism to provide good interactivity in the face of computationally intensive tasks like image processing. The main shortcoming of these prior efforts is that they cannot support an arbitrary mix of parallel threads due to the limitations of page protections.In this paper, we identify parallel permissions as a key requirement for multithreaded, on-demand native DIFT, and we describe the design and implementation of a system called SandTrap that embodies this approach. Using our prototype implementation, we demonstrate that SandTrap's native DIFT overhead is proportional to the amount of tainted data that native code processes. For example, in the photo-sharing app Instagram, SandTrap's performance is close to baseline (1x) when the app does not access tainted data. When it does, SandTrap imposes a slowdown comparable to prior DIFT systems (~8x).},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {230–242},
numpages = {13},
keywords = {dynamic information-flow tracking, native code, parallel memory permissions},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210332,
author = {Liu, Tian and Liu, Ziyu and Huang, Jun and Tan, Rui and Tan, Zhen},
title = {Detecting Wireless Spy Cameras Via Stimulating and Probing},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210332},
doi = {10.1145/3210240.3210332},
abstract = {The rapid proliferation of wireless video cameras has raised serious privacy concerns. In this paper, we propose a stimulating-and-probing approach to detecting wireless spy cameras. The core idea is to actively alter the light condition of a private space to manipulate the spy camera's video scene, and then investigates the responsive variations of a packet flow to determine if it is produced by a wireless camera. Following this approach, we develop Blink and Flicker -- two practical systems for detecting wireless spy cameras. Blink is a lightweight app that can be deployed on off-the-shelf mobile devices. It asks the user to turn on/off the light of her private space, and then uses the light sensor and the wireless radio of the mobile device to identify the response of wireless cameras. Flicker is a robust and automated system that augments Blink to detect wireless cameras in both live and offline streaming modes. Flicker employs a cheap and portable circuit, which harnesses daily used LEDs to stimulate wireless cameras using human-invisible flickering. The time series of stimuli is further encoded using FEC to combat ambient light and uncontrollable packet flow variations that may degrade detection performance. Extensive experiments show that Blink and Flicker can accurately detect wireless cameras under a wide range of network and environmental conditions.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {243–255},
numpages = {13},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210333,
author = {Schulz, Matthias and Link, Jakob and Gringoli, Francesco and Hollick, Matthias},
title = {Shadow Wi-Fi: Teaching Smartphones to Transmit Raw Signals and to Extract Channel State Information to Implement Practical Covert Channels over Wi-Fi},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210333},
doi = {10.1145/3210240.3210333},
abstract = {Wi-Fi chips offer vast capabilities, which are not accessible through the manufacturers' official firmwares. Unleashing those capabilities can enable innovative applications on off-the-shelf devices. In this work, we demonstrate how to transmit raw IQ samples from a large buffer on Wi-Fi chips. We further show how to extract channel state information (CSI) on a per frame basis. As a proof-of-concept application, we build a covert channel on top of Wi-Fi to stealthily exchange information between two devices by prefiltering Wi-Fi frames prior to transmission. On the receiver side, the CSI is used to extract the embedded information. By means of experimentation, we show that regular Wi-Fi clients can still demodulate the underlying Wi-Fi frames. Our results show that covert channels on the physical layer are practical and run on off-the-shelf smartphones. By making available our raw signal transmitter, the CSI extractor, and the covert channel application to the research community, we ensure reproducibility and offer a platform for further innovative applications on Wi-Fi devices.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {256–268},
numpages = {13},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210322,
author = {Nguyen, Phuc and Bui, Nam and Nguyen, Anh and Truong, Hoang and Suresh, Abhijit and Whitlock, Matt and Pham, Duy and Dinh, Thang and Vu, Tam},
title = {TYTH-Typing On Your Teeth: Tongue-Teeth Localization for Human-Computer Interface},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210322},
doi = {10.1145/3210240.3210322},
abstract = {This paper explores a new wearable system, called TYTH, that enables a novel form of human computer interaction based on the relative location and interaction between the user's tongue and teeth. TYTH allows its user to interact with a computing system by tapping on their teeth. This form of interaction is analogous to using a finger to type on a keypad except that the tongue substitutes for the finger and the teeth for the keyboard. We study the neurological and anatomical structures of the tongue to design TYTH so that the obtrusiveness and social awkwardness caused by the wearable is minimized while maximizing its accuracy and sensing sensitivity. From behind the user's ears, TYTH senses the brain signals and muscle signals that control tongue movement sent from the brain and captures the miniature skin surface deformation caused by tongue movement. We model the relationship between tongue movement and the signals recorded, from which a tongue localization technique and tongue-teeth tapping detection technique are derived. Through a prototyping implementation and an evaluation with 15 subjects, we show that TYTH can be used as a form of hands-free human computer interaction with 88.61\% detection rate and promising adoption rate by users.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {269–282},
numpages = {14},
keywords = {Brain-Muscles Sensing, Human Computer Interaction (HCI), Skin Deformation Sensing, Tongue-Teeth Typing, Wearable Devices},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210315,
author = {Sun, Ke and Wang, Wei and Liu, Alex X. and Dai, Haipeng},
title = {Depth Aware Finger Tapping on Virtual Displays},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210315},
doi = {10.1145/3210240.3210315},
abstract = {For AR/VR systems, tapping-in-the-air is a user-friendly solution for interactions. Most prior in-air tapping schemes use customized depth-cameras and therefore have the limitations of low accuracy and high latency. In this paper, we propose a fine-grained depth-aware tapping scheme that can provide high accuracy tapping detection. Our basic idea is to use light-weight ultrasound based sensing, along with one COTS mono-camera, to enable 3D tracking of user's fingers. The mono-camera is used to track user's fingers in the 2D space and ultrasound based sensing is used to get the depth information of user's fingers in the 3D space. Using speakers and microphones that already exist on most AR/VR devices, we emit ultrasound, which is inaudible to humans, and capture the signal reflected by the finger with the microphone. From the phase changes of the ultrasound signal, we accurately measure small finger movements in the depth direction. With fast and light-weight ultrasound signal processing algorithms, our scheme can accurately track finger movements and measure the bending angle of the finger between two video frames. In our experiments on eight users, our scheme achieves a 98.4\% finger tapping detection accuracy with FPR of 1.6\% and FNR of 1.4\%, and a detection latency of 17.69ms, which is 57.7ms less than video-only schemes. The power consumption overhead of our scheme is 48.4\% more than video-only schemes.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {283–295},
numpages = {13},
keywords = {Computer Vision, Depth aware, Finger tapping, Ultrasound},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210344,
author = {Lin, Feng and Cho, Kun Woo and Song, Chen and Xu, Wenyao and Jin, Zhanpeng},
title = {Brain Password: A Secure and Truly Cancelable Brain Biometrics for Smart Headwear},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210344},
doi = {10.1145/3210240.3210344},
abstract = {In recent years, biometric techniques (e.g., fingerprint or iris) are increasingly integrated into mobile devices to offer security advantages over traditional practices (e.g., passwords and PINs) due to their ease of use in user authentication. However, existing biometric systems are with controversy: once divulged, they are compromised forever - no one can grow a new fingerprint or iris. This work explores a truly cancelable brain-based biometric system for mobile platforms (e.g., smart headwear). Specifically, we present a new psychophysiological protocol via non-volitional brain response for trustworthy mobile authentication, with an application example of smart headwear. Particularly, we address the following research challenges in mobile biometrics with a theoretical and empirical combined manner: (1) how to generate reliable brain responses with sophisticated visual stimuli; (2) how to acquire the distinct brain response and analyze unique features in the mobile platform; (3) how to reset and change brain biometrics when the current biometric credential is divulged. To evaluate the proposed solution, we conducted a pilot study and achieved an f -score accuracy of 95.46\% and equal error rate (EER) of 2.503\%, thereby demonstrating the potential feasibility of neurofeedback based biometrics for smart headwear. Furthermore, we perform the cancelability study and the longitudinal study, respectively, to show the effectiveness and usability of our new proposed mobile biometric system. To the best of our knowledge, it is the first in-depth research study on truly cancelable brain biometrics for secure mobile authentication.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {296–309},
numpages = {14},
keywords = {Wearable computing, cancelable biometrics, event-related potential, mobile authentication},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210326,
author = {Corner, Mark D. and Levine, Brian N.},
title = {MicroMobile: Leveraging Mobile Advertising for Large-Scale Experimentation},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210326},
doi = {10.1145/3210240.3210326},
abstract = {Mobile systems researchers struggle with conducting experiments with real users: either the scale of the study lacks sufficient scale and diversity, or a great effort must be used to recruit and manage subjects. In this paper, we describe MicroMobile, a system for deploying short data-gathering experiments to an extremely diverse set of users via mobile advertising. We conduct experiments in three mediums: interactive advertisements, mobile browsers, and native applications on both major mobile operating systems.We use MicroMobile to demonstrate how researchers can use mobile advertising to recruit users, for as little as $1.50 per completed experiment. Across almost 500 completed experiments, we found that interactive ads have the highest participation rate (and thus lowest cost), which was 2x the participation rate of browser experiments and more than 6x native app experiments. Users were also highly diverse, spanning age, income, and ethnicity. While native apps are the most powerful platform, they constitute the most expensive targets. However, as mobile browsers add sensor APIs, browser-based experimentation has increasing applicability.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {310–322},
numpages = {13},
keywords = {Mobile advertising, Mobile measurement},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210342,
author = {Liu, Xiaochen and Jiang, Yurong and Jain, Puneet and Kim, Kyu-Han},
title = {TAR: Enabling Fine-Grained Targeted Advertising in Retail Stores},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210342},
doi = {10.1145/3210240.3210342},
abstract = {Mobile advertisements influence customers' in-store purchases and boost in-store sales for brick-and-mortar retailers. Targeting mobile ads has become significantly important to compete with online shopping. The key to enabling targeted mobile advertisement and service is to learn shoppers' interest during their stay in the store. Precise shopper tracking and identification are essential to gain the insights. However, existing sensor-based or vision-based solutions are neither practical nor accurate; no commercial solutions today can be readily deployed in a large store. On the other hand, we recognize that most retail stores have the installation of surveillance cameras, and most shoppers carry Bluetooth-enabled smartphones. Thus, in this paper, we propose TAR to learn shoppers' in-store interest via accurate multi-camera people tracking and identification. TAR leverages widespread camera deployment and Bluetooth proximity information to accurately track and identify shoppers in the store. TAR is composed of four novel design components: (1) a deep neural network (DNN) based visual tracking, (2) a user trajectory estimation by using shopper visual and BLE proximity trace, (3) an identity matching and assignment to recognize shopper's identity, and (4) a cross-camera calibration algorithm. TAR carefully combines these components to track and identify shoppers in real-time. TAR achieves 90\% accuracy in two different real-life deployments, which is 20\% better than the state-of-the-art solution.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {323–336},
numpages = {14},
keywords = {Bluetooth, Computer Vision, Edge Computing, Mobile Sensing, Shopping, Tracking},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210320,
author = {Wu, Fang-Jing and Solmaz, G\"{u}rkan},
title = {CrowdEstimator: Approximating Crowd Sizes with Multi-modal Data for Internet-of-Things Services},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210320},
doi = {10.1145/3210240.3210320},
abstract = {Crowd mobility has been paid attention for the Internet-of-things (IoT) applications. This paper addresses the crowd estimation problem and builds an IoT service to share the crowd estimation results across different systems. The crowd estimation problem is to approximate the crowd size in a targeted area using the observed information (e.g., Wi-Fi data). This paper exploits Wi-Fi probe request packets ("Wi-Fi probes" for short) broadcasted by mobile devices to solve this problem. However, using only Wi-Fi probes to estimate the crowd size may result in inaccurate results due to various environmental uncertainties which may lead to crowd overestimation or underestimation. Moreover, the ground-truth is unavailable because the coverage of Wi-Fi signals is time-varying and invisible. This paper introduces auxiliary sensors, stereoscopic cameras, to collect the near ground-truth at a specified calibration choke point. Two calibration algorithms are proposed to solve the crowd estimation problem. The key idea is to calibrate the Wi-Fi-only crowd estimation based on the correlations between the two types of data modalities. Then, to share the calibrated results across systems required by different stakeholders, our system is integrated with the FIWARE-based IoT platform. To verify the proposed system, we have launched an indoor pilot study in the Wellington Railway Station and an outdoor pilot study in the Christchurch Re:START Mall in New Zealand. The large-scale pilot studies show that stereoscopic cameras can reach minimum accuracy of 85\% and high precision detection for providing the near ground-truth. The proposed calibration algorithms reduce estimation errors by 43.68\% on average compared to the Wi-Fi-only approach.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {337–349},
numpages = {13},
keywords = {cyber-physical systems, human mobility, smart cities},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210314,
author = {Qian, Kun and Wu, Chenshu and Zhang, Yi and Zhang, Guidong and Yang, Zheng and Liu, Yunhao},
title = {Widar2.0: Passive Human Tracking with a Single Wi-Fi Link},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210314},
doi = {10.1145/3210240.3210314},
abstract = {This paper presents Widar2.0, the first WiFi-based system that enables passive human localization and tracking using a single link on commodity off-the-shelf devices. Previous works based on either specialized or commercial hardware all require multiple links, preventing their wide adoption in scenarios like homes where typically only one single AP is installed. The key insight underlying Widar2.0 to circumvent the use of multiple links is to leverage multi-dimensional signal parameters from one single link. To this end, we build a unified model accounting for Angle-of-Arrival, Time-of-Flight, and Doppler shifts together and devise an efficient algorithm for their joint estimation. We then design a pipeline to translate the erroneous raw parameters into precise locations, which first finds parameters corresponding to the reflections of interests, then refines range estimates, and ultimately outputs target locations. Our implementation and evaluation on commodity WiFi devices demonstrate that Widar2.0 achieves better or comparable performance to state-of-the-art localization systems, which either use specialized hardwares or require 2 to 40 Wi-Fi links.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {350–361},
numpages = {12},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210340,
author = {Tian, Zhao and Wei, Yu-Lin and Chang, Wei-Nin and Xiong, Xi and Zheng, Changxi and Tsai, Hsin-Mu and Lin, Kate Ching-Ju and Zhou, Xia},
title = {Augmenting Indoor Inertial Tracking with Polarized Light},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210340},
doi = {10.1145/3210240.3210340},
abstract = {Inertial measurement unit (IMU) has long suffered from the problem of integration drift, where sensor noises accumulate quickly and cause fast-growing tracking errors. Existing methods for calibrating IMU tracking either require human in the loop, or need energy-consuming cameras, or suffer from coarse tracking granularity. We propose to augment indoor inertial tracking by reusing existing indoor luminaries to project a static light polarization pattern in the space. This pattern is imperceptible to human eyes and yet through a polarizer, it becomes detectable by a color sensor, and thus can serve as fine-grained optical landmarks that constrain and correct IMU's integration drift and boost tracking accuracy. Exploiting the birefringence optical property of transparent tapes -- a low-cost and easily-accessible material -- we realize the polarization pattern by simply adding to existing light cover a thin polarizer film with transparent tape stripes glued atop. When fusing with IMU sensor signals, the light pattern enables robust, accurate and low-power motion tracking. Meanwhile, our approach entails low deployment overhead by reusing existing lighting infrastructure without needing an active modulation unit. We build a prototype of our light cover and the sensing unit using off-the-shelf components. Experiments show 4.3 cm median error for 2D tracking and 10 cm for 3D tracking, as well as its robustness in diverse settings.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {362–375},
numpages = {14},
keywords = {Inertial tracking, light polarization, particle filter},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210347,
author = {Soltanaghaei, Elahe and Kalyanaraman, Avinash and Whitehouse, Kamin},
title = {Multipath Triangulation: Decimeter-level WiFi Localization and Orientation with a Single Unaided Receiver},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210347},
doi = {10.1145/3210240.3210347},
abstract = {Decimeter-level localization has become a reality, in part due to the ability to eliminate the effects of multipath interference. In this paper, we demonstrate the ability to use multipath reflections to enhance localization rather than throwing them away. We present Multipath Triangulation, a new localization technique that uses multipath reflections to localize a target device with a single receiver that does not require any form of coordination with any other devices. In this paper, we leverage multipath triangulation to build the first decimeter-level WiFi localization system, called MonoLoco, that requires only a single access point (AP) and a single channel, and does not impose any overhead, data sharing, or coordination protocols beyond standard WiFi communication. As a bonus, it also determines the orientation of the target relative to the AP. We implemented MonoLoco using Intel 5300 commodity WiFi cards and deploy it in four environments with different multipath propagation. Results indicate median localization error of 0.5m and median orientation error of 6.6 degrees, which are comparable to the best performing prior systems, all of which require multiple APs and/or multiple frequency channels. High accuracy can be achieved with only a handful of packets.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {376–388},
numpages = {13},
keywords = {CSI, Channel State Information, WiFi, localization, multipath propagation, multipath triangulation},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210337,
author = {Liu, Sicong and Lin, Yingyan and Zhou, Zimu and Nan, Kaiming and Liu, Hui and Du, Junzhao},
title = {On-Demand Deep Model Compression for Mobile Devices: A Usage-Driven Model Selection Framework},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210337},
doi = {10.1145/3210240.3210337},
abstract = {Recent research has demonstrated the potential of deploying deep neural networks (DNNs) on resource-constrained mobile platforms by trimming down the network complexity using different compression techniques. The current practice only investigate stand-alone compression schemes even though each compression technique may be well suited only for certain types of DNN layers. Also, these compression techniques are optimized merely for the inference accuracy of DNNs, without explicitly considering other application-driven system performance (e.g. latency and energy cost) and the varying resource availabilities across platforms (e.g. storage and processing capability). In this paper, we explore the desirable tradeoff between performance and resource constraints by user-specified needs, from a holistic system-level viewpoint. Specifically, we develop a usage-driven selection framework, referred to as AdaDeep, to automatically select a combination of compression techniques for a given DNN, that will lead to an optimal balance between user-specified performance goals and resource constraints. With an extensive evaluation on five public datasets and across twelve mobile devices, experimental results show that AdaDeep enables up to 9.8x latency reduction, 4.3x energy efficiency improvement, and 38x storage reduction in DNNs while incurring negligible accuracy loss. AdaDeep also uncovers multiple effective combinations of compression techniques unexplored in existing literature.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {389–400},
numpages = {12},
keywords = {deep learning, deep reinforcement learning, model compression},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210335,
author = {Venkatnarayan, Raghav H. and Page, Griffin and Shahzad, Muhammad},
title = {Multi-User Gesture Recognition Using WiFi},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210335},
doi = {10.1145/3210240.3210335},
abstract = {WiFi based gesture recognition has received significant attention over the past few years. However, the key limitation of prior WiFi based gesture recognition systems is that they cannot recognize the gestures of multiple users performing them simultaneously. In this paper, we address this limitation and propose WiMU, a WiFi based Multi-User gesture recognition system. The key idea behind WiMU is that when it detects that some users have performed some gestures simultaneously, it first automatically determines the number of simultaneously performed gestures (Na) and then, using the training samples collected from a single user, generates virtual samples for various plausible combinations of Na gestures. The key property of these virtual samples is that the virtual samples for any given combination of gestures are identical to the real samples that would result from real users performing that combination of gestures. WiMU compares the detected sample against these virtual samples and recognizes the simultaneously performed gestures. We implemented and extensively evaluated WiMU using commodity WiFi devices. Our results show that WiMU recognizes 2, 3, 4, 5, and 6 simultaneously performed gestures with accuracies of 95.0, 94.6, 93.6, 92.6, and 90.9\%, respectively.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {401–413},
numpages = {13},
keywords = {Gesture recognition, Multi-user, WiFi},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210336,
author = {Ryoo, Jihoon and Karimi, Yasha and Athalye, Akshay and Stana\'{c}evi\'{c}, Milutin and Das, Samir R. and Djuri\'{c}, Petar},
title = {BARNET: Towards Activity Recognition Using Passive Backscattering Tag-to-Tag Network},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210336},
doi = {10.1145/3210240.3210336},
abstract = {We present the vision of BARNET (Backscattering Activity Recognition NEtwork of Tags), a network of passive RF tags that use RF backscatter for tag-to-tag communication. BARNET not only provides identification of tagged objects but also can serve as a 'device-free' activity recognition system. BARNET's key innovation is the concept of backscatter channel state information (BCSI) which can be measured via systematic multiphase probing of the backscatter tag-to-tag channel using innovative processing on the passive tags. So far such measurements were only possible using active radio receivers that consume much higher power. Changes in BCSI provide signatures for different activities in the environment that can be learned using suitable machine learning tools. We develop the BARNET tag architecture which shows that an ASIC implementation can run on harvested RF power. We develop a printed circuit board (PCB) prototype using discrete components to evaluate activity recognition performance. We show that the prototype can recognize human daily activities with an average error around 6\%. Overall, BARNET uses passive tags to achieve the same level of performance as systems that use powered, active radios.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {414–427},
numpages = {14},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210328,
author = {Jin, Haojian and Wang, Jingxian and Yang, Zhijian and Kumar, Swarun and Hong, Jason},
title = {WiSh: Towards a Wireless Shape-aware World using Passive RFIDs},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210328},
doi = {10.1145/3210240.3210328},
abstract = {This paper presents WiSh, a solution that makes ordinary surfaces shape-aware, relaying their real-time geometry directly to a user's handheld device. WiSh achieves this using inexpensive, light-weight and battery-free RFID tags attached to these surfaces tracked from a compact single-antenna RFID reader. In doing so, WiSh enables several novel applications: shape-aware clothing that can detect a user's posture, interactive shape-aware toys or even shape-aware bridges that report their structural health.WiSh's core algorithm infers the shape of ordinary surfaces using the wireless channels of signals reflected off RFID tags received at a single-antenna RFID reader. Indeed, locating every RFID tag using a single channel measurement per-tag is challenging, given that neither their 3-D coordinates nor orientation are known a priori. WiSh presents a novel algorithm that models the geometric constraints between the coordinates of the RFID tags based on flexibility of the surface upon which they are mounted. By inferring surface curvature parameters rather than the locations of individual RFID tags, we greatly reduce the number of variables our system needs to compute. Further, WiSh overcomes a variety of system-level challenges stemming from signal multipath, stretching of fabric and modeling large surfaces. We implement WiSh on commodity RFID readers and tags attached to a variety of surfaces and demonstrate mm-accurate shape-tracking across various applications.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {428–441},
numpages = {14},
keywords = {RFID sensing, shape-aware, smart fabric, smart material},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210345,
author = {Dhekne, Ashutosh and Gowda, Mahanth and Zhao, Yixuan and Hassanieh, Haitham and Choudhury, Romit Roy},
title = {LiquID: A Wireless Liquid IDentifier},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210345},
doi = {10.1145/3210240.3210345},
abstract = {This paper shows the feasibility of identifying liquids by shining ultra-wideband (UWB) wireless signals through them. The core opportunity arises from the fact that wireless signals experience distinct slow-down and attenuation when passing through a liquid, manifesting in the phase, strength, and propagation delay of the outgoing signal. While this intuition is simple, building a robust system entails numerous challenges, including (1) pico-second scale time of flight estimation, (2) coping with integer ambiguity due to phase wraps, (3) pollution from hardware noise and multipath, and (4) compensating for the liquid-container's impact on the measurements. We address these challenges through multiple stages of signal processing without relying on any feature extraction or machine learning. Instead, we model the behavior of radio signals inside liquids (using principles of physics), and estimate the liquid's permittivity, which in turn identifies the liquid. Experiments across 33 different liquids (spread over the whole permittivity spectrum) show median permittivity error of 9\%. This implies that coke can be discriminated from diet coke or pepsi, whole milk from 2\% milk, and distilled water from saline water. Our end system, LiquID, is cheap, non-invasive, and amenable to real-world applications.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {442–454},
numpages = {13},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210312,
author = {Tung, Yu-Chih and Bui, Duc and Shin, Kang G.},
title = {Cross-Platform Support for Rapid Development of Mobile Acoustic Sensing Applications},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210312},
doi = {10.1145/3210240.3210312},
abstract = {LibAS is a cross-platform framework to facilitate the rapid development of mobile acoustic sensing apps. It helps developers quickly realize their ideas by using a high-level Matlab script, and test them on various OS platforms, such as Android, iOS, Tizen, and Linux/Win. LibAS simplifies the development of acoustic sensing apps by hiding the platform-dependent details. For example, developers need not learn Objective-C/SWIFT or the audio buffer management in the CoreAudio framework when they want to implement acoustic sensing algorithms on an iPhone. Instead, developers only need to decide on the sensing signals and the callback function to handle each repetition of sensing signals. We have implemented apps covering three major acoustic sensing categories to demonstrate the benefits and simplicity of developing apps with LibAS. Our evaluation results show the adaptability of LibAS in supporting various acoustic sensing apps and tuning/improving their performance efficiently. Developers have reported that LibAS saves them a significant amount of time/effort and can reduce up to 90\% lines of code in their acoustic sensing apps.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {455–467},
numpages = {13},
keywords = {Acoustic sensing, cross-platform development, rapid prototype},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210325,
author = {Mao, Wenguang and Wang, Mei and Qiu, Lili},
title = {AIM: Acoustic Imaging on a Mobile},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210325},
doi = {10.1145/3210240.3210325},
abstract = {The popularity of smartphones has grown at an unprecedented rate, which makes smartphone based imaging especially appealing. In this paper, we develop a novel acoustic imaging system using only an off-the-shelf smartphone. It is an attractive alternative to camera based imaging under darkness and obstruction. Our system is based on Synthetic Aperture Radar (SAR). To image an object, a user moves a phone along a predefined trajectory to mimic a virtual sensor array. SAR based imaging poses several new challenges in our context, including strong self and background interference, deviation from the desired trajectory due to hand jitters, and severe speaker/microphone distortion. We address these challenges by developing a 2-stage interference cancellation scheme, a new algorithm to compensate trajectory errors, and an effective method to minimize the impact of signal distortion. We implement a proof-of-concept system on Samsung S7. Our results demonstrate the feasibility and effectiveness of acoustic imaging on a mobile.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {468–481},
numpages = {14},
keywords = {Acoustic imaging, SAR, autofocus, interference cancellation},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210323,
author = {He, Jian and Qureshi, Mubashir Adnan and Qiu, Lili and Li, Jin and Li, Feng and Han, Lei},
title = {Rubiks: Practical 360-Degree Streaming for Smartphones},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210323},
doi = {10.1145/3210240.3210323},
abstract = {The popularity of 360° videos has grown rapidly due to the immersive user experience. 360° videos are displayed as a panorama and the view automatically adapts with the head movement. Existing systems stream 360° videos in a similar way as regular videos, where all data of the panoramic view is transmitted. This is wasteful since a user only views a small portion of the 360° view. To save bandwidth, recent works propose the tile-based streaming, which divides the panoramic view to multiple smaller sized tiles and streams only the tiles within a user's field of view (FoV) predicted based on the recent head position. Interestingly, the tile-based streaming has only been simulated or implemented on desktops. We find that it cannot run in real-time even on the latest smartphone (e.g., Samsung S7, Samsung S8 and Huawei Mate 9) due to hardware and software limitations. Moreover, it results in significant video quality degradation due to head movement prediction error, which is hard to avoid. Motivated by these observations, we develop a novel tile-based layered approach to stream 360° content on smartphones to avoid bandwidth wastage while maintaining high video quality. Through real system experiments, we show our approach can achieve up to 69\% improvement in user QoE and 49\% in bandwidth savings over existing approaches. To the best of our knowledge, this is the first 360° streaming framework that takes into account the practical limitations of Android based smartphones.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {482–494},
numpages = {13},
keywords = {360° Videos, Rate Adaptation, Smartphones, Video Codecs},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3223572,
author = {Feeney, Laura Marie and Gunningberg, Per},
title = {Avoiding an IoT 'Tragedy of the Commons'},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3223572},
doi = {10.1145/3210240.3223572},
abstract = {The large number and wide diversity of IoT networks operating in unlicensed spectrum will create a complex and challenging interference environment. To avoid a 'tragedy of the commons', networks may need to more explicitly coordinate their use of the shared channel.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {495–497},
numpages = {3},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3223573,
author = {Krishnamachari, Bhaskar and Power, Jerry and Kim, Seon Ho and Shahabi, Cyrus},
title = {I3: An IoT Marketplace for Smart Communities},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3223573},
doi = {10.1145/3210240.3223573},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {498–499},
numpages = {2},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3223574,
author = {Nirjon, Shahriar},
title = {Lifelong Learning on Harvested Energy},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3223574},
doi = {10.1145/3210240.3223574},
abstract = {We introduce the vision of lifelong and intermittent learning, which will enable batteryless computing platforms to execute a certain class of machine learning tasks. We identify key properties and challenges to learning on harvested energy which relates to the semantics of machine learning tasks. Each of these challenges leads to a new research direction. We envision that a big chunk of research on batteryless IoT devices in the next 5-10 years will be about making them capable of continuously learning throughout their lifetime. Concepts related to intermittent learning will be at the heart of those works.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {500–501},
numpages = {2},
keywords = {energy harvester, intermittent learning, lifelong learning},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3223570,
author = {Zhao, Jianxin and Tiplea, Tudor and Mortier, Richard and Crowcroft, Jon and Wang, Liang},
title = {Data Analytics Service Composition and Deployment on IoT Devices},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3223570},
doi = {10.1145/3210240.3223570},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {502–504},
numpages = {3},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3226062,
author = {Psaras, Ioannis},
title = {Decentralised Edge-Computing and IoT through Distributed Trust},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3226062},
doi = {10.1145/3210240.3226062},
abstract = {The emerging Internet of Things needs edge-computing - this is an established fact. In turn, edge computing needs infrastructure decentralisation. What is not necessarily established yet is that infrastructure decentralisation needs a distributed model of Internet governance and decentralised trust schemes. We discuss the features of a decentralised IoT and edge-computing ecosystem and list the components that need to be designed, as well the challenges that need to be addressed.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {505–507},
numpages = {3},
keywords = {Blockchain, Distributed Trust, Edge-Computing, Programmable Privacy},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3223569,
author = {von Maltitz, Marcel and Carle, Georg},
title = {Leveraging Secure Multiparty Computation in the Internet of Things},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3223569},
doi = {10.1145/3210240.3223569},
abstract = {Centralized systems in the Internet of Things---be it local middleware or cloud-based services---fail to fundamentally address privacy of the collected data. We propose an architecture featuring secure multiparty computation at its core in order to realize data processing systems which already incorporate support for privacy protection in the architecture.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {508–510},
numpages = {3},
keywords = {Internet of Things, Secure Multiparty Computation, Sensor Data, Smart Environments},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210803,
author = {Feng, Wendi and Liu, Chuanchang and Ren, Bingfei and Cheng, Bo and Chen, Junliang},
title = {TrustGyges: A Hidden Volume Solution with Cloud Safe Storage and TEE},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210803},
doi = {10.1145/3210240.3210803},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {511},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210804,
author = {Walelgne, Ermias A. and Asrese, Alemnew S. and Bajpai, Vaibhav and Ott, J\"{o}rg and Manner, Jukka},
title = {Using Crowdsourcing Data for Adaptive Video Streaming in Cellular Network},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210804},
doi = {10.1145/3210240.3210804},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {512},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210805,
author = {Kietzmann, Peter and G\"{u}ndo\u{g}an, Cenk and Schmidt, Thomas C. and W\"{a}hlisch, Matthias},
title = {A PUF Seed Generator for RIOT: Introducing Crypto-Fundamentals to the Wild},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210805},
doi = {10.1145/3210240.3210805},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {513},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210806,
author = {Wang, Qing and Xu, Chenren and Leng, Supeng and Pollin, Sofie},
title = {When Autonomous Drones Meet Driverless Cars},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210806},
doi = {10.1145/3210240.3210806},
abstract = {In this poster, we envision the promising cooperation between autonomous drones and driverless cars. We discuss potential applications and opportunities enabled by this cooperation.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {514},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210808,
author = {Ni, Yunzhe and Xu, Chenren},
title = {A Multipath Transport Multihoming Mobile Relay Architecture for High-speed Rails Networking},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210808},
doi = {10.1145/3210240.3210808},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {515},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210809,
author = {Tavares, Miguel and Aponte, Omar and Mendes, Paulo},
title = {Named-data Emergency Network Services},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210809},
doi = {10.1145/3210240.3210809},
abstract = {This poster explains how to deploy emergency services leveraging Named-Data Networking with push communications and the capability of operating on intermittent wireless networks.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {516},
numpages = {1},
keywords = {Named-Data Networking, Opportunistic Networking},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210810,
author = {Min, Chulhong and Mathur, Akhil and Kawsar, Fahim},
title = {Audio-Kinetic Model for Automatic Dietary Monitoring with Earable Devices},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210810},
doi = {10.1145/3210240.3210810},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {517},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210811,
author = {Yang, Jing and S\"{o}r\"{o}s, G\'{a}bor},
title = {Spatial Audio for Human-Object Interactions in Small AR Workspaces},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210811},
doi = {10.1145/3210240.3210811},
abstract = {While spatial audio has been an essential component in Virtual Reality, it has been rarely applied to Augmented Reality. We propose a concept and a prototype to enhance human-object interactions in daily life with 3D audio. We augment real objects in a small workspace around the user with spatial audio notifications.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {518},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210813,
author = {Mortazavi, Seyed Hossein and Balasubramanian, Bharath and de Lara, Eyal and Narayanan, Shankaranarayanan Puzhavakath},
title = {Pathstore, A Data Storage Layer For The Edge},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210813},
doi = {10.1145/3210240.3210813},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {519},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210814,
author = {Forlivesi, Claudio and van den Broeck, Marc and Acer, Utku G\"{u}nay and Kawsar, Fahim},
title = {On-Wearable AI to Model Human Interruptibility},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210814},
doi = {10.1145/3210240.3210814},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {520},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210815,
author = {Fotouhi, Mohammadbagher and Niu, Ruixin and Cheng, Wei},
title = {An Accurate Smartphone Ranging System},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210815},
doi = {10.1145/3210240.3210815},
abstract = {In this poster, an accurate distance ranging system for off-the-shelf smartphones is introduced. Two ranging methods, namely improved Microsoft Beep-Beep and our Single-Beep, are developed and evaluated on 6 different Android phones.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {521},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210816,
author = {Yang, Zhuolin and Li, Zhengxiong and Zhuang, Yan and Xu, Wenyao},
title = {Exploring an Inclusive User Interface through Respiration},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210816},
doi = {10.1145/3210240.3210816},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {522},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210817,
author = {Liaqat, Daniyal and Wu, Robert and Gershon, Andrea and Alshaer, Hisham and Rudzicz, Frank and de Lara, Eyal},
title = {Speech in Smartwatch based Audio},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210817},
doi = {10.1145/3210240.3210817},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {523},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210818,
author = {Kim, Beomjun and Seo, Juhee and Lim, Jaebong and Baek, Yunju},
title = {Design and Implementation of Driving Information Collection System for Driver Behavior Analysis},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210818},
doi = {10.1145/3210240.3210818},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {524},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210819,
author = {Kwon, HyukSang and Ko, JeongGil},
title = {LightCert: Designing Smaller Certificates for the Internet of Things Devices},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210819},
doi = {10.1145/3210240.3210819},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {525},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210824,
author = {Collister, Keith and Yoneki, Eiko},
title = {RaDiCS: Distributed Computing Service over Raspberry Pis with Unikernels},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210824},
doi = {10.1145/3210240.3210824},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {526},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210820,
author = {Choi, Jaewon and Park, Hyeonjung and Paek, Jeongyeup and Ko, JeongGil},
title = {Reactive Mesh Simplification for Augmented Reality Head Mounted Displays},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210820},
doi = {10.1145/3210240.3210820},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {527},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210821,
author = {Alizadeh, Milad and Lane, Nicholas D.},
title = {Using Pre-trained Full-Precision Models to Speed Up Training Binary Networks For Mobile Devices},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210821},
doi = {10.1145/3210240.3210821},
abstract = {Binary Neural Networks (BNNs) are well-suited for deploying Deep Neural Networks (DNNs) to small embedded devices but state-of-the-art BNNs need to be trained from scratch for a long time. We show how weights from a pre-trained full-precision model can be used to speed-up training of binary networks. We show that for CIFAR-10, accuracies within 1\% of the full-precision model can be achieved in just 5 epochs.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {528},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210822,
author = {Fern\'{a}ndez-Marqu\'{e}s, Javier and Tseng, Vincent W.-S. and Bhattachara, Sourav and Lane, Nicholas D.},
title = {Deterministic binary filters for keyword spotting applications},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210822},
doi = {10.1145/3210240.3210822},
abstract = {We present a binary architecture with 60\% fewer parameters and 50\% fewer operations during inference compared to the current state of the art for keyword spotting (KWS) applications at the cost of 3.4\% accuracy. We construct convolutional filters on-the-fly using orthogonal binary codes and results in a compact architecture that would fit in devices with less than 30kB of memory.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {529},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3210823,
author = {Tong, Catherine and Harari, Gabriella M. and Chieh, Angela and Bellahsen, Otmane and Vegreville, Matthieu and Roitmann, Eva and Lane, Nicholas D.},
title = {Inference of Big-Five Personality Using Large-scale Networked Mobile and Appliance Data},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3210823},
doi = {10.1145/3210240.3210823},
abstract = {We present the first large-scale (9270-user) study of data from both mobile and networked appliances for Big-Five personality inference. We correlate aggregated behavioral and physical health features with personalities, and perform binary classification using SVM and Decision Tree. We find that it is possible to infer each Big-Five personality at accuracies of 75\% from this dataset despite its size and complexity (mix of mobile and appliance) as prior methods offer similar accuracy levels. We would like to achieve better accuracies and this study is a first step towards seeing how to model such data.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {530},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211119,
author = {Haus, Michael and Ding, Aaron Yi and Xu, Chenren and Ott, J\"{o}rg},
title = {Touchless Wireless Authentication via LocalVLC},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211119},
doi = {10.1145/3210240.3211119},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {531},
numpages = {1},
keywords = {Distance-bounding services, Visible light communication},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211106,
author = {Mahajan, Sachit and Tang, Yu-Siou and Wu, Dong-Yi and Tsai, Tzu-Chieh and Chen, Ling-Jyh},
title = {CAR: The Cleanest Air Routing Algorithm for Path Navigation with Minimal PM2.5 Exposure on the Move},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211106},
doi = {10.1145/3210240.3211106},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {532},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211107,
author = {Yang, Qiang and Fu, Hongrui and Zou, Yongpan and Wu, Kaishun},
title = {A Novel Finger-Assisted Touch-free Text Input System Without Training},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211107},
doi = {10.1145/3210240.3211107},
abstract = {Recently, tiny smart devices have become increasingly popular in our lives because of their neat features and stylish appearance. However, their small form factors, especially screens, make it inconvenient for users to enter texts with conventional methods such as soft keyboards, which need a fairly large screen. To address this problem, we propose a novel texts-input system, called EchoType, with which users can enter texts with a finger writing in the air. EchoType makes use of acoustic sensors (i.e., microphone and speaker) to sense finger gestures and infer texts based on mapping relation between gestures and basic letters. We take a step to enable users to input texts with acoustic signals. Compared with existing approaches, EchoType enjoys merits of low hardware requirements and high scalability to different mobile devices.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {533},
numpages = {1},
keywords = {Acoustic signals, Finger gestures, Texts input},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211108,
author = {Kim, Wonjung and Choo, Kenny Tsu Wei and Lee, Youngki and Misra, Archan and Balan, Rajesh Krishna},
title = {Empath-D: VR-based Empathetic App Design for Accessibility},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211108},
doi = {10.1145/3210240.3211108},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {534},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211120,
author = {Solmaz, G\"{u}rkan and Wu, Fang-Jing},
title = {VolksFlow: Crowd Mobility Analytics with Multi-modal Data for Internet-of-Things Services},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211120},
doi = {10.1145/3210240.3211120},
abstract = {VolksFlow is a real-time crowd mobility analytics system deployed in two pilot sites in New Zealand. In this demo we showcase real-time data analytics results from Wellington Railway Station. VolksFlow addresses the crowd estimation problem in a target area and provides an internet-of-things (IoT) service to share crowd estimation results across different applications. VolksFlow consists of three data analytics modules for analyzing crowd size, stay duration, and people flow. Our research for crowd estimation is based on correlating the Wi-Fi probes data with stereoscopic cameras to count people at specified "choke points".},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {535},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211109,
author = {Hessar, Mehrdad and Naderiparizi, Saman and Wang, Ye and Saffari, Ali and Gollakota, Shyamnath and Smith, Joshua R.},
title = {Wireless Video Streaming for Ultra-low-power Cameras},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211109},
doi = {10.1145/3210240.3211109},
abstract = {Wireless video streaming has traditionally been considered an extremely power-hungry operation. Existing approaches optimize the camera and communication modules individually to minimize their power consumption. However, designing a video streaming device requires power-consuming hardware components and video CODEC algorithms which makes battery-free video streaming currently infeasible. Existing RF-powered wireless camera prototypes require extensive duty-cycling on the order of tens of minutes, to capture, process and communicate a single frame. Self-powered cameras can capture an image once every few seconds, but do not have the capability to stream video wirelessly.To understand this case, let us look at the different components in a video-streaming device 1(a): optical lens, video compression and communication. Optical lens is an array of photo-diodes connected to amplifiers and an ADC to translate the analog pixels into digital values. A video CODEC then performs frame compression to compress video, which is then transmitted on the wireless medium. Existing approaches optimize the camera and communication modules separately to minimize their power consumption. However, designing a video streaming device requires power consuming hardware components and video CODEC algorithms that interface the camera and the communication modules.We present the design of an ultra-low-power video streaming device 1(b). We create "analog" video backscatter system that does not use amplifiers, ADCs and AGCs. At a high level, we feed analog pixels from the photo-diodes directly to the backscatter hardware. We achieve this by connecting the antenna to an array of photo-diodes whose output voltage/impedance varies as a function of the pixel value; thus, eliminate power-hungry hardware components including amplifiers, AGCs and ADCs. Such an approach would have the added benefit that the video quality scales smoothly with a varying wireless channel, without the need for explicit rate adaptation. We present our video streaming architecture with more details in [1, 2].We implement a prototype of our backscatter design on an ultra-low power FPGA platform using a 112 \texttimes{} 112 gray-scale random pixel access camera from CentEye, which provides readout access to the individual analog pixels. The prototype of our video streaming device burns as low as 2.36 mW while streaming live video at 13 fps. Our access point (AP) consist of two components. We use RTL2832U SDR to receive backsactter signal from the tag and Semtech SX1232 and SE2435L-EK5 power amplifier to generate helper signal. We demonstrate real-time display of video frames using Python scripts which interfaces with the SDR. We evaluate our prototype under different conditions to study its performance under different room lighting conditions and different distances from the access point. We can stream at 7-13 frames per second at distances of up to 27 feet from the AP. We show a video of our real-time demonstration in following link.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {536},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211121,
author = {Cozzolino, Vittorio and Ding, Aaron Yi and Sani, Ardalan Amiri and Mortier, Richard and Kutscher, Dirk and Ott, J\"{o}rg},
title = {Empowering Cyber-Physical Systems with FADEX},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211121},
doi = {10.1145/3210240.3211121},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {537},
numpages = {1},
keywords = {Edge computing, Image processing, Virtualization},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211110,
author = {Gaw\l{}owicz, Piotr and Zubow, Anatolij and Bayhan, Suzan},
title = {Cross-Technology Interference Nulling for Improved LTE-U/WiFi Coexistence},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211110},
doi = {10.1145/3210240.3211110},
abstract = {Smart antennas can unlock the potential of unlicensed spectrum by letting the coexisting networks transmit concurrently without harmful interference. This is possible by strategically allocating the antenna degrees-of-freedom for both beamforming toward the intended receiver and interference nulling toward the victim receiver(s). Our solution, named Xzero, achieves this goal for the particular case of LTE-unlicensed (LTE-U) and WiFi by overcoming the challenges of cross-technology interference nulling by a null search at the LTE-U BS with assistance from the WiFi network. Our demo shows a running prototype of Xzero implemented using USRP SDR platform running srsLTE and commodity WiFi hardware. We illustrate the change in the airtime of colocated WiFi and LTE-U networks upon activation of Xzero and fast reconfiguration of the null beam upon a change in WiFi node's location.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {538},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211111,
author = {Chandrashekhara, Sharath and Ki, Taeyeon and Dantu, Karthik and Ko, Steven Y.},
title = {System-E: Enhancing Privacy on Mobile Systems through Content-Based Classification and Storage},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211111},
doi = {10.1145/3210240.3211111},
abstract = {Mobile systems face privacy challenges including coarsegrained privacy control and the inability to distinguish private and public files. We propose System-E, a novel system which can enhance the user privacy on mobile systems (e.g., Android) by (1) enabling users to set finer grained permissions for apps accessing data, and (2) enabling automatic classification of data (e.g., photos) at the storage layer (e.g., by using deep learning) to prevent potentially sensitive data from being stored/accessed with open permissions.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {539},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211112,
author = {Qammaz, Ammar and Kosta, Sokol and Kyriazis, Nikolaos and Argyros, Antonis},
title = {Distributed Real-Time Generative 3D Hand Tracking using Edge GPGPU Acceleration},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211112},
doi = {10.1145/3210240.3211112},
abstract = {This work demonstrates a real-time 3D hand tracking application that runs via computation offloading. The proposed framework enables the application to run on low-end mobile devices such as laptops and tablets, despite the fact that they lack the sufficient hardware to perform the required computations locally. The network connection takes the place of a GPGPU accelerator and sharing resources with a larger workstation becomes the acceleration mechanism. The unique properties of a generative optimizer are examined and constitute a challenging use-case, since the requirement for real-time performance makes it very latency-sensitive.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {540},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211113,
author = {Kawsar, Fahim and Min, Chulhong and Mathur, Akhil and Van den Broeck, Marc and Acer, Utku G\"{u}nay and Forlivesi, Claudio},
title = {eSense: Earable Platform for Human Sensing},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211113},
doi = {10.1145/3210240.3211113},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {541},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211114,
author = {G\"{u}ndo\u{g}an, Cenk and Kietzmann, Peter and Schmidt, Thomas C. and Lenders, Martine and Petersen, Hauke and W\"{a}hlisch, Matthias and Frey, Michael and Shzu-Juraschek, Felix},
title = {Seamless Producer Mobility for the Industrial Information-Centric Internet},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211114},
doi = {10.1145/3210240.3211114},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {542},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211115,
author = {Xu, Xieyang and Shen, Yang and Chen, Guojun and Wu, Yue and Feng, Lilei and Wang, Qing and Xu, Chenren},
title = {Software-defined Visible Light Backscatter Network},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211115},
doi = {10.1145/3210240.3211115},
abstract = {We introduce PassiveVLN, a flexible, modular and software-defined platform for visible light backscatter networks. PassiveVLN incorporates a modular hardware design and a full-stack software implementation, enabling convenient and scalable deployment as well as rapid prototyping for testing new protocols and applications.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {543},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211116,
author = {Nikaein, Navid and Chang, Chia-Yu and Schmidt, Robert and Shariat, Shahab and Alexandris, Konstantinos and Vasilakos, Xenofon},
title = {Plug \& Play Network Application Chaining for Multi-Service Programmability in 5G RAN},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211116},
doi = {10.1145/3210240.3211116},
abstract = {RAN slicing is one of the key enabler to enable virtualization of a BS and its delivery as a service with different levels of network isolation and sharing so as to accommodate the needs of mobile network operators and verticals. In this demonstration, we show a prototype of a RAN slicing runtime system to enable flexible slice customization on the top of a disaggregated RAN infrastructure [1] with different levels of isolation and sharing in terms of resources and network functions, while retaining the quality of service (QoS) for different slice instances. Furthermore, a novel plug \& play network application chaining framework empowered by a network software development kit (SDK) is demonstrated to show how the multi-service programmability on per-slice basis can be achieved. Our demonstration is based on the OpenAirlnterface [3], Mosaic-5G FlexRAN [4] and LL-MEC [2] platforms. Finally, we highlight how the the proposed approach can be extended to an end-to-end network slicing scenario.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {544},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211117,
author = {Kang, Bumsoo and Hwang, Inseok and Lee, Jinho and Lee, Seungchul and Lee, Taegyeong and Chang, Youngjae and Lee, Min Kyung},
title = {HomeMeld: Co-present Robotic Avatar System for Illusion of Living Together},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211117},
doi = {10.1145/3210240.3211117},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {545},
numpages = {1},
location = {Munich, Germany},
series = {MobiSys '18}
}
@inproceedings{10.1145/3210240.3211118,
author = {Cao, Siyuan and Farrukh, Habiba and Wang, He},
title = {Video: Enabling Public Cameras to Talk to the Public},
year = {2018},
isbn = {9781450357203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3210240.3211118},
doi = {10.1145/3210240.3211118},
abstract = {This video presents a real-time end-to-end system which enables cameras to send personalized messages to people in a public area without knowing any addresses of their mobile phones. For facilitating this communication, we solve the problem of digitally associating people in the camera view with their smartphones without prior knowledge of the phones' IP/MAC addresses. The system doesn't need any dedicated devices and doesn't request people to wear digital tags. It utilizes users' motion patterns and leverages the diversity in motion features as the address for communication. The cameras broadcast a message to all the phones in the camera view using the target's motion features as the destination. Then a user's phone can locally compare the "motion address" of the packet against its own sensor data and will accept the packet if it's a "good" match. To protect the privacy of users' sensor data, we keep the users' personal sensing data on their phones instead of asking them to upload the data to server. Moreover, to prevent users' walking behavior from being revealed to public, we transform the raw motion features via principal component analysis (PCA) while maintaining their distinguishing power. On the whole, our system achieves 98\%, 95\%, 90\%, 90\%, 87\% matching correctness for 2, 4, 6, 8 and 10 users respectively.},
booktitle = {Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {546},
numpages = {1},
keywords = {Human addressing, camera, communication, motion features, principal component analysis},
location = {Munich, Germany},
series = {MobiSys '18}
}