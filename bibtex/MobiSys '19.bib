@inproceedings{10.1145/3340948,
author = {Lv, Qin (Christine)},
title = {Session details: Session 1: On the Horizon},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340948},
doi = {10.1145/3340948},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326077,
author = {Zhang, Chi and Kumar, Sidharth and Bharadia, Dinesh},
title = {Capttery: Scalable Battery-like Room-level Wireless Power},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326077},
doi = {10.1145/3307334.3326077},
abstract = {Internet-of-things (IoT) devices are becoming widely adopted, but they increasingly suffer from limited power, as power cords cannot reach the billions and batteries do not last forever. Existing systems address the issue with ultra-low-power designs and energy scavenging, which inevitably limit functionality. To unlock the full potential of ubiquitous computing and connectivity, our solution uses capacitive power transfer (CPT) to provide battery-like wireless power delivery, henceforth referred to as "Capttery". Capttery presents the first room-level (~5 m) CPT system, which delivers continuous milliwatt-level wireless power to multiple IoT devices concurrently. Unlike conventional one-to-one CPT systems that target kilowatt power in a controlled and potentially hazardous setup, Capttery is designed to be human-safe and invariant in a practical and dynamic environment. Our evaluation shows that Capttery can power end-to-end IoT applications across a typical room, where new receivers can be easily added in a plug-and-play manner.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {1–13},
numpages = {13},
keywords = {wireless power transfer (wpt), internet-of-things, energy harvesting, capacitive power transfer (cpt)},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326073,
author = {Xu, Chenhan and Li, Zhengxiong and Zhang, Hanbin and Rathore, Aditya Singh and Li, Huining and Song, Chen and Wang, Kun and Xu, Wenyao},
title = {WaveEar: Exploring a mmWave-based Noise-resistant Speech Sensing for Voice-User Interface},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326073},
doi = {10.1145/3307334.3326073},
abstract = {Voice-user interface (VUI) has become an integral component in modern personal devices (textite.g., smartphones, voice assistant) by fundamentally evolving the information sharing between the user and device. Acoustic sensing for VUI is designed to sense all acoustic objects; however, the existing VUI mechanism can only offer low-quality speech sensing. This is due to the audible and inaudible interference from complex ambient noise that limits the performance of VUI by causing denial-of-service (DoS) of user requests. Therefore, it is of paramount importance to enable noise-resistant speech sensing in VUI for executing critical tasks with superior efficiency and precision in robust environments. To this end, we investigate the feasibility of employing radio-frequency signals, such as millimeter wave (mmWave) for sensing the noise-resistant voice of an individual. We first perform an in-depth study behind the rationale of voice generation and resulting vocal vibrations. From the obtained insights, we presentWaveEar, an end-to-end noise-resistant speech sensing system.WaveEar comprises a low-cost mmWave probe to localize the position of the speaker among multiple people and direct the mmWave signals towards the near-throat region of the speaker for sensing his/her vocal vibrations. The received signal, containing the speech information, is fed to our novel deep neural network for recovering the voice through exhaustive extraction. Our experimental evaluation under real-world scenarios with 21 participants shows the effectiveness ofWaveEar to precisely infer the noise-resistant voice and enable a pervasive VUI in modern electronic devices.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {14–26},
numpages = {13},
keywords = {voice-user interface, speech recognition, neural network, mmwave},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326071,
author = {Cao, Qingqing and Weber, Noah and Balasubramanian, Niranjan and Balasubramanian, Aruna},
title = {DeQA: On-Device Question Answering},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326071},
doi = {10.1145/3307334.3326071},
abstract = {Today there is no effective support for device-wide question answering on mobile devices. State-of-the-art QA models are deep learning behemoths designed for the cloud which run extremely slow and require more memory than available on phones. We present DeQA, a suite of latency- and memory- optimizations that adapts existing QA systems to run completely locally on mobile phones. Specifically, we design two latency optimizations that (1) stops processing documents if further processing cannot improve answer quality, and (2) identifies computation that does not depend on the question and moves it offline. These optimizations do not depend on the QA model internals and can be applied to several existing QA models. DeQA also implements a set of memory optimizations by (i) loading partial indexes in memory, (ii) working with smaller units of data, and (iii) replacing in-memory lookups with a key-value database. We use DeQA to port three state-of-the-art QA systems to the mobile device and evaluate over three datasets. The first is a large scale SQuAD dataset defined over Wikipedia collection. We also create two on-device QA datasets, one over a publicly available email data collection and the other using a cross-app data collection we obtain from two users. Our evaluations show that DeQA can run QA models with only a few hundred MBs of memory and provides at least 13x speedup on average on the mobile phone across all three datasets.\% with less than a 1\% drop in accuracy.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {27–40},
numpages = {14},
keywords = {question answering, mobile systems, mobile devices},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326091,
author = {Meegahapola, Lakmal and Kandappu, Thivya and Jayarajah, Kasthuri and Akoglu, Leman and Xiang, Shili and Misra, Archan},
title = {BuScope: Fusing Individual \& Aggregated Mobility Behavior for "Live" Smart City Services},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326091},
doi = {10.1145/3307334.3326091},
abstract = {While analysis of urban commuting data has a long and demonstrated history of providing useful insights into human mobility behavior, such analysis has been performed largely in offline fashion and to aid medium-to-long term urban planning. In this work, we demonstrate the power of applying predictive analytics on real-time mobility data, specifically the smart-card generated trip data of millions of public bus commuters in Singapore, to create two novel and "live" smart city services. The key analytical novelty in our work lies in combining two aspects of urban mobility: (a) conformity: which reflects the predictability in the aggregated flow of commuters along bus routes, and (b) regularity: which captures the repeated trip patterns of each individual commuter. We demonstrate that the fusion of these two measures of behavior can be performed at city-scale using our BuScope platform, and can be used to create two innovative smart city applications. The Last-Mile Demand Generator provides O(mins) lookahead into the number of disembarking passengers at neighborhood bus stops; it achieves over 85\% accuracy in predicting such disembarkations by an ingenious combination of individual-level regularity with aggregate-level conformity. By moving driverless vehicles proactively to match this predicted demand, we can reduce wait times for disembarking passengers by over 75\%. Independently, the Neighborhood Event Detector uses outlier measures of currently operating buses to detect and spatiotemporally localize dynamic urban events, as much as 1.5 hours in advance, with a localization error of ~450 meters.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {41–53},
numpages = {13},
keywords = {regularity, mobility behavior, live smart city services, conformity},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326074,
author = {Xu, Xiangyu and Yu, Jiadi and Chen, Yingying and Zhu, Yanmin and Kong, Linghe and Li, Minglu},
title = {BreathListener: Fine-grained Breathing Monitoring in Driving Environments Utilizing Acoustic Signals},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326074},
doi = {10.1145/3307334.3326074},
abstract = {Given the increasing amount of time people spent on driving, the physical and mental health of drivers is essential to road safety. Breathing patterns are critical indicators of the well-being of drivers on the road. Existing studies on breathing monitoring require active user participation of wearing special sensors or relatively quiet environments during sleep, which are hardly applicable to noisy driving environments. In this work, we propose a fine-grained breathing monitoring system, BreathListener, which leverages audio devices on smartphones to estimate the fine-grained breathing waveform in driving environments. By investigating the data collected from real driving environments, we find that Energy Spectrum Density (ESD) of acoustic signals can be utilized to capture breathing procedures in driving environments. To extract breathing pattern in ESD signals, BreathListener eliminates interference from driving environments in ESD signals utilizing background subtraction and Ensemble Empirical Mode Decomposition (EEMD). After that, the extracted breathing pattern is transformed into Hilbert spectrum, and we further design a deep learning architecture based on Generative Adversarial Network (GAN) to generate fine-grained breathing waveform from the Hilbert spectrum of extracted breathing patterns in ESD signals. Experiments with 10 drivers in real driving environments show that BreathListener can accurately capture breathing patterns of drivers in driving environments.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {54–66},
numpages = {13},
keywords = {driving safety, breathing monitoring, acoustic sensing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3340949,
author = {Agarwal, Sharad},
title = {Session details: Session 2: Adding to the Toolkit},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340949},
doi = {10.1145/3340949},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326106,
author = {Afanasov, Mikhail and Djordjevic, Alessandro and Lui, Feng and Mottola, Luca},
title = {FlyZone: A Testbed for Experimenting with Aerial Drone Applications},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326106},
doi = {10.1145/3307334.3326106},
abstract = {FlyZone is a testbed architecture to experiment with aerial drone applications. Unlike most existing drone testbeds that focus on low-level mechanical control, FlyZone offers a high-level API and features geared towards experimenting with application-level functionality. These include the emulation of environment influences, such as wind, and the automatic monitoring of developer-provided safety constraints, for example, to mimic obstacles. We conceive novel solutions to achieve this functionality, including a hardware/software architecture that maximizes decoupling from the main application and a custom visual localization technique expressly designed for testbed operation. We deploy two instances of FlyZone and study performance and effectiveness. We demonstrate that we realistically emulate the environment influence with a positioning error bound by the size of the smallest drone we test, that our localization technique provides a root mean square error of 9.2cm, and that detection of violations to safety constraints happens with a 50ms worst-case latency. We also report on how FlyZone supported developing three real-world drone applications, and discuss a user study demonstrating the benefits of FlyZone compared to drone simulators.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {67–78},
numpages = {12},
keywords = {testbeds, localization, drones, dependability},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326089,
author = {Mantz, Dennis and Classen, Jiska and Schulz, Matthias and Hollick, Matthias},
title = {InternalBlue - Bluetooth Binary Patching and Experimentation Framework},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326089},
doi = {10.1145/3307334.3326089},
abstract = {Bluetooth is one of the most established technologies for short range digital wireless data transmission. With the advent of wearables and the Internet of Things (IoT), Bluetooth has again gained importance, which makes security research and protocol optimizations imperative. Surprisingly, there is a lack of openly available tools and experimental platforms to scrutinize Bluetooth. In particular, system aspects and close to hardware protocol layers are mostly uncovered. We reverse engineer multiple Broadcom Bluetooth chipsets that are widespread in off-the-shelf devices. Thus, we offer deep insights into the internal architecture of a popular commercial family of Bluetooth controllers used in smartphones, wearables, and IoT platforms. Reverse engineered functions can then be altered with our InternalBlue Python framework---outperforming evaluation kits, which are limited to documented and vendor-defined functions. The modified Bluetooth stack remains fully functional and high-performance. Hence, it provides a portable low-cost research platform. InternalBlue is a versatile framework and we demonstrate its abilities by implementing tests and demos for known Bluetooth vulnerabilities. Moreover, we discover a novel critical security issue affecting a large selection of Broadcom chipsets that allows executing code within the attacked Bluetooth firmware. We further show how to use our framework to fix bugs in chipsets out of vendor support and how to add new security features to Bluetooth firmware.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {79–90},
numpages = {12},
keywords = {security, link layer, iot, fuzzing, firmware, bluetooth, binary patching},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326080,
author = {Kalm\'{a}r, Gy\"{o}rgy and Wittemyer, George and V\"{o}lgyesi, P\'{e}ter and Rasmussen, Henrik Barner and Mar\'{o}ti, Mikl\'{o}s and L\'{e}deczi, \'{A}kos},
title = {Animal-Borne Anti-Poaching System},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326080},
doi = {10.1145/3307334.3326080},
abstract = {Wildlife poaching is a critical driver of biodiversity loss and population decline. Poaching is a particular threat to high value, large-bodied species, such as elephants, that are slow to reproduce. Increasingly, GPS tracking collars serve as a key tool for studying the behavior and monitoring wildlife globally, including application to anti-poaching efforts. However, collars provide indirect information on poaching, such as immobility, that is often not available in real time. In parallel to collar development, acoustic gunshot detection systems have proliferated in the military and law enforcement. Static systems in wildlife areas have been deployed for detecting poaching, but such systems do not scale geographically. This paper explores the idea of fusing GPS tracking collars with acoustic shockwave detectors to create an animal-borne anti-poaching sensor. A real-time alert of gunshots near elephant groups would enable rangers to respond immediately to such events. The two main technical challenges to such a system are battery life and detection accuracy. The paper presents a prototype designed for elephants that has great promise in addressing these significant technical challenges.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {91–102},
numpages = {12},
keywords = {wearable, shockwave, poaching, low-power, animal conservation, acoustics},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326076,
author = {Li, Zhengxiong and Rathore, Aditya Singh and Chen, Baicheng and Song, Chen and Yang, Zhuolin and Xu, Wenyao},
title = {SpecEye: Towards Pervasive and Privacy-Preserving Screen Exposure Detection in Daily Life},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326076},
doi = {10.1145/3307334.3326076},
abstract = {Digital devices have become a necessity in our daily life, with digital screens acting as a gateway to access a plethora of information present in the underlying device. However, these devices emit visible light through screens where long-term use can lead to significant screen exposure, further influencing users' health. Conventional methods on screen exposure detection (textite.g., photo logger) are usually privacy-invasive and expensive, further, require ideal light conditions, which are unattainable in real practice. Considering the light intensity and spectrum vary among different light sources, an effective screen spectrum estimation can provide vital information about screen exposure. To this end, we first investigate the characteristics of the junction between p-type and n-type semiconductor (i.e., PN junction) to sense the spectrum under various conditions. Empirically, we design and implement, textsfSpecEye, an end-to-end, low cost, wearable, and privacy-preserving screen exposure detection system with a mobile application. For validating the performance of our system, we conduct comprehensive experiments with $54$ commodity digital screens, at $43$ distinct locations, with results showing a base accuracy of $99$\%, and an equal error rate (EER) approaching $0.80$\% under the controlled lab setup. Moreover, we assess the reliability, robustness, and performance variation of textsfSpecEye under various real-world circumstances to observe a stable accuracy of $95$\%. Our real-world study indicates textsfSpecEye is a promising system for screen exposure detection in everyday life.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {103–116},
numpages = {14},
keywords = {screen exposure, privacy, health},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3340950,
author = {Lin, Kate Ching-Ju},
title = {Session details: Session 3: What is Real},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340950},
doi = {10.1145/3340950},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326079,
author = {Park, Yongtae and Yun, Sangki and Kim, Kyu-Han},
title = {When IoT met Augmented Reality: Visualizing the Source of the Wireless Signal in AR View},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326079},
doi = {10.1145/3307334.3326079},
abstract = {This paper presents VisIoT, a system that tracks the location of a wireless transmitter in IoT devices and displays it in the screen of an AR device such as smart glasses and tablet. The proposed system benefits existing IoT systems by enabling intuitive interaction between a user and IoT devices and further enhancing visualization of the data collected from IoT sensors. VisIoT achieves them through a combination of wireless sensing and camera motion tracking. By using the azimuth and elevation angles between the wireless transmitter and the camera-equipped mobile device, VisIoT can instantly identify the location of the IoT device from the camera image. This paper introduces novel azimuth and elevation estimation algorithms that leverage the phase difference of the signals from two antennas together with the tracked camera rotation. We prototype VisIoT using a tablet PC and a USRP software radio, and develop a software that tracks and visualizes the location of ZigBee nodes in real time. The evaluation results show that VisIoT can accurately track the nodes with the median position error of 6\%.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {117–129},
numpages = {13},
keywords = {wireless device tracking, internet of things, augmented reality},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326087,
author = {Shi, Shu and Gupta, Varun and Jana, Rittwik},
title = {Freedom: Fast Recovery Enhanced VR Delivery Over Mobile Networks},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326087},
doi = {10.1145/3307334.3326087},
abstract = {In this paper we design and implement Freedom, a mobile VR system that deliver high quality VR content on today's mobile devices using 4G/LTE cellular networks. Compared to existing state-of-the-art, Freedom does not rely on any video frame pre- rendering or viewpoint prediction. We send a latency-adaptive VAM frame that contains pixels around the FoV. This allows the clients to render locally at a high refresh rate of 60 Hz to accommodate and compensate for the user's head movements before the next server update arrives. We demonstrate that Freedom is the first system in the world that can support dynamic and live 8K resolution VR content, while adapting to the real-world latency variations experienced in cellular networks. Compared to streaming the whole 360° panoramic VR content, we show that Freedom achieves up to 80\% bandwidth savings. Finally, we provide detailed end to end latency measurements of actual VR systems by running extensive experiments in a private LTE testbed using a Mobile Edge Cloud (MEC).},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {130–141},
numpages = {12},
keywords = {remote rendering, motion-to-update latency, mobile vr, mobile edge cloud, 360 video},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326098,
author = {Prakash, Siddhant and Bahremand, Alireza and Nguyen, Linda D. and LiKamWa, Robert},
title = {GLEAM: An Illumination Estimation Framework for Real-time Photorealistic Augmented Reality on Mobile Devices},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326098},
doi = {10.1145/3307334.3326098},
abstract = {Mixed reality mobile platforms attempt to co-locate virtual scenes with physical environments, towards creating immersive user experiences. However, to create visual harmony between virtual and physical spaces, the virtual scene must be accurately illuminated with realistic lighting that matches the physical environment. To this end, we design GLEAM, a framework that provides robust illumination estimation in real-time by integrating physical light-probe estimation with current mobile AR systems. GLEAM visually observes reflective objects to compose a realistic estimation of physical lighting. Optionally, GLEAM can network multiple devices to sense illumination from different viewpoints and compose a richer estimation to enhance realism and fidelity. Using GLEAM, AR developers gain the freedom to use a wide range of materials, which is currently limited by the unrealistic appearance of materials that need accurate illumination, such as liquids, glass, and smooth metals. Our controlled environment user studies across 30 participants reveal the effectiveness of GLEAM in providing robust and adaptive illumination estimation over commercial status quo solutions, such as pre-baked directional lighting and ARKit 2.0 illumination estimation. Our benchmarks reveal the need for situation driven tradeoffs to optimize for quality factors in situations requiring freshness over quality and vice-versa. Optimizing for different quality factors in different situations, GLEAM can update scene illumination as fast as 30ms by sacrificing richness and fidelity in highly dynamic scenes, or prioritize quality by allowing an update interval as high as 400ms in scenes that require high-fidelity estimation.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {142–154},
numpages = {13},
keywords = {lighting models, light probe, light estimation, image-based lighting, image processing, geometry, augmented reality},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326097,
author = {Choi, Jaewon and Park, HyeonJung and Paek, Jeongyeup and Balan, Rajesh Krishna and Ko, JeongGil},
title = {LpGL: Low-power Graphics Library for Mobile AR Headsets},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326097},
doi = {10.1145/3307334.3326097},
abstract = {We present LpGL, an OpenGL API compatible Low-power Graphics Library for energy efficient AR headset applications. We first characterize the power consumption patterns of a state of the art AR headset, Magic Leap One, and empirically show that its internal GPU is the most impactful and controllable energy consumer. Based on the preliminary studies, we design LpGL so that it uses the device's gaze/head orientation information and geometry data to infer user perception information, intercepts application-level graphics API calls, and employs frame rate control, mesh simplification, and culling techniques to enhance energy efficiency of AR headsets without detriment of user experience. Results from a comprehen- sive set of controlled in-lab experiments and an IRB-approved user study with 25 participants show that LpGL reduces up to 22\% of total energy usage while adding only 46 sec of latency per object with close to no loss in subjective user experience.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {155–167},
numpages = {13},
keywords = {mobile headsets, energy efficiency, augmented reality},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3340951,
author = {Sani, Ardalan Amiri},
title = {Session details: Session 4: Taming Your Apps},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340951},
doi = {10.1145/3340951},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326094,
author = {Yan, Yuxuan and Li, Zhenhua and Chen, Qi Alfred and Wilson, Christo and Xu, Tianyin and Zhai, Ennan and Li, Yong and Liu, Yunhao},
title = {Understanding and Detecting Overlay-based Android Malware at Market Scales},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326094},
doi = {10.1145/3307334.3326094},
abstract = {As a key UI feature of Android, overlay enables one app to draw over other apps by creating an extra View layer on top of the host View. While greatly facilitating user interactions with multiple apps at the same time, it is often exploited by malicious apps (malware) to attack users. To combat this threat, prior countermeasures concentrate on restricting the capabilities of overlays at the OS level, while barely seeing adoption by Android due to the concern of sacrificing overlays' usability. To address this dilemma, a more pragmatic approach is to enable the early detection of overlay-based malware at the app market level during the app review process, so that all the capabilities of overlays can stay unchanged. Unfortunately, little has been known about the feasibility and effectiveness of this approach for lack of understanding of malicious overlays in the wild. To fill this gap, in this paper we perform the first large-scale comparative study of overlay characteristics in benign and malicious apps using static and dynamic analyses. Our results reveal a set of suspicious overlay properties strongly correlated with the malice of apps, including several novel features. Guided by the study insights, we build OverlayChecker, a system that is able to automatically detect overlay-based malware at market scales. OverlayChecker has been adopted by one of the world's largest Android app stores to check around 10K newly submitted apps per day. It can efficiently (within 2 minutes per app) detect nearly all (96\%) overlay-based malware using a single commodity server.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {168–179},
numpages = {12},
keywords = {malware detection, app market, android overlay},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326095,
author = {Raval, Nisarg and Razeen, Ali and Machanavajjhala, Ashwin and Cox, Landon P. and Warfield, Andrew},
title = {Permissions Plugins as Android Apps},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326095},
doi = {10.1145/3307334.3326095},
abstract = {The permissions framework for Android is frustratingly inflexible. Once granted a permission, Android will always allow an app to access the resource until the user manually revokes the app's permission. Prior work has proposed extensible plugin frameworks, but they have struggled to support flexible authorization and isolate apps and plugins from each other. In this paper, we propose DALF, a framework for extensible permissions plugins that provides both flexibility and isolation. The insight underlying DALF is that permissions plugins should be treated as apps themselves. This approach allows plugins to maintain state and access system resources such as a device's location while being restricted by Android's process-isolation mechanisms. Experiments with microbenchmarks and case studies with real third-party apps show promising results: plugins are easy to develop and impose acceptable overhead for most resources.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {180–192},
numpages = {13},
keywords = {plugins, flexible permissions, android},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326102,
author = {Hu, Yongjian and Riva, Oriana and Nath, Suman and Neamtiu, Iulian},
title = {Elix: Path-Selective Taint Analysis for Extracting Mobile App Links},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326102},
doi = {10.1145/3307334.3326102},
abstract = {App links, also known as mobile deep links, are URIs that point to specific pages in an app. App links are essential to many mobile experiences: Google and Bing use them to link search results directly to relevant pages in an app and apps use them for cross-app navigation. However, app links are hard to discover and, since they must be explicitly built into apps by developers, only exist for a small fraction of apps. To address these two problems, we propose Elix, an automated app link extractor. We define link extraction as a static information flow problem where a link, with its scheme and parameters, is synthesized by analyzing the data flow between subsequent pages in an app. As static analysis is prone to false positives, Elix adopts a novel, path-selective taint analysis that leverages symbolic execution to reason about path constraints and abandon infeasible paths. Elix can automatically and correctly discover links that are exposed by an app, and many others that are not explicitly exposed, thus increasing coverage of both link-enabled apps and link-enabled pages in an app. Elix also simplifies the scheme of extracted links by reducing complex types to a minimal set of primitive types. We have implemented Elix on Android and applied it to 1007 popular Android apps. Elix can extract 80-90\% of an app's links, and above 80\% of the extracted links are stable.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {193–206},
numpages = {14},
keywords = {symbolic execution, static analysis, mobile app links},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326108,
author = {Zhang, Tao and Zuck, Aviad and Porter, Donald E. and Tsafrir, Dan},
title = {Apps Can Quickly Destroy Your Mobile's Flash: Why They Don't, and How to Keep It That Way},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326108},
doi = {10.1145/3307334.3326108},
abstract = {Although flash cells wear out, a typical SSD has enough cells and sufficiently sophisticated firmware that its lifetime generally exceeds the expected lifetime of its host system. Even under heavy use, SSDs last for years and can be replaced upon failure. On a smartphone, in contrast, the hardware is more limited and we show that, under heavy use, one can easily, and more quickly, wear out smartphone flash storage. Consequently, a simple, unprivileged, malicious application can render a smartphone unbootable ("bricked") in a few weeks with no warning signs to the user. This bleak result becomes more worrisome when considering the fact that smartphone users generally believe it is safe to try out new applications. To combat this problem, we study the I/O behavior of a wide range of Android applications. We find that high-volume write bursts exist, yet none of the applications we checked sustains an average write rate that is high enough to damage the device (under reasonable usage assumptions backed by the literature). We therefore propose a rate-limiting algorithm for write activity that (1) prevents such attacks, (2) accommodates "normal" bursts, and (3) ensures that the smartphone drive lifetime is longer than a preconfigured lower bound (i.e., its warranty). In terms of user experience, our design only requires that, in the worst case of an app that issues continuous, unsustainable, and unusual writes, the user decides whether to shorten the phone's life or rate limit the problematic app.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {207–221},
numpages = {15},
keywords = {flash storage, device lifespan, app characterization, android},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326072,
author = {Shi, Luman and Fu, Jianming and Guo, Zhengwei and Ming, Jiang},
title = {"Jekyll and Hyde" is Risky: Shared-Everything Threat Mitigation in Dual-Instance Apps},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326072},
doi = {10.1145/3307334.3326072},
abstract = {Recent developed application-level virtualization brings a groundbreaking innovation to Android ecosystem: a host app is able to load and launch arbitrary guest APK files without the hassle of installation. Powered by this technology, the so-called "dual-instance apps" are becoming increasingly popular as they can run dual copies of the same app on a single device (e.g., login Facebook simultaneously with two different accounts). Given the large demand from smartphone users, it is imperative to understand how secure dual-instance apps are. However, little work investigates their potential security risks. Even worse, new Android malware variants have been accused of skimming the cream off application-level virtualization. They abuse legitimate virtualization engines to launch phishing attacks or even thwart static detection. We first demonstrate that, current dual-instance apps design introduces serious "shared-everything" threats to users, and severe attacks such as permission escalation and privacy leak have become tremendously easier. Unfortunately, we find that most critical apps cannot discriminate between host app and Android system. In addition, traditional fingerprinting features targeting Android sandboxes are futile as well. To inform users that an app is running in an untrusted environment, we study the inherent features of dual-instance app environment and propose six robust fingerprinting features to detect whether an app is being launched by the host app. We test our approach, called DiPrint, with a set of dual-instance apps collected from popular app stores, Android systems, and virtualization-based malware. Our evaluation shows that DiPrint is able to accurately identify dual-instance apps with negligible overhead.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {222–235},
numpages = {14},
keywords = {shared-everything threat, dynamic detection, android application-layer virtualization},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3340952,
author = {Balasubramanian, Aruna},
title = {Session details: Session 5: Sense and See},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340952},
doi = {10.1145/3340952},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326092,
author = {Hu, Jinhan and Shearer, Alexander and Rajagopalan, Saranya and LiKamWa, Robert},
title = {Banner: An Image Sensor Reconfiguration Framework for Seamless Resolution-based Tradeoffs},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326092},
doi = {10.1145/3307334.3326092},
abstract = {Mobile vision systems would benefit from the ability to situationally sacrifice image resolution to save system energy when imaging detail is unnecessary. Unfortunately, any change in sensor resolution leads to a substantial pause in frame delivery -- as much as 280 ms. Frame delivery is bottlenecked by a sequence of reconfiguration procedures and memory management in current operating systems before it resumes at the new resolution. This latency from reconfiguration impedes the adoption of otherwise beneficial resolution-energy tradeoff mechanisms. We propose Banner as a media framework that provides a rapid sensor resolution reconfiguration service as a modification to common media frameworks, e.g., V4L2. Banner completely eliminates the frame-to-frame reconfiguration latency (226 ms to 33 ms), i.e., removing the frame drop during sensor resolution reconfiguration. Banner also halves the end-to-end resolution reconfiguration latency (226 ms to 105 ms). This enables a more than 49\% reduction of system power consumption by allowing continuous vision applications to reconfigure the sensor resolution to 480p compared with downsampling from 1080p to 480p, as measured in a cloud-based offloading workload running on a Jetson TX2 board. As a result, Banner unlocks unprecedented capabilities for mobile vision applications to dynamically reconfigure sensor resolutions to balance the energy efficiency and task accuracy tradeoff.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {236–248},
numpages = {13},
keywords = {resolution-based tradeoff, reconfiguration, operating systems, energy efficiency, efficient visual computing, device drivers},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326093,
author = {Liu, Jian and Shi, Cong and Chen, Yingying and Liu, Hongbo and Gruteser, Marco},
title = {CardioCam: Leveraging Camera on Mobile Devices to Verify Users While Their Heart is Pumping},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326093},
doi = {10.1145/3307334.3326093},
abstract = {With the increasing prevalence of mobile and IoT devices (e.g., smartphones, tablets, smart-home appliances), massive private and sensitive information are stored on these devices. To prevent unauthorized access on these devices, existing user verification solutions either rely on the complexity of user-defined secrets (e.g., password) or resort to specialized biometric sensors (e.g., fingerprint reader), but the users may still suffer from various attacks, such as password theft, shoulder surfing, smudge, and forged biometrics attacks. In this paper, we propose, CardioCam, a low-cost, general, hard-to-forge user verification system leveraging the unique cardiac biometrics extracted from the readily available built-in cameras in mobile and IoT devices. We demonstrate that the unique cardiac features can be extracted from the cardiac motion patterns in fingertips, by pressing on the built-in camera. To mitigate the impacts of various ambient lighting conditions and human movements under practical scenarios, CardioCam develops a gradient-based technique to optimize the camera configuration, and dynamically selects the most sensitive pixels in a camera frame to extract reliable cardiac motion patterns. Furthermore, the morphological characteristic analysis is deployed to derive user-specific cardiac features, and a feature transformation scheme grounded on Principle Component Analysis (PCA) is developed to enhance the robustness of cardiac biometrics for effective user verification. With the prototyped system, extensive experiments involving $25$ subjects are conducted to demonstrate that CardioCam can achieve effective and reliable user verification with over $99\%$ average true positive rate (TPR) while maintaining the false positive rate (FPR) as low as $4\%$.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {249–261},
numpages = {13},
keywords = {mobile devices, cardiac biometric, camera, authentication},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326105,
author = {Balaji, Ananta Narayanan and Yuan, Chen and Wang, Bo and Peh, Li-Shiuan and Shao, Huilin},
title = {pH Watch - Leveraging Pulse Oximeters in Existing Wearables for Reusable, Real-time Monitoring of pH in Sweat},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326105},
doi = {10.1145/3307334.3326105},
abstract = {Sweat is a readily accessible bodily fluid for detecting biomarkers such as pH, glucose etc., enabling continuous and non-invasive assessment of the well-being of individuals. Our proposed work aims at leveraging pulse oximeter chips in current-day fitness trackers for real-time continuous monitoring of pH in sweat. We achieve that by fabricating a highly responsive and long-term reusable pH sweat sensor on a flexible material to achieve skin conformity, targeting the sensor to work at the reflected infrared (880nm) and red (660nm) photoplethysmograph (PPG) signal intensities recorded by pulse oximeters. The sensor can be readily mounted atop any wearable with a pulse oximeter. We have successfully demonstrated a low-cost, low-power, highly-responsive and long-term reusable wrist-worn wearable prototype, pH Watch, for real-time continuous monitoring of pH value of sweat. We conducted on-body trials with 10 participants and pH Watch achieves an accuracy of $approx$91\%. We also showed that the integration of our sweat sensor does not hinder the pulse oximeter from measuring heart rate and SpOtextsubscript2, and users can continue with their daily activities with motion artifacts removed efficiently from PPG signals using the TROIKA framework, resulting in heart rate and SpOtextsubscript2 measurements with an accuracy of $approx$95\% and $approx$96\% respectively when validated against commercial finger pulse oximeter measurements. To the best of our knowledge, pH Watch is the first demonstration of a reusable sweat sensor that can be readily integrated into today's smart watches with pulse oximeters, paving the way for ubiquitous sensing of biomarkers.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {262–274},
numpages = {13},
keywords = {wearables, sweat sensor, ph sensing, iot},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326078,
author = {Yue, Shichao and Katabi, Dina},
title = {Liquid Testing with Your Smartphone},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326078},
doi = {10.1145/3307334.3326078},
abstract = {Surface tension is an important property of liquids. It has diverse uses such as testing water contamination, measuring alcohol concentration in drinks, and identifying the presence of protein in urine to detect the onset of kidney failure. Today, measurements of surface tension are done in a lab environment using costly instruments, making it hard to leverage this property in ubiquitous applications. In contrast, we show how to measure surface tension using only a smartphone. We introduce a new algorithm that uses the small waves on the liquid surface as a series of lenses that focus light and generate a characteristic pattern. We then use the phone camera to capture this pattern and measure the surface tension. Our approach is simple, accurate and available to anyone with a smartphone. Empirical evaluations show that our mobile app can detect water contamination and measure alcohol concentration. Furthermore, it can track protein concentration in the urine, providing an initial at-home test for proteinuria, a dangerous complication that can lead to kidney failure.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {275–286},
numpages = {12},
keywords = {ubiquitous computing, surface tension, mobile sensing, liquid identification},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3340953,
author = {Min, Chulhong},
title = {Session details: Session 6: Simon Says},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340953},
doi = {10.1145/3340953},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326109,
author = {Liu, Yang and Li, Zhenjiang and Liu, Zhidan and Wu, Kaishun},
title = {Real-time Arm Skeleton Tracking and Gesture Inference Tolerant to Missing Wearable Sensors},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326109},
doi = {10.1145/3307334.3326109},
abstract = {This paper presents ArmTroi, a wearable system for understanding and analyzing the detailed arm motions of people primarily by using the motion sensors from wrist-worn wearable devices. ArmTroi can achieve real-time 3D arm skeleton tracking and reliable gesture inference tolerant to missing wearable sensors for enabling numerous useful application designs. We have coped with two major challenges through ArmTroi. First, the skeleton of each arm is determined from the locations of the elbow and wrist, whereas a wearable device only senses a single point from the wrist. We find that the potential solution space is huge. This underconstrained nature fundamentally challenges the achievement of accurate and real-time arm skeleton tracking. Second, wearable sensors may not reliably provide sensory data. For example, devices are not worn by the user, yet the learning tools for gesture inference, such as deep learning, typically have static network structures, which require nontrivial network adaptation to match the input's varying availability and ensure reliable gesture inference. We propose effective techniques to address above challenges, and all computations can be conducted on the user's smartphone. ArmTroi is thus a fully lightweight and portable system. We develop a prototype and extensive evaluation shows the efficacy of the ArmTroi design.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {287–299},
numpages = {13},
keywords = {mobile sensing, gesture inference, deep learning, arm tracking},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326090,
author = {Whitmire, Eric and Salemi Parizi, Farshid and Patel, Shwetak},
title = {Aura: Inside-out Electromagnetic Controller Tracking},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326090},
doi = {10.1145/3307334.3326090},
abstract = {The ability to track handheld controllers in 3D space is critical for interaction with head-mounted displays, such as those used in virtual and augmented reality systems. Today's systems commonly rely on dedicated infrastructure to track the controller or only provide inertial-based rotational tracking, which severely limits the user experience. Optical inside-out systems offer mobility but require line-of-sight and bulky tracking rings, which limit the ubiquity of these devices. In this work, we present Aura, an inside-out electromagnetic 6-DoF tracking system for handheld controllers. The tracking system consists of three coils embedded in a head-mounted display and a set of orthogonal receiver coils embedded in a handheld controller. We propose a novel closed-form and computationally simple tracking approach to reconstruct position and orientation in real time. Our handheld controller is small enough to fit in a pocket and consumes 45 mW of power, allowing it to operate for multiple days on a typical battery. An evaluation study demonstrates that Aura achieves a median tracking error of 5.5 mm and 0.8 degrees in 3D space within arm's reach.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {300–312},
numpages = {13},
keywords = {virtual reality, mixed reality, head-mounted display, electromagnetic tracking, controller},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326081,
author = {Zheng, Yue and Zhang, Yi and Qian, Kun and Zhang, Guidong and Liu, Yunhao and Wu, Chenshu and Yang, Zheng},
title = {Zero-Effort Cross-Domain Gesture Recognition with Wi-Fi},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326081},
doi = {10.1145/3307334.3326081},
abstract = {Wi-Fi based sensing systems, although sound as being deployed almost everywhere there is Wi-Fi, are still practically difficult to be used without explicit adaptation efforts to new data domains. Various pioneering approaches have been proposed to resolve this contradiction by either translating features between domains or generating domain-independent features at a higher learning level. Still, extra training efforts are necessary in either data collection or model re-training when new data domains appear, limiting their practical usability. To advance cross-domain sensing and achieve fully zero-effort sensing, a domain-independent feature at the lower signal level acts as a key enabler. In this paper, we propose Widar3.0, a Wi-Fi based zero-effort cross-domain gesture recognition system. The key insight of Widar3.0 is to derive and estimate velocity profiles of gestures at the lower signal level, which represent unique kinetic characteristics of gestures and are irrespective of domains. On this basis, we develop a one-fits-all model that requires only one-time training but can adapt to different data domains. We implement this design and conduct comprehensive experiments. The evaluation results show that without re-training and across various domain factors (i.e. environments, locations and orientations of persons), Widar3.0 achieves 92.7\% in-domain recognition accuracy and 82.6\%-92.4\% cross-domain recognition accuracy, outperforming the state-of-the-art solutions. To the best of our knowledge, Widar3.0 is the first zero-effort cross-domain gesture recognition work via Wi-Fi, a fundamental step towards ubiquitous sensing.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {313–325},
numpages = {13},
keywords = {gesture recognition, cots wi-fi, channel state information},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326107,
author = {Huang, Hua and Chen, Hongkai and Lin, Shan},
title = {MagTrack: Enabling Safe Driving Monitoring with Wearable Magnetics},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326107},
doi = {10.1145/3307334.3326107},
abstract = {"Hands on the wheel, eyes on the road" is the central guideline of safe vehicle driving practices. Many advanced driver assistance systems can effectively detect abnormal vehicle motions. However, these systems often leave insufficient time for drivers to respond to complex road situations, especially when the drivers are distracted. To reduce accidents, it is essential to detect whether a driver complies with safe driving guidelines in real time and provide warnings early before any dangerous maneuvers occur. There are vision-based driver distraction monitoring systems which rely on cameras in high-end vehicles, but their performances are heavily constrained by visibility requirements. In this paper, we present MagTrack, a driver monitoring system that is based on tracking magnetic tags worn by the user. With a single smartwatch and two low-cost magnetic accessories: a hand magnetic ring and a head magnetic eyeglasses clip, our system tracks and classifies a driver's bimanual and head movements simultaneously using both analytical and approximation sensing models. Our approach is robust to driver's postures, vehicles, and environmental changes. We demonstrate that a wide range of activities can be detected by our system, including bimanual steering, visual and manual distractions, and lane changes and turns. In extensive road tests with 500+ instances of driving activities and 500+ minutes of road driving with 10 subjects, MagTrack achieves 87\% of precision and 90\% of recall rate on the detection of unsafe driving activities.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {326–339},
numpages = {14},
keywords = {wearable magnetics, smartwatch sensing, driver assistance system},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3340954,
author = {Kravets, Robin},
title = {Session details: Session 7: Too Close for Comfort},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340954},
doi = {10.1145/3340954},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326100,
author = {Pierson, Timothy J. and Peters, Travis and Peterson, Ronald and Kotz, David},
title = {CloseTalker: Secure, Short-Range Ad Hoc Wireless Communication},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326100},
doi = {10.1145/3307334.3326100},
abstract = {Secure communication is difficult to arrange between devices that have not previously shared a secret. Previous solutions to the problem are susceptible to man-in-the-middle attacks, require additional hardware for out-of-band communication, or require an extensive public-key infrastructure. Furthermore, as the number of wireless devices explodes with the advent of the Internet of Things, it will be impractical to manually configure each device to communicate with its neighbors. Our system, CloseTalker, allows simple, secure, ad hoc communication between devices in close physical proximity, while jamming the signal so it is unintelligible to any receivers more than a few centimeters away. CloseTalker does not require any specialized hardware or sensors in the devices, does not require complex algorithms or cryptography libraries, occurs only when intended by the user, and can transmit a short burst of data or an address and key that can be used to establish long-term or long-range communications at full bandwidth. In this paper we present a theoretical and practical evaluation of CloseTalker, which exploits Wi-Fi MIMO antennas and the fundamental physics of radio to establish secure communication between devices that have never previously met. We demonstrate that CloseTalker is able to facilitate secure in-band communication between devices in close physical proximity (about 5~cm), even though they have never met nor shared a key.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {340–352},
numpages = {13},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326101,
author = {Tsai, Lillian and De Viti, Roberta and Lentz, Matthew and Saroiu, Stefan and Bhattacharjee, Bobby and Druschel, Peter},
title = {enClosure: Group Communication via Encounter Closures},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326101},
doi = {10.1145/3307334.3326101},
abstract = {New applications enabled by personal smart devices and the Internet-of-Things (IoT) require communication in the context of periods of spatial co-location. Examples of this encounter-based communication (EbC) include social exchange among individuals who shared an experience, and interaction among personal and IoT devices that provide location-based services. Existing EbC systems are limited to communication among participants that share a direct encounter. This paper is inspired by two insights: (1) encounters also enable group communication among devices connected by paths in the encounter graph that is contextual, spontaneous, secure, and does not require users to reveal identifying or linkable information; and (2) addressing communication partners using encounter closures subject to causal, spatial, and temporal constraints enables powerful new forms of group communication. We present the design of enClosure, a service providing group communication based on encounter closures for mobile and IoT applications, and a prototype implementation for Android and the Microsoft Embedded Social Cloud platform. Using real-world traces, we show that enClosure provides a privacy-preserving, secure platform for a wide range of group communication applications ranging from connecting attendees of a large event and virtual guest books to disseminating health risk warnings, lost-and-found, and tracing missing persons.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {353–365},
numpages = {13},
keywords = {privacy, mobile computing, internet-of-things (iot), group communication, encounter-based communication},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326084,
author = {Wang, Ju and Chang, Liqiong and Abari, Omid and Keshav, Srinivasan},
title = {Are RFID Sensing Systems Ready for the Real World?},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326084},
doi = {10.1145/3307334.3326084},
abstract = {Passive Radio Frequency IDentification (RFID) tags are commonly used to provide Radio Frequency (RF) accessible unique identifiers for physical objects due to their low-cost, lack of battery, and small size. Besides this basic function, many novel RFID-based sensing applications have been proposed in the last decade, including localization, gesture sensing, and touch sensing, among others. Nevertheless, none of these systems are in widespread use today. We hypothesize that this is because the accuracy of these systems does not meet application requirements when there are even minor changes in the RF environment or in tag geometry, i.e., changes in a tag's orientation or flexing. This paper uses both theoretical analysis and real-world experiments to test this hypothesis. Our theoretical analysis shows that even a small phase or RSS noise level can result in significant estimation errors. Our extensive real-world experiments find that both the absolute and differential values of phase and RSS readings of an RFID tag's signal can vary as much as by π radians and 10 dB, respectively, due to small changes in the tag's orientation or flexing. Because of these large variations, RFID-based application systems relying on the signal phase or RSS cannot meet application requirements, confirming our hypothesis. In addition to this strong negative result, we also present some insights into designing robust RFID systems that are suitable for use in the real world.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {366–377},
numpages = {12},
keywords = {rss, robustness, rfid, phase},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326085,
author = {Luo, Jiaqing and Shin, Kang G.},
title = {Detecting Misplaced RFID Tags on Static Shelved Items},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326085},
doi = {10.1145/3307334.3326085},
abstract = {A smart shelving system can visualize stock data in real time by leveraging item-level RFID tagging so that we can minimize out-of-stock and reduce warehousing and labor costs. The key issue of smart shelving is to locate RFID tags at any time, especially after misplacing tags. The detection of misplaced tags on stationary shelved items is very challenging due to position ambiguity, phase wrapping, device diversity, and phase ambiguity. Using a combination of theoretical analysis, simulation-based prediction and experimental verification, we propose an effective way of detecting misplaced tags, called FINDS, that integrates Particle Swarm Optimization (PSO), Synthetic Minority Over-sampling TEchnique (SMOTE) and Density-based Spatial Clustering of Applications with Noise (DBSCAN) algorithms to make theoretical and measured phases consistent with each other, and observe the phase shifts caused by misplaced tags. FINDS requires neither antenna movement nor external disturbances. We have implemented a prototype of FINDS with 20 tags and evaluated its performance, demonstrating FINDS's accuracy to be higher than 0.92 in the case of 2 stationary antennas.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {378–390},
numpages = {13},
keywords = {stationary tags, smart shelves, rfid, misplaced tags},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3340955,
author = {Druschel, Peter},
title = {Session details: Session 8: Waiting for 7G},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340955},
doi = {10.1145/3340955},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326088,
author = {Khazraee, Moein and Guddeti, Yeswanth and Crow, Sam and Snoeren, Alex C. and Levchenko, Kirill and Bharadia, Dinesh and Schulman, Aaron},
title = {SparSDR: Sparsity-proportional Backhaul and Compute for SDRs},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326088},
doi = {10.1145/3307334.3326088},
abstract = {We present SparSDR, a resource-efficient architecture for softwaredefined radios whose backhaul bandwidth and compute power requirements scale in inverse proportion to the sparsity (in time and frequency) of the signals received. SparSDR requires dramatically fewer resources than existing approaches to process many popular protocols while retaining both flexibility and fidelity. We demonstrate that our approach has negligible impact on signal quality, receiver sensitivity, and processing latency. The SparSDR architecture makes it possible to capture signals across bandwidths far wider than the capacity of a radio's backhaul through the addition of lightweight frontend processing and corresponding backend reconstruction to restore the signals to their original sample rate. We employ SparSDR to develop two wideband applications running on a USRP N210 and a Raspberry Pi 3+: an IoT sniffer that scans 100 MHz of bandwidth and decodes received BLE packets, and a wideband Cloud SDR receiver that requires only residential-class Internet uplink capacity. We show that our SparSDR implementation fits in the constrained resources of popular low-cost SDR platforms, such as the AD Pluto.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {391–403},
numpages = {13},
keywords = {sparsity, software defined radio, fpga, fft, cloud sdr},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326082,
author = {Lee, Gyuhong and Lee, Jihoon and Lee, Jinsung and Im, Youngbin and Hollingsworth, Max and Wustrow, Eric and Grunwald, Dirk and Ha, Sangtae},
title = {This is Your President Speaking: Spoofing Alerts in 4G LTE Networks},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326082},
doi = {10.1145/3307334.3326082},
abstract = {Modern cell phones are required to receive and display alerts via the Wireless Emergency Alert (WEA) program, under the mandate of the Warning, Alert, and Response Act of 2006. These alerts include AMBER alerts, severe weather alerts, and (unblockable) Presidential Alerts, intended to inform the public of imminent threats. Recently, a test Presidential Alert was sent to all capable phones in the United States, prompting concerns about how the underlying WEA protocol could be misused or attacked. In this paper, we investigate the details of this system, and develop and demonstrate the first practical spoofing attack on Presidential Alerts, using both commercially available hardware as well as modified open source software. Our attack can be performed using a commercially-available software defined radio, and our modifications to the open source NextEPC and srsLTE software libraries. We find that with only four malicious portable base stations of a single Watt of transmit power each, almost all of a 50,000-seat stadium can be attacked with a 90\% success rate. The true impact of such an attack would of course depend on the density of cell phones in range; fake alerts in crowded cities or stadiums could potentially result in cascades of panic. Fixing this problem will require a large collaborative effort between carriers, government stakeholders, and cell phone manufacturers. To seed this effort, we also discuss several defenses to address this threat in both the short and long term.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {404–416},
numpages = {13},
keywords = {wea, spoofing, security, presidential alert, lte, cmas},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326086,
author = {Lee, Jihoon and Lee, Jinsung and Im, Youngbin and Dhawaskar Sathyanarayana, Sandesh and Rahimzadeh, Parisa and Zhang, Xiaoxi and Hollingsworth, Max and Joe-Wong, Carlee and Grunwald, Dirk and Ha, Sangtae},
title = {CASTLE over the Air: Distributed Scheduling for Cellular Data Transmissions},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326086},
doi = {10.1145/3307334.3326086},
abstract = {This paper presents a fully distributed scheduling framework called CASTLE (Client-side Adaptive Scheduler That minimizes Load and Energy), which jointly optimizes the spectral efficiency of cellular networks and battery consumption of smart devices. To do so, we focus on scenarios when many smart devices compete for cellular resources in the same base station: spreading out transmissions over time so that only a few devices transmit at once improves both spectral efficiency and battery consumption. To this end, we devise two novel features in CASTLE. First, we explicitly consider inter-cell interference for accurate cellular load estimation. Based on our observations, we exploit the RSRQ (Reference Signal Received Quality) and SINR as features in a machine learning algorithm to accurately estimate the cellular load. Second, we propose a fully distributed scheduling algorithm that coordinates transmissions between clients based on the locally estimated load level at each client. Our formulation for minimizing battery consumption at each device leads to an optimized backoff-based algorithm that fits practical environments. To evaluate these features, we prototype a complete LTE system testbed consisting of mobile devices, eNodeBs, EPC (Evolved Packet Core) and application servers. Our comprehensive experimental results show that CASTLE's load estimation is up to 91\% accurate, and that CASTLE achieves higher spectral efficiency with less battery consumption, compared to existing centralized scheduling algorithms as well as a distributed CSMA-like protocol. Furthermore, we develop a light-weight SDK that can expedite the deployment of CASTLE into smart devices and evaluate it in a commercial LTE network.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {417–429},
numpages = {13},
keywords = {lte, energy saving, distributed scheduling, cell load},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326104,
author = {Netravali, Ravi and Sivaraman, Anirudh and Mickens, James and Balakrishnan, Hari},
title = {WatchTower: Fast, Secure Mobile Page Loads Using Remote Dependency Resolution},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326104},
doi = {10.1145/3307334.3326104},
abstract = {Remote dependency resolution (RDR) is a proxy-driven scheme for reducing mobile page load times; a proxy loads a requested page using a local browser, fetching the page's resources over fast proxy-origin links instead of a client's slow last-mile links. In this paper, we describe two fundamental challenges to efficient RDR proxying: the increasing popularity of encrypted HTTPS content, and the fact that, due to time-dependent network conditions and page properties, RDR proxying can actually increase load times. We solve these problems by introducing a new, secure proxying scheme for HTTPS traffic, and by implementing WatchTower, a selective proxying system that uses dynamic models of network conditions and page structures to only enable RDR when it is predicted to help. WatchTower loads pages 21.2\%-41.3\% faster than state-of-the-art proxies and server push systems, while preserving end-to-end HTTPS security.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {430–443},
numpages = {14},
keywords = {web performance, remote dependency resolution, page load times, mobile web, cloud browsers},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326103,
author = {Tai, Tzu-Chun and Lin, Kate Ching-Ju and Tseng, Yu-Chee},
title = {Toward Reliable Localization by Unequal AoA Tracking},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326103},
doi = {10.1145/3307334.3326103},
abstract = {Emerging applications require the location information of clients to enable human-environment interactions or personalized services. With an increasing number of antennas equipped in today's wireless devices, recent research has shown possibility of sub-meter level localization based only on the angle of arrival (AoA) of WiFi sig- nals. While most existing work provides promising median accu- racy, their tail performance however is usually far worse. We ob- serve from measurements that the root cause is due to unequal AoA estimation reliability. In some critical areas, a small variation in the channel state information of signals could introduce an extremely large AoA estimation error. With this observation, we propose UAT (Unequal Angle Tracking), a confidence-aware AoA-based localiza- tion system. We show that unequal reliability of AoA measures can be mathematically quantified, allowing a system to weigh the de- cisions of different APs according to their confidence. Our testbed evaluation shows that UAT's confidence-aware design provides reli- able decimeter level localization for around 90\% of locations. UAT is especially effective for risky areas and can reduce their localiza- tion errors by 27.5\%, as compared to reliability-oblivious designs.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {444–456},
numpages = {13},
keywords = {unequal tracking, localization, aoa estimation},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326070,
author = {Xiao, Ao and Liu, Yunhao and Li, Yang and Qian, Feng and Li, Zhenhua and Bai, Sen and Liu, Yao and Xu, Tianyin and Xin, Xianlong},
title = {An In-depth Study of Commercial MVNO: Measurement and Optimization},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326070},
doi = {10.1145/3307334.3326070},
abstract = {Recent years have witnessed the rapid growth of mobile virtual network operators (MVNOs), which operate on top of the existing cellular infrastructures of base carriers while offering cheaper or more flexible data plans compared to those of the base carriers. In this paper, we present a nearly two-year measurement study towards understanding various key aspects of today's MVNO ecosystem, including its architecture, performance, economics, customers, and the complex interplay with the base carrier. Our study focuses on a large commercial MVNO with reviseabout 1 million customers, operating atop a nation-wide base carrier. Our measurements clarify several key concerns raised by MVNO customers, such as inaccurate billing and potential performance discrimination with the base carrier. We also leverage big data analytics and machine learning to optimize an MVNO's key businesses such as data plan reselling and customer churn mitigation. Our proposed techniques can help achieve \%will lead to higher revenues and improved services for commercial MVNOs.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {457–468},
numpages = {12},
keywords = {network performance, mvno, machine learning, data prediction, churn mitigation},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3340956,
author = {LiKamWa, Robert},
title = {Session details: Session 9: Nuts and Bolts},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3340956},
doi = {10.1145/3340956},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326075,
author = {Choi, Yonghun and Park, Seonghoon and Cha, Hojung},
title = {Graphics-aware Power Governing for Mobile Devices},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326075},
doi = {10.1145/3307334.3326075},
abstract = {Graphics increasingly play a key role in modern mobile devices. The graphics pipeline requires a close relationship between the CPU and the GPU to ensure energy efficiency and the user's quality of experience (QoE). Our preliminary analysis showed that the current techniques employed to achieve energy efficiency in the Android graphics pipeline are not optimized especially in the frame generation process. In this paper, we aim to improve the energy efficiency of the Android graphics pipeline without degrading the user's QoE. To achieve this goal, we studied the internals of the Android graphics pipeline and observed the energy inefficiency in the existing governing framework of the CPU and GPU. Based on the findings, we propose three techniques for addressing energy inefficiency: (1) aggressively capping the maximum CPU frequency, (2) lowering the CPU frequency by raising the GPU minimum frequency, and (3) allocating the frame rendering-related threads in the energy-efficient CPU cores. These techniques are integrated into a single governing framework, called the GFX Governor, and implemented in the newest Android-based smartphones. Experimental results show that without hampering the user's QoE the average energy consumption of Nexus 6P, Pixel XL, and Pixel 2 XL is reduced at the device level by 24.2\%, 18.6\%, and 13.7\%, respectively, for the 60 chosen applications. We also analyzed the efficacy of the proposed technique in comparison with the state-of-the-art Energy-Aware Scheduling (EAS) implemented in the latest smartphone.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {469–481},
numpages = {13},
keywords = {smartphones, heterogeneous multi-core platform, energy efficiency, dvfs, android graphics pipeline},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326083,
author = {Dang, Fan and Li, Zhenhua and Liu, Yunhao and Zhai, Ennan and Chen, Qi Alfred and Xu, Tianyin and Chen, Yan and Yang, Jingyu},
title = {Understanding Fileless Attacks on Linux-based IoT Devices with HoneyCloud},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326083},
doi = {10.1145/3307334.3326083},
abstract = {With the wide adoption, Linux-based IoT devices have emerged as one primary target of today's cyber attacks. Traditional malware-based attacks can quickly spread across these devices, but they are well-understood threats with effective defense techniques such as malware fingerprinting and community-based fingerprint sharing. Recently, fileless attacks---attacks that do not rely on malware files---have been increasing on Linux-based IoT devices, and posing significant threats to the security and privacy of IoT systems. Little has been known in terms of their characteristics and attack vectors, which hinders research and development efforts to defend against them. In this paper, we present our endeavor in understanding fileless attacks on Linux-based IoT devices in the wild. Over a span of twelve months, we deploy 4 hardware IoT honeypots and 108 specially designed software IoT honeypots, and successfully attract a wide variety of real-world IoT attacks. We present our measurement study on these attacks, with a focus on fileless attacks, including the prevalence, exploits, environments, and impacts. Our study further leads to multi-fold insights towards actionable defense strategies that can be adopted by IoT vendors and end users.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {482–493},
numpages = {12},
keywords = {iot, honeypot, fileless attack},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3326096,
author = {AlDuaij, Naser and Van't Hof, Alexander and Nieh, Jason},
title = {Heterogeneous Multi-Mobile Computing},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3326096},
doi = {10.1145/3307334.3326096},
abstract = {As smartphones and tablets proliferate, there is a growing demand for multi-mobile computing, the ability to combine multiple mobile systems into more capable ones. We present M2, a system for multi-mobile computing that enables existing unmodified mobile apps to share and combine multiple devices, including cameras, displays, speakers, microphones, sensors, GPS, and input. M2 introduces a new data-centric approach that leverages higher-level device abstractions and hardware acceleration to efficiently share device data, not API calls. To support heterogeneous devices, M2 introduces device transformation, a new technique to mix and match different types of devices. Example transformations include combining multiple displays into a single larger display for better viewing, or substituting accelerometer for touchscreen input to provide a Nintendo Wii-like experience with existing mobile gaming apps. We have implemented M2 and show that it (1) operates across heterogeneous systems, including multiple versions of Android and iOS, (2) can enable unmodified Android apps to use multiple mobile devices in new and powerful ways, including supporting users with disabilities and better audio conferencing, and (3) can run apps across mobile systems with modest overhead and qualitative performance indistinguishable from using local device hardware.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {494–507},
numpages = {14},
keywords = {remote display, operating systems, mobile devices, mobile computing, ios, distributed computing, android},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328596,
author = {Lee, Sangjae and Han, Dongsoo},
title = {Rover Who Make Indoor Radio Map (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328596},
doi = {10.1145/3307334.3328596},
abstract = {The fingerprinting-based indoor positioning technique requires a database, i.e., a radio map, containing indoor scenes through the training phase. Since that offline phase is labor intensive, numerous studies are underway to minimize the effort. In this paper, we present a concept that applies to a collaborative crowdsourcing method. We designed a system that relies on people and robots moving in the indoor space to construct a radio map. Experiments at two testbeds provide proof of the concept and are the result of the last step of the proposed system.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {508–509},
numpages = {2},
keywords = {radio map, indoor positioning, fingerprint, crowdsourcing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328597,
author = {Choi, Hyunwoo and Gong, Taesik and Kim, Jaehun and Shin, Jaemin and Lee, Sung-Ju},
title = {Dissecting 802.11ac Performance - Why You Should Turn Off MU-MIMO (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328597},
doi = {10.1145/3307334.3328597},
abstract = {While the recent Wi-Fi standard 802.11ac achieves Gb/s theoretical capacity with Multi-User MIMO (MU-MIMO) technology, several studies reported that throughput of 802.11ac in practice is far from Gb/s link speed. We investigate the downlink throughput of Wi-Fi systems with commercially available 802.11ac products in multiple indoor environments to reveal the throughput of MU-MIMO system that user experiences in practice. From our experiments, Single-User MIMO (SU-MIMO) outperformed MU-MIMO at every experimental environments. We further provide analysis on our experimental results considering channel sounding overhead, user grouping, environmental impact, and transmission mode selection.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {510–511},
numpages = {2},
keywords = {user experienced throughput, mu-mimo, 802.11ac},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328599,
author = {Kim, Kihwan and Kim, Sanghoon and Lee, Chunggi and Ko, Sungahn},
title = {Modeling Exploration/Exploitation Decisions through Mobile Sensing for Understanding Mechanisms of Addiction (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328599},
doi = {10.1145/3307334.3328599},
abstract = {Addiction is a brain disease manifested by the loss of control over drugs or behaviors, despite negative consequences. Although addiction research has been conducted for decades in psychiatry and neuroscience, a comprehensive understanding of the mechanisms underlying addiction has not yet been achieved. Recent studies in neuroscience [1] have sought to bring light upon this issue by measuring exploration/exploitation decisions in sequential choice tasks, requiring balancing the need to exploit known options and to explore new ones. These studies show a relationship between addiction and exploration/exploitation decisions. For example, people addicted to substances (e.g. alcohol or methamphetamine) or behaviors (e.g. gambling) have tendencies to explore less, which implies they have difficulties 'seeing the big picture".There is a small yet growing literature modeling explore/exploit decisions of addicted people through inverse reinforcement learning (IRL) [4]. In this previous work, the models made by decision history of addicted people have higher learning weights and probability to exploit than those of normal people, which means that addicted people are more sensitive to their most recent activity. However, existing methods to measure exploration/exploitation decisions are lab-based game experiments such as n-armed bandit [3] or clock task [6], which are high cost, time-consuming and not scalable. Therefore, they are not suitable for modeling through IRL, which requires large behavioral trajectories. In this work, we argue for the first time that mobile sensing is a more cost-efficient and scalable alternative to the lab-based game experiments for understanding and modeling the mechanisms of addiction (Figure 1).},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {512–513},
numpages = {2},
keywords = {mobile sensing, inverse reinforcement learning, computational psychiatry},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328601,
author = {Kim, Joon-Gyum and Gong, Taesik and Huang, Evey and Kim, Juho and Lee, Sung-Ju and Kim, Bogoan and Park, JaeYeon and Kim, Woojeong and Han, Kyungsik and Ko, JeongGil},
title = {Bringing Context into Emoji Recommendations (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328601},
doi = {10.1145/3307334.3328601},
abstract = {We present Reeboc that combines machine learning and k-means clustering to analyze the conversation of a chat, extract different emotions or topics of the conversation, and recommend emojis that represent various contexts to the user. Instead of simply analyzing a single input sentence, we consider recent sentences exchanged in a conversation. we performed a user study with 17 participants in 8 groups in a realistic mobile chat environment. Participants spent the least amount of time in identifying and selecting the emojis of their choice with Reeboc (38\% faster than without emoji recommendation).},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {514–515},
numpages = {2},
keywords = {user experience, mobile applications, machine learning, emoji recommendation},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328602,
author = {Jang, Sooyoung and Son, Youngsung},
title = {Virtual-to-Real Transfer via Dynamics Models (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328602},
doi = {10.1145/3307334.3328602},
abstract = {The virtual world is essential for deep reinforcement learning. Since the deep reinforcement learning agent learns the optimal policy by interacting with the environment in a trial and error manner, training the agent in the real world is not only cost expensive and time-consuming but also unsafe. Several researches are ongoing in the field of but not limited to drone, vehicle, and robot arm control as the deep reinforcement learning is proven to be an effective solution to sequential decision-making problems such as Atari games [2] and several board games including Go [4]. Due to the above issue, most of these researches are done in the virtual world that mimics the real world.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {516–517},
numpages = {2},
keywords = {virtual-to-real transfer, dynamics models, deep reinforcement learning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328603,
author = {Liu, Yang and Lin, Chengdong and Li, Zhenjiang and Liu, Zhidan and Wu, Kaishun},
title = {When Wearable Sensing Meets Arm Tracking (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328603},
doi = {10.1145/3307334.3328603},
abstract = {In this poster, we present our recent work, a wearable system for achieving real-time 3D arm skeleton. We have coped with the major challenge that the skeleton of each arm is determined from the locations of the elbow and wrist, whereas a wearable device only senses a single point from the wrist. Result shows that the potential solution space is huge. This underconstrained nature fundamentally challenges the achievement of accurate and real-time arm skeleton tracking. In this study, we propose Hidden Markov Model (HMM) state reorganization and hierarchical search two methods to improve the heavyweight computation of the state-of-art arm tracking model and achieve real-time tracking even on mobile phone.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {518–519},
numpages = {2},
keywords = {mobile sensing, arm tracking},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328604,
author = {Byun, Hyungho and Kim, Chong-kwon},
title = {When Friends Move: A Deep Learning-based Approach for Friendship Prediction in Mobility Network (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328604},
doi = {10.1145/3307334.3328604},
abstract = {Considering location data for friendship prediction has become prevalent due to the huge success of online social networks. However, few studies have focused on investigating the possibility of using mobility information in a dense place such as a campus. The research direction for those mobility networks should be treated differently. We propose a CNN-based noble framework for friendship prediction, which starts from collecting location data to a classification model to learn their relation between friendships and mobility. From the experiment, we show that our system outperforms empirical supervised learning techniques and also can be useful for friendship prediction of the future.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {520–521},
numpages = {2},
keywords = {recommendation, neural networks, link prediction, datasets, bluetooth low energy},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328605,
author = {Han, Yunha and Lee, Chunggi and Kim, Sanghoon and Ko, Sungahn},
title = {System Architecture for Progressive Augmented Reality (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328605},
doi = {10.1145/3307334.3328605},
abstract = {In spite of the evolution of Augmented Reality~(AR) technology, it is not wide spread in everyday life. There may be many reasons, but one of the reasons is that it has been developed for very specific users, such as researchers and professionals. To overcome this problem, Grubert et al. proposed the pervasive AR. It is not limited to a specific situation, but is usable in various instances and providing continuous and flexible AR experience. The AR browser is the example of utilizing pervasive AR. The AR browser understands the context of the user and provides corresponding information. However, if the corresponding information to the context of user cannot reach the user in time due to massive data transmission, unexpected network congestion, poor service quality or signal strength, it cannot be guaranteed to be continuous. This leads to a degradation of the user experience, and it cannot support pervasive AR. This paper presents the Progressive Augmented Reality, the way which quickly send incomplete, yet informative, response about the user's current context rather than wait for sending complete information to the user. The concept of Progressive Augmented Reality comes from Progressive Data Science. Our system is aware of network quality by collecting various network health parameters. According to the network status quality, it divides the chunk information to the optimal number and transmits the one that have the highest priority among the divided information. By conducting the above process iteratively, all the divided information is updated. Our client-side system utilizes Android ARCore and has been tested on Google Pixel 2XL.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {522–523},
numpages = {2},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328606,
author = {Kwon, Dohyun and Park, Soohyun and Kim, Joongheon},
title = {Multi-Agent Deep Reinforcement Learning for Connected Vehicles (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328606},
doi = {10.1145/3307334.3328606},
abstract = {The vehicles take a role of mobile devices so that resource management issue among them in cellular networks is getting highlighted. In addition, the millimeter-wave (mmWave) base station is expected to be included in existing heterogeneous networks. In this regard, we present a multi-agent deep reinforcement learning (MADRL) based resource allocation strategy for mobile devices in heterogeneous vehicular networks, which suffer from shortage issue of shared frequency band. The downlink throughput of each mobile device is cooperatively enhanced by the proposed MADRL method, and thus each mobile device associates with a base station and uses a frequency band within low delay.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {524–525},
numpages = {2},
keywords = {resource allocation, multi-agent deep reinforcement learning, connected vehicle},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328607,
author = {Choi, Hong-Beom and Lim, Keun-Woo and Ko, Young-Bae},
title = {Sensor Localization System for AR-assisted Disaster Relief Applications (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328607},
doi = {10.1145/3307334.3328607},
abstract = {In this poster, we propose a sensor localization system assisted by wireless communication and augmented reality (AR) suitable for disaster relief applications. Generally, disaster environments are considered extremely hazardous and deteriorated, with unpredictable effects to human mobility and digital devices. To maximize the safety and efficiency of first responders, deployment of wireless sensors are of utmost importance, as sensor nodes can provide sensing information as well as location information. We analyze the issues and challenges that need to be tackled for high accuracy localization of sensor nodes in such environments, and then propose a system that we plan to develop in the near future.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {526–527},
numpages = {2},
keywords = {visual odometry, sensor localization, disaster relief},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328608,
author = {Mun, Hyunsu and Lee, Hyungjin and Kim, Soohyun and Lee, Youngseok},
title = {Measurement of Smart Speaker Wake-up Response Time with Camera (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328608},
doi = {10.1145/3307334.3328608},
abstract = {Voice-controlled smart speakers are popular due to Amazon Echo and Google Home. Though many smart speakers have appeared in the market, we do not know the exact performance of smart speakers. In particular, when we call a smart speaker to issue a voice command, we recognize that the smart speaker is ready when it turns its LED lamps on. The wake-up response time is important for improving user experience. Therefore, we have to measure the wake-up response time, which requires the video analysis of smart speaker LED's status for the voice command. In this work, we present a smart speaker wake-up response time measurement method with a camera. We record video files with camera while testing a smart speaker and analyze image similarity to find a wake-up event. For this purpose, we use the Google Inception-v3 model to improve the accuracy of detecting the image change of a small area.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {528–529},
numpages = {2},
keywords = {wake-up response time, transfer learning, smart speaker, measurements},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328609,
author = {Zhang, Xianzhong and Zhao, Dong and Lyu, Dian and Ma, Huadong},
title = {AutoCUP: A Platform for Automatically Creating Aerial Panoramic Map with Multi-UAVs (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328609},
doi = {10.1145/3307334.3328609},
abstract = {Unmanned Aerial Vehicle (UAV) provides an effective way to create an Aerial Panoramic Map (APM). Generally, it consists of three steps: 1) select a set of locations from a map, 2) take photos from different angles at each selected location one by one, and 3) make panoramic images by the Panoramic Mosaic technology, and then create an APM with these images. However, it is always labor-intensive and time-consuming to complete these steps in a large region such as a campus and a park, due to multiple reasons: 1) inexperience for location selection, 2) low-efficiency for manually operating UAV to fly among different locations one by one and make photos from different angles, and 3) limited energy supply and low-efficiency for a single UAV. DJI GO[1] has been developed to simplify a part of operations in steps 2) and 3), by which we only need one button to take photos automatically from different angles at a selected location. However, it is still required to manually select locations and control UAV to fly among different locations. Moreover, the defects of using a single UAV still exist. By contrast, we aim to design an Auto nomously C ooperative U AV system platform for P anoramic map generation, AutoCUP, which leverages multiple UAVs to full-automatically and high-efficiently complete all steps of creating an APM.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {530},
numpages = {1},
keywords = {path planning, navigation, UAV, GCS},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328610,
author = {Li, Tengpeng and Nguyen, Nam Son and Zhang, Xiaoqian and Wang, Teng and Sheng, Bo},
title = {PROMAR: Practical Reference Object-based Multi-user Augmented Reality (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328610},
doi = {10.1145/3307334.3328610},
abstract = {Mobile Augmented Reality (MAR) represents an emerging category of applications that bring users interactive experiences with the physical experiencesnvironment. In such applications, users can place virtual objects in real-world space, and view them through a camera view. In this work, we develop a framework that supports multi-users interactions for MAR apps, where one user places a virtual object that can be recognized by other users.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {531–532},
numpages = {2},
keywords = {computer version, augmented reality},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328611,
author = {Ahn, Sumin},
title = {Automation of Memory Leak Detection and Correction on Android JNI (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328611},
doi = {10.1145/3307334.3328611},
abstract = {As many people use smartphones, many Android applications are being developed and distributed. They are usually written in Java, including C legacy libraries through Java native interface (JNI). To execute these applications written in Java, a virtual machine (VM) is required. For Android, Google's own Dalvic VM had been used, and recently Android Runtime (ART) is being used.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {533–534},
numpages = {2},
keywords = {memory leak, dynamic memory, JNI},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328729,
author = {Zhang, Tao and Zuck, Aviad and Porter, Donald E. and Tsafrir, Dan},
title = {Apps Can Quickly Destroy Your Mobile's Flash - Why They Don't, and How to Keep It That Way (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328729},
doi = {10.1145/3307334.3328729},
abstract = {Smartphones typically include flash-based storage, because flash offers benefits such as fast random access, shock resistance, high density, and decreasing costs. A main drawback, however, is that flash cells can tolerate only a limited number of writes before becoming unusable.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {535–536},
numpages = {2},
keywords = {flash storage, device lifespan, app characterization, android},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328612,
author = {Soleiman, Andreas and Varshney, Ambuj},
title = {Towards Backscatter-enabled Networked Utensils (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328612},
doi = {10.1145/3307334.3328612},
abstract = {Backscatter communication enables wireless transmissions at orders of magnitude lower power consumption when compared to conventional radio transceivers. This introduces novel opportunities for battery-free and ubiquitous sensing. We take advantage of backscatter communication to enable networked utensils. We imagine a scenario where such utensils can provide essential information about the state of the food or the beverage; for instance, the temperature or the quality of food contained in the utensils. We propose flex sensors, to achieve this capability, by augmenting utensils with flexible and inexpensive battery-free sensors that can communicate wirelessly. We demonstrate our efforts by designing a smart cup that tracks the temperature of the beverage.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {537–538},
numpages = {2},
keywords = {food quality monitoring, battery-free sensing, backscatter communication},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328613,
author = {Park, Gunhoo and Paek, Jeongyeup},
title = {Audio-based Drone Ranging and Localization using Deep Learning (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328613},
doi = {10.1145/3307334.3328613},
abstract = {As the use of micro-UAV (a.k.a drone) increases, distance measurement and localization of drones becomes important. We propose a real-time audio-based system that uses deep learning for not only detecting but also ranging and localization of a drone. In the proposed system scenario, each node records sound and sends it to the server after processing, and the server receives the data from each node and computes the final location of a drone. To explore the design space and investigate the feasibility of real-time acoustic ranging using deep learning, we first measure the drone detection accuracy and processing latency using two deep learning models (CNN, DNN) on both an embedded and a server-class device. By analyzing the relationship between detection probability and distance measurement, and comparing between binary and multi-class classification, we suggest a system design to range and localize the drone.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {539–540},
numpages = {2},
keywords = {ranging, localization, drone, deep learning, UAV},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328614,
author = {Tsai, Lillian and De Viti, Roberta and Lentz, Matthew and Saroiu, Stefan and Bhattacharjee, Bobby and Druschel, Peter},
title = {enClosure: Group Communication via Encounter Closures (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328614},
doi = {10.1145/3307334.3328614},
abstract = {New applications enabled by personal smart devices and the Internet-of-Things (IoT) require communication in the context of an encounter (a period of spatial co-location). However, existing encounter-based communication (EbC) systems are limited to communication among participants that share a direct encounter. This work is inspired by two insights: (1) encounters also enable group communication among devices connected by paths in the encounter graph that is contextual, spontaneous, secure, and privacy-preserving; and (2) addressing communication partners using encounter closures subject to causal, spatial, and temporal constraints enables powerful new forms of group communication. We present the design of enClosure, a service providing group communication based on encounter closures for mobile and IoT applications, and a prototype implementation for Android and the Microsoft Embedded Social Cloud platform. Using real-world traces, we show that enClosure provides a privacy-preserving, secure platform for a wide range of group communication applications ranging from connecting attendees of a large event to disseminating health risk warnings and tracing missing persons.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {541–542},
numpages = {2},
keywords = {privacy, mobile computing, internet-of-things (IoT), group communication, encounter-based communication},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328615,
author = {Arora, Nivedita and Xue, Qiuyue and Bansal, Dhruva and McAughan, Peter and Bahr, Ryan and Osorio, Diego and Ma, Xiaomeng and Sample, Alanson P. and Starner, Thad E. and Abowd, Gregory D.},
title = {Surface++: A Scalable and Self-sustainable Wireless Sound Sensing Surface (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328615},
doi = {10.1145/3307334.3328615},
abstract = {We present Surface++, which leverages our previous work SATURN, a self-powered flexible acoustic sensor, and ZEUSSS, a passive wireless sound communication technique using analog backscatter, to create a scalable and self-sustainable wireless sound sensing surface. Our new prototype allows for large area acoustic sensing using modular fabrication techniques with the promise of being fully printable. A single small Surface++ patch can be used to extend voice and gesture input for everyday surfaces, while our more sensitive Surface++ modular array allows for large-area context sensing and localization.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {543–544},
numpages = {2},
keywords = {vibration, triboelectric nanogenerator, sound, sensing, self-sustainable, low-power, interaction and control, flexible electronics, backscatter communication, acoustic localization},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328617,
author = {Ali, Jehad and Lee, Seungwoon and Roh, Byeong-hee},
title = {Using the Analytical Network Process for Controller Placement in Software Defined Networks (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328617},
doi = {10.1145/3307334.3328617},
abstract = {The Software Defined Networking (SDN) paradigm has shifted the network intelligence from the network devices to the centralized controller. The controllers are placed in a distributed manner in a network for reliability and load balancing. However, the placement of controllers considering the whole network is not an efficient approach because applying the objective function to the overall network is a challenging task. Therefore, the division of the network into clusters makes the assignment of the switches to the controller more efficient. The placement of the controller in a cluster not only reduces the latency between the switches and the controller but other objectives such as reliability, load balancing, robustness and energy saving can also be applied to the clusters. Therefore, in this poster, a multi-criteria-decision-making (MCDM) scheme known as the Analytical Network Process (ANP) is proposed for controller place selection using clustering.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {545–546},
numpages = {2},
keywords = {multi-objective, controller placement problem, analytical network process, SDN},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328618,
author = {Tariq, Shahroz and Kim, Hoyoung and Ryoo, Jihoon},
title = {AuthGPS: Lightweight GPS Authentication against GPS and LTE Spoofing (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328618},
doi = {10.1145/3307334.3328618},
abstract = {While GPS (Global Positioning System) navigation and GPS based autonomous car driving techniques are mature, the security of GPS signal has not been a primary system concern. In fact, it has been shown that an ordinary GPS can be easily spoofed by a low-cost, open-source based software defined radio (SDR) system such as bladeRF and HackRF [3, 4] which can cause serious complications to the navigation system of the car especially for self-driving cars which are driven based on the information from sensors, cameras, and GPS. In this work, we design a new GPS authentication system called lightweight authentication GPS (AuthGPS) to authenticate GPS signal against GPS spoofing and LTE base station broadcast message spoofing. In the past, there have been many successful attempts on GPS spoofing which resulted in shifting the destination of the car to the spoofer's desired location. In a case where the car is connected to the Internet via LTE network, the navigation system can find out if the GPS is spoofed by acquiring the correct GPS satellite information from LTE base stations' location information. However, a skillful attacker can spoof the LTE base station signals [7] as well using another SDR which will produce spoofed LTE base station information. Hence giving wrong information about GPSinformation according to the will of the attacker. Currently, there are defense methods against the GPS spoofing [6]. One of them is signal-processing-based methods. By monitoring unusual or unreasonable signal changes at GPS receivers, GPS spoofing attack can be detected. Received Power Monitoring (RPM) looks at all the received amplitude and automatic gain control (AGC) setpoint [1]. The receiver will sense drastic power jump if a spoofing attack occurs. However, an overly powerful spoofing attack with noise is not detectable in the case of this mechanism. Another way to detect spoofing is the symmetric-key encryption mechanism of GPS signals. According to previous research [2], encrypted precision code for anti-spoofing referred to as P(Y) code, might not be able to be spoofed. A spoofing attack can be detected by calculating cross-correlation between spoofed coarse/acquisition code, referred to as C/A code, and P(Y) code. Unfortunately, this P(Y) code is only for military purpose while the C/A code can be publicly accessible. This method requires knowledge of specific key which is not revealed to the public to decrypt P(Y) code. Monitoring the direction of arrival of the signals can be one of the methods [6]. A GPS receiver measures the direction-of-arrival vector with more than 3 antennas. Even though this signal-geometrybased system with multiple antennas makes GPS robust, an attacker can spoof signals from multiple directions, which is more difficult to detect the spoofing. The idea here is to develop a system that can discriminate the spoofed signal without complex computation or heavy message exchange. An important component of AuthGPS is a verification of valid GPS satellite information via LTE base stations' location information. We propose 6-digit one-time password-based authentication system in this paper.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {547–548},
numpages = {2},
keywords = {mobile and wireless security, LTE authentication, GPS spoofing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328619,
author = {Lee, Ahyun and Jang, Insung},
title = {Visualization of City model with VWorld (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328619},
doi = {10.1145/3307334.3328619},
abstract = {The VWorld Data Center provides high quality spatial information data with 3D terrains and buildings of major cities in Korea. In this paper, we proposed the visualization method for the city model using VWorld data. Anyone can use through the VWorld 3D map service site. We expect that our platform can be used to visualize 3D spatial information for various applications.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {549},
numpages = {1},
keywords = {vworld, gis, 3d map},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328620,
author = {Park, Eunjeong and Lee, Myung-Sup and Bahk, Saewoong},
title = {Data Rate and Transmission Power Adaptation for Bluetooth Low Energy (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328620},
doi = {10.1145/3307334.3328620},
abstract = {The use of Bluetooth Low Energy (BLE) has steadily increased since 2010. Bluetooth specification 4.2 defined only one data rate, 1 Mb/s. However, Bluetooth specification 5 released in 2016 specifies 2 Mb/s and coded PHY for higher throughput and for more stable transmission, respectively. In addition, this version of specification defines transmission power from -20 dBm to 20 dBm. In this paper, we propose AdaptaBLE, an algorithm that selects the data rate and transmission power of BLE by considering link stability and energy consumption. We implement AdaptaBLE on real devices and measure its performance. As a result, we confirm that AdaptaBLE successfully lowers energy consumption while keeping the link stable.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {550–551},
numpages = {2},
keywords = {rate adaptation, power adaptation, bluetooth low energy},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328621,
author = {Kim, Donghwi and Park, Soo Young and Ko, Jihoon and Ko, Steven Y. and Lee, Sung-Ju},
title = {Prototyping Functional Android App Features with ProDroid (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328621},
doi = {10.1145/3307334.3328621},
abstract = {We present ProDroid, a framework that provides Android app developers an ability to quickly produce functional prototypes. With ProDroid, developers can create a new app that imports various kinds of functionality provided by other existing Android apps. Our evaluation shows that with the help of ProDroid, a developer was able to import a function from an existing Android app into a new prototype with only 55 lines of Java code, while the function itself requires 10,334 lines of Java code to implement.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {552–553},
numpages = {2},
keywords = {functional prototyping, development frameworks, android},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328622,
author = {Gong, Taesik and Kim, Yeonsu and Shin, Jinwoo and Lee, Sung-Ju},
title = {Towards Condition-Independent Deep Mobile Sensing (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328622},
doi = {10.1145/3307334.3328622},
abstract = {Deep mobile sensing applications are suffering from various individual conditions in the wild. We propose a meta-learned adaptation technique to adapt to a target condition with a few labeled data. We evaluate our system on a public dataset and it outperforms baselines.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {554–555},
numpages = {2},
keywords = {speech recognition, mobile sensing, deep learning, activity recognition},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328623,
author = {Berkner, Joseph},
title = {Sensorless Indoor Localization Utilizing Collaborative Data Acquisition through Gamification (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328623},
doi = {10.1145/3307334.3328623},
abstract = {Most of the currently developed indoor localization techniques depend on some kind of sensory input, utilizing, among others, WiFi-signals (e.g. [2]), smartphone sensors (e.g. [4]) or Bluetooth beacons (e.g. [1]). However, each of these systems has its own downsides, such as a lack of infrastructure, power consumption and proneness to noise. These are the reasons no such system is currently able to be truly considered as the "GPS for the indoors", as they cannot provide worldwide coverage.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {556–557},
numpages = {2},
keywords = {sensor-independent, landmarks, isovist, indoor localization},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328624,
author = {Urano, Kenta and Hiroi, Kei and Yonezawa, Takuro and Kawaguchi, Nobuo},
title = {Basic Study of BLE Indoor Localization using LSTM-based Neural Network (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328624},
doi = {10.1145/3307334.3328624},
abstract = {In this paper, LSTM-based neural network is applied to indoor localization using mobile BLE tag's signal strength collected by multiple scanners. Stability of signal strength is a critical factor of wireless indoor localization for higher accuracy. While traditional methods like trilateration and fingerprinting suffer from noise and packet loss, deep learning based methods perform well. We focus on large-scale exhibition where wireless signal gets unstable due to many people. Proposed neural network consists of fully connected layers for noise removal and LSTM layers for time-series feature extraction. The network takes the time-series of signal strength as input and outputs the estimated location. In the evaluation, the number of layers is changed to find the optimal structure. As a result, the best configuration achieved the error of 2.44m at 75 percentile for the data of a large-scale exhibition in Tokyo.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {558–559},
numpages = {2},
keywords = {lstm, indoor localization, deep learning, ble},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328625,
author = {Alawami, Mohsen A. and Aiken, William and Kim, Hyoungshick},
title = {The Light Will Be with You. Always -- A Novel Continuous Mobile Authentication with the Light Sensor (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328625},
doi = {10.1145/3307334.3328625},
abstract = {Existing continuous authentication proposals tend to have two major drawbacks. First, touch-based smartphone authentication approaches typically require explicit user interactions with the smartphone to collect sufficient touch data. These approaches may provide an attacker the opportunity to steal a victim's sensitive data before the system detects the attacker's intrusion. Likewise, an attacker may disable the continuous authentication scheme itself before detection. Second, sensor-based continuous authentication approaches inherently suffer from high energy consumption due to the constant usage of multiple sensors. In this paper, we present a novel continuous authentication system that collects light sensor data from a user's smartphone and analyzes them to authenticate users using support vector machines. We focus on the possibility of collecting light sensor data from users' smartphones while they are conducting daily behaviors to develop an anomaly detection system.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {560–561},
numpages = {2},
keywords = {smartphones, machine learning, light readings, indoor environments, continuous mobile authentication},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328626,
author = {Tazawa, Kouki and Hamada, Kana and Hara, Michiki and Komazawa, Makoto and Tobe, Yoshito},
title = {Relationship Between LF/HF Value in Heart Rate and Used Mobile Applications (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328626},
doi = {10.1145/3307334.3328626},
abstract = {We explore the possibility of detecting person's mood with the usage pattern of mobile applications. Towards this ultimate goal, we first examine the relationship between LF/HF values in heart rate and the CDR (Call Detail Record) logs. Our evaluation result shows that different LF/HF values correspond to different types of mobile applications.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {562–563},
numpages = {2},
keywords = {mobile application, lf/hf, kolmogorov-smirnov test},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328627,
author = {Allen, Ryan and Nekrasov, Michael and Belding, Elizabeth},
title = {Data Collection from Outdoor IoT 802.15.4 Sensor Networks using Unmanned Aerial Systems (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328627},
doi = {10.1145/3307334.3328627},
abstract = {Unmanned Aircraft Systems (UAS) are a promising technology for data collection from outdoor sensor networks. Environmental and agricultural networks may not have existing internet backhauls for data delivery due to low population densities in rural areas, making UASs a potential data delivery alternative. UASs can be deployed as aerial network relay nodes [1, 2, 3, 4] or as data mules [5, 6]. In addition to mending network fragmentation, UAS applications include post-disaster data collection involving inoperative communication infrastructure [7, 8, 9], supplementing existing communication in- frastructure for vehicular networks [10], and rural applications in environmental monitoring [11, 12] and precision agriculture [13, 14].},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {564–565},
numpages = {2},
keywords = {wireless networks, uav, uas, sensor network, internet of things, experimental measurements, drone, aerial networks, 802.15.4},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328628,
author = {Luo, Jiaqing and Shin, Kang G.},
title = {Detection of Misplaced Stationary RFID Tags (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328628},
doi = {10.1145/3307334.3328628},
abstract = {A smart shelving system can visualize stock data in real time by leveraging item-level RFID tagging. The detection of misplaced tags on stationary shelved items is very challenging due to position ambiguity, phase wrapping, device diversity, and phase ambiguity. We propose an effective way of detecting misplaced tags, called FINDS, that requires neither antenna movement nor external disturbances.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {566–567},
numpages = {2},
keywords = {stationary tags, rfid, misplaced tags},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328629,
author = {Park, JaeYeon and Cho, Hyeon and Hwang, Wonjun and Balan, Rajesh Krishna and Ko, JeongGil},
title = {Deep ECG Wave Estimation Model with Seismograph Sensor (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328629},
doi = {10.1145/3307334.3328629},
abstract = {Electrocardiogram (ECG) signals offer rich information for analyzing and understanding the cardiac activity of a person. The continuous monitoring of ECG can help diagnose cardiac disorders, such as arrhythmia, effectively. While many wearable healthcare platforms offer continuous ECG monitoring, these devices are cumbersome in the fact that they need to be continuously attached to the human body, which causes uncomfortableness, and limits their usage when monitoring a person's ECG throughout the night as they sleep. In this work, we propose a fully non-intrusive sensing system for monitoring the ECG of a person while in bed. Specifically, we present Heartquake, a geophone-based sensing system for extracting ECG patterns using heartbeat vibrations that penetrate through the mattress. The cardiac activity-originated vibration patterns are captured on the geophone and sent to a server, where the data is filtered to remove external noise and passed on to a bidirectional long short term memory (Bi-LSTM) deep learning model for ECG waveform extraction. Our experimental results with 21study participants suggest that Heartquake can detect all five ECG peaks (e.g., P, Q, R, S, T) with an average error of as low as 16 msec when participants are stationary on the bed. With additional noise factors, this error shows an increase, but can be mitigated from model personalization to still be sufficient enough as a screening tool to detect urgent situations.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {568–569},
numpages = {2},
keywords = {signal estimation, seismograph, seismocardiogram (scg), noise filter, electrocardiogram (ecg), bi-lstm},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328630,
author = {Boo, EunSeong and Raza, Shahid and H\"{o}glund, Joel and Ko, JeongGil},
title = {Towards Supporting IoT Device Storage and Network Security Using DTLS (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328630},
doi = {10.1145/3307334.3328630},
abstract = {This work presents FDTLS, a security framework that combines storage and network/communication-level security for resource limited Internet of Things (IoT) devices using Datagram Transport Layer Security (DTLS). While coalescing storage and networking security scheme can reduce redundent and unnecessary operations, we identify security- and system-level challenges that can occur when applying DTLS. FDTLS addresses these challenges by employing asymmetric key generation, a virtual peer, and header reduction-based storage optimization. Our results obtained using a Contiki-based implementation on OpenMote platforms show that compared to using storage and networking security separately, FDTLS can reduce the latency of packet transmission responses and also contribute to saving energy.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {570–571},
numpages = {2},
keywords = {self-key generation, secure internet of things, dtls},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328631,
author = {Kim, Dongwoo and Lee, Euihyeok and Kang, Seungwoo},
title = {Expediting IoT Application Testing (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328631},
doi = {10.1145/3307334.3328631},
abstract = {We propose TITAN, a tool that enables efficient testing of IoT applications during a development process. TITAN is designed to allow developers to execute and verify IoT applications in a development environment without being constrained by the physical environment and user behaviors required to test the application logic being developed. We present the initial design and prototype of TITAN and the preliminary study to evaluate its usefulness.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {572–573},
numpages = {2},
keywords = {testing, iot application, development tool},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328632,
author = {Miyagawa, Yuta and Segawa, Norihisa and Yazawa, Masato and Yamamoto, Masa-yuki},
title = {Development of a Low-cost Gas Sensor Unit for Wide Area Air Pollution Monitoring System (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328632},
doi = {10.1145/3307334.3328632},
abstract = {In this paper, we discuss the development of a low cost sensor unit for the monitoring of nitrogen dioxide (NO2). The developed sensor unit can operate at 267.21 mW and collect NO2 concentration, temperature, and relative humidity. The sensor unit was installed outdoors near a main road, for a 122 h experiment. The data collected from the sensor unit were stable. Further, the selected electrochemical NO2 sensor was effective, confirming that NO2 concentrations were high on weekdays (during heavy traffic) and low at night.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {574–575},
numpages = {2},
keywords = {nitrogen dioxide, monitoring system, air pollution},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328633,
author = {Toshnazarov, Kobiljon and Baazizi, Hamza and Narziev, Nematjon and Noh, Youngtae and Lee, Uichin},
title = {EasyTrack - Orchestrating Large-scale Mobile User Experimental Studies (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328633},
doi = {10.1145/3307334.3328633},
abstract = {In recent years, large-scale data collection has become crucial in Human-Computer Interaction (HCI) research. With a sharp climb of the amount of data being gathered due to an increasing number of mobile and wearable devices, real-time maintenance of Data Quality (DQ) of data-collection campaigns has already become an overwhelming task, especially in large-scale experiments. This paper proposes EasyTrack, a platform that collects large-scale data in an automatized manners. We describe how our proposed solution detects and tackles issues in data collection campaigns in an automated manner.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {576–577},
numpages = {2},
keywords = {wearable devices, user studies, streaming sensor data, human-computer interaction, human-centered computing, data quality},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328634,
author = {Kalm\'{a}r, Gy\"{o}rgy and Wittemyer, George and V\"{o}lgyesi, P\'{e}ter and Rasmussen, Henrik Barner and Mar\'{o}ti, Mikl\'{o}s and L\'{e}deczi, \'{A}kos},
title = {Animal-Borne Acoustic Gunshot Detector (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328634},
doi = {10.1145/3307334.3328634},
abstract = {Poaching is one of the primary drivers of wildlife decline [1]. Animalborne sensors, particularly GPS-equipped collars, are used to enhance real-time wildlife protection. Innovations that can be integrated into these systems can immediately scale, offering broad application. GPS tracking data streams have been valuable to resolve a number of conservation challenges, but these systems have not been particularly effective in identifying poaching in real-time. Detecting poaching events is a critical need to provide actionable information for law enforcement.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {578–579},
numpages = {2},
keywords = {wearable, shockwave, poaching, low-power, acoustics},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328635,
author = {Shin, Hoon and Han, Dongsoo},
title = {Detecting Arrivals and Departure of Subway Train Using Linear Accelerometer (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328635},
doi = {10.1145/3307334.3328635},
abstract = {Subway is one of the public transport which carries people at the exact time. In the metropolis all over the world, it transfers countless people in the rush hour. Since there is no traffic jam in the subway, accuracy is one of the most crucial characters of the subway. However, subway trains are often delayed by some reasons like an accident. The delay can make many people confused and inconvenient. In this context, the need for dynamic timetable model which corrects the error of timetable in real time has emerged. Since the method to detect train moving is necessary to modify timetable, various solutions are proposed in the indoor positioning way, such as Wi-Fi fingerprint, magnetometer and so on. A method using Wi-Fi fingerprint is a primary way in indoor positioning, but it is tough to build a radio map for every single station. Shin et al. suggested a solution using a magnetometer, with simple judging criteria named 'decision peak.' This research proved that a magnetometer is a practical solution. Nonetheless, it can not detect the train moving in some cases. We propose a new method to detect the subway moving using a linear accelerometer, based on the essence of the problem.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {580–581},
numpages = {2},
keywords = {subway timetable, sensing data, linear accelerometer},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328636,
author = {Kang, Hangil and Baek, Duin and Ryoo, Jihoon},
title = {Saliency based 360° Video Contents Encoding for Streaming Service (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328636},
doi = {10.1145/3307334.3328636},
abstract = {Video streaming service has been essential to the Internet ecosystem since a majority of Internet contents is consumed via streaming ser-vices, such as Netflix and Youtube [3]. Moreover, contents providers started to upload 4K and even 8K videos on streaming service to satisfy users' demand for higher quality of streaming service in accordance with the recent refinement on display technology.However, the available bandwidth in most of the developed countries can barely support single full HD contents streaming service [1]. Such bandwidth shortage intensifies in 360 video streaming service even at a larger scale, as 360 video contents providers started to upload 4K or 8K videos at the higher frame rate(60FPS or 120FPS). No current ISP (Internet service provider) can sustain the bandwidth needed for such scale of video contents [1]. To overcome the aforementioned network limitations, many re-searchers and engineers suggested ingenious mechanisms to reduce contents size. One of the mechanisms is viewport-only streaming service that streams a partial region in each video frame that fits in the exact viewport in an HMD device (e.g., HTC Vive, OculusVR, Google Daydream VR, and Samsung GearVR) in real-time [6].Assuming the size of the viewport is set to 90 degree, the bandwidth required for the viewport-only streaming service can be approximately reduced by an eighth of the original 360 video. Although the viewport-only streaming service can reduce con-tents size significantly, it is infeasible yet due to the existing streaming network latency. Even with the state-of-the-art content delivery network (CDN), viewport-only streaming service cannot satisfy the 10ms latency requirement in the standard Internet as demonstrated in other interactive multimedia systems [4]. Consequently, viewers can suffer discontinuity of streaming contents even in the highly optimized streaming service [8]. Thus, the research trend moved to the viewport adaptive stream-ing service that buffers segments of contents where a viewport Such reduction of contents size is achieved by the contents compression process that provides the original resolution in the Field ofView(FoV) while compromising the video quality outside the FoV. Despite the reduction of contents size and delivery of navigable 360 video contents, viewport adaptive streaming service cannot accommodate viewers' head movement within buffered video frames,especially when a viewer's focal point deviates from the viewport within the buffered frames. In this case, viewers can experience video distortions or degradation of resolutions [8]. Therefore, anew encoding mechanism that can handle viewers' deviation from the viewport while reducing contents size is required for viewers'immersive experience.To answer the requirements, we propose a saliency-based view-port adaptive streaming service, SALI360 that focuses on improving viewers' quality of perception in 360 video contents. To achieve high perception quality, we first adopt visual saliency model [9]to predict fixation regions in 360 video contents. Then we render the fixation regions on top of the geometry based encoded regions.Specifically, SALI360 encodes the peripheral regions in lower resolution to reduce the contents size, and encodes the fixation regions in higher resolution to increase the quality of perception.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {582–583},
numpages = {2},
keywords = {virtual reality, viewport adaptive streaming service, saliency, 360 video},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328637,
author = {Son, Jinho and Jo, Hyunwoo and Nyang, Daehun and Noh, Youngtae},
title = {Distributed Network Resource Sharing AP in Inter-WLAN Environments (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328637},
doi = {10.1145/3307334.3328637},
abstract = {As the number of wireless device deployments grows, it is desirable to share the highly limited wireless bandwidth efficiently and cooperatively. In WLAN, using a central controller for resource sharing and management is a common practice in mid-size and large-size network. However, in case of small businesses (i.e., restaurants, coffee shops, etc.), business owners cannot afford to obtain the controller. To realize the bandwidth sharing among Access Points (AP) in a distribute manner, seamless handoff of mobile devices (i.e., smartphones and tablets) between small-business owned Access Points (APs) via association control and maintain stable TCP connection are essential but quite challenging. This poster proposes a novel way to cooperatively share wireless resources among the APs. This includes an efficient association control between stations and APs, dedicated virtual access point per station, and tunneling support maintaining existing TCP connection after relocation to another AP.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {584–585},
numpages = {2},
keywords = {wireless network, wifi, virtual access point, distribued network},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328638,
author = {Park, Boseok and Kim, Sangwook},
title = {Intrusion Detection on IoT Services using Event Sampling and Correlation (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328638},
doi = {10.1145/3307334.3328638},
abstract = {The IoT services have different types of security frameworks. As a result, it is difficult for security manager or attack response systems to understand the alerts and take appropriate actions. In this paper, we describes the analysis of security methods in the area of IoT and describes a mechanism that analyzes logs generated by IoT devices attacks. We models an event network based on a graph of interconnected logs between network devices and IoT gateways. Moreover, suggests an algorithm that correlate logs into single meaningful messages.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {586–587},
numpages = {2},
keywords = {network security, intrusion detection, internet of things, event correlation},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328639,
author = {Jung, Hyungkun and Lee, Kang-Woo and Cho, Eun-Sun},
title = {Outlier Detection for Ship Trajectory Prediction (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328639},
doi = {10.1145/3307334.3328639},
abstract = {The ACM International Conference on Distributed and Eventbased Systems (ACM DEBS) Grand Challenge is aiming to build faster and more accurate distributed and event based systems. In 2018, the goal of the Grand Challenge was to make predictions for vessels' destinations and arrival times. In our previous work [3], as a participant of the Grand Challenge, we adopted a grid-based Bayesian inference model to yield a decent result. However, we found that a number of serious outliers in the real-world data may adversely affect predictions. This paper introduces our attempts to enhance the performance of the previous model for predicting the destination and arrival time of a vessel issued by ACM DEBS GC 2018, by proposing an outlier detection method based on clustering and refning training data.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {588–589},
numpages = {2},
keywords = {trajectory clustering, ship trajectory, outlier detection},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328640,
author = {Kang, Sungjoo and Lee, Junhee and Jeon, Jaeho and Chun, Ingeol},
title = {Multi-Access Edge Computing based Simulation Offloading for 5G Mobile Application (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328640},
doi = {10.1145/3307334.3328640},
abstract = {Simulation is a method of predicting future events and system states through analysis of the state model of the system over time. It can support to make decisions of mobile terminals (ex. threat assessment in an autonomous vehicle) operating in various situations under uncertain reality. Unlike a single simulation, which is executed in one mobile terminal using data collected from the same terminal, a multiple simulation, which supports to make sophisticated decisions through data collected from multiple terminals, is not only complicated to implement but also requires a large number of computations and has network delay problem in collecting data from plenty of data sources [1]. Consequently, it is impossible to implement in a single mobile terminal.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {590–591},
numpages = {2},
keywords = {simulation-as-a-service, simulation offloading, multi-access edge computing, kubernetes},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328641,
author = {Segawa, Norihisa and Yazawa, Masato and Yamamoto, Masa-yuki},
title = {Sensor Network for Transmitting Tsunami Information using MAD-SS Technology in Tosa Bay (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328641},
doi = {10.1145/3307334.3328641},
abstract = {In Japan, more than 1,000 earthquakes occur annually, thus causing enormous damage. However, in areas facing the ocean, the risks of secondary disasters due to tsunamis are extremely high. We conducted research the on an emergency disaster prevention system for transmitting tsunami information using ultra-low- frequency sound sensors and tide-level gauges. The system conveyed the information to members in the crisis management staff for the area concerned, and we assumed that the staff in charge made evacuation recommendations to the citizens of the area based on the information. In addition, when a tsunami occurs, there is a high possibility that an existing infrastructure cannot be used because an earthquake has already occurred. In this research, we develop a disaster prevention system using tsunami information using long-distance wireless communication technology, MAD-SS.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {592–593},
numpages = {2},
keywords = {sensor network, narrow band spread spectrum, lpwa, direct sequence of spread spectrum communication (ds-ss)},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328642,
author = {Cherrared, Sihem and Imadali, Sofiane and Fabre, Eric and G\"{o}ssler, Gregor},
title = {SAKURA a Model Based Root Cause Analysis Framework for vIMS (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328642},
doi = {10.1145/3307334.3328642},
abstract = {Model based machine learning (MBML) techniques solve novel diagnosis problems and provide explanations for their decisions. However, current MBMLs suffer some limitations, since virtualization of network brings new challenges such as the dynamic topology and elasticity. Those limitations include the high dependency on previous knowledge and the difficulty to represent the model. To face those limitations, we propose SAKURA: a root cause analysis framework for the virtual Ip Multimedia Subsystem (vIMS). SAKURA is composed of a self-modeling and a constraints solver.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {594–595},
numpages = {2},
keywords = {service function chain, self-modeling, root cause analysis},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328643,
author = {Li, Biyi and Cheng, Bo and Wang, Meng and Niu, Meng and Chen, Junliang},
title = {A Lightweight Network Slicing Orchestration Architecture (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328643},
doi = {10.1145/3307334.3328643},
abstract = {With the explosive growth of large scale services, traditional mobile networks have become increasingly unable to guarantee the efficient operation of services. However in the fifth generation (5G), supported by Software Defined Network (SDN) and Network Function Virtualization (NFV), network slicing technology [1] makes mobile networks more intelligent and flexible. 5G network slicing allows a set of logically independent virtual networks to be created on a common physical infrastructure and provides appropriate monitoring, management and resource allocation for a variety of different types of communication services [2].},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {596–597},
numpages = {2},
keywords = {template, network slicing, network interface, network function virtualization},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328644,
author = {Park, Seongjoon and Lee, Joon Yeop and Um, Inseop and Joe, Changhwan and Kim, Hyeong Tae and Kim, Hwangnam},
title = {RC Function Virtualization - You Can Remote Control Drone Squadrons (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328644},
doi = {10.1145/3307334.3328644},
abstract = {This poster presents a virtual control interface for Unmanned Vehicle System (UVS), to improve scalability and accessibility of Human-Computer Interaction (HCI) in their maneuvering. After the first remote control vehicle was born, the remote control unit was paired with a single vehicle for safety and security. To overcome this constrained remote control design, we propose a concept that a single manufacturing stand-alone RC can control one or several unmanned vehicles (UVs), regardless of vehicle type, named RC Function Virtualization (RFV). We can abstract the RC input to a high-level set of control commands and apply it to the numerous types of UVs connected through a wireless network. Our contribution is the separation of the RC and UV pairs so that the user can control all types of UVs even mixed types of UVs. We implemented the prototype of the RFV system, and demonstrated with Unmanned Ground Vehicle (UGV), Unmanned Air Vehicle (UAV), and the combinations of them, with only one RC.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {598–599},
numpages = {2},
keywords = {unmanned vehicle system, remote control virtualization, multi robot control},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328645,
author = {Rehman, Ubaid Ur and Lee, Sungyoung},
title = {Natural Language Voice based Authentication Mechanism for Smartphones (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328645},
doi = {10.1145/3307334.3328645},
abstract = {We have designed and implement a random text dependent voice based authentication protocol for smartphones. The objective was to provide an efficient and reliable authentication mechanism that ensure prevention against the emerging attacks. In this paper, we have focused on the architecture, protocol, and prevention against replay attack only.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {600–601},
numpages = {2},
keywords = {voice, smartphones, replay attack, authentication},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328646,
author = {Lee, Jihyun and Park, Gyeongcheol and Jung, Hyunggu},
title = {SEEjang: Smart, Easy, and Economical Offline Shopping Assist App Development through a Design Thinking Proces (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328646},
doi = {10.1145/3307334.3328646},
abstract = {It is difficult for shoppers to estimate the amount of cost spent while shopping offline. Existing mobile platforms can be used to assist offline shoppers, but there still remain questions about the usability and affordability of such platforms. To reduce this gap, we propose SEEjang, a prototype for providing users with a smart, easy, and economical experience with offline shopping. We developed the application through a design thinking process to maximize consumer satisfaction with offline shopping.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {602–603},
numpages = {2},
keywords = {user centered design, offline shopping experiences, mobile computing, human-computer interaction, design thinking},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328647,
author = {Zhang, Dan and Woo, Simon S.},
title = {Predicting Air Quality using Moving Sensors (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328647},
doi = {10.1145/3307334.3328647},
abstract = {In recent years, interest in measuring air quality has spiked due to rising environmental and health concerns in South Korea. In particular, microfine dust (microdust) is known to cause serious health issues to people. Therefore, measuring and predicting mircodust is an important problem. A typical way of measuring microdust is to use sensors from fixed location. However, this cannot capture the local dynamics of microdust and is limited to accurate measurement near fixed locations. Therefore, there is an immediate need to provide more accurate local air quality measurements in the areas where fixed local sensors are not installed. In this preliminary research, we focus on modeling the air quality pattern in a given local area by using vehicles equipped with cheap IoT sensors, where vehicles move around the area. As a pilot study, We measured the microdust level running experiments for 2 weeks with 3 different cars. Also, we developed an machine learning algorithm to better predict the local air quality using moving sensors. Further, we built an application where measured air quality is reported to the end users. We demonstrated the feasibility of using inexpensive IoT sensors in moving vehicles to provide better local air quality to end users.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {604–605},
numpages = {2},
keywords = {real time prediction, mobile sensors, machine learning, air quality},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328648,
author = {Shen, Yilin and Nama, Sandeep and Jin, Hongxia},
title = {Teach Once and Use Everywhere -- Building AI Assistant Eco-Skills via User Instruction and Demonstration (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328648},
doi = {10.1145/3307334.3328648},
abstract = {Voice-enabled AI assistants rely on developers to build every single skill, although many skills share similar functions. We propose a concept and prototype system, ksystem, to automatically build a set of similar skills in the ecosystem (eco-skills) with one-time teaching from end users. During teaching, a user only needs to demonstrate on the screen in one (native) mobile app and provides natural language (NL) instructions.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {606–607},
numpages = {2},
keywords = {eco-skill development for ai assistants, auto natural language development, auto action fulfillment},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328649,
author = {Lee, HyunJong and Lee, Hee Won and Ra, Moo-Ryong and Xiang, Yu and Flinn, Jason},
title = {Accelerating Applications in the Fast-moving Devices with Proactive Provisioning (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328649},
doi = {10.1145/3307334.3328649},
abstract = {An increasing number of applications that leverage built-in sensors is hosted on new types of devices such as vehicles and drones. Example applications are augmented reality Head-Up-Display in a connected car [2], scout drone that chases a target suspect among the crowd [3], autonomous fleet drones [1], and so on. These futuristic applications in various genres of devices are latency-sensitive and require a significant computation power to process a tremendous amount of data from built-in sensors [8]. However, the capabilities of processors shipped with these devices are limited. A natural solution is offloading to an edge surrogate,1 running on a 'nearby' edge-cloud that offers more computation capacity at low latency.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {608–609},
numpages = {2},
keywords = {proactive provisioning, fast-moving devices, edge provisioning, edge node prediction},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328650,
author = {Vishwanathan, Harishankar and Park, Chang Min and Mishra, Sidharth Kumar and Dantu, Karthik and Ko, Steven Y. and Ziarek, Lukasz},
title = {Partitioning Garbage Collection Between the Secure and Normal Worlds for Trusted Applications (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328650},
doi = {10.1145/3307334.3328650},
abstract = {Trusted Applications (TAs) written for Trusted Execution Environments (TEEs) using ARM TrustZone are currently written in C; there is limited support for higher-level languages. This leads to common manual memory management problems like buffer overflow and use-after-free. Higher-level languages, which have managed runtimes, allow for automated memory management, the benefits of which are widely accepted. To allow for automated memory management of TAs, we need to have a runtime that handles allocation and garbage collection (GC). However, having the entire allocator and GC in the secure world would increase the Trusted Computing Base (TCB) of the secure world. We propose TrustGC, a mechanism to partition garbage collection and allocation between the secure world and the normal world. TrustGC allows for automated memory management of TAs by leveraging the help of a GC partly running in the normal world.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {610–611},
numpages = {2},
keywords = {trustzone, security, memory management, garbage collection},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328651,
author = {Tao, Linfeng and Xu, Rui and Tian, Teng and Xiang, Zikun and Li, Yifei and Jin, Xi and Ren, Jun and Li, Zhengda and Li, Chenxia},
title = {CINT -- An Energy-efficient Mixed-signal In-Memory CNN Accelerator Based on NOR Flash Memory (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328651},
doi = {10.1145/3307334.3328651},
abstract = {Convolutional neural network (CNN) is a power-hungry and resource-consuming application, which makes it hard to deploy on end devices. We propose a method to perform convolution operations in NOR flash memory. Experiment results show that our method has great performance and high energy efficiency.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {612–613},
numpages = {2},
keywords = {nor flash, neural network, computing in memory},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328652,
author = {Kil, Woogeun and Ko, Kwangpyo and Lee, Seungwoon and Roh, Byeong-hee},
title = {MR and IoT Convergence Platform with AI Support for Disaster Recognition (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328652},
doi = {10.1145/3307334.3328652},
abstract = {Because disaster situations can cause damage to people and property, fast recognition and Countermeasure is important. IoT and MR, the technologies that have become popular nowadays, expected to play a key role in this domain. In this paper, we will introduce MR and IoT Convergence Platform with AI Support for Disaster Recognition This platform can recognize a disaster situation with sensors and AI system, and report to the user's MR devices. Also, we build a prototype using OneM2M-based Mobius Platform, Microsoft Hololens, and CNN-based AI Camera for proving feasibility.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {614–615},
numpages = {2},
keywords = {mixed-reality, internet of things, disaster recognition, disaster countermeasure, artificial intelligence},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328653,
author = {Lee, Soyeon and Park, Sangjoon},
title = {High Precision Relative Positioning on a Mobile (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328653},
doi = {10.1145/3307334.3328653},
abstract = {Although there are many commercial products and services advertising their capability of indoor navigation using smartphone, still the service coverage is highly restricted to the specific area due to tremendous effort on pre-survey and maintenance on positioning resources such as radio map of Wi-Fi signals. Most of indoor positioning is dependent on the installed facilities such as Wi-Fi APs and BLE beacons in service area. Without pre-surveyed information such as fingerprint database, one can not localize himself at the first visiting site.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {616–617},
numpages = {2},
keywords = {pedestrian dead reckoning, indoor positioning, heading adjustment},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328654,
author = {Bilal, Hafiz Syed Muhammad and Lee, Sungyoung},
title = {Right Intervention at Right Time to Right Person for Healthy Behavior Adaptation (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328654},
doi = {10.1145/3307334.3328654},
abstract = {Smart gadgets play a vital role to adapt the unhealthy lifestyle by converging science and technology in this digital world. The challenge of behavior change through step-by-step coaching and guidance is realized by just-in-time intervention using mobile computing. The amalgamation of behavior change theories with digital technologies support us to mold the behavior in a scientific manner. Wellness platform based behavior analysis is performed through unbiased life-log as well as questionnaire for permanent and ad-hoc users. Daily personalized coaching has been provided to motivate the users, whereas instant context-based recommendations have supported stage-wise adaptation of healthy behavior.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {618–619},
numpages = {2},
keywords = {wellness services, recommendations, mobile computing, lifestyle habits, just-in-time intervention},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328655,
author = {Kim, Sunwoo and Kang, Hyunwoo and Kim, Song Min and Lee, Sung-Ju},
title = {Gas Sensing with COTS RFID Devices (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328655},
doi = {10.1145/3307334.3328655},
abstract = {Gas monitoring, often as a part of safety and health systems, is widely used in a variety of sectors such as manufacturing, auto- mobiles, medical, households, food and beverages, environments, and HVACs. Existing gas monitoring approaches such as the use of catalytic and infrared sensors and electrochemical and metal oxide semiconductor technologies, typically require expensive hardware or are power hungry, and thus not suitable for long-term and large scale deployments. We propose a gas intensity measuring system with cost-effective commercial off-the-shelf (COTS) RFID devices. Our key intuition is that the changes in phase and strength of the signal result from not only the signal propagation but also from the hardware (i.e., tag's circuit). To this end, we propose a method to in- tegrate RFID with a chemiresistor, called Carbon Nanotubes (CNTs), whose electrical property varies with the nearby gas concentration. Our system shows the potential of low-cost, easy-to-make, and wireless sensing based gas monitoring systems.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {620–621},
numpages = {2},
keywords = {wireless sensing, sensors, rfid, gas sensors},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328656,
author = {Abbas, Asim and Bilal, Hafiz Syed Muhammad and Lee, Sungyoung},
title = {Smartphone Based Wellness Application for Healthy Lifestyle Promotion (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328656},
doi = {10.1145/3307334.3328656},
abstract = {Wellness platform plays a vital role to prevent chronic disease. In this paper, we have introduced wellness smartphone application within the ambit of the Mining Mind project, which aims to support the people to adopt healthy behavior and lifestyle. When an unhealthy behavior is detected, personalized physical recommendations are generated automatically by the Mining Mind wellness platform. Recommendations are delivered through Push notification and display on the application main screen for the user. The application has feedback functionalities on the effectiveness of recommendation and education. The application also supports descriptive analytics of wellness goals achieved on a monthly, weekly and daily basis.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {622–623},
numpages = {2},
keywords = {wellness application, lifestyle monitoring, healthy lifestyle program, behavior change},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328657,
author = {Dolui, Koustabh and Cuba Gyllensten, Illapha and Lowet, Dietwig and Michiels, Sam and Hallez, Hans and Hughes, Danny},
title = {Towards Privacy-preserving Mobile Applications with Federated Learning: The Case of Matrix Factorization (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328657},
doi = {10.1145/3307334.3328657},
abstract = {Recommender systems have gained prominence in bringing users tailor-made content from the web aiding their decision making process. However, this personalization comes at a cost of privacy of sharing personal information with the recommendation provider. Moreover, with growing sizes of datasets and models, centralized processing of such data has become challenging. To this end, we propose a federated matrix factorization algorithm to enable personal data to be stored and used on-device for training while sending updates to train a centralized model. We illustrate preliminary results from our algorithm applied to recommendation of articles to users of a mobile application based on their reading history. We compare our performance with centralized matrix factorization applied on the same dataset.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {624–625},
numpages = {2},
keywords = {recommender systems, privacy-preserving, machine learning, federated learning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328659,
author = {Kim, Sanghun and Kwon, Dongwoo and Ji, Youngmin},
title = {CNN Based Human Detection for Unmanned Aerial Vehicle (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328659},
doi = {10.1145/3307334.3328659},
abstract = {In order to utilize a unmanned aerial device such as a drone in terms of reconnaissance, surveillance and disaster management, a technique capable of performing real-time human detection is needed. In this study, we introduce a method of human detection by constructing environment similar to a drone by installing wide angle lens camera on the ceiling. Tiny-Yolo, which is a kind of Convolutional Neural Network, was used as recognition technology. Camera sensors were installed on ceilings in various places inside the building to collect training data for human detection. The Training was performed based on 4,000 pieces of collected data, and the accuracy of recognition was measured. As a result, 95.37\% precision and 96.60\% recall were obtained.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {626–627},
numpages = {2},
keywords = {{human detection, drone, convolutional neural networks},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328660,
author = {Reksten-Monsen, Christian August and Han, Jun},
title = {Towards Precise Localization of E-Scooters Using Sidewalk Ramps (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328660},
doi = {10.1145/3307334.3328660},
abstract = {Electric scooters (e-scooters) are proliferating rapidly as an inexpensive mode of transportation. GPS equipped smartphones are used to guide riders from points A to B, but GPS is known to have hundreds of meters of error in areas where the line of sight to navigation satellites is fully or partially obscured. To address this problem, we present ScootLoc, which enables precise e-scooter localization, by leveraging physical characteristics of sidewalk ramps, to correct for GPS error. We show that e-scooters equipped with a gyroscope and an accelerometer are able to uniquely identify sidewalk ramps and match the ramp to its physical location, thereby augmenting noisy GPS based navigation systems. We implement ScootLoc and present a preliminary evaluation on a route containing ten ramps, achieving 97\% classification accuracy.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {628–629},
numpages = {2},
keywords = {positioning and tracking, mobile sensing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328661,
author = {Abbas, Asim and Ansaar, Muhammad Zaki and Lee, Sungyoung},
title = {Medical Concept Extraction using Smartphone and Natural Language Processing Techniques (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328661},
doi = {10.1145/3307334.3328661},
abstract = {Over the past few decade, smartphone technology has played a vital role in the healthcare domain. In this paper, we proposed a methodology to allow end users to automatically process the medical text image using a camera or enter text manually. Then the system output allows to extract medical concepts, its semantic type and entity type from medical text apply Natural Processing Language techniques from UMLS medical dictionary. The medical text can be a health report, a clinical case, or other kinds of a text containing medically related information. The aim of this kind of methodology of the mobile application is to contribute in the area of natural language processing (NLP), intelligent system and to increase the medical students and bioinformatics researchers interest to quickly accessing information about medical data.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {630–631},
numpages = {2},
keywords = {umls, nlp, intelligent system, information extraction},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328662,
author = {Ramesh, Soundarya and Pathier, Thomas and Han, Jun},
title = {SoundUAV: Fingerprinting Acoustic Emanations for Delivery Drone Authentication (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328662},
doi = {10.1145/3307334.3328662},
abstract = {Delivery drones may become potential targets for package theft. An adversary may launch a drone impersonation attack, where the adversary's drone purports to be a legitimate delivery drone. To protect against such attacks, authenticating drones is crucial. Existing authentication schemes based on digital certificates have been shown to be compromised by security breaches on certificate authorities. Thus, we propose SoundUAV as a second factor of authentication for drones that leverages uniqueness in acoustic emanations to fingerprint drones, even within the same make and model. This uniqueness is attributed to hardware defects in motors, making SoundUAV secure against impersonation and robust to large scale attacks. Further, SoundUAV requires no hardware modifications to drones as it utilizes the pervasive acoustic emanations. We perform preliminary evaluation on eleven drones and obtain a fingerprinting accuracy of 99.48\%.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {632–633},
numpages = {2},
keywords = {fingerprinting, drones, authentication, acoustic analysis},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328663,
author = {Yang, Jin Mo and Kang, Byungjun and Bahk, Saewoong},
title = {RSSI based Power Control Algorithm for C-V2X Mode 4 (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328663},
doi = {10.1145/3307334.3328663},
abstract = {We propose transmission power control algorithm for Cellular-Vehicle-to-everything (C-V2X) mode 4, based on standard-compliant sensing scheme. We show that standard resource allocation scheme for Vehicle-to-vehicle (V2V) communication mode 4, with fixed transmission power, has room for improvement. Assuming channel reciprocity, proposed algorithm estimates neighbor's SINR and controls transmission power based on the estimation. We show that proposed scheme enhances system level PRR and also, performance of the algorithm increases as vehicles get more dense.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {634–635},
numpages = {2},
keywords = {v2v, power control, mode 4, cellular v2x, cam},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328664,
author = {Ha, Donghee and Kwon, Jinse and Kim, Hyungshin},
title = {Accelerating Colorizer of Shaded Image for Autonomous Driving in Resource-Constrained SoC (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328664},
doi = {10.1145/3307334.3328664},
abstract = {Image-based convolutional neural network(CNN) algorithms are spreading across a variety of applications. In particular, an autonomous vehicle recognizes objects and the surrounding situation using the CNN models. CNN models for image classification are trained using clear image dataset, so they are not robust to grayscale images or noise-intensive data. Therefore, there is a risk of an accident because the quality of the input image drops rapidly during night driving. The region that is revealed by the headlight can have colors, but in the shaded area it has a brightness that is not enough to get color values. We intend to increase the safety of autonomous driving by coloring this region of interest(ROI).},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {636},
numpages = {1},
keywords = {mobile gpu, deep learning, computer vision},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328665,
author = {Lee, Euihyeok and Kang, Seungwoo},
title = {Towards the Experience of Daytime Driving at Night (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328665},
doi = {10.1145/3307334.3328665},
abstract = {What if the window of our cars is a magic window, which transforms dark views outside of the window at night into bright ones as we can see in the daytime? In this paper, we investigate the feasibility of implementing such a magic window, addressing two important requirements: (1) the quality of transformed images (from the nighttime to the daytime) and (2) the frame rate of transformed image stream. We present our initial ideas to address the problem and report preliminary results towards the experience of daytime driving at night.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {637–638},
numpages = {2},
keywords = {real-time processing, image translation, image interpolation},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328666,
author = {Lee, Daehwa Rayer and Jang, Yunhee and Jang, Hanbin and Kim, Hyoungshick},
title = {80\% of Block Propagation Rate is Enough - Towards Secure and Efficient PoW-based Blockchain Consensus (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328666},
doi = {10.1145/3307334.3328666},
abstract = {Recently, Samsung released Galaxy S10 supporting the cryptowallet feature [5]. However, it is still questionable whether cryptocurrency can be popularly used for mobile payments because processing transactions in existing blockchain systems are too slow. For example, public blockchain systems such as Bitcoin [6] (7 transactions per second (TPS)) and Ethereum (15 TPS) are significantly slower than mainstream payment systems such as Visa (2,000 TPS) using a centralized database.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {639–640},
numpages = {2},
keywords = {security, consensus algorithm, blockchain},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328667,
author = {Yoshida, Takuto and Nozaki, Junto and Urano, Kenta and Hiroi, Kei and Yonezawa, Takuro and Kawaguchi, Nobuo},
title = {Gait Dependency of Smartphone Walking Speed Estimation using Deep Learning (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328667},
doi = {10.1145/3307334.3328667},
abstract = {This paper proposes an accurate estimation method of walking speed using deep learning for smartphone-based Pedestrian Dead Reckoning (PDR).PDR requires to estimate speed and direction of pedestrians accurately using accelerometer and gyroscope.To improve the accuracy of PDR, existing works focused to improve the key factors of speed estimation (i.e., stride and/or step estimation) by adapting deep learning.On the contrary, our research proposes to adapt deep learning more directly to estimate walking speed from sensor data of smartphone. We evaluate the accuracy of proposed method by comparing with conventional PDR method. As a result, we confirmed that proposed method can estimate the speed more accurately.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {641–642},
numpages = {2},
keywords = {pdr, location estimation, deep learning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328717,
author = {Jung, Hyunwoo and Kang, Cholmin and Lee, Youngki},
title = {Machine Learning without Real-world Data (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328717},
doi = {10.1145/3307334.3328717},
abstract = {It has been a common approach to apply Machine Learning (ML) techniques over sensory data for inferring human behavior, activities, emotions, and surrounding contexts. Especially, IMU (Inertial Measurement Unit) sensors are widely used to obtain dataset to train ML models for human activity recognition. A key challenge in building highly accurate ML models lies in collecting a wide variety of activity data from a large number of users. Such data collection is often a highly time-consuming and costly process.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {643–644},
numpages = {2},
keywords = {simulation, sensor, machine learning, human activity recognition},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328718,
author = {Son, Kyuho and Han, Dongsoo},
title = {Grid-based Gaussian Modeling for Cellular Positioning (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328718},
doi = {10.1145/3307334.3328718},
abstract = {By the infrastructure of cellular network changing, the conventional methods has became not be adequate. As an alternative, a probabilistic model for dynamic input aiming on signals from multiple cellular station is proposed in this study, and the feasibility was verified. The result from the experiment can be shown a little petty, but if one experiments in a better environment and utilizes LTE and 5G network, about 20~30m of the positioning error can be expected.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {645–646},
numpages = {2},
keywords = {grid, gaussian model, cellular positioning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328719,
author = {Yonezawa, Takuro and Nishiyama, Yuuki and Hiroi, Kei and Kawaguchi, Nobuo},
title = {Capturing Subjective Time as Context and It's Applications (poster)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328719},
doi = {10.1145/3307334.3328719},
abstract = {We propose an integrated framework for sensing, recognizing and utilizing of subjective time as context. Various studies on experimental psychology have showed several factors which affects subjective time. Those factors should be partially captured by ubiquitous sensors such as smartphones and wearable devices, therefore, we tackle to create common and individual model for subjective time based on the sensor data. We report our first prototype implementation for the framework based on AWARE framework with adding experience sampling method for subjective time recognition. In addition, we discuss potential applications which leveraging advantages of subjective time as context.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {647–648},
numpages = {2},
keywords = {subjective time, experience sampling method, context-awareness},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328565,
author = {Shin, Jaemin and Lee, Seungjoo and Lee, Sung-Ju},
title = {Accurate Eating Detection on a Daily Wearable Necklace (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328565},
doi = {10.1145/3307334.3328565},
abstract = {While there are many research proposals for wearable Automatic Dietary Monitoring (ADM) systems that detect eating of a user, it is difficult to notice real-world users wearing such devices in public. We propose a new wearable ADM system that could be used daily by real-world users. It is designed in a form of necklace, providing natural and firm contact of sensor on user's skin to accurately capture eating activities. At our preliminary experiments, our wearable ADM system detected eating of a user with 86.1\% accuracy.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {649–650},
numpages = {2},
keywords = {food journal, eating episode detection, automatic dietary monitoring},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328566,
author = {Shi, Shu and Hwang, Michael and Gupta, Varun and Jana, Rittwik},
title = {Latency Adaptive Streaming of 8K 360 Degree Video to Mobile VR Headsets (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328566},
doi = {10.1145/3307334.3328566},
abstract = {In this demo, we showcase how to stream 8K 360° video to commod- ity mobile devices without pre-processing or viewpoint prediction using our Freedom system. Users can freely select the viewpoint, zoom in and zoom out to enjoy the full quality of the 8K resolu- tion using any Samsung GearVR compatible smartphone. We also present how our system works internally to dynamically adjust margin size to accommodate to network latency and how our ap- proach can save up to 80\% bandwidth compared to streaming full video to mobile devices.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {651–652},
numpages = {2},
keywords = {mobile vr, mobile edge cloud, 360 degree video},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328567,
author = {Kim, Junhui and Kim, Joongheon},
title = {Light-Weight Programming Language for Blockchain (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328567},
doi = {10.1145/3307334.3328567},
abstract = {This demo abstract introduces a new light-weight programming language koa which is suitable for blockchain system design and implementation. In this abstract, the basic features of koa are introduced including working system (with playground), architecture, and virtual machine operations. Rum-time execution of software implemented by koa will be presented during the session.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {653–654},
numpages = {2},
keywords = {smart contract, programming language, blockchain},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328568,
author = {Lee, Jungho and Ryu, Woo-Jong and Ahn, Yoonjoo and Lee, Song-Eun and Kim, Kang-Min and Park, Jun-Hyung and Lee, SangKeun},
title = {meChat: In-device Conversational Photo Sharing Service (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328568},
doi = {10.1145/3307334.3328568},
abstract = {In this demo, we demonstrate an in-device conversational photo sharing service, termed meChat, which helps users share in-device photos easily in messaging applications by searching conversation-related photos automatically. In particular, meChat understands the semantics of on-going conversation and in-device photos by projecting both of them into a single semantic space. Subsequently, it retrieves in-device photos related to the conversation context. Through this process, meChat makes it easy for the users to share the photos while communicating in messaging applications. In addition, it is worth noting that meChat works in a stand-alone, privacy-protecting manner without sending out any in-device photos and conversations to the external servers. This is different from existing photo services (e.g., Google Photos) which resort on the cloud server.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {655–656},
numpages = {2},
keywords = {personal service, on-device intelligence},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328569,
author = {Katayama, Shin and Mathur, Akhil and Okoshi, Tadashi and Nakazawa, Jin and Kawsar, Fahim},
title = {Situation-Aware Conversational Agent with Kinetic Earables (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328569},
doi = {10.1145/3307334.3328569},
abstract = {Conversational agents are increasingly becoming digital partners of our everyday computing experiences offering a variety of purposeful information and utility services. Although rich on competency, these agents are entirely oblivious to their users' situational and emotional context today and incapable of adjusting their interaction style and tone contextually. To this end, we present a first-of-its-kind situation-aware conversational agent on kinetic earable that dynamically adjusts its conversation style, tone, volume in response to users emotional, environmental, social and activity context gathered through speech prosody, ambient sound and motion signatures.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {657–658},
numpages = {2},
keywords = {emotion regulation, earables, conversational agent, context awareness},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328570,
author = {Prakash, Siddhant and Bahremand, Alireza and Nguyen, Linda D. and LiKamWa, Robert},
title = {GLEAM -- An Illumination Estimation Framework for Real-time Photorealistic Augmented Reality on Mobile Devices (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328570},
doi = {10.1145/3307334.3328570},
abstract = {Mixed reality mobile platforms attempt to co-locate virtual scenes with physical environments, towards creating immersive user experiences. However, to create visual harmony between virtual and physical spaces, the virtual scene must be accurately illuminated with realistic lighting that matches the physical environment. To this end, we design GLEAM, a framework that provides robust illumination estimation in real-time by integrating physical light-probe estimation with current mobile AR systems. We present a demo implementation of GLEAM by means of an AR application that estimates environmental illumination and renders the scene with real-time illumination updates. We demonstrate the efficacy of GLEAM's estimation against a current commercial status quo solution, Apple's ARKit, with the same application.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {659–660},
numpages = {2},
keywords = {lighting models, light probe, light estimation, image-based lighting, image processing, geometry, augmented reality},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328571,
author = {Hwang, Inseok and Rozner, Eric and Yoo, Chungkuk},
title = {Telekinetic Thumb Summons Out-of-reach Touch Interface Beneath Your Thumbtip (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328571},
doi = {10.1145/3307334.3328571},
abstract = {As personal interactive devices become more ingrained into our daily lives, it becomes more important to understand how seamless interaction with those devices can be fostered. A typical mechanism to interface with a personal device is via a touch screen, in which users use their fingertip or stylus to scroll, type, select, or otherwise control device usage. Touch-based techniques, however, can become restrictive or inconvenient under a variety of scenarios. For example, personal devices such as phones or tablets are continuously increasing in size, making one-handed interaction difficult because one cannot easily hold the phone and touch the screen (with the thumb) at the same time with one hand. Therefore, in this demo, we present a new technique to interact with personal devices in which the screen and touch screen interactions can adapt to a user's grip or current touch constraints.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {661–662},
numpages = {2},
keywords = {user interface programming, mobile computing, intelligent interface, hand-held device, gesture input, adaptive interface},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328572,
author = {Hollingsworth, Max and Lee, Gyuhong and Lee, Jihoon and Lee, Jinsung and Im, Youngbin and Wustrow, Eric and Grunwald, Dirk and Ha, Sangtae},
title = {This is Your President Speaking: Spoofing Alerts in 4G LTE Networks (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328572},
doi = {10.1145/3307334.3328572},
abstract = {4G LTE networks across the world (e.g., United States, Europe, and South Korea) use the same mechanism to broadcast emergency alerts. These alerts include AMBER, severe weather alerts, and the (unblockable) Presidential Alert in the US. We demonstrate the ability to spoof these alerts by forcing any 4G phone in the area of our malicious cell tower to receive and display a fabricated message. This demonstration uses a commercially-available software-defined radio, an LTE base station, and our modifications to the open-source NextEPC and srsLTE libraries to send the Presidential Alert to phones volunteered from the audience.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {663–664},
numpages = {2},
keywords = {spoofing, security, presidential alert, lte, cmas},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328573,
author = {Mukhopadhyay, Shalini and Ahmed, Nasimuddin and Jaiswal, Dibyanshu and Ghose, Avik},
title = {A Robust and Customizable Tracking Algorithm for Accurate Heart Rate Estimation (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328573},
doi = {10.1145/3307334.3328573},
abstract = {Wearable health monitoring has become a very familiar term in today'sworld. One of the most popular means ofwearable sensing is photoplethysmogram (PPG). Due to its unobtrusive and ubiquitous nature, it is gaining popularity among people everywhere. Due to the ease of use, the utility of such technology is increasing day by day. However, in theworld of researchers, the accurate estimation of heart rate (HR) in presence of motion artefacts remains an unsolved problem due to the susceptibility of PPG signals to corruption by motion artefacts. The way in which a person fastens the device on the wrist plays an important role in the acquisition of signal from the device. While there are various research works going on in this field, there is always a trade-off between accuracy and complexity of algorithm and hardware resources. Also, in such scenarios where the sensor gets misplaced due to movements, there might be no PPG signal component available in the acquired signal data. In such cases the sophisticated denoising algorithms make no sense.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {665–666},
numpages = {2},
keywords = {wearable health, photoplethysmography, motion artefacts, heart rate},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328574,
author = {Zakaria, Camellia and Lee, Youngki and Balan, Rajesh},
title = {Passive Detection of Perceived Stress Using Location-driven Sensing Technologies at Scale (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328574},
doi = {10.1145/3307334.3328574},
abstract = {Much research argues that feeling overwhelmed by stress and for prolonged periods can lead to severe mental illness such as early onset depression and anxiety among many others. Recovering from severe stress to a normal state is much easier, in terms of the length of time and treatment required, compared to when more serious conditions have manifested [1]. Unfortunately, existing stress monitoring applications either require dedicated applications to be installed on the user's mobile device or use various mobile and wearable sensors [2, 4, 6, 7]; thus are not scalable to large number of users. Our goal is to provide a community-wide "safety net" that will automatically and non-intrusively detect individuals exhibiting signs of excessive stress without them installing any dedicated app. YouTube Demo Link https://youtu.be/LKQvIX4W6L0},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {667–668},
numpages = {2},
keywords = {wifi indoor localisation, stress, mental health, machine learning},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3329407,
author = {Cho, Hyunsung and Oh, Jinyoung and Kim, Juho and Lee, Sung-Ju},
title = {Sender-Controlled Mobile Instant Message Notifications Using Activity Information (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3329407},
doi = {10.1145/3307334.3329407},
abstract = {We propose the design of MyButler, a sender-controlled notification management system that mitigates disruption caused by mobile instant messaging through sharing the receiver's activity information with the sender.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {669–670},
numpages = {2},
keywords = {smartphone notifications, mobile instant messaging, interruptions, context-aware computing},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328575,
author = {Katsumata, Kento and Eigen, Yusaku and Noda, Yuka and Tsuruoka, Masayoshi and Hashiba, Satsuki and Numoto, Shotaro and Katayama, Shin and Okoshi, Tadashi and Nakazawa, Jin},
title = {Motivating Long-term Dietary Habit Modification through Mobile MR Gamification (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328575},
doi = {10.1145/3307334.3328575},
abstract = {In correlation with the socio-economic development, changes in people's lifestyle brought about significant impact on dietary patterns.  Though public concerns over healthy eating are increasing, many are still uncertain when choosing a well balanced meal amid welter of information.  In this paper, we propose "KomaFLens'', a mobile system and application built for Microsoft HoloLens, which aims to motivate long term dietary habit modification through gamification.  The primary purpose of this research is to enhance the users' nutritional knowledge and to guide them to make healthier choices in their diet. Our preliminary evaluation revealed interesting points for discussion regarding the procedure for capturing food labels. Streamlining the operational method to boost tractability will improve the accuracy when recording food intakes.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {671–672},
numpages = {2},
keywords = {well-being, mixed reality, gamification},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328576,
author = {Dhawaskar Sathyanarayana, Sandesh and Lee, Jihoon and Lee, Jinsung and Im, Youngbin and Rahimzadeh, Parisa and Zhang, Xiaoxi and Hollingsworth, Max and Joe-Wong, Carlee and Grunwald, Dirk and Ha, Sangtae},
title = {CASTLE over the Air -- Distributed Scheduling for Cellular Data Transmissions (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328576},
doi = {10.1145/3307334.3328576},
abstract = {We present the demonstration of a fully distributed scheduling framework called CASTLE (Client-side Adaptive Scheduler That minimizes Load and Energy) that jointly optimizes the spectral efficiency of cellular networks and battery consumption of smart devices. To do so, we focus on scenarios when many smart devices compete for cellular resources in the same base station: spreading out transmissions over time so that only a few devices transmit at once and improves both spectral efficiency and battery consumption. To this end, we devise two novel features in CASTLE. First, we explicitly consider inter-cell interference for accurate cellular load estimation in our machine learning algorithm. Second, we propose a fully distributed scheduling algorithm that coordinates transmissions between clients based on the locally estimated load level at each client. Our formulation for minimizing battery consumption at each device leads to an optimized back off-based algorithm that fits practical environments. Our comprehensive experimental results show that CASTLE's load estimation is up to 91 \% accurate, and that CASTLE achieves higher spectral efficiency with less battery consumption, compared to existing centralized scheduling algorithms as well as a distributed CSMA-like protocol. Furthermore,we develop a light-weight SDK that can expedite the deployment of CASTLE into smart devices and evaluate it in a commercial LTE network.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {673–674},
numpages = {2},
keywords = {lte, energy saving, distributed scheduling, cell load},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328577,
author = {Ramachandran, Gowri Sankar and Bogosian, Biayna and Vasudeva, Kunal and Sriramaraju, Sushanth Ikshwaku and Patel, Jay and Amidwar, Shubhesh and Malladi, Lavanya and Shylaja, Rohan Doddaiah and Kumar, Nishant Revur Bharath and Krishnamachari, Bhaskar},
title = {An Immersive Visualization of Micro-climatic Data using USC AiR (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328577},
doi = {10.1145/3307334.3328577},
abstract = {The air pollution level is increasing globally at an alarming rate. In the last two decades, many cities have adopted policies to control the emission of pollutants to the atmosphere as well as to promote sustainable urban developments. However, many of these initiatives have concluded that a long term success would require investing in the environmental literacy of the general population. In this demonstration paper, we present USC AiR, a mobile application that translates the air quality sensor feeds from the CCITI smart campus testbed into augmented reality visualizations for the USC community. USC AiR also allows users to report alarming air quality conditions and recommend environmental interventions such as planting trees. We believe that the integration of augmented reality for air quality monitoring enables the citizens to become more engaged with the air quality data while encouraging them to contribute to the reduction of anthropogenic air pollutants.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {675–676},
numpages = {2},
keywords = {smart city, smart campus, mixed reality, iot, augmented reality, air quality},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328578,
author = {Kang, Bumsoo and Hwang, Inseok and Lee, Jinho and Lee, Seungchul and Lee, Taegyeong and Chang, Youngjae and Lee, Min Kyung},
title = {Towards Peripheral Awareness of Remote Family Member's Context Using Self-mobile Robotic Avatars (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328578},
doi = {10.1145/3307334.3328578},
abstract = {Real-time remote interaction has become easier and richer powered by recent advances in mobile computing and communication. A number of research have been explored on enriching family interaction by augmenting an interaction channel with asynchronous communication [6] or additional sensory stimuli [5]. However, it is still far from achieving a sense of living together for family members involuntarily living apart, especially in context-aware impromptu interaction. For families living together, it is trivial to naturally perceive behavioral and situational contexts of the other and initiate a relevant interaction intuitively. For example, a wife starts a casual chat with asking her husband what he is going to cook when she sees him going to the kitchen or hears a simmering sound.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {677–678},
numpages = {2},
keywords = {robotic avatar, peripheral awareness, context-aware impromptu interaction},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328579,
author = {Park, Juyoung and Im, Kiyoung and Lee, Jung Hee},
title = {PotholeEye -- How Can We Effectively Maintain the Pavement Distress? (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328579},
doi = {10.1145/3307334.3328579},
abstract = {We propose a mobile system, called PotholeEye, for automatically monitoring the surface of a roadway and providing real-time analysis of images, with the specific goal of detecting the pavement distress. PotholeEye pre-processes the images, extracts features, and classifies the distress into a variety of types, while the road manager is driving. We have tested PotholeEye on real highway involving real settings, a camera, a mini computer, a GPS receiver, and so on, and have shown how we can effectively maintain the pavement distress.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {679–680},
numpages = {2},
keywords = {pavement distress, image processing, convolution neural network},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328580,
author = {Jeon, Sanghoon and Lee, Yang-Soo and Son, Sang Hyuk},
title = {Automatic Assessment Framework for Range of Motion Test using Wearable Device and Smartphone (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328580},
doi = {10.1145/3307334.3328580},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {681–682},
numpages = {2},
keywords = {range of motion test, goniometer, automatic assessment framework},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328581,
author = {Soleiman, Andreas and Varshney, Ambuj},
title = {Backscatter-enabled Polymorphic Light Sensors (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328581},
doi = {10.1145/3307334.3328581},
abstract = {Light as a medium for sensing and communication enables new scenarios, such as controlling devices with gestures, or communication for Internet of Things~(IoT) devices. However, a limitation of existing systems is that they often sense only a narrow part of the light spectrum. We argue that the ability to sense a broad light spectrum significantly enhances ability of such systems expanding possible application scenarios. We demonstrate our work in progress to develop the concept of polymorphic light sensing~(PLS). PLS sensor morphs itself according to applications requirements, to track desired parts of the light spectrum (colours, infrared, and ultraviolet light). We couple the PLS sensor with ultra-low power backscatter mechanism, and demonstrate this enables us to sense and communicate the broad spectrum, while operating battery-free.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {683–684},
numpages = {2},
keywords = {polymorphic sensing, light sensing, battery-free, backscatter communication},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328582,
author = {Pham, Nhat and Kim, Taeho and Thayer, Frederick M. and Nguyen, Anh and Vu, Tam},
title = {Earable -- An Ear-Worn Biosignal Sensing Platform for Cognitive State Monitoring and Human-Computer Interaction (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328582},
doi = {10.1145/3307334.3328582},
abstract = {Cognitive state monitoring is crucial for neurological disorders such as epilepsy, narcolepsy, insomnia, and many other human health concerns. The capability to continuously monitor an individual wearing the device and accurately provide early warnings of seizures or narcolepsy sleep attacks would be game-changing for these disorders. Beyond human health, complete hand-free/voice-free human-computer interaction is desirable for privacy-sensitive use cases or people with disabilities. To achieve this goal, we propose Earable, an ear-worn biosensing platform for cognitive state quantification and human-computer interaction. Earable can capture biosignal including brain waves activities, eyes movements, and facial muscle contractions from the back of the ears. Its form factor is convenient to use in everyday life. In this demo, we show two use cases for our Earable platform. First, as an example of cognitive state monitoring, our system plays relaxing music and dims the light when the user is trying to relax or sleep by detecting alpha and beta waves generated by the brain. Second, as an example of human-computer interaction, our system controls a drone with eye movements and facial muscle activity.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {685–686},
numpages = {2},
keywords = {wearable computing, human-computer interaction, ear-worn biosensing, cognitive state monitoring},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328583,
author = {Balaji, Ananta Narayanan and Yuan, Chen and Wang, Bo and Peh, Li-Shiuan and Shao, Huilin},
title = {pH Watch - Leveraging Pulse Oximeters in Existing Wearables for Reusable, Real-time Monitoring of pH in Sweat (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328583},
doi = {10.1145/3307334.3328583},
abstract = {Most present day fitness trackers and smart watches measure critical health indicators such as heart rate, SpO2 concentration, sleep cycle etc. but they fail in their ability to track health indicators at the molecular level. This has attracted rapid research in the development of chemical sensors which can non-invasively measure analytes available in raw biofluids such as sweat, tears and urine. Of all the available raw bio-fluids, sweat can be obtained non-intrusively and readily, and thus is the most suitable choice for continuous real-time monitoring of indicators at a molecular level.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {687–688},
numpages = {2},
keywords = {wearables, sweat sensor, ph sensing, iot},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328584,
author = {Ji, Youngmin and Ok, Kisu and Kwon, Dongwoo},
title = {The Indoor Environment Monitoring System for Intelligent Buildings Using Wifi Mesh Based Internet of Things (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328584},
doi = {10.1145/3307334.3328584},
abstract = {Retrofit could be still expensive solution to existing building. However, with IoT(Internet of Things) environment sensors, it is possible to build a powerful intelligent building monitoring system with relatively low costs. The IoT environment sensor can analyze the IAQ(Indoor Air Quality), occupancy, and comfort level of the individual space by integrating temperature, humidity, carbon dioxide, sound, illuminance, organic compound, human body detection and IR sensor in the individual space of the building. In addition, because it supports Wifi mesh network, it can be easily installed without performing construction for retrofit in existing building, and real time monitoring can be performed. In this paper, we introduce the result of applied the IoT environment sensors to three buildings and visualization interface based on the result of analysis and real environment sensing},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {689–690},
numpages = {2},
keywords = {wifi mesh network, occupants detection, internet of things, indoor comfort, indoor air quality, building application},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328586,
author = {Mondal, Jayeeta and Dey, Swarnava and Mukherjee, Arijit and Dutta, Jeet and Pal, Arpan and P, Balamurali},
title = {Edge Acceleration of Deep Neural Networks (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328586},
doi = {10.1145/3307334.3328586},
abstract = {Running deep learning algorithms at the edge is a necessity in many industrial use-cases, especially in applications that use robots and drones in disaster recovery, surveillance, oil \& gas operations etc. Current state of the art deep learning algorithms are extremely efficient in analysing image, audio, video and other time-series signals. However, their performance degrades considerably on constrained edge devices. In this demo, we show how standard pretrained CNN (Convolutional Neural Network) models can be partitioned for efficient parallel execution between constrained devices and also achieve real-time response.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {691–692},
numpages = {2},
keywords = {partitioning, network, latency, edge, dnn, computing, acceleration},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328587,
author = {Choi, Jaewon and Ko, JeongGil},
title = {RemoteGL - Towards Low-latency Interactive Cloud Graphics Experience for Mobile Devices (demo)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328587},
doi = {10.1145/3307334.3328587},
abstract = {can enable futuristic applications including many Virtual Reality, Augmented Reality, and cloud gaming applications on resource constraint mobile devices. While RGR requires a high-level of networking bandwidth for seamless servicing, emerging high-speed communication technologies such as IEEE 802.11ax and millimeter wavebased communications are expected to provide high-bandwidth and low-latency networking performance. Thus, they can potentially resolve the transmission latency constraint, which is one of the most tricky obstacles to resolve prior to applying various RGR applications in the real world.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {693–694},
numpages = {2},
keywords = {remote graphics rendering, low-latency},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328589,
author = {Ananthanarayanan, Ganesh and Bahl, Victor and Cox, Landon and Crown, Alex and Nogbahi, Shadi and Shu, Yuanchao},
title = {Video Analytics - Killer App for Edge Computing},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328589},
doi = {10.1145/3307334.3328589},
abstract = {The world is witnessing an unprecedented increase in camera deployment. The USA and UK, for instance, have one camera for every 8 people. Video analytics from these cameras are becoming more and more pervasive, exerting important functions on a wide range of verticals including manufacturing, transportation, and retails. While vision techniques have seen considerable advancement, they have come at the expense of compute and network cost.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {695–696},
numpages = {2},
keywords = {video analytics, edge computing, dnn, cloud, camera},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328590,
author = {Lan, Kun-Chan and Li, Guan-Sheng and Zhang, Jun-Xiang},
title = {Robot-Assisted Acupuncture (video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328590},
doi = {10.1145/3307334.3328590},
abstract = {An acupuncture points localization method is implemented on an Android platform. Such a system can be used to locate the relevant acupuncture point and/or drive a robot arm for the purpose of symptom relief (e.g. through acupressure).},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {697–698},
numpages = {2},
keywords = {robot arm, augmented reality, acupuncture point estimation, 3d morphable model},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328591,
author = {Ko, Ju-Chun},
title = {Crypto Wallet Working on Low-cost 4G LTE Mobile Phone (video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328591},
doi = {10.1145/3307334.3328591},
abstract = {In this paper, we describe a simple and light way of using 4G LTE low-cost phone as blockchain cryptocurrencies wallet on-the-go. The main purpose of this project is to make general mobile phone user could easily use Crypto Wallet " a crypto currency wallet connected to the blockchain without installing an App, to get benefit from decentralized financial services such as e-commerce, Peer to Peer financial services etc. In this research, we have implemented a full-functional e-commerce Web App through WordPress combining with WooCommerce open-source package, with additional Crypto Wallet plugin compose by PHP installed, which allows user to create crypto wallet and make transaction on a very low-cost phone such like Nokia 8810 4GLTE, worth only $80. With the possibility of using low-cost phone to do Blockchain and cryptocurrency related operations, it may lead us to a more distributed commerce, and equally traded world. YouTube link: https://youtu.be/Dqmh-OgbvM8},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {699–700},
numpages = {2},
keywords = {mobile web applications, dapp, crypto wallet, blockchain},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328592,
author = {Ramachandran, Gowri Sankar and Ji, Xiang and Navaney, Pavas and Zheng, Licheng and Martinez, Martin and Krishnamachari, Bhaskar},
title = {Micropayments for Trusted Vehicular Services using MOTIVE (video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328592},
doi = {10.1145/3307334.3328592},
abstract = {The connected and autonomous vehicles are expected to rely heavily on connectivity to exchange data and computation services with other vehicles and remote infrastructure including roadside units and other edge infrastructure to increase their immediate view, which leads to greater safety, coordination and more comfortable experience for their human occupants. In order for vehicles to obtain data, compute and other services from other vehicles or road-side infrastructure, it is important to be able to make micropayments for those services and for the services to run seamlessly despite the challenges posed by mobility and ephemeral interactions with a dynamic set of neighboring devices. We present MOTIVE, a trusted and decentralized framework that allows vehicles to make peer-to-peer micropayments for data, compute and other services obtained from other vehicles or road-side infrastructure within radio range. The framework utilizes distributed ledger technologies including smart contracts to enable autonomous operation and trusted interactions between vehicles and nearby entities.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {701–702},
numpages = {2},
keywords = {v2x, micropayments, edge computing, connected and autonomous vehicles, blockchain},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328593,
author = {Gong, Taesik and Cho, Hyunsung and Lee, Bowon and Lee, Sung-Ju},
title = {Real-Time Object Identification with a Smartphone Knock (video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328593},
doi = {10.1145/3307334.3328593},
abstract = {We propose Knocker, a real-time object identification technique with smartphones. Knocker leverages unique impulse signals that are generated by knocking on an object with a smartphone. Knocker does not require any special augmentation for both smartphones and objects.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {703–704},
numpages = {2},
keywords = {smartphone sensing, object identification, machine learning, interaction with objects},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328594,
author = {Hu, Jinhan and Shearer, Alexander and Rajagopalan, Saranya and LiKamWa, Robert},
title = {Banner -- An Image Sensor Reconfiguration Framework for Seamless Resolution-based Tradeoffs (video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328594},
doi = {10.1145/3307334.3328594},
abstract = {Mobile vision systems would benefit from the ability to situationally sacrifice image resolution to save system energy when imaging detail is unnecessary. Unfortunately, any change in sensor resolution leads to a substantial pause in frame delivery -- as much as 280 ms. Frame delivery is bottlenecked by a sequence of reconfiguration procedures and memory management in current operating systems before it resumes at the new resolution. This latency from reconfiguration impedes the adoption of otherwise beneficial resolution-energy tradeoff mechanisms. We propose Banner as a media framework that provides a rapid sensor resolution reconfiguration service as a modification to common media frameworks, e.g., V4L2. Banner completely eliminates the frame-to-frame reconfiguration latency (226 ms to 33 ms), i.e., removing the frame drop during sensor resolution reconfiguration. Banner also halves the end-to-end resolution reconfiguration latency (226 ms to 105 ms). This enables a more than 49\% reduction of system power consumption by allowing continuous vision applications to reconfigure the sensor resolution to 480p compared with downsampling from 1080p to 480p, as measured in a cloud-based offloading workload running on a Jetson TX2 board. As a result, Banner unlocks unprecedented capabilities for mobile vision applications to dynamically reconfigure sensor resolutions to balance the energy efficiency and task accuracy tradeoff.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {705–706},
numpages = {2},
keywords = {resolution-based tradeoff, reconfiguration, operating systems, energy efficiency, efficient visual computing, device drivers},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3332163,
author = {AlDuaij, Naser and Van't Hof, Alexander and Nieh, Jason},
title = {Heterogeneous Multi-Mobile Computing (video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3332163},
doi = {10.1145/3307334.3332163},
abstract = {As smartphones and tablets proliferate, there is a growing demand for multi-mobile computing [1, 2], the ability to combine multiple commodity mobile systems into more capable ones, including using multiple hardware devices such as cameras, displays, speakers, microphones, sensors, GPS, and input. However, the tremendous device, hardware, and software heterogeneity of mobile systems makes this difficult. In this demo, we present M2, a system for multi-mobile computing that enables existing unmodified mobile apps to make use of new ways of sharing and combining multiple devices. M2 introduces a new data-centric approach that leverages higher-level device abstractions and encoding/decoding hardware to efficiently share device data as opposed to low-level device-specific APIs.},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {707},
numpages = {1},
keywords = {remote display, operating systems, mobile devices, mobile computing, ios, distributed computing, android},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}
@inproceedings{10.1145/3307334.3328595,
author = {Park, KyuHwon and Jeong, Young-Seob},
title = {Indoor Dialog Agent in Mixed Reality (video)},
year = {2019},
isbn = {9781450366618},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3307334.3328595},
doi = {10.1145/3307334.3328595},
abstract = {We aimed at implementing an indoor dialog agent, namely PhoenixBot, working in a mixed-reality environment. The agent occupies a certain position in a real-world space, and interacts with other nearby human.We developed a server that maintains information of agents and smartphone users, where the information includes current indoor position and direction. We also developed an Android application as a client, which collects real-time data from various sensors such as gyroscope, accelerometer, step detector, WiFi, magnetic field, and gravity sensor. The step detector values and WiFi signals are used to estimate the current location of the user, and the other remaining sensors are used to compute the user direction. The client application displays the real-world scene covered with some virtual objects (e.g., agent, board), as depicted in Fig. 1, where the cartoon character at the center is the dialog agent. In order to compute the right position to display the components, the client keeps consistent information of the virtual objects with the server. That is, if a user moves to other position, then it will be reported to the server and will be disclosed to the other agents and users. The dialog agent works in the way similar to other dialog agents, as it has a pipeline of modules such as Natural Language Understanding (NLU), Dialog Management (DM), and Natural Language Generation (NLG). The agent currently supports four domains: weather, campus, transport, and bible. The agent speaks only Korean for now, but will be portable to other langauges if a dataset for the target language is prepared. You can see the video clip at https://youtu.be/U2FA-XxVPvM},
booktitle = {Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {708–709},
numpages = {2},
keywords = {mobile phone, mixed reality, dialog agent, chatbot},
location = {Seoul, Republic of Korea},
series = {MobiSys '19}
}