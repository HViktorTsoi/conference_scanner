@inproceedings{10.1145/3636534.3649343,
author = {Banerjee, Avishek and Zhao, Xingya and Chhabra, Vishnu and Srinivasan, Kannan and Parthasarathy, Srinivasan},
title = {HORCRUX: Accurate Cross Band Channel Prediction},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649343},
doi = {10.1145/3636534.3649343},
abstract = {Recent advancement in Frequency Domain Duplexing (FDD) enables wireless systems to use different frequency bands for uplink and downlink communication without explicit channel feedback information. The current state-of-the-art approaches either estimate the underlying variables in the uplink channel or use an artificial neural network architecture to estimate the downlink channel from the uplink channel. However, such techniques fail to perform accurately in multipath-rich environments and environments unseen during training. This paper presents HORCRUX, a physics-based machine learning system that can be generalized and scaled to any environment while predicting downlink channels with high accuracy and applies to single-antenna and MIMO systems. Our approach uses multiple neural networks, trained on the standard wireless channel model, firstly to divide the uplink channel into smaller sub-channels and secondly to generate coarse estimates for the variables for each of the underlying sub-channels. Finally, we use an efficient and fast optimization framework to get fine-tuned variable estimates to predict the downlink channel. We implement our system using software-defined radios. Our evaluations show that HORCRUX performs ~8 dB better than state of the art in downlink channel prediction accuracy in diverse wireless environments. 1},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1–15},
numpages = {15},
keywords = {physics-guided machine learning, wireless networks},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649344,
author = {Li, Xinyi and Zhao, Gaoteng and Chen, Ling and Zhang, Xinyu and Ren, Ju},
title = {RFMagus: Programming the Radio Environment With Networked Metasurfaces},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649344},
doi = {10.1145/3636534.3649344},
abstract = {The complexity and volatility of real-world radio environments often hamper wireless networks from achieving optimal performance. Recently, intelligent metasurfaces have been explored to dynamically reshape the radio propagation environment. However, existing systems are limited to standalone metasurfaces, only enabling one-time signal redirection/reshaping effects within their direct line-of-sight. They cannot effectively scale to cover larger areas. In this paper, we propose RFMagus, which employs a network of metasurfaces to overcome the limitation. We carefully optimize the configurations of the networked metasurfaces so that they can cooperatively and coherently propagate the analog signals towards the target regions. We have implemented the networked metasurfaces and deployed them in a variety of real-world environments. Experimental results demonstrate that RFMagus can effectively expand the coverage, improve the throughput, and operate transparently to different wireless standards.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {16–30},
numpages = {15},
keywords = {metasurface, networked metasurface, beamforming},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649345,
author = {Zhang, Tianfang and Phan, Huy and Tang, Zijie and Shi, Cong and Wang, Yan and Yuan, Bo and Chen, Yingying},
title = {Inaudible Backdoor Attack via Stealthy Frequency Trigger Injection in Audio Spectrogram},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649345},
doi = {10.1145/3636534.3649345},
abstract = {Deep learning-enabled Voice User Interfaces (VUIs) have surpassed human-level performance in acoustic perception tasks. However, the significant cost associated with training these models compels users to rely on third-party data or outsource training services. Such emerging trends have drawn substantial attention to training-phase attacks, particularly backdoor attacks. Such attacks implant hidden trigger patterns (e.g., tones, environmental sounds) into the model during training, thereby manipulating the model's predictions in the inference phase. However, existing backdoor attacks can be easily undermined in practice as the inserted triggers are audible. Users may notice such attacks when listening to the training data and remaining alert for suspicious sounds. In this work, we present a novel audio backdoor attack that exploits completely inaudible triggers in the frequency domain of the audio spectrograms. Specifically, we optimize the trigger to be a frequency-domain pattern with the energy below the noise floor (e.g., background and hardware noises) at any given frequency, thereby rendering the trigger inaudible. To realize such attacks, we design a strategy that automatically generates inaudible triggers in the spectrum supported by commodity playback devices (e.g., smartphones and laptops). We further develop optimization techniques to enhance the trigger's robustness against speech content and onset variations. Experiments on hotword and speaker recognition indicate that our attack can achieve attack success rates of more than 98.2\% and 81.0\% under digital and physical attack scenarios. The results also demonstrate the trigger's inaudibility with a Signal-to-Noise Ratio (SNR) less than -3.54 dB against background noises. We further verify that our attack can successfully bypass state-of-the-art backdoor defense strategies based on learning and audio processing.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {31–45},
numpages = {15},
keywords = {inaudible attack, audio backdoor attack, frequency injection, audio spectrogram},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649346,
author = {Chen, Lili and Yu, Bozhong and Fu, Yongjian and Ren, Ju and Pan, Hao and Gummeson, Jeremy and Zhang, Yaoxue},
title = {Pushing Wireless Charging from Station to Travel},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649346},
doi = {10.1145/3636534.3649346},
abstract = {Wireless charging has achieved promising progress in recent years. However, the severe bottlenecks are the small charging range and poor flexibility. This paper presents ChargeX to enable smart and long-range wireless charging for small mobile devices. ChargeX incorporates emerging smart metasurface into the magnetic resonance coupling-based wireless charging to extend the charging range and accommodates the mobility of charging device. Unlike previous endeavors in metasurface-assisted wireless charging that focused on simulation, ChargeX makes efforts across software and hardware to meet three crucial requirements for a practical wireless charging system: (i) realize high-freedom and accurate metasurface control under the premise of low loss; (ii) obtain real-time feedback from the receiver and make effective manipulation for transmitted magnetic flux; and (iii) generate a proper AC signal source at the desired frequency band. We developed a prototype of ChargeX, and evaluated its performance through controlled experiments and real-world phone charging. Extensive experiments demonstrate the great potential of ChargeX for long-range and flexible wireless charging with a compact receiver design.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {46–61},
numpages = {16},
keywords = {wireless charging, magnetic-beamforming, metasurface},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649347,
author = {Ma, Ruichun and Zheng, Shicheng and Pan, Hao and Qiu, Lili and Chen, Xingyu and Liu, Liangyu and Liu, Yihong and Hu, Wenjun and Ren, Ju},
title = {AutoMS: Automated Service for mmWave Coverage Optimization using Low-cost Metasurfaces},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649347},
doi = {10.1145/3636534.3649347},
abstract = {mmWave networks offer wide bandwidth for high-speed wireless communication but suffer from limited range and susceptibility to blockage. Existing coverage provisioning solutions not only incur high costs but also require significant expert knowledge and manual efforts. In this paper, we present AutoMS, an automated service framework to optimize mmWave coverage by strategically designing and placing low-cost passive metasurfaces. Our approach consists of three key components: (1) joint optimization of metasurface phase configurations and placement as well as access point beamforming codebooks. (2) a fast 3D ray-tracing simulator for accelerated large-scale metasurface channel modeling. (3) a metasurface design amenable to ultra-low-cost hot stamping fabrication, featuring high reflectivity, near 2π phase control, and wideband support. Simulation and testbed experiments show that AutoMS can increase the median received signal strength by 11 dB in target rooms and over 20 dB at previous blind spots, and improve the median throughput by over 3\texttimes{} in real-world scenarios.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {62–76},
numpages = {15},
keywords = {millimeter-wave, coverage optimization, cloud service, meta-surfaces, ray-tracing simulator},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649348,
author = {Chi, Guoxuan and Yang, Zheng and Wu, Chenshu and Xu, Jingao and Gao, Yuchong and Liu, Yunhao and Han, Tony Xiao},
title = {RF-Diffusion: Radio Signal Generation via Time-Frequency Diffusion},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649348},
doi = {10.1145/3636534.3649348},
abstract = {Along with AIGC shines in CV and NLP, its potential in the wireless domain has also emerged in recent years. Yet, existing RF-oriented generative solutions are ill-suited for generating high-quality, time-series RF data due to limited representation capabilities. In this work, inspired by the stellar achievements of the diffusion model in CV and NLP, we adapt it to the RF domain and propose RF-Diffusion. To accommodate the unique characteristics of RF signals, we first introduce a novel Time-Frequency Diffusion theory to enhance the original diffusion model, enabling it to tap into the information within the time, frequency, and complex-valued domains of RF signals. On this basis, we propose a Hierarchical Diffusion Transformer to translate the theory into a practical generative DNN through elaborated design spanning network architecture, functional block, and complex-valued operator, making RF-Diffusion a versatile solution to generate diverse, high-quality, and time-series RF data. Performance comparison with three prevalent generative models demonstrates the RF-Diffusion's superior performance in synthesizing Wi-Fi and FMCW signals. We also showcase the versatility of RF-Diffusion in boosting Wi-Fi sensing systems and performing channel estimation in 5G networks.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {77–92},
numpages = {16},
keywords = {RF signal, generative model, time-frequency diffusion, wireless sensing, channel estimation},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649349,
author = {Guo, Xiuzhen and Tan, Long and Chen, Tao and Gu, Chaojie and Shu, Yuanchao and He, Shibo and He, Yuan and Chen, Jiming and Shangguan, Longfei},
title = {Exploring Biomagnetism for Inclusive Vital Sign Monitoring: Modeling and Implementation},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649349},
doi = {10.1145/3636534.3649349},
abstract = {This paper presents the design, implementation, and evaluation of MagWear, a novel biomagnetism-based system that can accurately and inclusively monitor the heart rate and respiration rate of mobile users with diverse skin tones. MagWear's contributions are twofold. Firstly, we build a mathematical model that characterizes the magnetic coupling effect of blood flow under the influence of an external magnetic field. This model uncovers the variations in accuracy when monitoring vital signs among individuals. Secondly, leveraging insights derived from this mathematical model, we present a softwarehardware co-design that effectively handles the impact of human diversity on the performance of vital sign monitoring, pushing this generic solution one big step closer to real adoptions. We have implemented a prototype of MagWear on a two-layer PCB board and followed IRB protocols to conduct system evaluations. Our extensive experiments involving 30 volunteers demonstrate that MagWear achieves high monitoring accuracy with a mean percentage error (MPE) of 1.55\% for heart rate and 1.79\% for respiration rate. The head-to-head comparison with Apple Watch 8 further demonstrates MagWear's consistently high performance in different user conditions.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {93–107},
numpages = {15},
keywords = {wearable health, mobile computing, magnetic sensing},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649350,
author = {Chang, Zhaoxin and Zhang, Fusang and Xiong, Jie and Chen, Weiyan and Zhang, Daqing},
title = {MSense: Boosting Wireless Sensing Capability Under Motion Interference},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649350},
doi = {10.1145/3636534.3649350},
abstract = {Wireless signals have been widely utilized for human sensing. However, wireless sensing systems face a fundamental limitation, i.e., the wireless device must keep static during the sensing process. Also, when sensing fine-grained human motions such as respiration, the human target is required to stay stationary. This is because wireless sensing relies on signal variations for sensing. When device is moving or human body is moving, the signal variation caused by the target area (e.g., chest for respiration sensing) is mixed with the signal variation induced by device or other body parts, failing wireless sensing. In this paper, we propose MSense, a general solution to deal with motion interference from wireless device and/or human body, moving wireless sensing one step forward towards real-life adoption. We establish the sensing model by taking both device motion and interfering body motion into consideration. By extracting the effect of body and device motions through pure signal processing, the motion interference can be removed to achieve accurate target sensing. Comprehensive experiments demonstrate the effectiveness of the proposed scheme. The achieved solution is general and can be applied to different sensing tasks involving both periodic and aperiodic motions.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {108–123},
numpages = {16},
keywords = {wireless sensing, motion interference cancellation, body motion and device motion interference, MmWave radar},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649351,
author = {Xie, Mingqi and Jin, Meng and Zhu, Fengyuan and Zhang, Yuzhe and Tian, Xiaohua and Wang, Xinbing and Zhou, Chenghu},
title = {Enabling High-rate Backscatter Sensing at Scale},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649351},
doi = {10.1145/3636534.3649351},
abstract = {This paper presents μTag, an ultra-low-power backscatter sensor that supports high-frequency sensing of a large number of targets simultaneously. The core of μTag is an RF "gene editing" technique that embeds both the identity of the sensor and the real-time motion state of the attached target intensively in the transient features of the sensor's RF signal, in a collision-resilient manner. We provide practical techniques which i) generate such "genetic signal" with purely analog and extremely simple circuits; and ii) separate the signals from a large scale of sensors reliably. Our experimental results show that our design can support concurrent tracking of 150 targets with a 12kHz per-tag sampling rate. We also demonstrate with multiple sensing applications that μTag can achieve high-speed and large-scale motion tracking and rotation frequency sensing. The PCB power consumption of μTag is 38~107μW, according to the operating frequency of the tag. Our ASIC simulation based on the 40nm CMOS process shows that the power consumption can be further reduced to 0.13~0.52μW.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {124–138},
numpages = {15},
keywords = {internet-of-things, backscatter, wireless sensing},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649352,
author = {Shi, Shuyao and Ling, Neiwen and Jiang, Zhehao and Huang, Xuan and He, Yuze and Zhao, Xiaoguang and Yang, Bufang and Bian, Chen and Xia, Jingfei and Yan, Zhenyu and Yeung, Raymond W. and Xing, Guoliang},
title = {Soar: Design and Deployment of A Smart Roadside Infrastructure System for Autonomous Driving},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649352},
doi = {10.1145/3636534.3649352},
abstract = {Recently, smart roadside infrastructure (SRI) has demonstrated the potential of achieving fully autonomous driving systems. To explore the potential of infrastructure-assisted autonomous driving, this paper presents the design and deployment of Soar, the first end-to-end SRI system specifically designed to support autonomous driving systems. Soar consists of both software and hardware components carefully designed to overcome various system and physical challenges. Soar can leverage the existing operational infrastructure like street lampposts for a lower barrier of adoption. Soar adopts a new communication architecture that comprises a bi-directional multi-hop I2I network and a downlink I2V broadcast service, which are designed based on off-the-shelf 802.11ac interfaces in an integrated manner. Soar also features a hierarchical DL task management framework to achieve desirable load balancing among nodes and enable them to collaborate efficiently to run multiple data-intensive autonomous driving applications. We deployed a total of 18 Soar nodes on existing lampposts on campus, which have been operational for over two years. Our real-world evaluation shows that Soar can support a diverse set of autonomous driving applications and achieve desirable real-time performance and high communication reliability. Our findings and experiences in this work offer key insights into the development and deployment of next-generation smart roadside infrastructure and autonomous driving systems.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {139–154},
numpages = {16},
keywords = {smart roadside infrastructure, infrastructure-assisted autonomous driving, V2X, edge computing},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649353,
author = {Ma, Ruichun and Hu, Wenjun},
title = {RF-Mediator: Tuning Medium Interfaces with Flexible Metasurfaces},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649353},
doi = {10.1145/3636534.3649353},
abstract = {Emerging wireless IoT applications increasingly venture beyond over-the-air communication, such as deep-tissue networking for medical sensors, air-water communication for oceanography, and soil sensing for agriculture. These applications face the fundamental challenge of significant reflection and power loss at medium interfaces. We present RF-Mediator, a programmable metasurface placed near a medium interface to mask the presence of a physical boundary. Our hardware design comprises a single layer of varactor-based surface elements with specific metallic patterns and wiring. With the biasing voltage tuned element-wise, the surface dynamically mediates between the adjacent media to minimize unwanted reflection and boost transmission through the medium interface. A multi-stage control algorithm efficiently determines the surface configuration to handle all dynamic adaptation needs for medium impedance matching and beamforming jointly. We implement a lightweight and flexible metasurface prototype and experiment with diverse cross-medium setups. Extensive evaluation shows that RF-Mediator provides a median power gain of 8 dB for air-tissue links and up to 30 dB for cross-medium backscatter links.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {155–169},
numpages = {15},
keywords = {cross-medium, wireless, metasurfaces, impedance matching, beamforming},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649354,
author = {Zhang, Huanhuan and An, Congkai and Zhou, Anfu and Zhu, Yifan and Sun, Weilin and Lu, Yixuan and Chen, Jiahao and Liu, Liang and Ma, Huadong and Fei, Aiguo},
title = {Venus: Enhancing QoE of Crowdsourced Live Video Streaming by Exploiting Multiflow Viewer Assistance},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649354},
doi = {10.1145/3636534.3649354},
abstract = {Despite the prevalence of Crowdsourced Live Video Streaming (CLVS), video viewers still suffer from low QoE particularly under rush hours, as the existing Content Delivery Network (CDN) is not scalable enough to handle the massive concurrent streaming. The rapid emergence of Web 3.0 provides new incentives for revisiting and applying the classical P2P networking in CLVS. However, the highly dynamic joining or leaving behavior of CLVS viewers frequently interrupts the real-time streaming and leads to low QoE, which demands to retrofit P2P. In this work, we bridge the gap by proposing a reliable P2P-assisted CLVS system named Venus, where viewers can share their streaming content smoothly, without video freeze regardless of viewers leaving. To realize Venus, different from the single-flow sharing in previous P2P video streaming, we design a novel multiflow framework with lightweight redundancy encoding, so as to handle the inherently high viewer dynamics. Correspondingly, we introduce a multiflow scheduler to enable QoE adaption concertedly over heterogeneous multiple flows. Real-world evaluation confirms the benefits of decentralized CLVS streaming, with Venus outperforming the state-of-the-art CDN solution by almost totally eliminating the video stall while enhancing the video quality by 10.2\%.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {170–184},
numpages = {15},
keywords = {CLVS, viewer assistance, multiflow P2P, QoE enhancement},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649355,
author = {Yao, Zhiyun and Wang, Xuanzhi and Niu, Kai and Zheng, Rong and Wang, Junzhe and Zhang, Daqing},
title = {WiProfile: Unlocking Diffraction Effects for Sub-Centimeter Target Profiling Using Commodity WiFi Devices},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649355},
doi = {10.1145/3636534.3649355},
abstract = {Despite intensive research efforts in radio frequency noncontact sensing, capturing fine-grained geometric properties of objects, such as shape and size, remains an open problem using commodity WiFi devices. Prior attempts are incapable of characterizing object shape or size because they predominantly rely on weak signals reflected off objects in a very small number of directions. In this paper, motivated by the observation that the diffracted signals around an object between two WiFi devices carry the contour information of the object, we formulate the problem of reconstructing the 2D target profile and develop WiProfile, the first WiFi-based system that unlocks the diffraction effects for target profiling. We introduce a CSI-Profile model to characterize the relationship between the CSI measured at different target positions and the target profile in the diffraction zone. With suitable approximations, the inverse problem of deriving the target profile from CSI can be solved by the inverse Fresnel transform. To mitigate CSI measurement errors on commodity WiFi devices, we propose a novel antenna placement strategy. Comprehensive experiments demonstrate that WiProfile can accurately reconstruct profiles with median absolute errors of less than 1 cm under various conditions, and effectively estimate the profiles of everyday objects of diverse shapes, sizes, and materials. We believe this work opens up new directions for fine-grained target imaging using commodity WiFi devices.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {185–199},
numpages = {15},
keywords = {wifi imaging, wifi sensing, diffraction, CSI-profile model},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649356,
author = {Fan, Xiubin and Li, Guanyao and Lin, Zhongming and Hu, Yuming and Liu, Yang and Jiang, Tianrui and Yin, Zhimeng and Qian, Feng and Wang, Shuai and Chan, S.-H. Gary},
title = {Experiences of Deploying a Citywide Crowdsourcing Platform to Search for Missing People with Dementia},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649356},
doi = {10.1145/3636534.3649356},
abstract = {People with Dementia (PwD) suffer from a high risk of getting lost due to their cognitive deterioration, leading to potential safety hazards and significant search efforts. In this paper, we propose DEmentia Caring System (DECS), an effective crowdsourcing platform to search for missing PwD. Specifically, PwD carry our customized Bluetooth Low Energy (BLE) tags that broadcast BLE packets, which are detected and then uploaded by mobile volunteers via their smartphones. To further enhance search efficiency, DECS deploys BLE gateways as its infrastructure and analyzes PwD's daily spatial-temporal mobility patterns. DECS has been deployed in Hong Kong since 2019, supporting 3,100+ PwD's families with over 45,000 app downloads by volunteers. More importantly, it has successfully served the search for 254 missing cases. This paper reports the unique lessons and experiences learned through our 4-year citywide deployment of DECS.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {200–214},
numpages = {15},
keywords = {crowdsourcing, searching system, bluetooth low energy},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649357,
author = {Zheng, Jianwei and Li, Zhenhua and Qian, Feng and Liu, Wei and Lin, Hao and Liu, Yunhao and Xu, Tianyin and Zhang, Nan and Wang, Ju and Zhang, Cang},
title = {Rethinking Process Management for Interactive Mobile Systems},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649357},
doi = {10.1145/3636534.3649357},
abstract = {Modern mobile systems are featured by their increasing interactivity with users, which however is accompanied by a severe side effect---users constantly suffer from slow UI responsiveness (SUR). To date, the community have limited understandings of this issue for the challenges of comprehensively measuring SUR events on massive mobile devices. As a major Android phone vendor, in this paper we close the knowledge gap by conducting the first large-scale, long-term measurement study on SUR with 47M devices. Our study identifies the critical factors that lead to SUR from the perspectives of device, system, application, and app market. Most importantly, we note that the largest root cause lies in the wide existence of "hogging" apps, which persistently occupy an unreasonable amount of system resources by leveraging the optimistic design of Android process management. We have built on the insights to remodel Android process states by fully considering their time-sensitive transitions and the actual behaviors of processes, with remarkable real-world impact---the occurrences of SUR are reduced by 60\%, together with 10.7\% saving of battery consumption.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {215–229},
numpages = {15},
keywords = {interactive mobile systems, slow UI responsiveness, android resource management, app behaviors},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649358,
author = {Ren, Yidong and Sun, Wei and Du, Jialuo and Zeng, Huaili and Dong, Younsuk and Zhang, Mi and Chen, Shigang and Liu, Yunhao and Li, Tianxing and Cao, Zhichao},
title = {Demeter: Reliable Cross-soil LPWAN with Low-cost Signal Polarization Alignment},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649358},
doi = {10.1145/3636534.3649358},
abstract = {Soil monitoring plays an essential role in agricultural systems. Rather than deploying sensors' antennas above the ground, burying them in the soil is an attractive way to retain a non-intrusive aboveground space. Low Power Wide-Area Network (LPWAN) has shown its long-distance and low-power features for aboveground Internet-of-Things (IoT) communication, presenting a potential of extending to underground cross-soil communication over a wide area, which however has not been investigated before. The variation of soil conditions brings significant signal polarization misalignment, degrading communication reliability. In this paper, we propose Demeter, a low-cost low-power programmable antenna design to keep reliable cross-soil communication automatically. First, we propose a hardware architecture to enable polarization adjustment on commercial-off-the-shelf (COTS) single-RF-chain LoRa radio. Moreover, we develop a low-power programmable circuit to obtain polarization adjustment. We further design an energy-efficient heuristic calibration algorithm and an adaptive calibration scheduling method to keep signal polarization alignment automatically. We implement Demeter with a customized PCB circuit and COTS devices. Then, we evaluate its performance in various soil types and environmental conditions. The results show that Demeter can achieve up to 11.6 dB SNR gain indoors and 9.94 dB outdoors, 4\texttimes{} horizontal communication distance, at least 20 cm deeper underground deployment, and up to 82\% energy consumption reduction per day compared with the standard LoRa.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {230–245},
numpages = {16},
keywords = {agricultural IoT, LPWAN, cross-soil communication},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649359,
author = {Lv, Gerui and Wu, Qinghua and Liu, Yanmei and Li, Zhenyu and Tan, Qingyue and Yang, Furong and Chen, Wentao and Ma, Yunfei and Guo, Hongyu and Chen, Ying and Xie, Gaogang},
title = {Chorus: Coordinating Mobile Multipath Scheduling and Adaptive Video Streaming},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649359},
doi = {10.1145/3636534.3649359},
abstract = {Increasing bandwidth demands of mobile video streaming pose a challenge in optimizing the Quality of Experience (QoE) for better user engagement. Multipath transmission promises to extend network capacity by utilizing multiple wireless links simultaneously. Previous studies mainly tune the packet scheduler in multipath transmission, expecting higher QoE by accelerating transmission. However, since Adaptive BitRate (ABR) algorithms overlook the impact of multipath scheduling on throughput prediction, multipath adaptive streaming can even experience lower QoE than single-path. This paper proposes Chorus, a cross-layer framework that coordinates multipath scheduling with adaptive streaming to optimize QoE jointly. Chorus establishes two-way feedback control loops between the server and the client. Furthermore, Chorus introduces Coarse-grained Decisions, which assist appropriate bitrate selection by considering the scheduling decision in throughput prediction, and Finegrained Corrections, which meet the predicted throughput by QoE-oriented multipath scheduling. Extensive emulation and real-world mobile Internet evaluations show that Chorus outperforms the state-of-the-art MPQUIC scheduler, improving average QoE by 23.5\% and 65.7\%, respectively.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {246–262},
numpages = {17},
keywords = {multipath QUIC, adaptive video streaming, QoE},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649360,
author = {Li, Yijie and Zhou, Juntao and Ding, Dian and Chen, Yi-Chao and Qiu, Lili and Yu, Jiadi and Xue, Guangtao},
title = {MuDiS: An Audio-independent, Wide-angle, and Leak-free Multi-directional Speaker},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649360},
doi = {10.1145/3636534.3649360},
abstract = {This paper introduces a novel multi-directional speaker, named MuDiS, which utilizes a parametric array to generate highly focused sound beams in multiple directions. The system capitalizes on air nonlinearity to reproduce sound from ultrasounds, successfully overcoming challenges inherent in traditional parametric arrays, such as transducer size and wavefront shape. It supports three important features simultaneously: independent beams, wide-angle digital steering, and unintended leakage suppression. To address these challenges, we designed a specialized cell structure that connects ultrasonic transducers, redirecting an approximately omnidirectional wavefront with optimal interspacing. An optimization-based algorithm is developed to minimize unintended leakages, and a nonlinear distortion reduction scheme is proposed to enhance sound quality. The paper showcases a prototype demonstrating the system's capabilities as a multidirectional speaker with a wide sound projection angle. Experimental results validate the effectiveness of our approach. The proposed multi-beam projection system rivals the performance of commercially available single-beam projection directional speakers, and improved steering angle and sound fidelity compared to multi-beamforming performance using traditional parametric arrays.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {263–278},
numpages = {16},
keywords = {multi-directional speaker, air nonlinearity},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649361,
author = {Yuan, Jinliang and Yang, Chen and Cai, Dongqi and Wang, Shihe and Yuan, Xin and Zhang, Zeling and Li, Xiang and Zhang, Dingge and Mei, Hanzi and Jia, Xianqing and Wang, Shangguang and Xu, Mengwei},
title = {Mobile Foundation Model as Firmware},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649361},
doi = {10.1145/3636534.3649361},
abstract = {In the current AI era, mobile devices such as smartphones are tasked with executing a myriad of deep neural networks (DNNs) locally. It presents a complex landscape, as these models are highly fragmented in terms of architecture, operators, and implementations. Such fragmentation poses significant challenges to the co-optimization of hardware, systems, and algorithms for efficient and scalable mobile AI.Inspired by the recent groundbreaking progress in large foundation models, this work introduces a novel paradigm for mobile AI, where mobile OS and hardware jointly manage a foundation model that is capable of serving a wide array of mobile AI tasks. This foundation model functions akin to firmware, unmodifiable by apps or the OS, exposed as a system service to Apps. They can invoke this foundation model through a small, offline fine-tuned "adapter" for various downstream tasks. We propose a tangible design of this vision called M4, and prototype it from publicly available pre-trained models. To assess its capability, we also build a comprehensive benchmark consisting of 38 mobile AI tasks and 50 datasets, spanning 5 multimodal inputs. Extensive experiments demonstrate M4's remarkable results: it achieves comparable accuracy in 85\% of tasks, offers enhanced scalability regarding storage and memory, and has much simpler operations. In broader terms, this work paves a new way towards efficient and scalable mobile AI in the post-LLM era.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {279–295},
numpages = {17},
keywords = {mobile computing, multimodal foundation model, efficient and scalable mobile AI},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649362,
author = {Li, Yuanjie and Liu, Lixin and Li, Hewu and Liu, Wei and Chen, Yimei and Zhao, Wei and Wu, Jianping and Wu, Qian and Liu, Jun and Lai, Zeqi},
title = {Stable Hierarchical Routing for Operational LEO Networks},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649362},
doi = {10.1145/3636534.3649362},
abstract = {Low Earth Orbit (LEO) satellite mega-constellations promise ubiquitous network services to "unconnected" users. But their upcoming global routing for Earth will be unstable due to exhaustive topology updates between satellites and Earth, inside an orbital shell, and across heterogeneous orbital shells. In real LEO networks, these multi-dimensional dynamics are interleaved and complicated by chaotic orbital maneuvers and random failures. They are less predictable than most satellite routing proposals expect and threaten these proposals' availability, efficiency, or resiliency at scale.We propose SHORT, a Stable Hierarchical Orbital Routing Technique to decouple, localize, and mask multi-dimensional dynamics from operational LEO networks. SHORT takes a geographic paradigm to organize the LEO network as stable hierarchical routing domains, split heterogeneous LEO dynamics into each domain, mask them with domain-specific routing via orbital-geodetic coordinates, and localize adaptions to orbital maneuvers, random failures, and partial deployments. SHORT can work incrementally as a control-plane overlay to enhance existing LEO routing proposals. Our evaluations with the U.S. Space Surveillance Network datasets and prototype validate SHORT's near-optimal availability, efficiency, and resiliency in operational LEO networks.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {296–311},
numpages = {16},
keywords = {satellite networks, network addressing and routing},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649363,
author = {Ye, Shengyuan and Zeng, Liekang and Chu, Xiaowen and Xing, Guoliang and Chen, Xu},
title = {Asteroid: Resource-Efficient Hybrid Pipeline Parallelism for Collaborative DNN Training on Heterogeneous Edge Devices},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649363},
doi = {10.1145/3636534.3649363},
abstract = {On-device Deep Neural Network (DNN) training has been recognized as crucial for privacy-preserving machine learning at the edge. However, the intensive training workload and limited onboard computing resources pose significant challenges to the availability and efficiency of model training. While existing works address these challenges through native resource management optimization, we instead leverage our observation that edge environments usually comprise a rich set of accompanying trusted edge devices with idle resources beyond a single terminal. We propose Asteroid, a distributed edge training system that breaks the resource walls across heterogeneous edge devices for efficient model training acceleration. Asteroid adopts a hybrid pipeline parallelism to orchestrate distributed training, along with a judicious parallelism planning for maximizing throughput under certain resource constraints. Furthermore, a fault-tolerant yet lightweight pipeline replay mechanism is developed to tame the device-level dynamics for training robustness and performance stability. We implement Asteroid on heterogeneous edge devices with both vision and language models, demonstrating up to 12.2\texttimes{} faster training than conventional parallelism methods and 2.1\texttimes{} faster than state-of-the-art hybrid parallelism methods through evaluations. Furthermore, Asteroid can recover training pipeline 14\texttimes{} faster than baseline methods while preserving comparable throughput despite unexpected device exiting and failure.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {312–326},
numpages = {15},
keywords = {edge intelligence, distributed machine learning, data parallelism, pipeline parallelism, hybrid parallelism},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649364,
author = {Liu, Yu and Zhou, Puqi and Zhang, Zejun and Zhang, Anlan and Han, Bo and Li, Zhenhua and Qian, Feng},
title = {MuV2: Scaling up Multi-user Mobile Volumetric Video Streaming via Content Hybridization and Sharing},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649364},
doi = {10.1145/3636534.3649364},
abstract = {Volumetric videos offer a unique interactive experience and have the potential to enhance social virtual reality and telepresence. Streaming volumetric videos to multiple users remains a challenge due to its tremendous requirements of network and computation resources. In this paper, we develop MuV2, an edge-assisted multi-user mobile volumetric video streaming system to support important use cases such as tens of students simultaneously consuming volumetric content in a classroom. MuV2 achieves high scalability and good streaming quality through three orthogonal designs: hybridizing direct streaming of 3D volumetric content with remote rendering, dynamically sharing edge-transcoded views across users, and multiplexing encoding tasks of multiple transcoding sessions into a limited number of hardware encoders on the edge. MuV2 then integrates the three designs into a holistic optimization framework. We fully implement MuV2 and experimentally demonstrate that MuV2 can deliver high-quality volumetric videos to over 30 concurrent untethered mobile devices with a single WiFi access point and a commodity edge server.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {327–341},
numpages = {15},
keywords = {volumetric video streaming, mobile mixed reality, edge computing, quality-of-experience (QoE)},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649365,
author = {Sun, Xue and Xiong, Jie and Feng, Chao and Li, Xiaohui and Zhang, Jiayi and Li, Binghao and Fang, Dingyi and Chen, Xiaojiang},
title = {Gastag: A Gas Sensing Paradigm using Graphene-based Tags},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649365},
doi = {10.1145/3636534.3649365},
abstract = {Gas sensing plays a key role in detecting explosive/toxic gases and monitoring environmental pollution. Existing approaches usually require expensive hardware or high maintenance cost, and are thus ill-suited for large-scale long-term deployment. In this paper, we propose Gastag, a gas sensing paradigm based on passive tags. The heart of Gastag design is embedding a small piece of gas-sensitive material to a cheap RFID tag. When gas concentration varies, the conductivity of gas-sensitive materials changes, impacting the impedance of the tag and accordingly the received signal. To increase the sensing sensitivity and gas concentration range capable of sensing, we carefully select multiple materials and synthesize a new material that exhibits high sensitivity and high surface-to-weight ratio. To enable a long working range, we redesigned the tag antenna and carefully determined the location to place the gas-sensitive material in order to achieve impedance matching. Comprehensive experiments demonstrate the effectiveness of the proposed system. Gastag can achieve a median error of 6.7 ppm for CH4 concentration measurements, 12.6 ppm for CO2 concentration measurements, and 3 ppm for CO concentration measurements, outperforming a lot of commodity gas sensors on the market. The working range is successfully increased to 8.5 m, enabling the coverage of many tags with a single reader, laying the foundation for large-scale deployment.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {342–356},
numpages = {15},
keywords = {gas sensing, RFID, backscatter, wireless sensing, internet of things (IoT), graphene antenna},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649366,
author = {Chen, Tao and Yang, Yongjie and Fan, Xiaoran and Guo, Xiuzhen and Xiong, Jie and Shangguan, Longfei},
title = {Exploring the Feasibility of Remote Cardiac Auscultation Using Earphones},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649366},
doi = {10.1145/3636534.3649366},
abstract = {The elderly over 65 accounts for 80\% of COVID deaths in the United States. In response to the pandemic, the federal, state governments, and commercial insurers are promoting video visits, through which the elderly can access specialists at home over the Internet, without the risk of COVID exposure. However, the current video visit practice barely relies on video observation and talking. The specialist could not assess the patient's health conditions by performing auscultations.This paper tries to address this key missing component in video visits by proposing Asclepius, a hardware-software solution that turns the patient's earphones into a stethoscope, allowing the specialist to hear the patient's fine-grained heart sound (i.e., PCG signals) in video visits. To achieve this goal, we contribute a low-cost plug-in peripheral that repurposes the earphone's speaker into a microphone and uses it to capture the patient's minute PCG signals from her ear canal. As the PCG signals suffer from strong attenuation and multi-path effects when propagating from the heart to ear canals, we then propose efficient signal processing algorithms coupled with a data-driven approach to de-reverberate and further correct the amplitude and frequency distortion in raw PCG receptions. We implement Asclepius on a 2-layer PCB board and follow the IRB protocol to evaluate its performance with 30 volunteers. Our extensive experiments show that Asclepius can effectively recover Phonocardiogram (PCG) signals with different types of earphones. The objective blind testing and subjective interview with five cardiologists further confirm the clinical efficacy and efficiency of our system. PCG signal samples, benchmark results, and cardiologist interviews can be found at: https://asclepius-system.github.io/},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {357–372},
numpages = {16},
keywords = {remote health, cardiac monitoring, earable computing},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649367,
author = {Li, Changming and Xu, Mingjing and Du, Yicong and Liu, Limin and Shi, Cong and Wang, Yan and Liu, Hongbo and Chen, Yingying},
title = {Practical Adversarial Attack on WiFi Sensing Through Unnoticeable Communication Packet Perturbation},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649367},
doi = {10.1145/3636534.3649367},
abstract = {The pervasive use of WiFi has driven the recent research in WiFi sensing, converting communication tech into sensing for applications such as activity recognition, user authentication, and vital sign monitoring. Despite the integration of deep learning into WiFi sensing systems, potential security vulnerabilities to adversarial attacks remain unexplored. This paper introduces the first physical attack focusing on deep learning-based WiFi sensing systems, demonstrating how adversaries can subtly manipulate WiFi packet preambles to affect channel state information (CSI), a critical feature in such systems, and thereby influence underlying deep learning models without disrupting regular communication. To realize the proposed attack in practical scenarios, we rigorously analyze and derive the intricate relationship between the pilot symbol and CSI. A novel mechanism is proposed to facilitate quantitive control of receiver-side CSI through minimal modifications to the pilot symbols of WiFi packets at the transmitter. We further develop a perturbation optimization method based on the Carlini \& Wagner (CW) attack and a penalty-based training process to ensure the attack's universal efficacy across various CSI responses and noise. The physical attack is implemented and evaluated in two representative WiFi sensing systems (i.e., activity recognition and user authentication) with 35 participants over 3 months. Extensive experiments demonstrate the remarkable attack success rates of 90.47\% and 83.83\% for activity recognition and user authentication, respectively.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {373–387},
numpages = {15},
keywords = {adversarial attack, wifi sensing, unnoticeable attack, communication packet perturbation},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649369,
author = {Lai, Haowen and Luo, Gaoxiang and Liu, Yifei and Zhao, Mingmin},
title = {Enabling Visual Recognition at Radio Frequency},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649369},
doi = {10.1145/3636534.3649369},
abstract = {This paper introduces PanoRadar, a novel RF imaging system that brings RF resolution close to that of LiDAR, while providing resilience against conditions challenging for optical signals. Our LiDAR-comparable 3D imaging results enable, for the first time, a variety of visual recognition tasks at radio frequency, including surface normal estimation, semantic segmentation, and object detection. PanoRadar utilizes a rotating single-chip mmWave radar, along with a combination of novel signal processing and machine learning algorithms, to create high-resolution 3D images of the surroundings. Our system accurately estimates robot motion, allowing for coherent imaging through a dense grid of synthetic antennas. It also exploits the high azimuth resolution to enhance elevation resolution using learning-based methods. Furthermore, PanoRadar tackles 3D learning via 2D convolutions and addresses challenges due to the unique characteristics of RF signals. Our results demonstrate PanoRadar's robust performance across 12 buildings. Code, datasets, and demo videos are available on our website.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {388–403},
numpages = {16},
keywords = {RF sensing, mmWave radar, egomotion estimation, 3D imaging, robust perception, machine learning},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649370,
author = {Ouyang, Xiaomin and Shuai, Xian and Li, Yang and Pan, Li and Zhang, Xifan and Fu, Heming and Cheng, Sitong and Wang, Xinyan and Cao, Shihua and Xin, Jiang and Mok, Hazel and Yan, Zhenyu and Yu, Doris Sau Fung and Kwok, Timothy and Xing, Guoliang},
title = {ADMarker: A Multi-Modal Federated Learning System for Monitoring Digital Biomarkers of Alzheimer's Disease},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649370},
doi = {10.1145/3636534.3649370},
abstract = {Alzheimer's Disease (AD) and related dementia are a growing global health challenge due to the aging population. In this paper, we present ADMarker, the first end-to-end system that integrates multi-modal sensors and new federated learning algorithms for detecting multidimensional AD digital biomarkers in natural living environments. ADMarker features a novel three-stage multi-modal federated learning architecture that can accurately detect digital biomarkers in a privacy-preserving manner. Our approach collectively addresses several major real-world challenges, such as limited data labels, data heterogeneity, and limited computing resources. We built a compact multi-modality hardware system and deployed it in a four-week clinical trial involving 91 elderly participants. The results indicate that ADMarker can accurately detect a comprehensive set of digital biomarkers with up to 93.8\% accuracy and identify early AD with an average of 88.9\% accuracy. ADMarker offers a new platform that can allow AD clinicians to characterize and track the complex correlation between multidimensional interpretable digital biomarkers, demographic factors of patients, and AD diagnosis in a longitudinal manner.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {404–419},
numpages = {16},
keywords = {digital biomarkers, behavior monitoring, multi-modal federated learning systems},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649371,
author = {Xing, Ruolin and Xu, Mengwei and Zhou, Ao and Li, Qing and Zhang, Yiran and Qian, Feng and Wang, Shangguang},
title = {Deciphering the Enigma of Satellite Computing with COTS Devices: Measurement and Analysis},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649371},
doi = {10.1145/3636534.3649371},
abstract = {In the wake of the rapid deployment of large-scale low-Earth orbit satellite constellations, exploiting the full computing potential of Commercial Off-The-Shelf (COTS) devices in these environments has become a pressing issue. However, understanding this problem is far from straightforward due to the inherent differences between the terrestrial infrastructure and the satellite platform in space. In this paper, we take an important step towards closing this knowledge gap by presenting the first measurement study on the thermal control, power management, and performance of COTS computing devices on satellites. Our measurements reveal that the satellite platform and COTS computing devices significantly interplay in terms of the temperature and energy, forming the main constraints on satellite computing. Further, we analyze the critical factors that shape the characteristics of onboard COTS computing devices. We provide guidelines for future research on optimizing the use of such devices for computing purposes. Finally, we have released the datasets to facilitate further study in satellite computing.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {420–435},
numpages = {16},
keywords = {satellite networking, earth observation, satellite computing, network measurement, dataset},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649372,
author = {Zhu, Yi and Miao, Chenglin and Xue, Hongfei and Yu, Yunnan and Su, Lu and Qiao, Chunming},
title = {Malicious Attacks against Multi-Sensor Fusion in Autonomous Driving},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649372},
doi = {10.1145/3636534.3649372},
abstract = {Multi-sensor fusion has been widely used by autonomous vehicles (AVs) to integrate the perception results from different sensing modalities including LiDAR, camera and radar. Despite the rapid development of multi-sensor fusion systems in autonomous driving, their vulnerability to malicious attacks have not been well studied. Although some prior works have studied the attacks against the perception systems of AVs, they only consider a single sensing modality or a camera-LiDAR fusion system, which can not attack the sensor fusion system based on LiDAR, camera, and radar. To fill this research gap, in this paper, we present the first study on the vulnerability of multi-sensor fusion systems that employ LiDAR, camera, and radar. Specifically, we propose a novel attack method that can simultaneously attack all three types of sensing modalities using a single type of adversarial object. The adversarial object can be easily fabricated at low cost, and the proposed attack can be easily performed with high stealthiness and flexibility in practice. Extensive experiments based on a real-world AV testbed show that the proposed attack can continuously hide a target vehicle from the perception system of a victim AV using only two small adversarial objects.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {436–451},
numpages = {16},
keywords = {autonomous driving, multi-sensor fusion, adversarial attack},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649373,
author = {Johnson, Jacob and Palacios, Ashton and Arvonen, Cody and Lundrigan, Philip},
title = {Wireless Latency Shift Keying},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649373},
doi = {10.1145/3636534.3649373},
abstract = {IEEE 802.11 (WiFi) only has two modes of trust---complete trust or complete untrust. The lack of nuance leaves no room for sensors that a user does not fully trust but wants to connect to their network, such as a WiFi sensor. Solutions exist, but they require advanced knowledge of network administration. We solve this problem by introducing a new way of modulating data in the latency of the network, called Latency Shift Keying. We use specific characteristics of the WiFi protocol to carefully control the latency of just one device on the network. We build a transmitter, receiver, and modulation scheme that is designed to encode data in the latency of a network. We develop an application, Wicket, that solves the WiFi trust issue using Latency Shift Keying to create a new security association between an untrusted WiFi sensor and a wired device on the trusted network. We evaluate its performance and show that it works in many network conditions and environments.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {452–466},
numpages = {15},
keywords = {wireless subprotocol, IoT, sensor networks, 802.11, wifi},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649374,
author = {Ning, Jingyi and Xie, Lei and Yan, Zhihao and Bu, Yanling and Luo, Jun},
title = {Moir\'{e}Vision: A Generalized Moir\'{e}-based Mechanism for 6-DoF Motion Sensing},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649374},
doi = {10.1145/3636534.3649374},
abstract = {Ultra-high precision motion sensing leveraging computer vision (CV) is a key technology in many high-precision AR/VR applications such as precise industrial manufacture and image-guided surgery, yet conventional CV can be challenged by moir\'{e}-based sensing mechanism, thanks to moir\'{e} pattern's high sensitivity to six degrees of freedom (6-DoF) pose changes. Unfortunately, existing moir\'{e}-based solutions, in their infancy, cannot deal with complicated curvilinear moir\'{e} patterns caused by various perspective angles. In this paper, we propose a generalized moir\'{e}-based mechanism, Moir\'{e}Vision, towards practical adoptions; it relies on high-frequency gratings as visual marker to help extract the fine-grained feature points for ultra-high precision motion sensing. As the foundation of general moir\'{e}-based sensing, we propose a formulation to characterize "uncontrolled" curvilinear moir\'{e} patterns in practical scenarios. To deal with the problem of moir\'{e} feature interference in practice, we propose a Gabor-based algorithm to separate overlapped curvilinear moir\'{e} patterns from two dimensions. Furthermore, to extract fine-grained feature points for high-precision motion sensing, we propose a bending function-based model and a resolution-enhanced strategy to reconstruct detailed texture of moir\'{e} markers and extract moir\'{e} feature points at sub-pixel level. Extensive experimental results show that Moir\'{e}Vision greatly enhances the usability and generalizability of moir\'{e}-based sensing systems in real-world applications.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {467–481},
numpages = {15},
keywords = {moir\'{e} pattern, fine-grained feature point, 6-DoF motion sensing, generalizability},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649375,
author = {Yu, Shiming and Xia, Xianjin and Hou, Ningning and Zheng, Yuanqing and Gu, Tao},
title = {Revolutionizing LoRa Gateway with XGate: Scalable Concurrent Transmission across Massive Logical Channels},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649375},
doi = {10.1145/3636534.3649375},
abstract = {LoRa is a promising technology that offers ubiquitous low-power IoT connectivity. With the features of multi-channel communication, orthogonal transmission, and spectrum sharing, LoRaWAN is poised to connect millions of IoT devices across thousands of logical channels. However, current LoRa gateways utilize hardwired Rx chains that cover only a small fraction (<1\%) of the logical channels, limiting the potential for massive LoRa communications. This paper presents XGate, a novel gateway design that uses a single Rx chain to concurrently receive packets from all logical channels, fundamentally enabling scalable LoRa transmission and flexible network access. Unlike hardwired Rx chains in the current gateway design, XGate allocates resources including software-controlled Rx chains and demodulators based on the extracted meta information of incoming packets. XGate addresses a series of challenges to efficiently detect incoming packets without prior knowledge of their parameter configurations. Evaluations show that XGate boosts LoRa concurrent transmissions by 8.4\texttimes{} than state-of-the-art.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {482–496},
numpages = {15},
keywords = {internet of things, LPWAN, LoRa, logical channel},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649376,
author = {Li, Ke and Zhang, Ruidong and Chen, Boao and Chen, Siyuan and Yin, Sicheng and Mahmud, Saif and Liang, Qikang and Guimbretiere, Francois and Zhang, Cheng},
title = {GazeTrak: Exploring Acoustic-based Eye Tracking on a Glass Frame},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649376},
doi = {10.1145/3636534.3649376},
abstract = {In this paper, we present GazeTrak, the first acoustic-based eye tracking system on glasses. Our system only needs one speaker and four microphones attached to each side of the glasses. These acoustic sensors capture the formations of the eyeballs and the surrounding areas by emitting encoded inaudible sound towards eyeballs and receiving the reflected signals. These reflected signals are further processed to calculate the echo profiles, which are fed to a customized deep learning pipeline to continuously infer the gaze position. In a user study with 20 participants, GazeTrak achieves an accuracy of 3.6° within the same remounting session and 4.9° across different sessions with a refreshing rate of 83.3 Hz and a power signature of 287.9 mW. Furthermore, we report the performance of our gaze tracking system fully implemented on an MCU with a low-power CNN accelerator (MAX78002). In this configuration, the system runs at up to 83.3 Hz and has a total power signature of 95.4 mW with a 30 Hz FPS.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {497–512},
numpages = {16},
keywords = {eye tracking, acoustic sensing, smart glasses, low-power},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649377,
author = {Shi, Jingwen and Wang, Sihan and Chen, Min-Yue and Tu, Guan-Hua and Xie, Tian and Chen, Man-Hsin and Hu, Yiwen and Li, Chi-Yu and Peng, Chunyi},
title = {IMS is Not That Secure on Your 5G/4G Phones},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649377},
doi = {10.1145/3636534.3649377},
abstract = {IMS (IP Multimedia Subsystem) is vital for delivering IP-based multimedia services in mobile networks. Despite constant upgrades by 3GPP over the past two decades to support heterogeneous radio access networks (e.g., 4G LTE, 5G NR, and Wi-Fi) and enhance IMS security, the focus has primarily been on cellular infrastructure. Consequently, IMS security measures on mobile equipment (ME), such as smartphones, lag behind rapid technological advancements. Our study reveals that mandated IMS security measures on ME fail to keep pace, resulting in new vulnerabilities and attack vectors, including denial of service (DoS) across all networks, named SMS source spoofing, and covert communications over Video-over-IMS attacks. All vulnerabilities and proof-of-concept attacks have been experimentally validated in operational 5G/4G networks across various phone models and network operators. Finally, we propose and prototype standard-compliant remedies for these vulnerabilities.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {513–527},
numpages = {15},
keywords = {cellular networks, IP multimedia services (IMS), security},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649378,
author = {Sun, Zehua and Ni, Tao and Chen, Yongliang and Duan, Di and Liu, Kai and Xu, Weitao},
title = {RF-Egg: An RF Solution for Fine-Grained Multi-Target and Multi-Task Egg Incubation Sensing},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649378},
doi = {10.1145/3636534.3649378},
abstract = {Eggs and chickens serve as crucial animal-source proteins in our diets, making large-scale breeding egg incubation an essential undertaking. However, current solutions, i.e., vision-based and sensor-based methods, are primarily designed for egg fertility detection tasks under single-egg settings, which have not yet satisfied the goal of multi-target and multi-task sensing. In this paper, we propose RF-Egg, the first RF-based fine-grained multi-target and multi-task egg incubation sensing system with respect to sensing fertility, incubation status, and early mortality of chicken embryos. RF-Egg leverages the weak coupling effects of RFID tags when interacting with eggs, which induces different impedance changes of RFID tags with the incubation levels of eggs, thereby resulting in a variation of low-level phase readings of the backscatter signals. Regarding the challenge of multi-target profiling interference, we propose a multipath combating algorithm to extract the target-induced signal component based on the built signal model, and address non-uniformity issues across multiple tags. Moreover, we devise three unique feature maps tailored to each task, and then design an Multi-Task Triplet (MTT) network for multitasking. Our evaluation results based on 189 eggs show that RF-Egg achieves an accuracy of 94.4\%, 96.1\%, and 90.1\% for the aforementioned three tasks when supporting 16 targets. Additionally, our extensive field study in a local egg hatchery suggests that RF-Egg presents the potential to be widely deployed in the modern poultry industry.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {528–542},
numpages = {15},
keywords = {RFID sensing, egg incubation},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649379,
author = {Wen, Hao and Li, Yuanchun and Liu, Guohong and Zhao, Shanhui and Yu, Tao and Li, Toby Jia-Jun and Jiang, Shiqi and Liu, Yunhao and Zhang, Yaqin and Liu, Yunxin},
title = {AutoDroid: LLM-powered Task Automation in Android},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649379},
doi = {10.1145/3636534.3649379},
abstract = {Mobile task automation is an attractive technique that aims to enable voice-based hands-free user interaction with smartphones. However, existing approaches suffer from poor scalability due to the limited language understanding ability and the non-trivial manual efforts required from developers or endusers. The recent advance of large language models (LLMs) in language understanding and reasoning inspires us to rethink the problem from a model-centric perspective, where task preparation, comprehension, and execution are handled by a unified language model. In this work, we introduce AutoDroid, a mobile task automation system capable of handling arbitrary tasks on any Android application without manual efforts. The key insight is to combine the commonsense knowledge of LLMs and domain-specific knowledge of apps through automated dynamic analysis. The main components include a functionality-aware UI representation method that bridges the UI with the LLM, exploration-based memory injection techniques that augment the app-specific domain knowledge of LLM, and a multi-granularity query optimization module that reduces the cost of model inference. We integrate AutoDroid with off-the-shelf LLMs including online GPT-4/GPT-3.5 and on-device Vicuna, and evaluate its performance on a new benchmark for memory-augmented Android task automation with 158 common tasks. The results demonstrated that AutoDroid is able to precisely generate actions with an accuracy of 90.9\%, and complete tasks with a success rate of 71.3\%, outperforming the GPT-4-powered baselines by 36.4\% and 39.7\%.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {543–557},
numpages = {15},
keywords = {task automation, large language models, app analysis},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649381,
author = {Schiavo, Leonardo Lo and Garcia-Aviles, Gines and Garcia-Saavedra, Andres and Gramaglia, Marco and Fiore, Marco and Banchs, Albert and Costa-Perez, Xavier},
title = {CloudRIC: Open Radio Access Network (O-RAN) Virtualization with Shared Heterogeneous Computing},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649381},
doi = {10.1145/3636534.3649381},
abstract = {Open and virtualized Radio Access Networks (vRANs) are breeding a new market with unprecedented opportunities. However, carrier-grade vRANs today are expensive and energy-hungry, as they rely on hardware accelerators (HAs) that are dedicated to individual distributed units (DUs). In this paper, we argue that sharing pools of heterogeneous processors among DUs leads to more cost- and energy-efficient vRANs. We then design CloudRIC, a system that, powered by lightweight data-driven models, meets specific reliability targets while (i) coordinating access between DUs and heterogeneous computing infrastructure; and (ii) assisting DUs with compute-aware radio scheduling procedures. Experiments on a GPU-accelerated O-Cloud show that CloudRIC can achieve, respectively, 3x and 15x mean gains in energy- and cost-efficiency under real RAN workloads while ensuring 99.999\% reliability even in dense scenarios.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {558–572},
numpages = {15},
keywords = {vRAN, O-RAN, O-Cloud, distributed unit, HW accelerators},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649382,
author = {Seth, Avishkar and James, Alice and Kuantama, Endrowednes and Han, Richard and Mukhopadhyay, Subhas},
title = {AeroBridge: Autonomous Drone Handoff System for Emergency Battery Service},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649382},
doi = {10.1145/3636534.3649382},
abstract = {This paper proposes an Emergency Battery Service (EBS) for drones in which an EBS drone flies to a drone in the field with a depleted battery and transfers a fresh battery to the exhausted drone. The authors present a unique battery transfer mechanism and drone localization that uses the Cross Marker Position (CMP) method. The main challenges include a stable and balanced transfer that precisely localizes the receiver drone. The proposed EBS drone mitigates the effects of downwash due to the vertical proximity between the drones by implementing diagonal alignment with the receiver, reducing the distance to 0.5 m between the two drones. CFD analysis shows that diagonal instead of perpendicular alignment minimizes turbulence, and the authors verify the actual system for change in output airflow and thrust measurements. The CMP marker-based localization method enables position lock for the EBS drone with up to 0.9 cm accuracy. The performance of the transfer mechanism is validated experimentally by successful mid-air transfer in 5 seconds, where the EBS drone is within 0.5 m vertical distance from the receiver drone, wherein 4m/s turbulence does not affect the transfer process.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {573–587},
numpages = {15},
keywords = {drone, UAV, pose estimation, handoff, localization},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649383,
author = {Liu, Yuxin (Myles) and Yao, Zhihao and Chen, Mingyi and Amiri Sani, Ardalan and Agarwal, Sharad and Tsudik, Gene},
title = {ProvCam: A Camera Module with Self-Contained TCB for Producing Verifiable Videos},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649383},
doi = {10.1145/3636534.3649383},
abstract = {Our perception of reality is under constant threat from ever-improving video manipulation techniques, including deep-fakes and generative AI. Therefore, proving authenticity of videos is increasingly important, especially in legal and news contexts. However, it is very challenging to prove it based on post-factum video content analysis.In this work, we take a preventative stance and construct ProvCam, a novel camera module that generates a cryptographic proof of video authenticity. Our solution greatly reduces the size of Trusted Computing Base (TCB) to include the module itself. Moreover, it mitigates tampering during the numerous processing steps between video capture by the camera sensor and generation of the digital video output. To confirm its practicality, we present a complete prototype of ProvCam on a Xilinx FPGA evaluation board. As experiments show, ProvCam incurs a negligible performance overhead (latency and throughput) and small energy consumption overhead when recording a video. It imposes a moderate hardware cost but is relatively small compared to other major components such as SoC. Moreover, it does not change the existing camera software stack and thus can be easily integrated with various camera-bearing devices, such as smartphones.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {588–602},
numpages = {15},
keywords = {video provenance, deepfakes, secure camera},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649384,
author = {Yang, Xueyuan and An, Zhenlin and Pan, Qingrui and Yang, Lei and Lei, Dangyuan and Fan, Yulong},
title = {Binary Optical Machine Learning: Million-Scale Physical Neural Networks with Nano Neurons},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649384},
doi = {10.1145/3636534.3649384},
abstract = {Deep learning excels in advanced inference tasks using electronic neural networks (ENN), but faces energy consumption and limited computation speed challenges. To mitigate this, optical neural networks (ONNs) were developed, utilizing light for computations. However, their high manufacturing costs limited accessibility. In this work, we first introduce the binary optical neural network (BONN) - a streamlined ONN variant with binarized weights, which significantly reduces fabrication complexities and costs. Specifically, we address (i) the development of a binarization weight function aligned with backward-error propagation, and (ii) a simulation-based training for extra-large neural networks housing millions of neurons. We prototype six BONNs, each comprising four 0.8 \texttimes{} 0.8mm2 layers with one million 800 nm diameter neurons. Costs are cut to 0.13 USD per layer, marking a substantial decrease of 769\texttimes{} from previous ONNs. Experimental results reveal BONNs consume 2, 405\texttimes{} less power than leading ENNs while maintaining an average recognition accuracy of 74\% across six datasets.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {603–617},
numpages = {15},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649385,
author = {Li, Tianxiang and Mazaheri, Mohammad Hossein and Abari, Omid},
title = {Enabling On-Demand Low-Power mmWave Repeaters via Passive Beamforming},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649385},
doi = {10.1145/3636534.3649385},
abstract = {Advancements in computing have enabled emerging applications such as telesurgery, robot automation, holographic telepresence, and extended reality, which require gigabitper-second throughput, sub-millisecond latency, and highly reliable wireless connectivity. Millimeter wave (mmWave) technology has promised to enable such connectivity by operating over a large bandwidth in the high-frequency spectrum bands (24 GHz and above). However, due to the short wavelength and high directionality of mmWave signals, mmWave networks have limited coverage and are highly susceptible to blockage. In particular, high-data-rate mmWave networks work reliably only when there is a clear line-of-sight (LOS) path between users and base stations. Unfortunately, due to this problem, mmWave networks have not been able to scale and become ubiquitous. Past work has proposed mmWave repeaters and intelligent surfaces to solve this issue by rerouting signal around blockages. However, these solutions are expensive and complex to build, consume high power, or/and require constant feedback from the network to operate since they use active techniques for beam steering. In this paper, we present the first mmWave repeater which uses passive beamforming technique. Our repeater is low-cost, low-power, and can support multiple users simultaneously. Most importantly, it does not require any feedback from the network to operate. Hence, it can be easily deployed on-demand to solve the coverage and blockage problem of mmWave networks whenever and wherever high-data-rate and low-latency connectivity is needed.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {618–632},
numpages = {15},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649386,
author = {Zhang, Xinran and Zhu, Hanqi and Duan, Yifan and Zhang, Wuyang and Shangguan, Longfei and Zhang, Yu and Ji, Jianmin and Zhang, Yanyong},
title = {Map++: Towards User-Participatory Visual SLAM Systems with Efficient Map Expansion and Sharing},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649386},
doi = {10.1145/3636534.3649386},
abstract = {Constructing precise 3D maps is crucial for the development of future map-based systems such as self-driving and navigation. However, generating these maps in complex environments, such as multi-level parking garages or shopping malls, remains a formidable challenge. In this paper, we introduce a participatory sensing approach that delegates map-building tasks to map users, thereby enabling cost-effective and continuous data collection. The proposed method harnesses the collective efforts of users, facilitating the expansion and ongoing update of the maps as the environment evolves.We realized this approach by developing Map++, an efficient system that functions as a plug-and-play extension, supporting participatory map-building based on existing SLAM algorithms. Map++ addresses a plethora of scalability issues in this participatory map-building system by proposing a set of lightweight, application-layer protocols. We evaluated Map++ in four representative settings: an indoor garage, an outdoor plaza, a public SLAM benchmark, and a simulated environment. The results demonstrate that Map++ can reduce traffic volume by approximately 46\% with negligible degradation in mapping accuracy, i.e., less than 0.03m compared to the baseline system. It can support approximately 2\texttimes{} as many concurrent users as the baseline under the same network bandwidth. Additionally, for users who travel on already-mapped trajectories, they can directly utilize the existing maps for localization and save 47\% of the CPU usage.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {633–647},
numpages = {15},
keywords = {user-participatory, SLAM, map sharing, map expansion},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649387,
author = {Gong, Zheng and An, Zhenlin and Dai, Donghui and Tong, Jingyu and Long, Shuijie and Yang, Lei},
title = {Enabling Cross-Medium Wireless Networks with Miniature Mechanical Antennas},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649387},
doi = {10.1145/3636534.3649387},
abstract = {Within the burgeoning 6G wireless network landscape, there is an intensified push toward achieving all-encompassing accessibility through integrated solutions spanning a multitude of domains. Notwithstanding recent advancements, the conventional relay-centric communication paradigms grapple with scalability and optimal performance issues. In this paper, we introduce MeAnt ---a versatile IoT platform uniquely architected to foster seamless cross-medium communication by leveraging the compact design of piezoelectric-based mechanical antennas (Piezo-MAs). By capitalizing on the propagation attributes of medium-frequency radios emitted from Piezo-MAs, MeAnt promises communication across diverse environments such as air, water, soil, concrete, and even biological tissue, all while maintaining a compact antenna footprint. Moreover, in light of challenges such as potential interference from AM broadcasts and the intrinsic unidirectional nature of Piezo-MAs, we have developed a finely crafted full-stack communication protocol. Comprehensive tests underscore the system's proficiency, demonstrating a penetration depth of up to 10 m in cross-medium environments and realizing a throughput of 8.7 kbps.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {648–662},
numpages = {15},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649388,
author = {Cho, Hsun-Wei and Shin, Kang G.},
title = {DREW: Double-Throughput Emulated WiFi},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649388},
doi = {10.1145/3636534.3649388},
abstract = {Bidirectional communication between BLE/FSK devices and WiFi access points (APs) combines the benefits of long battery life, low device cost, and ubiquitous Internet access. However, prior cross-technology communication (CTC) solutions require transmission mixers inside FSK chips, thus not applicable to newer ultra-low-power (ULP) BLE chips, which removes these mixers to conserve power. Furthermore, throughputs of prior CTC solutions are limited to 1Mbps.We present DREW that fundamentally overcomes these limitations. It is designed to effectively transmit WiFi packets by only controlling the power amplifier (PA), and is thus applicable to mixer-less ULP BLE chips. We also propose an innovative use of BLE's IQ sampling capability to receive standard WiFi packets. We design efficient algorithms with SIMD (Single Instruction Multiple Data) acceleration to detect, synchronize and demodulate WiFi packets from IQ samples in real time. DREW also implements WiFi's CS-MA/CA and timing, thus adding direct WiFi connectivity to ULP BLE devices. Unlike prior work, DREW uniquely supports QPSK and therefore doubles the downlink throughput. This 2x throughput increase is crucial for new applications that prior work cannot support. In particular, DREW can stream lossless, HiFi-quality audio from WiFi to ULP BLE chips. Since stereo audio requires a throughput of 1.411Mbps, no prior work can support this important application due to their 1Mbps limitation.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {663–678},
numpages = {16},
keywords = {cross-technology communication, wifi, bluetooth, BLE},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649389,
author = {Cui, Minhao and Xie, Binbin and Wang, Qing and Xiong, Jie},
title = {EVLeSen: In-Vehicle Sensing with EV-Leaked Signal},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649389},
doi = {10.1145/3636534.3649389},
abstract = {While out-vehicle sensing has achieved great success with the development of vehicle radar and Lidar systems, invehicle sensing attracts a lot of attention recently. However, the popular camera-based solutions raise privacy concerns and pose requirement on lighting conditions. Researchers recently utilize wireless signals for sensing. However, besides requiring dedicated hardware, the rich multipath in a small cabin space causes severe interference, degrading the sensing reliability. In this paper, we propose a new sensing modality for in-vehicle sensing, leveraging the leaked EM signals from electric vehicles. The key observation is that the human body can capture the leaked signals, and body motions affect the signal variation patterns. Our solution involves designing conductive cloth tags on the seat to effectively collect body-captured signals and adopting a reference tag to deal with interference. Through extensive experiments conducted over 100 hours, covering a driving distance of 4000 kilometers on various real roads, our system, EVLeSen, can achieve over 90\% accuracy in recognizing body motions utilizing just the leaked ambient signals.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {679–693},
numpages = {15},
keywords = {wireless sensing, electric vehicle, RF leakage},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649390,
author = {Gao, Zhihui and Qi, Zhenzhou and Chen, Tingjun},
title = {Mambas: Maneuvering Analog Multi-User Beamforming using an Array of Subarrays in mmWave Networks},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649390},
doi = {10.1145/3636534.3649390},
abstract = {Beyond-5G and 6G wireless networks exploit the millimeter-wave (mmWave) frequency bands to achieve significantly improved data rates, and existing mmWave systems rely on analog single-user beamforming (SUBF) or hybrid multi-user beamforming (MUBF). In this work, we focus on improving the performance of multi-user communication in mmWave networks by exploring analog MUBF using an array of subarrays (ASA) with reduced system overhead and hardware complexity as it eliminates digital beamforming and the need for estimating the channel state information (CSI). We present Mambas, a novel system that maneuvers analog MUBF using an ASA to support simultaneous communication with multiple users located in close proximity, e.g., within the half-power beamwidth of the ASA. In essence, Mambas effectively decouples the user selection, subarray allocation, and beamforming optimization based on a comprehensive understanding of the multi-user support determined by the ASA. We evaluate Mambas using a 28 GHz software-defined radio testbed and show that, compared to existing methods, Mambas can effectively support users that are 2\texttimes{} more closely spaced while achieving an improved sum rate of up to 2\texttimes{}, using only two subarrays. Large-scale ray tracing-based simulations also show that Mambas can achieve a sum rate gain of 1.92--3.86\texttimes{} and is able to maintain consistent performance with significantly increased user density.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {694–708},
numpages = {15},
keywords = {millimeter-wave, multi-user beamforming, optimization},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649391,
author = {Li, Xiangyu and Li, Yuanchun and Li, Yuanzhe and Cao, Ting and Liu, Yunxin},
title = {FlexNN: Efficient and Adaptive DNN Inference on Memory-Constrained Edge Devices},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649391},
doi = {10.1145/3636534.3649391},
abstract = {Due to the popularity of deep neural networks (DNNs) and considerations over network overhead, data privacy, and inference latency, there is a growing interest in deploying DNNs to edge devices in recent years. However, the limited memory becomes a major bottleneck for on-device DNN deployment, making it crucial to reduce the memory footprint of DNN. The mainstream model customization solutions require intensive deployment efforts and may lead to severe accuracy degradation, and existing deep learning (DL) frameworks don't take memory as a priority. Besides, recent works to enhance the memory management scheme cannot be directly applied because of several challenges, including the unbalanced memory footprint across layers, the inevitable overhead of memory management, and the memory budget dynamicity. To tackle these challenges, we introduce FlexNN, an efficient and adaptive memory management framework for DNN inference on memory-constrained devices. FlexNN uses a slicing-loading-computing joint planning approach, to achieve optimal memory utilization and minimal memory management overhead. We implemented FlexNN atop NCNN, and conducted comprehensive evaluations with common model architectures on various devices. The results have shown that our approach is able to adapt to different memory constraints with optimal latency-memory trade-offs. For example, FlexNN can reduce the memory consumption by 93.81\% with only a 3.64\% increase in latency, as compared with the original NCNN on smartphones.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {709–723},
numpages = {15},
keywords = {edge device, deep learning, DNN inference, memory management},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690657,
author = {Shenoy, Jayanth and Chabra, Om and Chakraborty, Tusher and Jog, Suraj and Vasisht, Deepak and Chandra, Ranveer},
title = {CosMAC: Constellation-Aware Medium Access and Scheduling for IoT Satellites},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690657},
doi = {10.1145/3636534.3690657},
abstract = {Pico-satellite (picosat) constellations aim to become the de facto connectivity solution for Internet of Things (IoT) devices. These constellations rely on a large number of small picosats and offer global plug-and-play connectivity at low data rates, without the need for Earth-based gateways. As picosat constellations scale, they run into new bottlenecks due to their traditional medium access designs optimized for single (or few) satellite operations. We present CosMAC - a new constellation-scale medium access and scheduling system for picosat networks. CosMAC includes a new overlap-aware medium access approach for uplink from IoT to picosats and a new network layer that schedules downlink traffic from satellites. We empirically evaluate CosMAC using measurements from three picosats and large-scale trace-driven simulations for a 173 picosat network supporting 100k devices. Our results demonstrate that CosMAC can improve the overall network throughput by up to 6.5X over prior state-of-the-art satellite medium access schemes.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {724–739},
numpages = {16},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690658,
author = {He, Chenming and Meng, Chengzhen and He, Chunwang and Fan, Xiaoran and Wang, Beibei and Yan, Yubo and Zhang, Yanyong},
title = {See Through Vehicles: Fully Occluded Vehicle Detection with Millimeter Wave Radar},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690658},
doi = {10.1145/3636534.3690658},
abstract = {A crucial task in autonomous driving is to continuously detect nearby vehicles. Problems thus arise when a vehicle is occluded and becomes "unseeable", which may lead to accidents. In this study, we develop mmOVD, a system that can detect fully occluded vehicles by involving millimeter-wave radars to capture the ground-reflected signals passing beneath the blocking vehicle's chassis. The foremost challenge here is coping with ghost points caused by frequent multi-path reflections, which highly resemble the true points. We devise a set of features that can efficiently distinguish the ghost points by exploiting the neighbor points' spatial and velocity distributions. We also design a cumulative clustering algorithm to effectively aggregate the unstable ground-reflected radar points over consecutive frames to derive the bounding boxes of the vehicles.We have evaluated mmOVD in both controlled environments and real-world environments. In an underground garage and two campus roads, we conducted controlled experiments in 56 scenes with 8 vehicles, including a minibus and a motorcycle. Our system accurately detects occluded vehicles for the first time, with a 91.1\% F1 score for occluded vehicle detection and a 100\% success rate for occlusion event detection. More importantly, we drove 324km on crowded roads at a speed up to 70km per hour and show we could achieve an occlusion detection success rate of 92\% and a low false alarm rate of 4\% with only 10\% of the training data in complex real-world environments.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {740–754},
numpages = {15},
keywords = {millimeter-wave radar sensing, autonomous driving},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690659,
author = {Ren, Yidong and Gamage, Amalinda and Liu, Li and Li, Mo and Chen, Shigang and Dong, Younsuk and Cao, Zhichao},
title = {SateRIoT: High-performance Ground-Space Networking for Rural IoT},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690659},
doi = {10.1145/3636534.3690659},
abstract = {Rural Internet of Things (IoT) systems connect sensors and actuators in remote areas, serving crucial roles in agriculture and environmental monitoring. Given the absence of networking infrastructure for backhaul in these regions, satellite IoT techniques offer a cost-effective solution for connectivity. However, current satellite IoT architectures often struggle to deliver high performance due to temporal and spatial link challenges. This paper presents SateRIoT, a new network architecture with temporal link estimation and spatial link sharing that fully exploits the capability of space low-cost low-earth-orbit (LEO) IoT satellites and ground low-power wide area (LPWA) IoT techniques in rural areas. First, we introduce a bursty link model that predicts the number of transmittable packets within a transmission window, reducing energy waste from failed uplink transmissions. Moreover, we enhance the model by selecting informative features and optimizing the window length. Additionally, we develop a multi-hop flooding protocol that enables gateways to buffer and share data packets across the network while incorporating a priority data queue to avoid duplicate transmissions. We implement SateRIoT with commercial-off-the-shelf (COTS) IoT satellite and LoRa radios, then evaluate its performance based on real deployment and real-world collected traces. The results show that SateRIoT can consume 3.3X less energy consumption for an individual gateway. Moreover, SateRIoT offers up to a 5.6X reduction in latency for a single packet and a 1.9X enhancement in throughput.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {755–769},
numpages = {15},
keywords = {rural IoT, LPWAN, satellite networks},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690660,
author = {Zhu, Huadi and Wang, Chaowei and Darmanola, Venkateshwar Reddy and Guo, Hongbo and Jin, Wenqiang and Li, Ming},
title = {Bere: A Novel Video Recommender System for Virtual Reality Using Human Behavioral Signals},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690660},
doi = {10.1145/3636534.3690660},
abstract = {While video recommendation has been studied extensively in regular PC and smartphone settings, such a topic has been rarely discussed in the virtual reality (VR) context so far. On the other hand, as the popularity of VR videos continues to soar, its recommendation will play a crucial part in providing suggestions and guiding users through a deluge of available content. Given this unmet need, in this work, we present Bere, a video recommender system tailored for VR. Our approach leverages viewers' behavioral responses as they engage with VR videos to infer their preferences and thus make future recommendations. We integrate these new behavioral user-video interaction measures into the mainstream recommendation framework and renovate the graph learning-based paradigm to accommodate the new changes. The recommender system is further empowered with a novel domain adaptation approach named CMCCDA to address the data scarcity problem for model training. We also develop an energy-efficient adaptive encoding scheme to reduce the energy consumption on the VR device. We collect a behavioral dataset for video recommendation in VR and demonstrate through extensive evaluation that Bere significantly outperforms state-of-the-art schemes by up to 68.0\% in precision and up to 28.8\% in ranking quality.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {770–784},
numpages = {15},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690661,
author = {Naeem, Nazish and Rademacher, Jack and Patnaik, Ritik and Boroushaki, Tara and Adib, Fadel},
title = {SeaScan: An Energy-Efficient Underwater Camera for Wireless 3D Color Imaging},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690661},
doi = {10.1145/3636534.3690661},
abstract = {We present the design, implementation, and evaluation of SeaScan, an energy-efficient camera for 3D imaging of underwater environments. At the core of SeaScan's design is a trinocular lensing system, which employs three ultra-low-power monochromatic image sensors to reconstruct color images. Each of the sensors is equipped with a different filter (red, green, and blue) for color capture. The design introduces multiple innovations to enable reconstructing 3D color images from the captured monochromatic ones. This includes an ML-based cross-color alignment architecture to combine the monochromatic images. It also includes a cross-refractive compensation technique that overcomes the distortion of the wide-angle imaging of the low-power CMOS sensors in underwater environments. We built an end-to-end prototype of SeaScan, including color filter integration, 3D reconstruction, compression, and underwater backscatter communication. Our evaluation in real-world underwater environments demonstrates that SeaScan can capture underwater color images with as little as 23.6 mJ, which represents 37X reduction in energy consumption in comparison to the lowest-energy state-of-the-art underwater imaging system. We also report qualitative and quantitative evaluation of SeaScan's color reconstruction and demonstrate its success in comparison to multiple potential alternative techniques (both geometric and ML-based) in the literature. SeaScan's ability to image underwater environments at such low energy opens up important applications in long-term monitoring for ocean climate change, seafood production, and scientific discovery.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {785–799},
numpages = {15},
keywords = {subsea IoT, energy efficient imaging, deep learning, backscatter},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690662,
author = {Liu, Yimeng and Gan, Maolin and Zeng, Huaili and Liu, Li and Dong, Younsuk and Cao, Zhichao},
title = {Hydra: Accurate Multi-Modal Leaf Wetness Sensing with mm-Wave and Camera Fusion},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690662},
doi = {10.1145/3636534.3690662},
abstract = {Leaf Wetness Duration (LWD), the time that water remains on leaf surfaces, is crucial in the development of plant diseases. Existing LWD detection lacks standardized measurement techniques, and variations across different plant characteristics limit its effectiveness. Prior research proposes diverse approaches, but they fail to measure real natural leaves directly and lack resilience in various environmental conditions. This reduces the precision and robustness, revealing a notable practical application and effectiveness gap in real-world agricultural settings. This paper presents Hydra, an innovative approach that integrates millimeter-wave (mm-Wave) radar with camera technology to detect leaf wetness by determining if there is water on the leaf. We can measure the time to determine the LWD based on this detection. Firstly, we design a Convolutional Neural Network (CNN) to selectively fuse multiple mm-Wave depth images with an RGB image to generate multiple feature images. Then, we develop a transformer-based encoder to capture the inherent connection among the multiple feature images to generate a feature map, which is further fed to a classifier for detection. Moreover, we augment the dataset during training to generalize our model. Implemented using a frequency-modulated continuous-wave (FMCW) radar within the 76 to 81 GHz band, Hydra's performance is meticulously evaluated on plants, demonstrating the potential to classify leaf wetness with up to 96\% accuracy across varying scenarios. Deploying Hydra in the farm, including rainy, dawn, or poorly light nights, it still achieves an accuracy rate of around 90\%.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {800–814},
numpages = {15},
keywords = {agricultural IoT, precision farming, multi-modality sensing},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690663,
author = {Mollahosseini, Poorya and Afzal, Sayed Saad and Adib, Fadel and Ghasempour, Yasaman},
title = {SURF: Eavesdropping on Underwater Communications from the Air},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690663},
doi = {10.1145/3636534.3690663},
abstract = {This paper investigates how an airborne node can eavesdrop on the underwater acoustic communication between submerged nodes. Conventionally, such eavesdropping has been assumed impossible as acoustic signals do not cross the water-air boundary. Here, we demonstrate that underwater acoustic communications signals can be picked up and (under certain conditions) decoded using an airborne mmWave radar due to the minute vibrations induced by the communication signals on the water surface. We implemented and evaluated a proof-of-concept prototype of our method and tested it in controlled (pool) and uncontrolled environments (lake). Our results demonstrate that an airborne device can identify the modulation and bitrate of acoustic transmissions from an uncooperative underwater transmitter (victim), and even decode the transmitted symbols. Unlike conventional over-the-air communications, our results indicate that the secrecy of underwater links varies depending on the modulation type and provide insights into the underlying reasons behind these differences. We also highlight the theoretical limitations of such a threat model, and how these results may have a significant impact on the stealthiness of underwater communications, with particular concern to submarine warfare, underwater operations (e.g., oil \& gas, search \& rescue, mining), and conservation of endangered species. Finally, our investigation uncovers countermeasures that can be used to improve or restore the stealthiness of underwater acoustic communications against such threats.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {815–829},
numpages = {15},
keywords = {wireless, cross-medium communications, security, subsea internet of things},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690664,
author = {Pallaprolu, Anurag and Peng, Phillip and Sandhu, Shaan and Hurst, Winston and Mostofi, Yasamin},
title = {Crowd Analytics with a Single mmWave Radar},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690664},
doi = {10.1145/3636534.3690664},
abstract = {This paper presents a novel approach for crowd analytics using a single monostatic mmWave radar. We propose a new mathematical model that infers the crowd size for dynamic and quasi-dynamic crowd behaviors. More specifically, we derive a novel closed-form mathematical expression that describes the statistical dynamics of undercounting due to crowd shadowing. This new methodical finding allows for significantly improved crowd density estimates. For spatially-patterned crowds where the mathematical solution does not extend, we then develop a Temporal Convolutional Network (TCN) which is purely trained on simulated data. We perform extensive testing over a total of 22 experiments, with up to (and including) 21 people and in 4 different areas, including indoors, and the proposed mathematical solution achieves a Mean Absolute Error (MAE) of 1.53. Lastly, we show how our framework can infer anomalies, bottlenecks, and crowd engagement level. Overall, the paper can have a significant impact on crowd management and urban planning.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {830–844},
numpages = {15},
keywords = {mmWave radar, crowd analytics, crowd counting, occupancy estimation},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690665,
author = {Liao, Yunming and Xu, Yang and Xu, Hongli and Yao, Zhiwei and Huang, Liusheng and Qiao, Chunming},
title = {ParallelSFL: A Novel Split Federated Learning Framework Tackling Heterogeneity Issues},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690665},
doi = {10.1145/3636534.3690665},
abstract = {Mobile devices contribute more than half of the world's web traffic, providing massive and diverse data for powering various federated learning (FL) applications. In order to avoid the communication bottleneck on the parameter server (PS) and accelerate the training of large-scale models on resource-constraint workers in edge computing (EC) system, we propose a novel split federated learning (SFL) framework, termed ParallelSFL. Concretely, we split an entire model into a bottom submodel and a top submodel, and divide participating workers into multiple clusters, each of which collaboratively performs the SFL training procedure and exchanges entire models with the PS. However, considering the statistical and system heterogeneity in edge systems, it is challenging to arrange suitable workers to specific clusters for efficient model training. To address these challenges, we carefully develop an effective clustering strategy by optimizing a utility function related to training efficiency and model accuracy. Specifically, ParallelSFL partitions workers into different clusters under the heterogeneity restrictions, thereby promoting model accuracy as well as training efficiency. Meanwhile, ParallelSFL assigns diverse and appropriate local updating frequencies for each cluster to further address system heterogeneity. Extensive experiments are conducted on a physical platform with 80 NVIDIA Jetson devices, and the experimental results show that ParallelSFL can reduce the traffic consumption by at least 21\%, speed up the model training by at least 1.36X, and improve model accuracy by at least 5\% in heterogeneous scenarios, compared to the baselines.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {845–860},
numpages = {16},
keywords = {edge computing, split federated learning, system heterogeneity, statistical heterogeneity},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690666,
author = {Hu, Haiyan and Zhu, Yinan and Yang, Baichen and Kang, Hua and Chen, Shanwen and Zhang, Qian},
title = {MeatSpec: Enabling Ubiquitous Meat Fraud Inspection through Consumer-Level Spectral Imaging},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690666},
doi = {10.1145/3636534.3690666},
abstract = {Meat adulteration is a significant problem that can pose health risks economic losses to consumers. Current detection methods are hindered by high costs, limited capabilities, or time-consuming sample preparation, making them only accessible in laboratory tests and can not protect the safety of end-users. This paper introduces MeatSpec, a low-cost and user-friendly system for detecting meat adulteration using spectral imaging, to move the adulteration inspection out of laboratories. MeatSpec employs a multispectral camera to reduce costs while quickly capturing spectral images, but this leads to a decrease in spectral resolution and coverage. To solve this challenge, the system uses spectral reconstruction technology and innovative designs tailored for meat adulteration detection. This includes involving adulteration-related prior information during the reconstruction training phase and incorporating contrastive learning to enlarge the distances among reconstructed samples belonging to various adulteration types. Additionally, we devise distinct feature extractors for different bands based on characteristics of the reconstructed spectra and employ knowledge distillation to mitigate error in full-band reconstructed spectra while capturing features related to adulteration. Experimental evaluations on 347 paired spectral images demonstrate that our system achieves a 91.06\% accuracy in detecting multiple adulteration types, merely 7.78\% inferior to the expensive professional solution, yet 21.58\% superior to the baseline at the same price point.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {861–874},
numpages = {14},
keywords = {meat adulteration, spectral imaging and reconstruction},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690667,
author = {Li, Ruinan and Zheng, Xiaolong and Liu, Liang and Ma, Huadong},
title = {Plug-and-play Indoor GPS Positioning System with the Assistance of Optically Transparent Metasurfaces},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690667},
doi = {10.1145/3636534.3690667},
abstract = {Due to the poor indoor coverage and positioning accuracy, existing indoor GPS positioning systems leverages additional RF infrastructure as relay with known position. However, in practice, learning the relay position requires establishing an additional connection between user and relays, which is user unfriendly and even infeasible. In this paper, we propose GPSWindow, a plug-and-play indoor GPS positioning system without the prior knowledge of the relay position. By attaching optically transparent metasurfaces to windows, GPSWindow focuses the incident signal towards determined direction and provide an indoor continuous GPS signal coverage. We exploit the difference between consecutive satellite measurements and the Doppler shift measurements to recover the satellite-to-user true distance from the measured satellite-metasurface-user distance, and then locate the user using the traditional trilateration positioning method, eliminating the requirement of relay position. We also design an error correction method that leverages IMU on smartphone and the Doppler shift information to enhance GPSWindow in mobile scenarios. Extensive real-world experiments demonstrate that GPSWindow can provide continuous position service and achieve median positioning accuracy of 3.6m in indoor environments.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {875–889},
numpages = {15},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690668,
author = {Laskaridis, Stefanos and Katevas, Kleomenis and Minto, Lorenzo and Haddadi, Hamed},
title = {MELTing Point: Mobile Evaluation of Language Transformers},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690668},
doi = {10.1145/3636534.3690668},
abstract = {Transformers have recently revolutionized the machine learning (ML) landscape, gradually making their way into everyday tasks and equipping our computers with "sparks of intelligence". However, their runtime requirements have prevented them from being broadly deployed on mobile. As personal devices become increasingly powerful at the consumer edge and prompt privacy becomes an ever more pressing issue, we explore the current state of mobile execution of Large Language Models (LLMs). To achieve this, we have created our own automation infrastructure, MELT, which supports the headless execution and benchmarking of LLMs on device, supporting different models, devices and frameworks, including Android, iOS and Nvidia Jetson devices. We evaluate popular instruction fine-tuned LLMs and leverage different frameworks to measure their end-to-end and granular performance, tracing their memory and energy requirements along the way.Our analysis is the first systematic study of on-device LLM execution, quantifying performance, energy efficiency and accuracy across various state-of-the-art models and showcases the state of on-device intelligence in the era of hyperscale models. Results highlight the performance heterogeneity across targets and corroborates that LLM inference is largely memory-bound. Quantization drastically reduces memory requirements and renders execution viable, but at a non-negligible accuracy cost. Drawing from its energy footprint and thermal behavior, the continuous execution of LLMs remains elusive, as both factors negatively affect user experience. Last, our experience shows that the ecosystem is still in its infancy, and algorithmic as well as hardware break-throughs can significantly shift the execution cost. We expect NPU acceleration, and framework-hardware co-design to be the biggest bet towards efficient standalone execution, with the alternative of offloading tailored towards edge deployments.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {890–907},
numpages = {18},
keywords = {machine learning, mobile systems, large language models},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690669,
author = {Xu, Mingming and He, Yinghui and Li, Xin and Hu, Jingzhi and Chen, Zhe and Xiao, Fu and Luo, Jun},
title = {Beamforming made Malicious: Manipulating Wi-Fi Traffic via Beamforming Feedback Forgery},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690669},
doi = {10.1145/3636534.3690669},
abstract = {New Wi-Fi systems have leveraged beamforming to manage a significant portion of traffic for achieving high throughput and reliability. Unfortunately, this has amplified certain security risks since beamforming critically relies on the clear-text beamforming feedback information (BFI): though similar risks have been exposed using emulation platforms (e.g., USRP), they have never proven realistic till this day. In this paper, we propose BeamCraft, the first attack to manipulate traffic in commodity Wi-Fi systems; it differs significantly from existing attacks either staying only on emulation platforms with limited real-world applicability or jamming communications by brute force. The core idea of BeamCraft involves corrupting beamforming decisions by injecting crafted BFIs that feed an access point (AP) with erroneous information on channel states. To mount a covert yet purposeful attack, we develop i) a joint location and transmit power selection strategy to evade detection by victims and ii) a novel BFI forgery method to effectively manipulate AP's beamforming decisions. We implement BeamCraft using commodity Wi-Fi devices and perform extensive evaluations with it; the results reveal that BeamCraft effectively manipulates Wi-Fi traffic while maintaining a low exposure rate.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {908–922},
numpages = {15},
keywords = {Wi-Fi communication, beamforming, physical layer security},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3649380,
author = {Sun, Chuanhao and Pawar, Ujjwal and Khoja, Molham and Foukas, Xenofon and Marina, Mahesh K. and Radunovic, Bozidar},
title = {SpotLight: Accurate, Explainable and Efficient Anomaly Detection for Open RAN},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3649380},
doi = {10.1145/3636534.3649380},
abstract = {The Open RAN architecture, with disaggregated and virtualized RAN functions communicating over standardized interfaces, promises a diversified and multi-vendor RAN ecosystem. However, these same features contribute to increased operational complexity, making it highly challenging to troubleshoot RAN related performance issues and failures. Tackling this challenge requires a dependable, explainable anomaly detection method that Open RAN is currently lacking. To address this problem, we introduce SpotLight, a tailored system archtecture with a distributed deep generative modeling based method running across the edge and cloud. SpotLight takes in a diverse, fine grained stream of metrics from the RAN and the platform, to continually detect and localize anomalies. It introduces a novel multi-stage generative model to detect potential anomalies at the edge using a light-weight algorithm, followed by anomaly confirmation and an explain-ability phase at the cloud, that helps identify the minimal set of KPIs that caused the anomaly. We evaluate SpotLight using the metrics collected from an enterprise-scale 5G Open RAN deployment in an indoor office building. Our results show that compared to a range of baseline methods, SpotLight yields significant gains in accuracy (13\% higher F1 score), explain-ability (2.3 -- 4X reduction in the number of reported KPIs) and efficiency (4 -- 7X bandwidth reduction).},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {923–937},
numpages = {15},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690670,
author = {Zhang, Yangfan and Xie, Yaxiong and Hui, Zhihao and Jia, Hao and Chen, Xiaojiang},
title = {Hydra: Attacking OFDM-base Communication System via Metasurfaces Generated Frequency Harmonics},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690670},
doi = {10.1145/3636534.3690670},
abstract = {While Reconfigurable Intelligent Surfaces (RIS) have been shown to enhance OFDM communication performance, this paper unveils a potential security concern arising from widespread RIS deployment. Malicious actors could exploit vulnerabilities to hijack or deploy rogue RIS, transforming them from communication boosters into attackers. We present a novel attack that disrupts the critical orthogonality property of OFDM subcarriers, severely degrading communication performance. This attack is achieved by manipulating the RIS to generate frequency-shifted reflections/harmonics of the original OFDM signal. We also propose algorithms to simultaneously beamform the multiple RIS-generated frequency-shifted reflections towards selected targets. Extensive experiments conducted in indoor, outdoor, 3D, and office settings demonstrate that Hydra can achieve a 90\% throughput reduction in targeted attack scenarios and a 43\% throughput reduction in indiscriminate attack scenarios. Furthermore, we validated the effectiveness of our attacks on both the 802.11 protocol and the 5G NR protocol.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {938–952},
numpages = {15},
keywords = {reconfigurable intelligent surfaces, wireless communication},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690671,
author = {Dodds, Laura and Shanbhag, Hailan and Guan, Junfeng and Gupta, Saurabh and Hassanieh, Haitham},
title = {Around the Corner mmWave Imaging in Practical Environments},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690671},
doi = {10.1145/3636534.3690671},
abstract = {We present the design, implementation, and evaluation of RFlect, a mmWave imaging system capable of producing around-the-corner high-resolution images in practical environments. RFlect leverages signals reflected off complex surfaces (e.g., poles, concave surfaces, or composition of multiple surfaces) to image objects that are not in the RF line-of-sight. RFlect models the reflections and introduces reconstruction algorithms for different types of surfaces. It also leverages a novel method for precisely mapping the location and geometry of the reflecting surface. We also derive the theoretical resolution and coverage for different reflecting surface geometries. We built a prototype of RFlect and performed extensive evaluations to demonstrate its ability to reconstruct the shape of objects around the corner, with an average Chamfer Distance of 2cm and 3D F-Score of 88.6\%.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {953–967},
numpages = {15},
keywords = {around-the-corner imaging, millimeter-wave, mmWave},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690672,
author = {Qin, Qihui and Chen, Kai and Xie, Yaxiong and Luo, Heng and Fang, Dingyi and Chen, Xiaojiang},
title = {Pushing the Throughput Limit of OFDM-based Wi-Fi Backscatter Communication},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690672},
doi = {10.1145/3636534.3690672},
abstract = {The majority of existing Wi-Fi backscatter systems transmit tag data at rates lower than 250 kbps, as the tag data is modulated at OFDM symbol level, allowing for demodulation using commercial Wi-Fi receivers. However, it is necessary to modulate tag data at OFDM sample level to satisfy the requirements for higher throughput. A comprehensive theoretical analysis and experimental investigation conducted in this paper demonstrates that demodulating sample-level modulated tag data using commercial Wi-Fi receivers is unattainable due to excessive computational overhead and demodulation errors. This is because the significant tag information dispersion, loss, and shuffling are caused by Wi-Fi physical layer operations. We conclude that the optimal position for demodulation is the time-domain IQ samples, which do not undergo any Wi-Fi physical layer operations and preserve the intact, ordered, and undispersed information of tag-modulated data, thereby minimizing complexity and maximizing accuracy.We devise a demodulation algorithm using time domain IQ samples and implement on two types of demodulator: a dual radio chain demodulator and a single radio chain demodulator. Experiments show that our demodulation algorithm not only decrease the BER by at least three orders of magnitude, but also reduces the time complexity from exponential to linear. It achieves a tag data rate of up to 10 Mbps with QPSK modulation and a BER at 10-4 for the dual radio chain demodulator, and a tag data rate of up to 1 Mbps with BPSK and a BER at 10-4 for the single radio demodulator. We believe our results pave the way for designing Wi-Fi backscatter system with extremely high throughput.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {968–983},
numpages = {16},
keywords = {IoT, wi-fi backscatter, high throughput backscatter, wireless communication system},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690673,
author = {Liu, Hongyao and Wang, Junyi and Zhai, Liuqun and Fang, Yuguang and Huang, Jun},
title = {Neuralite: Enabling Wireless High-Resolution Brain-Computer Interfaces},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690673},
doi = {10.1145/3636534.3690673},
abstract = {Intracortical brain-computer interfaces (iBCIs) promise to sense brain activity at an unprecedented scale and resolution. However, unlocking this potential for practical, untethered applications remains an unsolved challenge. The major barrier is the significant wireless bandwidth required to stream high-resolution brain signals. Existing approaches rely on extensive on-device processing, which is severely constrained by the limited resources of iBCI devices, the complexity of brain signals, and the dynamic nature of neural activity. This paper introduces Neuralite, a wireless iBCI system that integrates high-fidelity brain signal models and effective brain sensing mechanisms within an efficient server-driven streaming framework. By thoroughly characterizing brain signal variability, Neuralite adaptively optimizes streaming under dynamic neural conditions, minimizing bandwidth consumption without imposing excessive burdens on resource-constrained iBCI devices. Experimental results demonstrate that Neuralite significantly reduces bandwidth consumption while preserving neural decoding precision across key iBCI components and representative applications.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {984–999},
numpages = {16},
keywords = {brain-computer interface, spike sorting, neural decoding},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690674,
author = {Dong, Huixin and Cui, Minhao and Wang, Ning and Qiu, Lili and Xiong, Jie and Wang, Wei},
title = {GPSense: Passive Sensing with Pervasive GPS Signals},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690674},
doi = {10.1145/3636534.3690674},
abstract = {Wireless sensing is gaining increasing attention from both academia and industry. Various wireless signals, such as Wi-Fi, UWB, and acoustic signals, have been leveraged for sensing. While promising in many aspects, two critical limitations still exist: a) limited sensing coverage; and b) the requirement for dedicated sensing signals, which may interfere with the original function of the wireless technology. To address these issues, we propose to utilize GPS signals for sensing, as GPS signals are already pervasive and emitted from satellites 24/7 at pre-allocated frequency bands, causing no interference. To make GPS sensing possible, we reconstruct signals with amplitude and phase information which is critical for sensing using the raw measurements reported by commercial GPS receiver module. We also develop sensing models to tailor the unique properties of GPS signals such as extremely long transmission distance. Finally, we introduce the concept of distributed sensing and design signal processing methods to fuse signals from multiple satellites to improve sensing performance. With all these designs, we prototype the first GPS wireless sensing system on commercial GPS receiver modules. Comprehensive experiments demonstrate that the proposed system can realize meaningful sensing applications such as human activity sensing, passive trajectory tracking, and respiration monitoring.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1000–1014},
numpages = {15},
keywords = {GPS sensing, Pervasive sensing, Wireless sensing},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690675,
author = {Ding, Jian and Chandra, Ranveer and Lal, Rattan and Tassiulas, Leandros},
title = {Cost-Effective Soil Carbon Sensing with Wi-Fi and Optical Signals},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690675},
doi = {10.1145/3636534.3690675},
abstract = {Soil carbon is a critical factor in maintaining soil health and combating climate change. Understanding and managing soil carbon levels is essential for sustainable agriculture and environmental protection. However, current methods for measuring soil carbon are time-consuming and costly, hindering efforts to monitor soil health and increase carbon sequestration. In this paper, we propose Scarf, a novel soil carbon sensing approach that combines widely accessible radio frequency (RF) and optical signals to detect soil carbon contents without dedicated hardware. Our key insight is that soil carbon content closely correlates with two indicators: the effective permittivity derived from RF signals and soil lightness determined from soil surface images. We mathematically model the correlations and leverage the non-linear correlation between the two signal modalities to compute soil carbon content. We employ machine learning to model relationships that cannot be captured by traditional mathematical equations. Our experimental results indicate that Scarf can achieve high soil carbon prediction accuracy that is comparable to the state-of-the-art soil carbon sensing techniques which cost US$1000s.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1015–1029},
numpages = {15},
keywords = {soil carbon, sustainable agriculture, Wi-Fi, smartphone image, machine learning, multi-modality},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690676,
author = {Yamaguchi, Shunpei and Arun, Aditya and Fujiwara, Takuya and Sakuta, Misaki and Hada, Ryotaro and Fujihashi, Takuya and Watanabe, Takashi and Bharadia, Dinesh and Saruwatari, Shunsuke},
title = {Experience: Practical Challenges for Indoor AR Applications},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690676},
doi = {10.1145/3636534.3690676},
abstract = {This paper shares the challenges facing today's augmented reality (AR) smartphone applications, particularly in the realm of localization and tracking failure. Our research identifies limitations in current vision-based landmarks such as QR codes and AprilTags, commonly used to aid in localization, and the drawbacks of LiDAR integration in variable lighting conditions, compromising AR's accuracy and functionality. We also examine the constraints of Inertial Measurement Units (IMU) on movement speed, highlighting its impact on the dynamic performance of AR applications. Based on our extensive 316 experimental cases for 113 hours, including 34 case studies with 17 subjects in 2 sites, this paper presents the field with a nuanced analysis of the failure modes inherent in smartphone-based AR localization. We further explore a prototype solution which fuses ultra-wideband (UWB)-based sensing with the vision-based systems to alleviate these failure modes. Our approach addresses the immediate challenges of AR localization and opens avenues for future research and development in creating more spatially aware and interactive digital worlds. All of our demonstration videos, code, and datasets are available here1.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1030–1044},
numpages = {15},
keywords = {AR, indoor localization, tracking, smartphone, wireless sensing, VIO-UWB fusion},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690677,
author = {Zhou, Hao and Yuan, Kuang and Gowda, Mahanth and Qiu, Lili and Xiong, Jie},
title = {Rethinking Orientation Estimation with Smartphone-equipped Ultra-wideband Chips},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690677},
doi = {10.1145/3636534.3690677},
abstract = {While localization has gained a tremendous amount of attention from both academia and industry, much less attention has been paid to equally important orientation estimation. Traditional orientation estimation systems relying on gyroscopes suffer from cumulative errors. In this paper, we propose UWBOrient, the first fine-grained orientation estimation system utilizing ultra-wideband (UWB) modules embedded in smartphones. The proposed system presents an alternative solution that is more accurate than gyroscope estimates and free of error accumulation. We propose to fuse UWB estimates with gyroscope estimates to address the challenge associated with UWB estimation alone and further improve the estimation accuracy. UWBOrient decreases the estimation error from the state-of-the-art 7.6° to 2.7° while maintaining a low latency (20 ms) and low energy consumption (40 mWh). Comprehensive experiments with both iPhone and Android smartphones demonstrate the effectiveness of the proposed system under various conditions including natural motion, dynamic multipath and NLoS. Two real-world applications, i.e., head orientation tracking and 3D reconstruction are employed to showcase the practicality of UWBOrient.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1045–1059},
numpages = {15},
keywords = {orientation estimation, smartphone-based ultra-wideband sensing},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690678,
author = {Shi, Xiaofeng and Sheoran, Amit and Wang, Jia and Mantan, Mukesh},
title = {SEEN: ML Assisted Cellular Service Diagnosis},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690678},
doi = {10.1145/3636534.3690678},
abstract = {As the primary channel for users to report and resolve service issues, customer care has historically been a critical and resource-intensive aspect of operating cellular networks. However, owing to the inherent complexity in correlating network events with the service performance experienced by individual users, adoption of data-driven solutions leveraging network data for realtime troubleshooting during customer care calls has remained a challenge to cellular service providers (CSPs). In this work, we propose a novel ML aSsisted cEllular sErvice diagNosis (SEEN) solution that infers the cause of user service issues from performance metrics observed from network and assists care agents during customer care calls. Our extensive evaluations demonstrated that SEEN can accurately identify the root cause of user reported performance issues in >80\% cases, without relying on information provided by users. Accurate root cause prediction coupled with automated recommended resolution actions implemented in SEEN, lead to significant reduction in handling time to resolve service issues and in trouble tickets volume, improving customer satisfaction and reducing customer care operational expense. Benefit of SEEN is further demonstrated by field deployment in a large CSP.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1060–1073},
numpages = {14},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690679,
author = {Lin, Chi and Wang, Zhaohe and Xiong, Jie and Li, Fengqi and Wu, Guowei},
title = {Fine-grained Textile Moisture Sensing with Commodity UWB},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690679},
doi = {10.1145/3636534.3690679},
abstract = {RF sensing has attracted a tremendous amount of attention and achieved promising progress in applications such as human gesture recognition and vital sign monitoring. This paper delves into sensing the moisture level of fabrics---an important metric for smart clothing, wound care, and textile manufacturing. We present TMSense, an innovative contact-free fabric moisture measurement system that leverages UWB signals for sensing. We introduce a set of signal processing methods to tackle the challenge of weak fabric reflections that can be easily overwhelmed by noise interference. Additionally, we adopt a model-driven approach to get rid of reliance on extensive datasets. By exploiting the changes in the dielectric properties induced by moisture in textile fabrics, we establish a theoretical model that bridges the characteristics of the RF signal with the moisture content. Based on this model, we successfully eliminate interfering factors such as target-device distance and target attributes through delicate signal processing and parameter calibration. Comprehensive experiments conducted under various conditions, including different materials, sample forms, and parameter settings, demonstrate an impressively low median error of 1.4\% on textile moisture measurements, outperforming commodity moisture sensors on the market.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1074–1088},
numpages = {15},
keywords = {textile moisture sensing, RF sensing, UWB, contactless},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690680,
author = {Liu, Zhutian and Deng, Qing and Tan, Zhaowei and Qian, Zhiyun and Zhang, Xinyu and Swami, Ananthram and Krishnamurthy, Srikanth V.},
title = {M2HO: Mitigating the Adverse Effects of 5G Handovers on TCP},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690680},
doi = {10.1145/3636534.3690680},
abstract = {The advent of 5G promises high bandwidth with the introduction of mmWave technology recently, paving the way for throughput-sensitive applications. However, our measurements in commercial 5G networks show that frequent handovers in 5G, due to physical limitations of mmWave cells, introduce significant under-utilization of the available bandwidth. By analyzing 5G link-layer and TCP traces, we uncover that improper interactions between these two layers causes multiple inefficiencies during handovers. To mitigate these, we propose M2HO, a novel device-centric solution that can predict and recognize different stages of a handover and perform state-dependent mitigation to markedly improve throughput. M2HO is transparent to the firmware, base stations, servers, and applications. We implement M2HO and our extensive evaluations validate that it yields significant improvements in TCP throughput with frequent handovers.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1089–1103},
numpages = {15},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690681,
author = {Du, Jialuo and Liu, Yunhao and Ren, Yidong and Liu, Li and Cao, Zhichao},
title = {LoRaTrimmer: Optimal Energy Condensation with Chirp Trimming for LoRa Weak Signal Decoding},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690681},
doi = {10.1145/3636534.3690681},
abstract = {LoRa has been widely used for the Internet of Things (IoT) due to its low power consumption and long communication range. The standard LoRa demodulation process condenses the energy of LoRa chirps to combat noise. However, there is an intrinsic frequency jump in real-life LoRa signals that standard demodulation neglects, reducing communication range in practice. We thoroughly study the frequency jump phenomenon and observe that it affects LoRa demodulation mainly in two folds: First, it makes each section of the signal shorter than the standard FFT perception range, introducing additional noise; Second, it induces a random phase jump that causes destructive addition of signal power. To mitigate the influence of frequency jump on LoRa demodulation, we propose LoRaTrimmer, a novel, fast, and noise-resilient LoRa decoding algorithm that optimally condenses LoRa signal power. LoRaTrimmer contains two innovative designs: First, we trim the perception range of FFT at the frequency jump, trimming off the additional noise; Second, we bypass the phase jump induced by frequency jump by probabilistic modeling and add up signal power constructively. Furthermore, we performed theoretical analysis to guarantee the performance of our method. Thorough experiments in various real-life environments show 1.70 to 2.49 dB SNR gain over the state-of-the-art and 3.44 to 3.79 dB SNR gain over FFT-based methods, translating to at most 1.67 times gain of coverage area. LoRaTrimmer is also robust under complex noise patterns, and capable of real-time decoding, with the only overhead being a slight increase in computational cost (0.51 to 3.17 ms per packet, compared with 0.23 to 0.94 ms of baseline methods).},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1104–1118},
numpages = {15},
keywords = {internet-of-things, low-power wide area networks, LoRa},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690682,
author = {Lee, Sunjae and Choi, Junyoung and Lee, Jungjae and Wasi, Munim Hasan and Choi, Hojun and Ko, Steve and Oh, Sangeun and Shin, Insik},
title = {MobileGPT: Augmenting LLM with Human-like App Memory for Mobile Task Automation},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690682},
doi = {10.1145/3636534.3690682},
abstract = {The advent of large language models (LLMs) has opened up new opportunities in the field of mobile task automation. Their superior language understanding and reasoning capabilities allow users to automate complex and repetitive tasks. However, due to the inherent unreliability and high operational cost of LLMs, their practical applicability is quite limited. To address these issues, this paper introduces MobileGPT1, an innovative LLM-based mobile task automator equipped with a human-like app memory. MobileGPT emulates the cognitive process of humans interacting with a mobile app---explore, select, derive, and recall. This approach allows for a more precise and efficient learning of a task's procedure by breaking it down into smaller, modular sub-tasks that can be re-used, re-arranged, and adapted for various objectives. We implement MobileGPT using online LLMs services (GPT-3.5 and GPT-4) and evaluate its performance on a dataset of 185 tasks across 18 mobile apps. The results indicate that MobileGPT can automate and learn new tasks with 82.7\% accuracy, and is able to adapt them to different contexts with near perfect (98.75\%) accuracy while reducing both latency and cost by 62.5\% and 68.8\%, respectively, compared to the GPT-4 powered baseline.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1119–1133},
numpages = {15},
keywords = {AI agent, task automation, large language models},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690683,
author = {Mishra, Manas and Jain, Saurabh and M, Suraj Patel and Mani, Sharmila and Boragule, Abhijeet and Sahni, Nikhil and Nair, Renju Chirakarotu},
title = {Multimodal Strategy To Defend Mobile Devices Against Vishing Attacks},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690683},
doi = {10.1145/3636534.3690683},
abstract = {In the landscape of Vishing calls, it's crucial to determine if users are unknowingly falling prey to fraudsters' tactics, potentially leading to fraud. This paper introduces the Multimodal Vishing Threat Detection (MmVTD) framework, designed to counter Vishing threats and issue alerts on potential fraudulent activities leveraging three key data modalities: call transcripts, sequences of mobile screenshots, and extracted Optical Character Recognition(OCR) text. The novelty of our approach lies in utilization of transformer encoders to build the learnable context for each modality, with a decoder generating warning content while an MLP head classifies the current call as Vishing or Safe at any given instance. This innovative architecture enhances the model's ability to analyze the diverse data sources and generate effective warning in real-time. Furthermore, the MmVTD framework offers robust protection through multimodal analysis, providing real-time alerts when user action suggest susceptibility fraud. Finally, the MmVTD model achieved an impressive 94.44\% accuracy in identifying Vishing and Safe calls on a dedicated dataset. Additionally, it attained a BLEU score of 0.583 in generating cautionary messages, effectively deterring users from potential harmful actions.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1134–1146},
numpages = {13},
keywords = {vishing, mobile security, multimodal deep learning, behavior analysis, security and privacy, SmartPhone},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690684,
author = {Khalili, Hossein and Park, Seongbin and Li, Vincent and Bright, Brandan and Payani, Ali and Kompella, Ramana Rao and Sehatbakhsh, Nader},
title = {LightPure: Realtime Adversarial Image Purification for Mobile Devices Using Diffusion Models},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690684},
doi = {10.1145/3636534.3690684},
abstract = {Autonomous mobile systems increasingly rely on deep neural networks for perception and decision-making. While effective, these systems are vulnerable to adversarial machine learning attacks where small perturbations in the input could significantly impact the outcome of the system. Common countermeasures include leveraging adversarial training and/or data or network transformation. Although widely used, the main drawback of these countermeasures is that they require full and invasive access to the classifiers, which are typically proprietary. Additionally, the cost of training or retraining is often prohibitively expensive for large models. To tackle this, purification models have recently been proposed. The aim is to incorporate a "purification" layer before classification, thereby eliminating the necessity to modify the classifier. Despite their effectiveness, state-of-the-art purification methods are compute-intensive, rendering them unsuitable for mobile systems where resources are constrained and large latency is not desired.This paper presents a new approach, LightPure, that enhances the purification of adversarial images. It improves the accuracy of the current leading purification methods while also providing notable enhancements in speed and computational efficiency, making it suitable for mobile devices with limited resources. Our approach uses a two-step diffusion and one-shot Generative Adversarial Network (GAN) framework for purification, prioritizing latency without compromising robustness. We propose several new techniques in designing our model to achieve a reasonable balance between classification accuracy and adversarial robustness while maintaining a desired latency. We design and implement a proof-of-concept on a Jetson Nano board and evaluate our method using several attack scenarios and datasets. Our results show that LightPure can outperform existing purification methods by up to 10x in terms of latency while achieving higher accuracy and robustness for various black-, gray-, and white-box attack scenarios. The fusion of speed and robust defense mechanisms positions our method as a significant advancement in the field of adversarial image purification, offering a scalable and effective solution for real-world mobile systems.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1147–1161},
numpages = {15},
keywords = {autonomous mobile system, adversarial machine learning, diffusion models},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690685,
author = {Fang, Tiancheng and Niu, Chaoyue and Sun, Yujie and Lv, Chengfei and Jiang, Xiaotang and Xue, Ben and Wu, Fan and Chen, Guihai},
title = {An End-to-End, Low-Cost, and High-Fidelity 3D Video Pipeline for Mobile Devices},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690685},
doi = {10.1145/3636534.3690685},
abstract = {To provide full-body 3D videos of performers showcasing diverse clothes with dynamic movements for e-commerce platforms, we develop an end-to-end, low-cost, and high-fidelity production and deployment pipeline. We first set up a low-cost capture studio with only 24 RGB cameras and embrace fast neural surface reconstruction to produce high-quality meshes without depth information. We then quickly group all the frames with local motion priors, select a keyframe for each group, and accurately register any other frame to the keyframe under the guidance of semantic labels, thereby avoiding transmitting all the frames to mobile devices and loading them into memory. For real-time rendering, we propose an on-device sparse computation method for efficient deformation from keyframes to the other frames. Evaluation over 2 self-captured performances and 8 public performances reveals that the pipeline achieves the reconstruction time of 28 minutes per frame, the average PSNR of 30.4, the average bandwidth requirement of 4.2MB/s, and the on-device frame rate of 60 fps, demonstrating superiority over existing baselines.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1162–1176},
numpages = {15},
keywords = {3D video, fast neural surface reconstruction, frame grouping and registration, mobile real-time rendering},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690686,
author = {Wang, Han and Song, Yihang and Meng, Qianhe and Gao, Zetao and Zhang, Chong and Lu, Li},
title = {Sisyphus: Redefining Low Power for LoRa Receiver},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690686},
doi = {10.1145/3636534.3690686},
abstract = {Legacy LoRa receiver adopts a superheterodyne architecture with a runtime power consumption of up to 100mW, resulting in its low-power promise can only be delivered in low duty-cycle mode. This paper presents Sisyphus as an ultra-low-power LoRa receiver, ensuring around-the-clock LoRa availability while extending battery life significantly. To achieve this, we propose a novel receiver design for passive coherent demodulation of LoRa. In this design, we creatively couple LoRa's down-conversion with de-chirping (dc2), leveraging the processing gain brought by chirp spread spectrum (CSS) modulation to boost communication range without the need for additional power supply. Moreover, we exploit the cyclical time-frequency feature intrinsic to LoRa for demodulation, and a low-power analog-digital signal processing circuit with negligible power is devised to replace the existing power-intensive sampling and costly digital computation. We prototype Sisyphus for proof-of-concept, and comprehensive experimental results demonstrate that Sisyphus can achieve significant power savings compared to legacy LoRa receiver while retaining the anti-interference ability of legacy LoRa. We envision that the design of Sisyphus can unlock the potential for broader applications of LoRa.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1177–1191},
numpages = {15},
keywords = {LoRa receiver, ultra-low-power communication, IoT},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690687,
author = {Chen, Baicheng and Nolan, John and Zhang, Xinyu},
title = {MetaBioLiq: A Wearable Passive Metasurface Aided mmWave Sensing Platform for BioFluids},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690687},
doi = {10.1145/3636534.3690687},
abstract = {Human external biofluid (e.g., sweat, urine) contains vast health data that is readily harvestable. Currently, wearable sweat sensors require an electrochemical-based approach that is used in single use, creating environmental pollution as people track their exercise in the wild. Moreover, such solution relies on a battery-powered design, which brings battery health and thermal related issues. We present MetaBioLiq, a 3D printed wireless-readable sweat sensing system that offers continuous monitoring, featuring completely passive, environmentally friendly, and easily accessible. MetaBioLiq is developed upon sweat liquid's resonance upon high frequency RF interaction, with different sweat content driving RF resonance characteristics. To activate such resonance, we design 3D PolyLactic Acid (PLA) structures that capture e-field energy from the air, and tunneling it to the sweat. Once the resonance effect occurs, we analyze return signal from a wireless RF receiver to decouple the sweat's resonance. Lastly, we evaluate MetaBioLiq's performance with 24 artificial sweat samples containing different levels of glucose, electrolytes, and fat. MetaBioLiq proves its effectiveness with 95\% liquid level detection performance, and 96\% sweat liquid identification performance. We further investigate MetaBioLiq's robustness and reliability, as well as limitations. Overall, MetaBioLiq shows promising results to expand the realm of mobile continuous sensing to microscopic realm untangible in the past.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1192–1206},
numpages = {15},
keywords = {metasurface, mmWave sensing, 3D printing, IoT},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690688,
author = {Lee, Jeho and Jung, Chanyoung and Kim, Jiwon and Cha, Hojung},
title = {Panopticus: Omnidirectional 3D Object Detection on Resource-constrained Edge Devices},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690688},
doi = {10.1145/3636534.3690688},
abstract = {3D object detection with omnidirectional views enables safety-critical applications such as mobile robot navigation. Such applications increasingly operate on resource-constrained edge devices, facilitating reliable processing without privacy concerns or network delays. To enable cost-effective deployment, cameras have been widely adopted as a low-cost alternative to LiDAR sensors. However, the compute-intensive workload to achieve high performance of camera-based solutions remains challenging due to the computational limitations of edge devices. In this paper, we present Panopticus, a carefully designed system for omnidirectional and camera-based 3D detection on edge devices. Panopticus employs an adaptive multi-branch detection scheme that accounts for spatial complexities. To optimize the accuracy within latency limits, Panopticus dynamically adjusts the model's architecture and operations based on available edge resources and spatial characteristics. We implemented Panopticus on three edge devices and conducted experiments across real-world environments based on the public self-driving dataset and our mobile 360° camera dataset. Experiment results showed that Panopticus improves accuracy by 62\% on average given the strict latency objective of 33ms. Also, Panopticus achieves a 2.1\texttimes{} latency reduction on average compared to baselines.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1207–1221},
numpages = {15},
keywords = {edge computing, omnidirectional 3D object detection, low-cost sensors, spatial awareness},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690689,
author = {Lin, Chi and Lin, Jianan and Xiong, Jie and Wang, Qiwei and Wang, Lei and Wu, Guowei and Fan, Xin and Luo, Zhongxuan},
title = {UWBeacon: Lighting up Centimeter-Level Underwater Positioning},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690689},
doi = {10.1145/3636534.3690689},
abstract = {Underwater positioning plays a key role in many underwater operations. This paper presents the design, implementation, and evaluation of UWBeacon, a centimeter-level visible light-based underwater positioning system. UWBeacon consists of LED beacons as the light signal transmitter and a camera-based receiver as the target. To address unique challenges in underwater environment such as limited visibility and strong ambient interference, we exploit a novel design that utilizes polarized lights of different colors with different polarization angles for background subtraction. UWBeacon is implemented with commercial-off-the-shelf LEDs and cameras. Comprehensive experiments conducted in various real underwater environments show that UWBeacon can achieve a mean positioning error below 6 cm and an orientation error below 1.5° at a distance of 10 meters.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1222–1236},
numpages = {15},
keywords = {underwater positioning, visible light positioning, camera-based positioning, polarized light},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690690,
author = {Jiao, Wenli and Wang, Ju and Gao, Xinzhuo and Du, Long and Li, Yanlin and Zhao, Lili and Fang, Dingyi and Chen, Xiaojiang},
title = {ZEROECG: Zero-Sensation ECG Monitoring By Exploring RFID MOSFET},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690690},
doi = {10.1145/3636534.3690690},
abstract = {ECG monitoring during human activities is crucial since many heart attacks occur when people are exercising, driving a car, operating a machine, etc. Unfortunately, existing ECG monitoring devices fail to timely detect abnormal ECG signals during activities due to the need for many cables or a sustained press on devices (e.g., smartwatches). This paper introduces ZeroEcg, a wireless, battery-free, lightweight, electronic-skin-like tag integrated with commodity RFIDs, which can continuously track a user's ECG during activities. By exploring and leveraging the RFID MOSFET switch, which is traditionally used for backscatter modulation, we map the ECG signal to the RFID RSS and phase measurement. It opens a new RFID sensing approach for sensing any physical world variable that can be translated into voltage signals. We model and analyze the RFID MOSFET-based backscatter modulation principle, providing design guidance for other sensing tasks. Real-world results illustrate the effectiveness of ZeroEcg on ECG sensing.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1237–1251},
numpages = {15},
keywords = {wearable ECG sensing, RFID, backscatter, internet of things},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690691,
author = {Shin, Christina Suyong and Pang, Weiwu and Li, Chuan and Bai, Fan and Ahmad, Fawad and Paek, Jeongyeup and Govindan, Ramesh},
title = {RECAP: 3D Traffic Reconstruction},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690691},
doi = {10.1145/3636534.3690691},
abstract = {On-vehicle 3D sensing technologies, such as LiDARs and stereo cameras, enable a novel capability, 3D traffic reconstruction. This produces a volumetric video consisting of a sequence of 3D frames capturing the time evolution of road traffic. 3D traffic reconstruction can help trained investigators reconstruct the scene of an accident. In this paper, we describe the design and implementation of RECAP, a system that continuously and opportunistically produces 3D traffic reconstructions from multiple vehicles. RECAP builds upon prior work on point cloud registration, but adapts it to settings with minimal point cloud overlap (both in the spatial and temporal sense) and develops techniques to minimize error and computation time in multi-way registration. On-road experiments and trace-driven simulations show that RECAP can, within minutes, generate highly accurate reconstructions that have 2\texttimes{} or more lower errors than competing approaches.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1252–1267},
numpages = {16},
keywords = {collaborative sensing, accident traffic reconstruction, iterative closest point},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690692,
author = {Guo, Hanqing and Wang, Guangjing and Chen, Bocheng and Wang, Yuanda and Zhang, Xiao and Chen, Xun and Yan, Qiben and Xiao, Li},
title = {WavePurifier: Purifying Audio Adversarial Examples via Hierarchical Diffusion Models},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690692},
doi = {10.1145/3636534.3690692},
abstract = {In this paper, we propose WavePurifier, an audio purification framework to defend against audio adversarial attacks. Audio adversarial attacks craft adversarial examples or perturbations to attack the automated speech recognition (ASR) models. Although existing defense mechanisms can detect such attacks and raise alarms, they fail to recover or maintain benign commands. Consequently, this leads to the denial of users' benign commands. Different than existing defenses, WavePurifier aims to purify adversarial examples, thereby rectifying the user's benign commands. We find that the forward diffusion process of the diffusion model effectively eliminates perturbations, whereas the reverse diffusion process restores benign speech. Based on this, we develop a hierarchical diffusion model to defend against audio adversarial examples. This model is capable of purifying different spectrogram bands to varying degrees. To validate the performance of WavePurifier, we purify the adversarial examples from 3 different adversarial attacks in 140 distinct settings. In total, we collect 78,864 diffused spectrograms and 21,000 purified audios. Then, we evaluate WavePurifier on 2 different ASR models, 4 commercial speech-to-text APIs, 2 real-world attack scenarios, and compare them against 7 existing defense approaches. Our result shows that WavePurifier is a universal framework, demonstrating adaptability across diverse attacks with the same hyperparameters. Notably, WavePurifier outperforms existing methods with the lowest character error rate (CER), word error rate (WER), and a high purification success rate against different attacks.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1268–1282},
numpages = {15},
keywords = {speech recognition services, purification, diffusion model},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690693,
author = {He, Guorong and Xie, Yaxiong and Zheng, Chao and Zhang, Longlong and Wu, Qi and Zhang, Wenyan and Xu, Dan and Chen, Xiaojiang},
title = {Hornbill: A Portable, Touchless, and Battery-Free Electrochemical Bio-tag for Multi-pesticide Detection},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690693},
doi = {10.1145/3636534.3690693},
abstract = {Pesticide overuse poses significant risks to human health and environmental integrity. Addressing the limitations of existing approaches, which struggle with the diversity of pesticide compounds, portability issues, and environmental sensitivity, this paper introduces Hornbill. A wireless and battery-free electrochemical bio-tag that integrates the advantages of NFC technology with electrochemical biosensors for portable, precise, and touchless multi-pesticide detection. The basic idea of Hornbill is comparing the distinct electrochemical responses between a pair of biological receptors and different pesticides to construct a unique set of feature fingerprints to make multi-pesticide sensing feasible. To incorporate this idea within small NFC tags, we reengineer the electrochemical sensor, spanning the antenna to the voltage regulator. Additionally, to improve the system's sensitivity and environmental robustness, we carefully design the electrodes by combining microelectrode technology and materials science. Experiments with 9 different pesticides show that Hornbill achieves a mean accuracy of 93\% in different concentration environments and its sensitivity and robustness surpass that of commercial electrochemical sensors.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1283–1298},
numpages = {16},
keywords = {NFC, embedded systems, electrochemical measurement, microelectrode technology, pesticide sensing},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690694,
author = {Wang, Rongxiang and Lin, Felix Xiaozhu},
title = {Turbocharge Speech Understanding with Pilot Inference},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690694},
doi = {10.1145/3636534.3690694},
abstract = {Modern speech understanding (SU) runs a sophisticated pipeline: ingesting streaming voice input, the pipeline executes encoder-decoder based deep neural networks repeatedly; by doing so, the pipeline generates tentative outputs (called hypotheses), and periodically scores the hypotheses.This paper sets to accelerate SU on resource-constrained edge devices. It takes a hybrid approach: to speed up on-device execution; to offload inputs that are beyond the device's capacity. While the approach is well-known, we address SU's unique challenges with novel techniques: (1) late contextualization, which executes a model's attentive encoder in parallel to the input ingestion; (2) pilot inference, which mitigates the SU pipeline's temporal load imbalance; (3) autoregression offramps, which evaluate offloading decisions based on pilot inferences and hypotheses.Our techniques are compatible with existing speech models, pipelines, and frameworks; they can be applied independently or in combination. Our prototype, called PASU, is tested on Arm platforms with 6 -- 8 cores: it delivers SOTA accuracy; it reduces the end-to-end latency by 2x and reduces the offloading needs by 2x.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1299–1313},
numpages = {15},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690695,
author = {Yang, Kichang and Jeong, Minkyung and Yi, Juheon and Lee, Jingyu and Park, KyoungSoo and Lee, Youngki},
title = {Logan: Loss-tolerant Live Video Analytics System},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690695},
doi = {10.1145/3636534.3690695},
abstract = {Cloud-based live video analytics with tight latency bound is gaining importance to support emerging applications such as UAVs and augmented reality. However, existing systems often struggle to meet stringent latency constraints under fluctuating network conditions with packet losses and late-arriving packets. We propose a loss-tolerant live video analytics system called Logan, which effectively accepts packet losses while maintaining high accuracy by utilizing the inherent resilience in DNNs. We design i) Codec-aware Inpainting, which accurately recovers the frame error from packet losses ii) Fast-Forward Recovery that prevents the remaining un-recovered error from propagating over future frames indefinitely. Our results show a 3\texttimes{} improvement (33.2\%→99.9\%) in SLO satisfaction rate compared to the reliable transmission scheme with <1\% accuracy drop under a 5\% packet loss rate.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1314–1329},
numpages = {16},
keywords = {live video analytics, packet loss, mobile systems},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690696,
author = {Eleftherakis, Stavros and Otim, Timothy and Santaromita, Giuseppe and Zayas, Almudena D\'{\i}az and Giustiniano, Domenico and Kourtellis, Nicolas},
title = {Demystifying Privacy in 5G Stand Alone Networks},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690696},
doi = {10.1145/3636534.3690696},
abstract = {Ensuring user privacy remains critical in mobile networks, particularly with the rise of connected devices and denser 5G infrastructure. Privacy concerns have persisted across 2G, 3G, and 4G/LTE networks. Recognizing these concerns, the 3rd Generation Partnership Project (3GPP) has made privacy enhancements in 5G Release 15. However, the extent of operator adoption remains unclear, especially as most networks operate in 5G Non Stand Alone (NSA) mode, relying on 4G Core Networks. This study provides the first qualitative and experimental comparison between 5G NSA and Stand Alone in real operator networks, focusing on privacy enhancements addressing top 8 pre-5G attacks based on recent academic literature. Also, it evaluates the privacy levels of OpenAirInterface, a leading open-source software for 5G, against real network deployments for the same attacks, revealing two new 5G privacy vulnerabilities, and underscoring the need for further studies and stricter standards.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1330–1345},
numpages = {16},
keywords = {5G, wireless networks, OpenAirInterface, network identifiers, security, privacy},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690697,
author = {Song, Yiwen and Pan, Hao and Ge, Longyuan and Qiu, Lili and Kumar, Swarun and Chen, Yi-Chao},
title = {MicroSurf: Guiding Energy Distribution inside Microwave Oven with Metasurfaces},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690697},
doi = {10.1145/3636534.3690697},
abstract = {Microwave ovens have become an essential cooking appliance owing to their convenience and efficiency. However, microwave ovens suffer from uneven distribution of energy, which causes prolonged delays, unpleasant cooking experiences, and even safety concerns. Despite significant research efforts, current solutions remain inadequate. In this paper, we first conduct measurement studies to understand the energy distribution for 10 microwave ovens and show their energy distribution in both 2D and 3D is very skewed, with notably lower energy levels at the center of the microwave cavity, where food is commonly placed. To tackle this challenge, we propose a novel methodology to enhance the performance of microwave ovens. Our approach begins with the development of a measurement driven model of a microwave oven. We construct a detailed 3D model in the High Frequency Structure Simulator (HFSS) and use real temperature measurements from a microwave to derive critical parameters relevant to the appliance's functionality (e.g., operating frequency, waveguide specifications). We then develop a novel approach that optimizes the design and placement of a low-cost passive metasurface for a given heating objective. Using extensive experiments, we demonstrate the efficacy of our approach across diverse food, optimization objectives, and microwave ovens.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1346–1360},
numpages = {15},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690698,
author = {Huang, Kai and Yin, Xiangyu and Gu, Tao and Gao, Wei},
title = {Perceptual-Centric Image Super-Resolution using Heterogeneous Processors on Mobile Devices},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690698},
doi = {10.1145/3636534.3690698},
abstract = {Image super-resolution (SR) is widely used on mobile devices to enhance user experience. However, neural networks used for SR are computationally expensive, posing challenges for mobile devices with limited computing power. A viable solution is to use heterogeneous processors on mobile devices, especially the specialized hardware AI accelerators, for SR computations, but the reduced arithmetic precision on AI accelerators can lead to degraded perceptual quality in upscaled images. To address this limitation, in this paper we present SR For Your Eyes (FYE-SR), a novel image SR technique that enhances the perceptual quality of upscaled images when using heterogeneous processors for SR computations. FYE-SR strategically splits the SR model and dispatches different layers to heterogeneous processors, to meet the time constraint of SR computations while minimizing the impact of AI accelerators on image quality. Experiment results show that FYE-SR outperforms the best baselines, improving perceptual image quality by up to 2\texttimes{}, or reducing SR computing latency by up to 5.6\texttimes{} with on-par image quality.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1361–1376},
numpages = {16},
keywords = {image super-resolution, perceptual quality, neural networks, heterogeneous computing, mobile devices},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690699,
author = {Zhao, Chenyu and Ruan, Ciyu and Xu, Jingao and Wang, Haoyang and Wang, Shengbo and Li, Jiaqi and Zha, Jirong and Yang, Zheng and Liu, Yunhao and Zhang, Xiao-Ping and Chen, Xinlei},
title = {Foes or Friends: Embracing Ground Effect for Edge Detection on Lightweight Drones},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690699},
doi = {10.1145/3636534.3690699},
abstract = {Drone-based rapid and accurate environmental edge detection is highly advantageous for tasks such as disaster relief and autonomous navigation. Current methods, using radar or cameras, raise deployment costs and burden lightweight drones with high computational demands. In this paper, we propose AirTouch, a system that transforms the ground effect from a stability "foe" in traditional flight control views, into a "friend" for accurate and efficient edge detection. Our key insight is that analyzing drone sensor readings and flight commands allows us to detect ground effect changes. Such changes typically indicate the drone flying over an edge, making this information valuable for edge detection. We approach this insight through theoretical analysis, algorithm design, and implementation, fully leveraging the ground effect as a new sensing modality without compromising drone flight stability, thereby achieving accurate and efficient scene edge detection. Extensive evaluations demonstrate that our system achieves a high detection accuracy with mean detection distance errors of 0.051m, outperforming the baseline performance by 86\%.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1377–1392},
numpages = {16},
keywords = {quadrotors, sensing modality, physical knowledge aided AI},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690700,
author = {Ning, Jingyi and Yan, Zhihao and Wu, Zhaowei and Xie, Lei and Wang, Chuyu and Chen, Yingying and Ye, Baoliu and Lu, Sanglu},
title = {Moir\'{e}Vib: Micron-level Vibration Detection based on Moir\'{e} Pattern},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690700},
doi = {10.1145/3636534.3690700},
abstract = {Detection and assessment of micro vibrations are crucial tasks in both industrial settings and daily life. However, vibration sensors attached to the target vibrator may introduce potential resonance, and wireless detection methods suffer from severe multipath interference. Fortunately, moir\'{e}-based sensing methods have gained recognition in recent years due to their ability to perceive micro motion changes. In this paper, we propose Moir\'{e}Vib, a micro-vibration detection solution based on moir\'{e} patterns for dynamic and high-frequency environments. We attach a printed marker with periodic gratings to the surface of vibration devices to generate moir\'{e} patterns, which can amplify micro vibrations due to their low-frequency magnification effect. However, moir\'{e} pattern's changes caused by micro vibrations are often overwhelmed by random pixel-level noises, and the limited frame rate of the camera fails to capture high-frequency moir\'{e} features. To deal with these problems, we propose a spectrum-based method to refine and enhance the dynamic and micro moir\'{e} features. Additionally, we propose a dual-frame-rate-based fusion mechanism to realize high-frequency reconstruction of moir\'{e} features. Extensive experimental results show that Moir\'{e}Vib can realize a median amplitude detection error of 4.37 μm and achieve frequency detection up to 300Hz with a frame rate range of 10~30 fps.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1393–1407},
numpages = {15},
keywords = {moir\'{e} pattern, vibration detection, microscale},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690701,
author = {Gong, Chen and Zheng, Zhenzhe and Wu, Fan and Jia, Xiaofeng and Chen, Guihai},
title = {Delta: A Cloud-assisted Data Enrichment Framework for On-Device Continual Learning},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690701},
doi = {10.1145/3636534.3690701},
abstract = {In modern mobile applications, users frequently encounter various new contexts, necessitating on-device continual learning (CL) to ensure consistent model performance. While existing research predominantly focused on developing lightweight CL frameworks, we identify that data scarcity is a critical bottleneck for on-device CL. In this work, we explore the potential of leveraging abundant cloud-side data to enrich scarce on-device data, and propose a private, efficient and effective data enrichment framework Delta. Specifically, Delta first introduces a directory dataset to decompose the data enrichment problem into device-side and cloud-side sub-problems without sharing sensitive data. Next, Delta proposes a soft data matching strategy to effectively solve the device-side sub-problem with sparse user data, and an optimal data sampling scheme for cloud server to retrieve the most suitable dataset for enrichment with low computational complexity. Further, Delta refines the data sampling scheme by jointly considering the impact of enriched data on both new and past contexts, mitigating the catastrophic forgetting issue from a new aspect. Comprehensive experiments across four typical mobile computing tasks with varied data modalities demonstrate that Delta could enhance the overall model accuracy by an average of 15.1\%, 12.4\%, 1.1\% and 5.6\% for visual, IMU, audio and textual tasks compared with few-shot CL, and consistently reduce the communication costs by over 90\% compared to federated CL.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1408–1423},
numpages = {16},
keywords = {continual learning, on-device training, data enrichment},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690702,
author = {Wang, Yezhou and Pan, Hao and Qiu, Lili and Zhong, Linghui and Liu, Jiting and Ma, Ruichun and Chen, Yi-Chao and Xue, Guangtao and Ren, Ju},
title = {GPMS: Enabling Indoor GNSS Positioning using Passive Metasurfaces},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690702},
doi = {10.1145/3636534.3690702},
abstract = {Global Navigation Satellite System (GNSS) is extensively utilized for outdoor positioning and navigation. However, achieving high-precision indoor positioning is challenging due to the significant attenuation of GNSS signals indoors. To address this issue, we propose an innovative indoor GNSS positioning system called GPMS, which uses passive metasurface technology to redirect GNSS signals from outdoors into indoor spaces. These passive metasurfaces are strategically optimized for indoor coverage by steering and scattering the GNSS signals across a wide range of incident angles. We further develop a novel localization algorithm that can determine which metasurface the signal goes through and localize the user using the set of metasurfaces as anchor points. A distinct advantage of our localization algorithm is that it can be implemented on existing mobile devices without any hardware modifications. We implement the prototype of GPMS, and deploy six metasurfaces in two indoor environments, a 10\texttimes{}50 m2 office floor and a 15\texttimes{}20 m2 lecture room, to evaluate system performance. In terms of coverage, our GPMS increases the C/N0 from 9.1 dB-Hz to 23.2 dB-Hz and increases the number of visible satellites from 3.6 to 21.5 in the office floor. In terms of indoor positioning accuracy, our proposed system decreases the absolute positioning error from 30.6 m to 3.2 m in the office floor, and from 11.2 m to 2.7 m in the lecture room, demonstrating the feasibility and benefits of metasurface-assisted GNSS for indoor positioning.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1424–1438},
numpages = {15},
keywords = {GNSS system, indoor positioning, passive metasurface},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690703,
author = {Song, Kunzhe and Wang, Qijun and Zhang, Shichen and Zeng, Huacheng},
title = {SiWiS: Fine-grained Human Detection Using Single WiFi Device},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690703},
doi = {10.1145/3636534.3690703},
abstract = {Sub-6GHz radio sensing offers several compelling advantages, such as resilience to poor lighting conditions, privacy preservation, and the ability to see through walls. However, in indoor environments, the sub-6GHz ISM spectrum is heavily occupied by WiFi devices, leaving little available spectrum for sensing purposes. In this paper, we introduce SiWiS, a new approach to integrate radio sensing capabilities into individual WiFi devices for fine-grained human activity detection. SiWiS comprises two main components: (i) a new hardware component that can be easily installed on an off-the-shelf WiFi device, and (ii) a dual-branch deep neural network (DNN) optimized for concurrent human mask segmentation and pose estimation. We have built a prototype of SiWiS and installed it on a commercial WiFi router for evaluation. Extensive experimental results demonstrate a significant performance improvement over WiFi channel state information (CSI) based sensing methods. More importantly, zero-shot experiments confirm that SiWiS can be directly transferred to unseen real-world environments.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1439–1454},
numpages = {16},
keywords = {WiFi, joint communication and sensing, OFDM waveform for sensing, human pose estimation, human mask segmentation},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690704,
author = {Hu, Yiwen and Chen, Min-Yue and Yan, Haitian and Cheng, Chuan-Yi and Tu, Guan-Hua and Li, Chi-Yu and Xie, Tian and Peng, Chunyi and Xiao, Li and Tang, Jiliang},
title = {Uncovering Problematic Designs Hindering Ubiquitous Cellular Emergency Services Access},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690704},
doi = {10.1145/3636534.3690704},
abstract = {Cellular networks provide the most accessible emergency services with ubiquitous coverage, yet their emergency-specific designs remain largely unexplored. To systematically explore potential design defects that lead to failures or delays in emergency services, we introduce M911-Verifier, an emergency-specific model checking tool. It reveals many counterintuitive findings regarding the ubiquitous access support for cellular emergency services. Our study shows that, despite sufficient wireless signal coverage, users may still experience prolonged emergency call setup times, call initiation failures, or call drops due to flaws in the design of cellular emergency services. These design defects arise from three major causes: problematic network selection for initiating emergency calls, emergency-unaware call operation, and network escalation forbidden during emergency calls. The impacts of these defects have been experimentally validated across three U.S. carriers and two Taiwan carriers using commodity smartphones. Finally, we propose solutions and evaluate their effectiveness.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1455–1469},
numpages = {15},
keywords = {emergency services, 911 (9-1-1), mobility, cellular networks},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690705,
author = {Wang, Kun and Zhou, Zimu and Li, Zhenjiang},
title = {LATTE: Layer Algorithm-aware Training Time Estimation for Heterogeneous Federated Learning},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690705},
doi = {10.1145/3636534.3690705},
abstract = {Accurate estimation of on-device model training time is increasingly required for emerging learning paradigms on mobile edge devices, such as heterogeneous federated learning (HFL). HFL usually customizes the model architecture according to the different capabilities of mobile edge devices to ensure efficient use of local data from all devices for training. However, due to oversimplification of latency modeling, existing methods rely on a single coefficient to represent computational heterogeneity, resulting in sub-optimal HFL efficiency. We find that existing methods ignore the important impact of runtime optimization of deep learning frameworks, which we call development-chain diversity. Specifically, layers of a model may have different algorithm implementations, and deep learning frameworks often have different strategies for selecting the algorithm they believe is the best based on a range of runtime factors, resulting in different training latencies and invalid predictions from existing methods. In this paper, in addition to considering this diversity to ensure synchronized completion time of model training, we also study how to select the best algorithm each time to reduce the latency of the per-round training, thereby further improving the overall efficiency of federated training. To this end, we propose LATTE, which consists of a novel selector that identifies the best algorithm at runtime based on relative runtime factors. By further integrating it into our training latency model, LATTE provides accurate training time estimation. We develop LATTE as middleware, compatible with different deep learning frameworks. Extensive results show significantly improved training convergence speed and model accuracy compared to state-of-the-art methods.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1470–1484},
numpages = {15},
keywords = {heterogeneous federated learning, training time estimation},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690706,
author = {Wang, Shen and Zhao, Xiaopeng and Dai, Donghui and Yang, Lei},
title = {Mirror Never Lies: Unveiling Reflective Privacy Risks in Glass-laden Short Videos},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690706},
doi = {10.1145/3636534.3690706},
abstract = {In the era of ubiquitous short-video sharing, an overlooked yet significant privacy risk has arisen: the accidental disclosure of confidential information through reflective surfaces, such as mirrors, glass, or even polished metal. Such reflections can inadvertently disclose sensitive personal details to a broad audience without the awareness of content creators. Our examination of 100 top-rated TikTok short videos reveals that, on average, 37.2\% of frames in each video feature identifiable reflective surfaces, posing potential privacy risks. In this work, we introduce a framework designed to scrutinize reflective privacy risks in glass-laden short videos. At the heart of the framework is the development of a reflection-specific neural radiance field, termed RP-NeRF, which enables reflection-aware ray tracing for precise extraction and reconstruction of the reflective scenes from the surfaces they appear on. A detailed field study on the framework indicates that the precision in detecting human presence and recognizing objects from the reconstructed reflective images reaches as high as 90.8\% and 89.6\%, respectively, even when dealing with a reflective surface that boasts 90\% transparency and a mere 4\% reflectance rate. These findings highlight the urgent need for greater awareness and advanced solutions to safeguard privacy in our digital age, especially in light of the significant impact of short-video sharing.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1485–1499},
numpages = {15},
keywords = {visual privacy, neural rendering, ray tracing, scene reconstruction},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690707,
author = {Qi, Zhenzhou and Tung, Chung-Hsuan and Kalia, Anuj and Chen, Tingjun},
title = {Savannah: Efficient mmWave Baseband Processing with Minimal and Heterogeneous Resources},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690707},
doi = {10.1145/3636534.3690707},
abstract = {5G new radio (NR) employs frequency range 2 (FR2) in the millimeter-wave (mmWave) bands, which employs a much shorter slot duration compared to FR1 (sub-7 GHz) systems and, therefore, poses significant challenges for softwarized baseband processing in virtualized radio access networks (vRANs). Existing systems supporting software baseband processing focus on enabling (massive) multiple-input and multiple-output (MIMO) using multi-core edge server(s). These solutions may fail to meet the more stringent processing deadline in FR2 or require more intensive computational resources. In this paper, we present Savannah, an efficient mmWave baseband processing framework using minimal and heterogeneous computing resources including CPU and eASIC. Savannah addresses the challenges associated with baseband processing in FR2 by applying techniques for vectorizing matrix operations and memory access patterns, supporting heterogeneous computation via offloading LDPC decoding to an eASIC, and enabling single-core operation. We show that Savannah, using a single CPU core and the ACC100 accelerator, can support a 2\texttimes{}2 MIMO link with 100 MHz bandwidth, yielding a data rate of up to 487 Mbps.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1500–1514},
numpages = {15},
keywords = {millimeter-wave, baseband processing, ACC100 accelerator},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690708,
author = {Cui, Jiahe and He, Yuze and Niu, Jianwei and Ouyang, Zhenchao and Xing, Guoliang},
title = {αLiDAR: An Adaptive High-Resolution Panoramic LiDAR System},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690708},
doi = {10.1145/3636534.3690708},
abstract = {LiDAR technology holds vast potential across various sectors, including robotics, autonomous driving, and urban planning. However, the performance of current LiDAR sensors is hindered by limited field of view (FOV), low resolution, and lack of flexible focusing capability. We introduce αLiDAR, an innovative LiDAR system that employs controllable actuation to provide a panoramic FOV, high resolution, and adaptable scanning focus. The core concept of αLiDAR is to expand the operational freedom of a LiDAR sensor through the incorporation of a controllable, active rotational mechanism. This modification allows the sensor to scan previously inaccessible blind spots and focus on specific areas of interest in an adaptive manner. By modeling uncertainties in LiDAR rotation process and estimating point-wise uncertainty, αLiDAR can correct point cloud distortions resulted from significant rotation. In addition, by optimizing LiDAR's rotation trajectory, αLiDAR can swiftly adapt to dynamic areas of interest. We developed several prototypes of αLiDAR and conducted comprehensive evaluations in various indoor and outdoor real-world scenarios. Our results demonstrate that αLiDAR achieves centimeter-level pose estimation accuracy, with an average latency of only 37 ms. In two typical LiDAR applications, αLiDAR significantly enhances 3D mapping accuracy, coverage, and density by 8.5\texttimes{}, 2\texttimes{}, and 1.6\texttimes{} respectively, compared to conventional LiDAR sensors. Additionally, αLiDAR's adaptive rotation improves the effective sensing distance by 1.8\texttimes{} and increases the number of perceived objects by 1.9\texttimes{}. A video demonstration of αLiDAR's in action in real world is available at https://youtu.be/x4zc_I_xTaw. The code is available at https://github.com/HViktorTsoi/alpha_lidar.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1515–1529},
numpages = {15},
keywords = {LiDAR, active sensing, pose estimation, state estimation, sensor fusion},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690709,
author = {Oh, Taekkyung and Bae, Sangwook and Ahn, Junho and Lee, Yonghwa and Hoang, Tuan Dinh and Kang, Min Suk and Tippenhauer, Nils Ole and Kim, Yongdae},
title = {Enabling Physical Localization of Uncooperative Cellular Devices},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690709},
doi = {10.1145/3636534.3690709},
abstract = {In cellular networks, authorities may need to physically locate user devices to track criminals or illegal equipment. This process involves authorized agents tracing devices by monitoring uplink signals with cellular operator assistance. However, tracking uncooperative uplink signal sources remains challenging, even for operators and authorities. Three key challenges persist for fine-grained localization: i) devices must generate sufficient, consistent uplink traffic over time, ii) target devices may transmit uplink signals at very low power, and iii) signals from cellular repeaters may hinder localization of the target device. While these challenges pose significant practical obstacles to localization, they have been largely overlooked in existing research.This work examines the impact of these real-world challenges on cellular localization and introduces the Uncooperative Multiangulation Attack (UMA) to address them. UMA can 1) force a target device to transmit traffic continuously, 2) boost the target's signal strength to maximum levels, and 3) uniquely differentiate between signals from the target and repeaters. Importantly, UMA operates without requiring privileged access to cellular operators or user devices, making it applicable to any LTE network. Our evaluations demonstrate that UMA effectively overcomes practical challenges in physical localization when devices are uncooperative.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1530–1544},
numpages = {15},
keywords = {cellular localization, LTE, law enforcement},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690710,
author = {Mehrotra, Nishant and Pandey, Divyanshu and Prabhakara, Akarsh and Liu, Yawen and Kumar, Swarun and Sabharwal, Ashutosh},
title = {Hydra: Exploiting Multi-Bounce Scattering for Beyond-Field-of-View mmWave Radar},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690710},
doi = {10.1145/3636534.3690710},
abstract = {In this paper, we ask, "Can millimeter-wave (mmWave) radars sense objects not directly illuminated by the radar - for instance, objects located outside the transmit beamwidth, behind occlusions, or placed fully behind the radar?" Traditionally, mmWave radars are limited to sense objects that are directly illuminated by the radar and scatter its signals directly back. In practice, however, radar signals scatter to other intermediate objects in the environment and undergo multiple bounces before being received back at the radar. In this paper, we present Hydra, a framework to explicitly model and exploit multi-bounce paths for sensing. Hydra enables standalone mmWave radars to sense beyond-field-of-view objects without prior knowledge of the environment. We extensively evaluate the localization performance of Hydra with an off-the-shelf mmWave radar in five different environments with everyday objects. Exploiting multi-bounce via Hydra provides 2\texttimes{}-10\texttimes{} improvement in the median beyond-field-of-view localization error over baselines.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1545–1559},
numpages = {15},
keywords = {millimeter-wave, multi-bounce scattering, radar, sensing},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
@inproceedings{10.1145/3636534.3690711,
author = {Wang, Jike and Iravantchi, Yasha and Sample, Alanson and Shin, Kang G. and Wang, Xinbing and Chen, Dongyao},
title = {Polaris: Accurate, Vision-free Fiducials for Mobile Robots with Magnetic Constellation},
year = {2024},
isbn = {9798400704895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3636534.3690711},
doi = {10.1145/3636534.3690711},
abstract = {Fiducial marking is indispensable in mobile robots, including their pose calibration, contextual perception, and navigation. However, existing fiducial markers rely solely on vision-based perception which suffers such limitations as occlusion, energy overhead, and privacy leakage.We present Polaris, the first vision-free fiducial marking system, based on a novel, full-stack magnetic sensing design. Polaris can achieve reliable and accurate pose estimation and contextual perception, even in NLOS scenarios. Its core design includes: (1) a novel digital modulation scheme, Magnetic Orientation-shift Keying (MOSK) that can encode key information like waypoints and coordinates with passive magnets; (2) a robust and lightweight magnetic sensing framework to decode and localize the magnetic tags. Our design also equips Polaris with three key features: sufficient encoding capacity, robust detection accuracy, and low energy consumption. We have built an end-to-end system of Polaris and tested it extensively in real-world scenarios. The testing results have shown Polaris to achieve an accuracy of up to 0.58 mm and 1° in posture estimation with a power consumption of only 25.08 mW.},
booktitle = {Proceedings of the 30th Annual International Conference on Mobile Computing and Networking},
pages = {1560–1574},
numpages = {15},
keywords = {magnetic sensing, fiducial system, magnetometer},
location = {Washington D.C., DC, USA},
series = {ACM MobiCom '24}
}
