@inproceedings{10.1145/3581791.3596867,
author = {Wang, Lei and Gu, Tao and Li, Wei and Dai, Haipeng and Zhang, Yong and Yu, Dongxiao and Xu, Chenren and Zhang, Daqing},
title = {DF-Sense: Multi-user Acoustic Sensing for Heartbeat Monitoring with Dualforming},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596867},
doi = {10.1145/3581791.3596867},
abstract = {Acoustic sensing for heartbeat monitoring has become a prevailing research topic in wireless sensing. Existing acoustic sensing systems have two limitations---limited sensing range, and heartbeat monitoring for a single user only, hindering the large-scale deployment of applications. In this paper, we present DF-Sense, a Dual Forming based multi-user acoustic Sensing system for heartbeat monitoring in home settings. Specifically, we design a novel sensing signal-to-noise ratio (SSNR) enhancement model, namely Dualforming, based on the constructive superposition across multiple subcarriers and microphones, and further build the quantitative relationship between critical factors and SSNR enhancement to optimize sensing performance. To enable Dualforming, we propose a novel MUltiple Subtle SIgnal Classification (MUS2IC) method to identify multiple subjects with subtle motions. We implement DF-Sense using commercial acoustic devices and conduct extensive experiments in a home setting. Results show that DF-Sense achieves high precision measurement of instantaneous heart rate within the range of 10 m, which is sufficient for most daily space requirements, and is able to monitor heartbeat for up to 6 subjects in a 2-D space simultaneously.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {1–13},
numpages = {13},
keywords = {heartbeat, acoustic sensing, beamforming},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596832,
author = {He, Lixing and Hou, Haozheng and Shi, Shuyao and Shuai, Xian and Yan, Zhenyu},
title = {Towards Bone-Conducted Vibration Speech Enhancement on Head-Mounted Wearables},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596832},
doi = {10.1145/3581791.3596832},
abstract = {Head-mounted wearables are rapidly growing in popularity. However, a gap exists in providing robust voice-related applications like conversation or command control in complex environments, such as competing speakers and strong noises. The compact design of HMWs introduces non-trivial challenges to existing speech enhancement systems that use microphone recording only. In this paper, we handle this problem by using bone vibration conducted through the head skull. The principle is that the accelerometer is widely installed on head-mounted wearables and can capture the clean user's voice. Hence, we develop VibVoice, a lightweight multi-modal speech enhancement system for head-mounted wearables. We design a two-branch encoder-decoder deep neural network to fuse the high-level features of the two modalities and reconstruct clean speech. To address the issue of insufficient paired data for training, we extensively measure the bone conduction effect from a limited dataset to extract the physical impulse function for cross-modal data augmentation. We evaluate VibVoice on a dataset collected in real world and compare it with two state-of-the-art baselines. Results show that VibVoice yields up to 21\% better performance in PESQ and up to 26\% better performance in SNR compared with the baseline with 72 times less paired data required. We also conduct a user study with 35 participants, in which 87\% participants prefer VibVoice compared with the baseline. In addition, VibVoice requires 4 to 31 times less execution time compared with baselines on mobile devices. The demo audio of VibVoice is available at https://www.youtube.com/watch?v=8_-s_C_NGRI.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {14–27},
numpages = {14},
keywords = {earable sensing, ear-worn wearable, speech enhancement},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596859,
author = {Monjur, Mahathir and Luo, Yubo and Wang, Zhenyu and Nirjon, Shahriar},
title = {SoundSieve: Seconds-Long Audio Event Recognition on Intermittently-Powered Systems},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596859},
doi = {10.1145/3581791.3596859},
abstract = {A fundamental problem of every intermittently-powered sensing system is that signals acquired by these systems over a longer period in time are also intermittent. As a consequence, these systems fail to capture parts of a longer-duration event that spans over multiple charge-discharge cycles of the capacitor that stores the harvested energy. From an application's perspective, this is viewed as sporadic bursts of missing values in the input data - which may not be recoverable using statistical interpolation or imputation methods. In this paper, we study this problem in the light of an intermittent audio classification system and design an end-to-end system - SoundSieve - that is capable of accurately classifying audio events that span multiple on-off cycles of the intermittent system. SoundSieve employs an offline audio analyzer that learns to identify and predict important segments of an audio clip that must be sampled to ensure accurate classification of the audio. At runtime, SoundSieve employs a lightweight, energy- and content-aware audio sampler that decides when the system should wake up to capture the next chunk of audio; and a lightweight, intermittence-aware audio classifier that performs imputation and on-device inference. Through extensive evaluations using popular audio datasets as well as real systems, we demonstrate that SoundSieve yields 5\%--30\% more accurate inference results than the state-of-the-art.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {28–41},
numpages = {14},
keywords = {classification, sampling, scheduling, audio perforation},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596845,
author = {Jeon, Seunghyeok and Choi, Yonghun and Cho, Yeonwoo and Cha, Hojung},
title = {HarvNet: Resource-Optimized Operation of Multi-Exit Deep Neural Networks on Energy Harvesting Devices},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596845},
doi = {10.1145/3581791.3596845},
abstract = {Optimizing deep neural networks (DNNs) running on resource-constrained devices, such as energy harvesting sensor devices, poses unique challenges due to the limited memory and varying energy conditions. Existing efforts have shown that deploying a multi-exit network mitigates the problem by allowing tradeoffs between accuracy and computational complexity. However, previous works did not fully consider two essential requirements: optimized neural architecture and optimized inference policy. In this paper, we present HarvNet, which comprises two complementary techniques for generating and operating a multi-exit network for energy harvesting devices. First, we provide a neural architecture search scheme, HarvNAS, which configures the best multi-exit architecture while meeting memory and energy constraints. Second, HarvSched learns and constructs the best progressive inference policy with different energy constraints by considering runtime factors, such as the harvesting status and the energy storage level. We implemented HarvNAS using the TensorFlow framework and then implemented and evaluated HarvSched on an MSP430-based sensor device. The evaluation showed that HarvNAS generated a model with up to 2.6\%p higher accuracy while saving up to 70\% of memory compared to the existing technique, and HarvSched enabled zero-downtime operation of the generated model.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {42–55},
numpages = {14},
keywords = {multi-exit network, embedded intelligence, energy harvesting device},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596852,
author = {Huang, Kai and Yang, Boyuan and Gao, Wei},
title = {ElasticTrainer: Speeding Up On-Device Training with Runtime Elastic Tensor Selection},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596852},
doi = {10.1145/3581791.3596852},
abstract = {On-device training is essential for neural networks (NNs) to continuously adapt to new online data, but can be time-consuming due to the device's limited computing power. To speed up on-device training, existing schemes select trainable NN portion offline or conduct unrecoverable selection at runtime, but the evolution of trainable NN portion is constrained and cannot adapt to the current need for training. Instead, runtime adaptation of on-device training should be fully elastic, i.e., every NN substructure can be freely removed from or added to the trainable NN portion at any time in training. In this paper, we present ElasticTrainer, a new technique that enforces such elasticity to achieve the required training speedup with the minimum NN accuracy loss. Experiment results show that ElasticTrainer achieves up to 3.5\texttimes{} more training speedup in wall-clock time and reduces energy consumption by 2\texttimes{}-3\texttimes{} more compared to the existing schemes, without noticeable accuracy loss.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {56–69},
numpages = {14},
keywords = {elasticity, tensor selection, speedup, neural network, on-device training},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596870,
author = {Wei, Jianyu and Cao, Ting and Cao, Shijie and Jiang, Shiqi and Fu, Shaowei and Yang, Mao and Zhang, Yanyong and Liu, Yunxin},
title = {NN-Stretch: Automatic Neural Network Branching for Parallel Inference on Heterogeneous Multi-Processors},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596870},
doi = {10.1145/3581791.3596870},
abstract = {Mobile devices are increasingly equipped with heterogeneous multiprocessors, e.g., CPU + GPU + DSP. Yet existing Neural Network (NN) inference fails to fully utilize the computing power of the heterogeneous multi-processors due to the sequential structures of NN models. Towards this end, this paper proposes NN-Stretch, a new model adaption strategy, as well as the supporting system. It automatically branches a given model according to the processor architecture characteristics. Compared to other popular model adaption techniques such as model pruning that often sacrifices accuracy, NN-Stretch accelerates inference while preserving accuracy.The key idea of NN-Stretch is to horizontally stretch a model structure, from a long and narrow model to a short and wide one with multiple branches. We formulate the model branching into an optimization problem. NN-Stretch attempts to narrow down the design space by taking into account the hard latency constraints through varying where the branches converge and how each branch is scaled to fit heterogeneous processors, as well as the soft accuracy constraints through maintaining the model skeleton and expressiveness of each branch. According to the constraints, NN-Stretch can efficiently generate accurate and efficient multi-branch models. To facilitate easy deployment, this paper also devises a subgraph-based spatial scheduler for existing inference frameworks to parallelly execute the multi-branch models. Our experimental results are very promising, with up to 3.85\texttimes{} speedup compared to single CPU/GPU/DSP execution and up to 0.8\% accuracy improvement.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {70–83},
numpages = {14},
keywords = {model parallelism, multiple branch, mobile devices, heterogeneous processors, neural networks},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596856,
author = {Chan, Justin and Glenn, Antonio and Itani, Malek and Mancl, Lisa R. and Gallagher, Emily and Bly, Randall and Patel, Shwetak and Gollakota, Shyamnath},
title = {Wireless earbuds for low-cost hearing screening},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596856},
doi = {10.1145/3581791.3596856},
abstract = {We present the first wireless earbud hardware that can perform hearing screening by detecting otoacoustic emissions. The conventional wisdom has been that detecting otoacoustic emissions, which are the faint sounds generated by the cochlea, requires sensitive and expensive acoustic hardware. Thus, medical devices for hearing screening cost thousands of dollars and are inaccessible in low and middle income countries. We show that by designing wireless ear-buds using low-cost acoustic hardware and combining them with wireless sensing algorithms, we can reliably identify otoacoustic emissions and perform hearing screening. Our algorithms combine frequency modulated chirps with wideband pulses emitted from a low-cost speaker to reliably separate otoacoustic emissions from in-ear reflections and echoes. We conducted a clinical study with 50 ears across two healthcare sites. Our study shows that the low-cost earbuds detect hearing loss with 100\% sensitivity and 89.7\% specificity, which is comparable to the performance of a $8000 medical device. By developing low-cost and open-source wearable technology, our work may help address global health inequities in hearing screening by democratizing these medical devices.Open-source hardware and code can be found here: https://github.com/uw-x/OAEbuds},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {84–95},
numpages = {12},
keywords = {acoustic sensing, wearable technologies, otoacoustic emissions, mobile health, hearing screening, wireless earbuds},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596848,
author = {Zhang, Tianfang and Shi, Cong and Walker, Payton and Ye, Zhengkun and Wang, Yan and Saxena, Nitesh and Chen, Yingying},
title = {Passive Vital Sign Monitoring via Facial Vibrations Leveraging AR/VR Headsets},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596848},
doi = {10.1145/3581791.3596848},
abstract = {Vital signs (e.g., breathing and heart rates) and personal identities are essential information for personalized medicine and healthcare. The popularity of augmented reality/virtual reality (AR/VR) provides an excellent opportunity for enabling long-term health monitoring in a broad range of scenarios, including virtual entertainment, education, and telemedicine. However, commercial-off-the-shelf AR/VR devices do not have dedicated biosensors for providing vital signs and personal identities. In this work, we propose a novel framework that can generate fine-grained vital sign signals and other personalized health information of an AR/VR user through passive sensing on AR/VR devices. In particular, we find that the user's minute facial vibrations induced by breathing and heart beating can impact the readily available motion sensors on AR/VR headsets, which encode rich vital sign patterns and unique biometrics. The proposed framework further estimates the breathing and heartbeat rates, detects the gender and identity, and derives the body fat percentage of the user. To mitigate the impacts of body movement, we design an adaptive filtering scheme to cancel the spontaneous and non-spontaneous motion artifacts. We also develop unique facial vibration features and deep learning techniques to facilitate vital sign signal reconstruction and user identification. Extensive experiments demonstrate that our framework can achieve a low error of vital sign signal reconstruction and rate measurement, along with 95.51\% and 93.33\% accuracy on identity and gender recognition.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {96–109},
numpages = {14},
keywords = {AR/VR headsets, facial vibrations, health monitoring},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596854,
author = {Yin, Xiangyu and Huang, Kai and Forno, Erick and Chen, Wei and Huang, Heng and Gao, Wei},
title = {PTEase: Objective Airway Examination for Pulmonary Telemedicine using Commodity Smartphones},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596854},
doi = {10.1145/3581791.3596854},
abstract = {Remote monitoring and evaluation of pulmonary diseases via tele-medicine are important to disease diagnosis and management, but current telemedicine solutions have limited capability of objectively examining the airway's internal physiological conditions that are crucial to pulmonary disease evaluation. Existing solutions based on smartphone sensing are also limited to externally monitoring breath rates, respiratory events, or lung function. In this paper, we present PTEase, a new system design that addresses these limitations and uses commodity smartphones to examine the airway's internal physiological conditions. PTEase uses active acoustic sensing to measure the internal changes of lower airway caliber, and then leverages machine learning to analyze the sensory data for pulmonary disease evaluation. We implemented PTEase as a smartphone app, and verified its measurement error in lab-controlled settings as <10\%. Clinical studies further showed that PTEase reaches 75\% accuracy on disease prediction and 11\%-15\% errors in estimating lung function indices. Given that such accuracy is comparable with that in clinical practice using spirometry, PTEase can be reliably used as an assistive telemedicine tool for disease evaluation and monitoring.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {110–123},
numpages = {14},
keywords = {multi-task learning, smartphone, acoustic sensing, airway examination, pulmonary telemedicine},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596866,
author = {Zhong, Linling and Ouyang, Mingwei and Zhu, Fengyuan and Jin, Meng and Wang, Xinbing and Guan, Xinping and Zhou, Chenghu and Tian, Xiaohua},
title = {SmartShell: A Near-Field Reflective Surface Enhancing RSS},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596866},
doi = {10.1145/3581791.3596866},
abstract = {Reconfigurable reflective arrays can be used to program the radio propagation environment in order to form favorable wireless channel conditions. Previous designs have used large-scale arrays containing hundreds to thousands of reflecting elements located external to the receiving node, with the reflection coefficients of all array elements managed by a controller. However, these designs can be costly to deploy and are challenging to quickly adapt to the time-varying nature of wireless channels caused by mobility.In this paper, we propose using a small-sized and low-cost reflective surface attached to the mobile device, called SmartShell, to program the micro-environment of radio propagation near the device. We provide a systematic analysis of the near-field reflective surface, laying the theoretical foundation for the feasibility and effectiveness of SmartShell. We then present insight into controlling the surface units of SmartShell, showing that this is fundamentally different from existing far-field designs and can be formulated as a binary quadratic programming (BQP) problem, with performance bounds derived. We develop a prototype of the SmartShell system and conduct comprehensive experiments. Results show that the SmartShell can increase the received signal strength (RSS) of the wireless node by 5--10 dB, which is comparable to far-field large-scale reflective surfaces but at a much lower cost.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {124–136},
numpages = {13},
keywords = {RSS, reflective array, near-field},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596833,
author = {Chen, Lili and Yu, Bozhong and Ren, Ju and Gummeson, Jeremy and Zhang, Yaoxue},
title = {Towards Seamless Wireless Link Connection},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596833},
doi = {10.1145/3581791.3596833},
abstract = {Sub-6GHz and mmWave complement each other in the next generation of wireless communications for wide coverage and high capacity. However, there is still a gap between current network technology and seamless connection in indoor environments due to the inevitable occlusions that particularly affect higher frequency bands like Wi-Fi 5GHz and mmWave. To overcome this gap, economical tunable metasurfaces offer a promising solution by redirecting the beam direction of incoming waves to bypass blockages. However, existing metasurface technologies focus on a single frequency band and lack a theoretical framework to guide surface design for multiple desired bands, limiting their potential for diverse applications.This work attempts to provide a general method for cross-band metasurface design, extend wireless link coverage by using a new metasurface prototype called CrossFlit, which can maximize the link quality with efficient aperture usage and low cost. We addressed a series of challenges to enable CrossFlit to independently control the wireless communication links across multiple frequency bands; our proof of concept implementation is for Wi-Fi 5 GHz and mmWave bands. We integrate a fast beam-scanning algorithm into an end-to-end system that actuates the metasurface to optimize links in realtime. Empirical evaluation demonstrates that CrossFlit can enhance multiple wireless links simultaneously, providing 10 dB and 15 dB power improvements for Wi-Fi and mmWave links, respectively. CrossFlit achieves less than 4° beam mismatch even in challenging mobile scenarios.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {137–149},
numpages = {13},
keywords = {metasurface, cross-band, seamless, wireless},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596860,
author = {Grosheva, Nina and Deram, Sai Pavan and Lacruz, Jesus O. and Widmer, Joerg},
title = {SIGNiPHY: Reconciling random access with directional reception for efficient mmWave WLANs},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596860},
doi = {10.1145/3581791.3596860},
abstract = {Millimeter-Wave (mmWave) WiFi can provide very low latency and multi-Gbps throughput, but real-world deployments usually do not achieve the theoretically feasible performance. One main source of inefficiency is the contention-based random channel access, as it requires omni-directional reception which limits performance. Additionally, carrier sensing at mmWave frequencies is highly unreliable, leading to reduced channel usage. In this paper, we present SIGNalling in the PHY Preamble (SIGNiPHY) for efficient directional communications, a solution that allows to embed user identity in the preamble of data packets. It allows for true early user identification and then immediately steering the beam towards the transmitter while receiving the physical layer preamble. SIGNiPHY enables directional reception in random access mmWave networks, and additionally helps to quickly filter unwanted packets. It does not affect any preamble functions and is backward-compatible with legacy stations. We implement SIGNiPHY on an FPGA-based mmWave testbed and show that it achieves 99.6\% decoding accuracy even under very low SINR conditions. We also implement SIGNiPHY in ns-3 to evaluate large networks and show that it achieves throughput gains between 13\% and 230\% compared to different baseline schemes, due to the lower packet loss rate and improved spatial sharing.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {150–162},
numpages = {13},
keywords = {directional MAC, IEEE 802.11ad/ay, PHY Signaling, mmWave},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596840,
author = {Xie, Zhiyuan and Ouyang, Xiaomin and Pan, Li and Lu, Wenrui and Xing, Guoliang and Liu, Xiaoming},
title = {Mozart: A Mobile ToF System for Sensing in the Dark through Phase Manipulation},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596840},
doi = {10.1145/3581791.3596840},
abstract = {Sensing in low-light and dark environments has a wide range of applications. However, existing sensing technologies suffer several major challenges, such as excessive noise and low resolution. This paper proposes Mozart - a new mobile sensing system that leverages off-the-shelf Time-of-Flight (ToF) depth cameras to generate high-resolution and rich-in-texture maps for applications in dark scenarios. The design of Mozart is based on our key observation that the phase components of ToF measurements can be manipulated to expose texture information. Through in-depth analysis of the physical reflection model, we show that the textures can be exposed and enhanced using highly compute-efficient phase manipulation functions. By exploiting the physics texture models, we propose an autoencoder-based unsupervised learning approach that can automatically learn efficient representations from phase components to generate high-resolution maps. We implemented Mozart on several Android smartphone models1, and an edge testbed with standalone ToF camera platforms for various applications in the dark. The results show that Mozart can work in real time and delivers significant improvement over existing sensing technologies. Therefore, Mozart offers a low-cost, high-performance sensing technology for next-generation applications in the dark.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {163–176},
numpages = {14},
keywords = {phase manipulation, sensing in the dark, ToF depth camera},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596847,
author = {Xie, Binbin and Cui, Minhao and Ganesan, Deepak and Chen, Xiangru and Xiong, Jie},
title = {Boosting the Long Range Sensing Potential of LoRa},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596847},
doi = {10.1145/3581791.3596847},
abstract = {Wireless sensing is capable of capturing rich information of human target without requiring sensors attached to the target. Although promising, two critical issues still exist, i.e., (i) limited sensing range, and (ii) severe interference in real-world settings. Recently, LoRa is employed to improve the sensing range. Although LoRa sensing is able to achieve a longer sensing range than WiFi and acoustic sensing, it is still limited to tens of meters. In this paper, we propose ChirpSen, which fully exploits the property of chirp signal to increase the sensing range. ChirpSen adopts a chirp concentration scheme to concentrate the power of all signal samples in a LoRa chirp at one timestamp, improving the signal power and accordingly boosting the sensing range. With a longer sensing range, the interference issue also becomes more severe. We propose a novel scheme to flexibly control the sensing coverage by tuning the LoRa chirp length in software. Real-world experiments show that ChirpSen is able to increase the detection range of a small size drone (12 cm \texttimes{} 10 cm \texttimes{} 8 cm) from 18 m to 160 m. ChirpSen is capable of monitoring a human's respiration rate at 138 m and tracking a human target's walking trajectory 210 m away.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {177–190},
numpages = {14},
keywords = {controlling sensing coverage, interference mitigation, long sensing range, time-domain processing, chirp concentration},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596834,
author = {Jiao, Wenli and Li, Yanlin and Xi, Xiangdong and Wang, Ju and Fang, Dingyi and Chen, Xiaojiang},
title = {BioScatter: Low-Power Sweat Sensing with Backscatter},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596834},
doi = {10.1145/3581791.3596834},
abstract = {Sweat contains a wealth of physiologically relevant information and has been used to detect underlying diseases or the sub-health state. However, existing sweat sensors suffer from high energy consumption due to the need for energy-hungry components (i.e., ADC and DAC) and active radio front-ends, making them unable to support continuous and long-term monitoring.This paper introduces BioScatter, a backscatter-based accurate and ultra-low-power sweat sensing wearable sensor that does not need any energy-hungry ADC, DAC, and active radios. The key to eliminating DAC is a novel low-power voltage sweeping circuit design that can perform as well as a 12-bit DAC. To eliminate the ADC, we borrow backscatter technology that can directly transmit the measured analog sensing values to the reader, thus avoiding digital sampling. Extensive results show that BioScatter has a low-power consumption of 313.5 μW and achieves more than 98.5\% sensing accuracy for detecting five concentration levels of three types of important bio-fluid in sweat.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {191–204},
numpages = {14},
keywords = {internet of things (IoT), backscatter, sweat sensing, low-power, wearable biosensors},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596857,
author = {Ma, Xiaoyue and Zeng, Qiang and Chi, Haotian and Luo, Lannan},
title = {No More Companion Apps Hacking but One Dongle: Hub-Based Blackbox Fuzzing of IoT Firmware},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596857},
doi = {10.1145/3581791.3596857},
abstract = {Given the massive difficulty in emulating IoT firmware, blackbox fuzzing of IoT devices for vulnerability discovery has become an attractive option. However, existing blackbox IoT fuzzers need much time and tedious effort to reverse engineer the IoT companion app (or manually collect test scripts) of each IoT device, which is unscalable when analyzing many devices. Moreover, fuzzing through a companion app is impeded by the input sanitization inside the app and limited to the manually revealed functions. We notice that IoT devices are typically able to connect a hub using standard wireless protocols (such as ZigBee, Z-Wave, and WiFi). We thus propose a uniform hub-based architecture for fuzzing various IoT devices, without reverse engineering any companion apps. It exploits the messages exchanged between a hub and an IoT device to automatically discover all the functions, and then launches systematic function-oriented message-semantics-guided fuzzing. It avoids sanitization imposed by a companion app. In addition, it conducts device state-sensitive fuzzing, which we find very effective in finding IoT bugs. We implement the system named HubFuzzer. The evaluation shows that HubFuzzer leads to much higher coverage than prior state of the art. We test 21 IoT devices and find 23 zero-day vulnerabilities. Four CVEs have been assigned.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {205–218},
numpages = {14},
keywords = {vulnerability discovery, fuzzing, IoT security},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596862,
author = {Shahid, Irtaza and Roy, Nirupam},
title = {"Is this my president speaking?" Tamper-proofing Speech in Live Recordings},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596862},
doi = {10.1145/3581791.3596862},
abstract = {Malicious editing of audiovisual content has emerged as a popular tool for targeted defamation, spreading disinformation, and triggering political unrest. Public speeches and statements of political leaders, public figures, or celebrities are particularly at target due to their effectiveness in influencing the masses. Ubiquitous audiovisual recording of live speeches with smart devices and unrestricted content sharing and redistributing on social media make it difficult to address this threat using existing authentication techniques. Given public recordings of live events lack source control over the media, standard solutions falter. This paper presents TalkLock, a speech integrity verification system that can enable live speakers to protect their speeches from malicious alterations even when the speech is recorded by any member of the audience. The core idea is to generate meta-information from the speech signal in real-time and disseminate it through a secure QR code-based screen-camera communication. The QR code when recorded along with the speech embeds the meta-information in the content and it can be used later for independent verification in stand-alone applications or online platforms. A user study with live speech and real-world experiments with different types of voices, languages, environments, and distances show that TalkLock can verify fake content with 94.4\% accuracy.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {219–232},
numpages = {14},
keywords = {QR code, voice features, speech verification, deepfake},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596864,
author = {Yao, Zhihao and Seyed Talebi, Seyed Mohammadjavad and Chen, Mingyi and Amiri Sani, Ardalan and Anderson, Thomas},
title = {Minimizing a Smartphone's TCB for Security-Critical Programs with Exclusively-Used, Physically-Isolated, Statically-Partitioned Hardware},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596864},
doi = {10.1145/3581791.3596864},
abstract = {Smartphone owners often need to run security-critical programs on the same device as other untrusted and potentially malicious programs. This requires users to trust hardware and system software to correctly sandbox malicious programs, trust that is often misplaced. Our goal is to minimize the number and complexity of hardware and software components that a smartphone owner needs to trust. We present a split-trust hardware design composed of statically-partitioned, physically-isolated trust domains. We introduce a few simple, formally-verified hardware components to enable a program to gain provably exclusive and simultaneous access to both computation and I/O on a temporary basis. To manage this hardware, we present OctopOS, an OS composed of mutually distrustful subsystems. We present a prototype of this machine (hardware and OS) on a CPU-FPGA board and show that it incurs a small hardware cost compared to modern smartphone SoCs. For security-critical programs, we show that this machine significantly reduces the required trust compared to mainstream TEEs while achieving usable performance. For normal programs, performance is similar to a legacy machine.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {233–246},
numpages = {14},
keywords = {exclusive use, static partitioning, physical isolation},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596843,
author = {Kwak, Jaeheon and Lee, Sunjae and Jeong, Dae R. and Kumar, Arjun and Shin, Dongjae and Kim, Ilju and Shin, Donghwa and Lee, Kilho and Lee, Jinkyu and Shin, Insik},
title = {MixMax: Leveraging Heterogeneous Batteries to Alleviate Low Battery Experience for Mobile Users},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596843},
doi = {10.1145/3581791.3596843},
abstract = {Despite the physical advance of an existing single-cell battery system, mobile users are still suffering from low battery anxiety. With a careful analysis of users' battery usage behavior collected for 19,855 hours, we propose a heterogeneous battery system, MixMax, consisting of three complementary battery types tailored to minimizing the low battery time. While composing a heterogeneous battery system opens up a chance to simultaneously improve the capacity and the charging speed, one must face non-trivial challenges to determine the ratio of enclosed batteries and charge/discharge policies during the run-time. They are highly dependent on each other, which entails almost infinite candidates for the choice. MixMax gracefully unwinds the dependencies as it formulates the decision-making problem into an optimization problem and decomposes it into multiple sub-problems instead. To evaluate MixMax, we fabricate coin-cell batteries and experiment with them to model an accurate battery emulator which sophisticatedly reproduces the dynamics of battery systems. Our experimental results demonstrate that MixMax can reduce the low battery time by up to 24.6\% without compromising capacity, volume, weight, and more importantly, users' battery usage behavior. In addition, we prototype MixMax on a smartphone, presenting the practicality of MixMax on mobile systems.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {247–260},
numpages = {14},
keywords = {heterogeneous battery systems, low battery anxiety, mobile devices},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596851,
author = {Park, Seonghoon and Cho, Yeonwoo and Jun, Hyungchol and Lee, Jeho and Cha, Hojung},
title = {OmniLive: Super-Resolution Enhanced 360° Video Live Streaming for Mobile Devices},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596851},
doi = {10.1145/3581791.3596851},
abstract = {The live streaming of omnidirectional video (ODV) on mobile devices demands considerable network resources; thus, current mobile networks are incapable of providing users with high-quality ODV equivalent to conventional flat videos. We observe that mobile devices, in fact, underutilize graphics processing units (GPUs) while processing ODVs; hence, we envisage an opportunity exists in exploiting video super-resolution (VSR) for improved ODV quality. However, the device-specific discrepancy in GPU capability and dynamic behavior of GPU frequency in mobile devices create a challenge in providing VSR-enhanced ODV streaming. In this paper, we propose OmniLive, an on-device VSR system for mobile ODV live streaming. OmniLive addresses the dynamicity of GPU capability with an anytime inference-based VSR technique called Omni SR. For Omni SR, we design a VSR deep neural network (DNN) model with multiple exits and an inference scheduler that decides on the exit of the model at runtime. OmniLive also solves the performance heterogeneity of mobile GPUs using the Omni neural architecture search (NAS) scheme. Omni NAS finds an appropriate DNN model for each mobile device with Omni SR-specific neural architecture search techniques. We implemented OmniLive as a fully functioning system encompassing a streaming server and Android application. The experiment results show that our anytime VSR model provides four times upscaled videos while saving up to 57.15\% of inference time compared with the previous super-resolution model showing the lowest inference time on mobile devices. Moreover, OmniLive can maintain 30 frames per second while fully utilizing GPUs on various mobile devices.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {261–274},
numpages = {14},
keywords = {neural architecture search, multi-exit deep neural network, on-device video super-resolution, mobile omnidirectional video live streaming},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596853,
author = {Jin, Liuyi and Liu, Tian and Haroon, Amran and Stoleru, Radu and Middleton, Michael and Zhu, Ziwei and Chaspari, Theodora},
title = {EMSAssist: An End-to-End Mobile Voice Assistant at the Edge for Emergency Medical Services},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596853},
doi = {10.1145/3581791.3596853},
abstract = {Accurate and prompt delivery of Emergency Medical Services (EMS) is critical in emergency incidents, e.g., man-made or natural disaster areas. However, quickly selecting the correct EMS protocol(s) (which dictate the medical procedures to be administered to patients) in complex medical scenarios, remains a key, demanding task for Emergency Medical Technicians (EMT). In this paper, we present EMSAssist, the first end-to-end mobile voice assistant at the edge for EMS. EMSAssist consists of three major components that address technical challenges present in state-of-the-art solutions: 1) For the first time, EMSAssist proposes and applies a few-sample fine-tuning technique in medical speech recognition task, that achieves a faster and more accurate speech transcription on our EMS audio dataset, when compared to Google Cloud Speech-to-Text; 2) A WordPiece tokenizer helps boosting the end-to-end EMS protocol selection accuracy by retrieving useful information from incorrect transcriptions; 3) A novel data customization framework that enables our data-driven EMSMobileBERT model to become the new state-of-the-art for EMS protocol selection. Extensive end-to-end evaluation results at the edge show EMSAssist can more accurately select EMS protocols (Top-5 accuracy above 96\%) for EMTs, with end-to-end latencies of around 4.2 seconds.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {275–288},
numpages = {14},
keywords = {edge computing, emergency medical services, voice assistance},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596861,
author = {Garg, Nakul and Roy, Nirupam},
title = {Sirius: A Self-Localization System for Resource-Constrained IoT Sensors},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596861},
doi = {10.1145/3581791.3596861},
abstract = {Low-power sensor networks are transforming large-scale sensing in precision farming, livestock tracking, climate-monitoring and surveying. Accurate and robust localization in such low-power sensor nodes has never been as crucial as it is today. This paper presents, Sirius, a self-localization system using a single receiver for low-power IoT nodes. Traditionally, systems have relied on antenna arrays and tight synchronization to estimate angle-of-arrival (AoA) and time-of-flight with known access points. While these techniques work well for regular mobile systems, low-power IoT nodes lack the resources to support these complex systems. Sirius explores the use of gain-pattern reconfigurable antennas with passive envelope detector-based radios to perform AoA estimation without requiring any kind of synchronization. It shows a technique to embed direction specific codes to the received signals which are transparent to regular communication channel but carry AoA information with them. Sirius embeds these direction-specific codes by using reconfigurable antennas and fluctuating the gain pattern of the antenna. Our prototype demonstrates a median error of 7 degrees in AoA estimation and 2.5 meters in localization, which is similar to state-of-the-art antenna array-based systems. Sirius opens up new possibilities for low-power IoT nodes.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {289–302},
numpages = {14},
keywords = {low-power antenna, embedded AI, ultra-low-power localization, IoT, low-power sensing},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596869,
author = {Bae, Kang Min and Moon, Hankyeol and Sohn, Sung-Min and Kim, Song Min},
title = {Hawkeye: Hectometer-range Subcentimeter Localization for Large-scale mmWave Backscatter},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596869},
doi = {10.1145/3581791.3596869},
abstract = {Accurate localization of a large number of objects over a wide area is one of the keys to the pervasive interaction with the Internet of Things. This paper presents Hawkeye, a new mmWave backscatter that, for the first time, offers over (i) hundred-scale simultaneous 3D localization at (ii) subcentimeter accuracy for over an (iii) hectometer distance. Hawkeye generally applies to indoors and outdoors as well as under mobility. Hawkeye tag's Van Atta array design with retro-reflectivity in both elevation and azimuth planes offers 3D localization and effectively suppresses the multipath. Hawkeye localization algorithm is a lightweight signal processing compatible with the commodity FMCW radar. It uniquely leverages the interplay between the tag signal and clutter, and leverages the spectral leakage for fine-grained positioning. Prototype evaluations in corridor, lecture room, and soccer field reveal 7 mm median accuracy at 160 m range, and simultaneously localize 100 tags in only 33.2 ms. Hawkeye is reliable under temperature change with significant oscillator frequency offset. Demo video: https://tinyurl.com/4zkwxatu},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {303–316},
numpages = {14},
keywords = {FMCW, localization, backscatter, mmWave, internet-of-things},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596863,
author = {Jiang, Jinyan and Wang, Jiliang and Chen, Yijie and Liu, Yihao and Liu, Yunhao},
title = {LocRa: Enable Practical Long-Range Backscatter Localization for Low-Cost Tags},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596863},
doi = {10.1145/3581791.3596863},
abstract = {Long-range backscatter localization is a promising technology for the Internet of Things. Existing works cannot work well for distributed base stations and low-cost tags. We present LocRa, which provides accurate localization for long-range backscatter with distributed base stations. We present a novel method to extract accurate channel information and synchronize the phase of different base stations. To compensate for the frequency and phase error on low-cost tags, we combine multiple channel measurements and eliminate the error by aligning different channels. Finally, we exploit frequency domain characteristics of the backscatter signal to extend its bandwidth and improve the SNR, thereby enhancing the localization accuracy. We prototype LocRa tags using custom low-cost hardware and implement LocRa base stations on USRP. Through extensive experiments, we show that the localization error of LocRa is 6.8 cm and 88 cm when the tag is 5m and 50m away from the base station, which is 3.1\texttimes{} and 2.3\texttimes{} better than the state-of-the-arts methods.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {317–329},
numpages = {13},
keywords = {backscatter, wireless localization, LoRa},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596838,
author = {Zhang, Xiao and Klevering, Griffin and Wang, Juexing and Xiao, Li and Li, Tianxing},
title = {RoFin: 3D Hand Pose Reconstructing via 2D Rolling Fingertips},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596838},
doi = {10.1145/3581791.3596838},
abstract = {Smart homes, medical devices, and education systems, among other emerging cyber-physical systems, hold immense promise for sensing-based user interfaces, especially for using fingers and hand gestures as system input. However, vision approaches compatible with time-consuming image processing adopt low 60 Hz location sampling rate (frame rate) for real-time hand gesture recognition. Furthermore, they are not suitable for low-light environment and long detection range. In this paper, we propose RoFin, which first exploits 6 temporal-spatial 2D rolling fingertips for real-time 3D reconstructing of 20-joint hand pose. RoFin designs active optical labeling for finger identification and enhances inside-frame 3D location tracking via high rolling shutter rate (5--8 KHz). These features enable great potentials for enhanced multi-user HCI, virtual writing for Parkinson suffers, etc. We implement RoFin prototypes with wearable gloves attached with low-power single-colored LED nodes and commercial cameras. The experiment results show that (1) In flexible sensing distances up to 2.5 m, RoFin achieves an average labeling parsing accuracy of 85\%. (2) In comparison to vision-based techniques, RoFin improves the tracking grain with 4\texttimes{} more sampled points each frame. (3) RoFin reconstructs a hand pose in real time with 16 mm mean deviation error compared with Leap Motion under flexible distance.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {330–342},
numpages = {13},
keywords = {optical wireless communication, wearable device, deep learning, hand pose reconstructing, sensing, rolling shutter},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596855,
author = {Ye, Hanting and Xiong, Jie and Wang, Qing},
title = {When VLC Meets Under-Screen Camera},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596855},
doi = {10.1145/3581791.3596855},
abstract = {While radio communication still dominates in 5G, light and radios are expected to complement each other in the coming 6G networks. Visible Light Communication (VLC) is therefore attracting a tremendous amount of attention from both academia and industry. Recent studies showed that the front camera of pervasive smartphones is an ideal candidate to serve as the VLC receiver. While promising, we observe a recent trend with smartphones that can greatly hinder the adoption of smartphones for VLC, i.e., smartphones are moving towards full-screen for the best user experience. This trend forces front cameras to be placed under the devices' screen---leading to the so-called Under-Screen Camera (USC)---but we observe a severe performance degradation in VLC with USC: the transmission range is reduced from a few meters to merely 0.04 m, and the throughput is decreased by more than 90\%. To address this issue, we leverage the unique spatiotemporal characteristics of the rolling shutter effect on USC to design a pixel-sweeping algorithm to identify the sampling points with minimal interference from the translucent screen. We further propose a novel slope-boosting demodulation method to deal with color shift brought by the leakage interference. We build a proof-of-concept prototype using two commercial smart-phones. Experiment results show that our proposed design reduces the BER by two orders of magnitude on average and improves the data rate by 59\texttimes{}: from 914 b/s to 54.43 kb/s. The transmission range is extended by roughly 100\texttimes{}: from 0.04 m to 4.2 m.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {343–355},
numpages = {13},
keywords = {color-shift keying, optical camera communication, under-screen camera, translucent screen, full-screen, through-screen VLC},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596836,
author = {Wang, Zeyu and Xu, Jingao and Wang, Xu and Zhuge, Xiangwen and He, Xiaowu and Yang, Zheng},
title = {Industrial Knee-jerk: In-Network Simultaneous Planning and Control on a TSN Switch},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596836},
doi = {10.1145/3581791.3596836},
abstract = {Rapid advances in programmable network devices catalyzed the development of in-network computing, which is foreseen as a key enabler to empower the intelligence of production lines and mechanical arms in Industry 4.0. Various pioneering approaches have demonstrated the significant benefits of moving simple yet delay-sensitive industrial control tasks performed by servers to network switches. However, our detailed field study at a top-tier auto glass factory reveals that current practice fails to achieve a real-time and deterministic intelligent decision closure as leaving those complex yet essential planning tasks still on edge or cloud. In this paper, we design and implement a brand-new industrial switch, named Netopia, on a commercial Zynq platform through software and hardware co-design. Netopia enables planning and control to simultaneously perform on a network switch during communication. At the core of Netopia are three simple yet effective modules - a determinism guarantee mechanism, a computing acceleration scheme, and a packet deterministic forwarding framework that work hand-in-hand to ensure mechanical arms obtain intelligent control commands with low and deterministic latency. Comprehensive evaluations in industrial environments demonstrate that Netopia achieves an average end-to-end intelligent decision latency of 3.0ms with a jitter < 0.4ms, reduced by > 86\% over existing works.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {356–369},
numpages = {14},
keywords = {industrial control, in-network computing, time-sensitive networking},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596830,
author = {Corbett, Matthew and David-John, Brendan and Shang, Jiacheng and Hu, Y. Charlie and Ji, Bo},
title = {BystandAR: Protecting Bystander Visual Data in Augmented Reality Systems},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596830},
doi = {10.1145/3581791.3596830},
abstract = {Augmented Reality (AR) devices are set apart from other mobile devices by the immersive experience they offer. While the powerful suite of sensors on modern AR devices is necessary for enabling such an immersive experience, they can create unease in bystanders (i.e., those surrounding the device during its use) due to potential bystander data leaks, which is called the bystander privacy problem. In this paper, we propose BystandAR, the first practical system that can effectively protect bystander visual (camera and depth) data in real-time with only on-device processing. BystandAR builds on a key insight that the device user's eye gaze and voice are highly effective indicators for subject/bystander detection in interpersonal interaction, and leverages novel AR capabilities such as eye gaze tracking, wearer-focused microphone, and spatial awareness to achieve a usable frame rate without offloading sensitive information. Through a 16-participant user study,we show that BystandAR correctly identifies and protects 98.14\% of bystanders while allowing access to 96.27\% of subjects. We accomplish this with average frame rates of 52.6 frames per second without the need to offload unprotected bystander data to another device.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {370–382},
numpages = {13},
keywords = {eye tracking, augmented reality, visual data, bystander privacy},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596837,
author = {Li, Gen and Cao, Zhichao and Li, Tianxing},
title = {EchoAttack: Practical Inaudible Attacks To Smart Earbuds},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596837},
doi = {10.1145/3581791.3596837},
abstract = {Recent years have shown substantial interest in revealing vulnerability issues of voice-controllable systems on smartphones and smart speakers. While significant prior works have leveraged inaudible signals to attack these smart devices, smart earbuds present unique challenges and vulnerabilities due to their extreme hardware constraints. In this paper, we present EchoAttack, a practical inaudible attack system for smart earbuds. The primary innovation of EchoAttack is the ability to leverage both indirect and direct paths to attack smart earbuds. To search for the optimal path, we design a path-searching algorithm based on the attenuation model of ultrasound. We also propose a novel approach to remove harmonics noise, which improves the attacking signal's SNR further. Finally, we propose using Zigbee radios to sniff the Bluetooth signal and enable a hidden feedback channel without the victim's awareness. We implement the EchoAttack prototype using off-the-shelf hardware components and evaluate the prototypes in four typical indoor and outdoor scenarios using six smart earbuds. Experimental results show that EchoAttack outperforms the pure direct-path attack by 75.8\% on average in terms of attack success rate.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {383–396},
numpages = {14},
keywords = {earable security and privacy, inaudible attack, voice controllable systems},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596841,
author = {Yang, Yilin and Li, Xin and Ye, Zhengkun and Wang, Yan and Chen, Yingying},
title = {BioCase: Privacy Protection via Acoustic Sensing of Finger Touches on Smartphone Case Mini-Structures},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596841},
doi = {10.1145/3581791.3596841},
abstract = {Finger biometrics are widely used by smartphones as a secure and user-friendly credential for privacy protection. However, this information is difficult to measure without high-resolution images, leaving most works to treat this as an image-domain problem. We demonstrate that low-effort alternatives on smartphones are possible through the use of sound propagation in ubiquitous smartphone cases. Inexpensive and widely adopted, smartphone cases are always in contact with fingers, making them ideal for collecting finger biometrics. We thus design BioCase, an acoustic sensing system that leverages smartphone cases equipped with mini-structures to capture unique biometric-hybrid signatures (i.e., reflections influenced by the user's fingertip physiology and behavior) for smartphone privacy protection. The system generates inaudible structure-borne sound and measure the propagation through the smartphone case, mini-structures, and user finger. The design of the mini-structure controls the behavior of structure-borne sound such that unique responses are produced when different users and fingers touch the smartphone case. This enables low-cost, low-effort privacy protection, merely touching the smartphone case can authenticate users. Comprehensive experiments with 46 users over 10 weeks demonstrate BioCase can differentiate users with over 94\% accuracy at a 5\% false positive rate.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {397–409},
numpages = {13},
keywords = {smartphone cases, acoustic sensing, privacy protection},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596846,
author = {Peeters, Christian and Tucker, Tyler and Jain, Anushri and Butler, Kevin and Traynor, Patrick},
title = {LeopardSeal: Detecting Call Interception via Audio Rogue Base Stations},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596846},
doi = {10.1145/3581791.3596846},
abstract = {Audio Rogue Base Stations (ARBSs) allow an adversary to intercept cellular calls. These devices represent a substantial escalation in the threat posed by traditional rogue base stations, which only collect device identity information. This paper presents the first technique for detecting call eavesdropping via an ARBS. Our system, which we call LeopardSeal, uses distance bounding over the call audio channel to determine whether or not extra wireless hops (and therefore increased audio delay) that are characteristic of ARBSs are present during a call. We implement a proof of concept ARBS using open-source guides and perform a measurement study across the United States. We demonstrate the ability to detect all attacks (with zero false positives) due to a statistically significant difference in round trip times between benign and attack call audio (i.e., t-test: p ≪ 0.01) due to the large cost of additional wireless hops. Through this effort, we demonstrate the ability to robustly detect these eavesdropping devices.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {410–422},
numpages = {13},
keywords = {distance bounding, cellular security, cellular networks, audio rogue base stations},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596868,
author = {Yuan, Longzhi and Gong, Wei},
title = {Enabling Native WiFi Connectivity for Ambient Backscatter},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596868},
doi = {10.1145/3581791.3596868},
abstract = {WiFi backscatter communication has required unwanted constraints on either excitations or receivers since its inception eight years ago. We present Chameleon, the first native WiFi backscatter system where WiFi tags can generate native WiFi packets using uncontrolled productive WiFi as carriers. Our tag-only solution requires no particular excitation patterns and no change for software/hardware on WiFi NICs. The key insight is that the Chameleon tag can demodulate productive WiFi and backscatter this arbitrary carrier into a full-function packet using on-the-fly modulation. We prototype WiFi tags using ultra-low-power FPGAs and evaluate them in real-world scenarios where excitations are ambient traffic and backscatter receivers are a range of COTS NICs. Comprehensive field studies show that the maximal backscatter throughput of Chameleon is almost 1 Mbps, which is over 125\texttimes{} and 1000\texttimes{} better than WiTAG and FS-Backscatter. Also, we show that Chameleon can natively communicate with various COTS WiFi devices on Windows, iOS, and Android platforms. We believe this native WiFi backscatter design will enable ubiquitous WiFi connectivity for billions of IoT devices via widely available mobile gadgets and existing wireless infrastructure.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {423–435},
numpages = {13},
keywords = {802.11b, wifi, backscatter},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596835,
author = {Na, Xin and Guo, Xiuzhen and Yu, Zihao and Zhang, Jia and He, Yuan and Liu, Yunhao},
title = {Leggiero: Analog WiFi Backscatter with Payload Transparency},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596835},
doi = {10.1145/3581791.3596835},
abstract = {Backscatter is an enabling technology for battery-free sensing in today's Artificial Intelligence of Things (AIOT). Building a backscatter-based sensing system, however, is a daunting task, due to two obstacles: the unaffordable power consumption of the microprocessor and the coexistence with the ambient carrier's traffic. In order to address the above issues, in this paper, we present Leggiero, the first-of-its-kind analog WiFi backscatter with payload transparency. Leveraging a specially designed circuit with a varactor diode, this design avoids using a microprocessor to interface between the radio and the sensor, and directly converts the analog sensor signal into the phase of RF (radio frequency) signal. By carefully designing the reference circuit on the tag and precisely locating the extra long training field (LTF) section of a WiFi packet, Leggiero embeds the analog phase value into the channel state information (CSI). A commodity WiFi receiver without hardware modification can simultaneously decode the WiFi and the sensor data. We implement Leggiero design and evaluate its performance under varied settings. The results show that the power consumption of the Leggiero tag (excluding the power of the peripheral sensor module) is 30μW at a sampling rate of 400Hz, which is 4.8\texttimes{} and 4\texttimes{} lower than the state-of-the-art WiFi backscatter schemes. The uplink throughput of Leggiero is suficient to support a variety of sensing applications, while keeping the WiFi carrier's throughput performance unaffected.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {436–449},
numpages = {14},
keywords = {RF computing, phase, analog, backscatter},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596858,
author = {Du, Caihui and Liu, Jiahao and Wang, Shuai and Zhang, Rongrong and Gong, Wei and Yu, Jihong},
title = {Timespan-based Backscatter Using a Single COTS Receiver},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596858},
doi = {10.1145/3581791.3596858},
abstract = {This paper presents TiScatter, a timespan-based WiFi backscatter system that provides high-throughput communication with a single COTS receiver used. It outperforms the prior works that tradeoff between considerable data rate and practical deployment. To improve the data rate, TiScatter introduces a symbol-level times-pan modulation method that encodes tag data into the timespan between two modulated WiFi codewords in two successive WiFi packets. For decoding, TiScatter for the first time employs the injective feature between the checksum and the modulated codeword positions, which enables the demodulation of both the tag and original WiFi data using only one COTS receiver. This makes TiScatter more practical. Furthermore, we design TiScatter+ that shows these advantages while providing an even higher throughput under 802.11b excitations. We prototype our design, and comprehensive evaluations demonstrate that TiScatter shows a throughput over 100\texttimes{} higher than prior single-receiver backscatter systems like FS-Backscatter. It even has a better BER and throughput than the prior double-receiver backscatter systems like MOXcatter. Specifically, TiScatter provides 1) 2\texttimes{} higher peak throughput than MOXcatter and 2) an order of magnitude lower BER than MOXcatter with the presence of substantial interferences. In addition, TiScatter+ can deliver a throughput 3\texttimes{} higher than TiScatter under 802.11b ambient excitations. Our evaluation also confirms that TiScatter is generic and applicable to excitations under diverse WiFi standards (e.g., 802.11b/g/n).},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {450–461},
numpages = {12},
keywords = {802.11 networks, wifi, IoT, backscatter communications},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596839,
author = {Xie, Jiahong and Kong, Hao and Yu, Jiadi and Chen, Yingying and Kong, Linghe and Zhu, Yanmin and Tang, Feilong},
title = {mm3DFace: Nonintrusive 3D Facial Reconstruction Leveraging mmWave Signals},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596839},
doi = {10.1145/3581791.3596839},
abstract = {Recent years have witnessed the emerging market of 3D facial reconstruction that supports numerous face-driven scenarios including modeling in virtual reality (VR), human-computer interaction, and affective computing applications. Current mainstream approaches rely on vision for 3D facial reconstruction, which may encounter privacy concerns and suffer from obstruction scenes and bad lighting conditions. In this paper, we present a nonintrusive 3D facial reconstruction system, mm3DFace, which leverages a millimeter wave (mmWave) radar to reconstruct 3D human faces that continuously express facial expressions in a privacy-preserving and passive manner. Based on the pre-processed mmWave signals, mm3DFace first extracts facial geometric features that capture subtle changes in facial expressions through a ConvNeXt model with triple loss embedding. Then, mm3DFace derives distance and orientation-robust facial shapes with 68 facial landmarks using region-divided affine transformation. mm3DFace next reconstructs facial expressions through a designed regional amplification method and finally generates 3D facial avatars that continuously express facial expressions. Extensive experiments involving 15 participants in real-world environments show that mm3DFace can accurately track 68 facial landmarks with 3.94\% normalized mean error, 2.30mm mean absolute error, and 4.10mm 3D-mean absolute error, which is effective and practical in real-world 3D facial reconstruction.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {462–474},
numpages = {13},
keywords = {deep learning, mmWave, facial reconstruction, mobile sensing},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596850,
author = {Shanbhag, Hailan and Madani, Sohrab and Isanaka, Akhil and Nair, Deepak and Gupta, Saurabh and Hassanieh, Haitham},
title = {Contactless Material Identification with Millimeter Wave Vibrometry},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596850},
doi = {10.1145/3581791.3596850},
abstract = {This paper introduces RFVibe, a system that enables contactless material and object identification through the fusion of millimeter wave wireless signals with acoustic signals. In particular, RFVibe plays an audio sound next to the object that generates micro-vibrations in the object. These micro-vibrations can be captured by shining a millimeter wave radar signal on the object and analyzing the phase of the reflected wireless signal. RFVibe can then extract several features including resonance frequencies and vibration modes, damping time of vibrations, and wireless reflection coefficients. These features are then used to enable more accurate identification, with a step towards generalizing towards different setups and locations. We implement RFVibe using an off-the-shelf millimeter-wave radar and an acoustic speaker. We evaluate it on 23 objects of 7 material types (Metal, Wood, Ceramic, Glass, Plastic, Cardboard, and Foam), obtaining 81.3\% accuracy for material classification, a 30\% improvement over prior work. RFVibe is able to classify with reasonable accuracy in scenarios that it has not encountered before, including different locations, angles, boundary conditions, and objects.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {475–488},
numpages = {14},
keywords = {wireless vibrometry, object classification, material classification, millimeter-wave sensing},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596849,
author = {He, Guorong and Chen, Shaojie and Xu, Dan and Chen, Xiaojiang and Xie, Yaxiong and Wang, Xinhuai and Fang, Dingyi},
title = {Fusang: Graph-inspired Robust and Accurate Object Recognition on Commodity mmWave Devices},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596849},
doi = {10.1145/3581791.3596849},
abstract = {This paper presents the design and implementation of Fusang, a low-barrier system that brings accurate and robust 3D object recognition to Commercial-Off-The-Shelf mmWave devices. The basic idea of Fusang is leveraging the large bandwidth of mmWave Radars to capture a unique set of fine-grained reflected responses generated by object shapes. Moreover, Fusang constructs two novel graph-structured features to robustly represent the reflected responses of the signal in the frequency domain and IQ domain, and carefully designs a neural network to accurately recognize objects even in different multipath scenarios. We have implemented a prototype of Fusang on a commodity mmWave Radar device. Our experiments with 24 different objects show that Fusang achieves a mean accuracy of 97\% in different multipath environments. The code, dataset, and trained models of Fusang can be obtained at https://github.com/OpenNISLab/Pro-Fusang.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {489–502},
numpages = {14},
keywords = {object recognition, graph-inspired feature, HRRP, mmwave radar},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596831,
author = {Kong, Rui and Li, Yuanchun and Yuan, Yizhen and Kong, Linghe},
title = {ConvReLU++: Reference-based Lossless Acceleration of Conv-ReLU Operations on Mobile CPU},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596831},
doi = {10.1145/3581791.3596831},
abstract = {Many activation values of Convolutional Neural Networks (CNNs) are zeros due to ReLU (Rectified Linear Unit), one of the most common activation functions used in modern neural networks. Since ReLU outputs are zero for all negative inputs, existing CNN acceleration approaches estimate zero outputs to skip redundant computation, which has to sacrifice accuracy for efficiency and leads to dilemma trade-offs and cockamamie configuration. In this paper, we introduce a lossless acceleration method ConvReLU++ for CNN inference on mobile devices, which accurately detects and skips zero-outputs for speedup without failures. The key to early negative detection is adopting reference-based upper-bounds calculation. This ensures that as soon as the intermediate results become negative, the final results are guaranteed to be negative. Upon detection, the remaining computation can be skipped and the following ReLU output can be simply set to zero. We rigorously prove the losslessness property of ConvReLU++, analyze the theoretical FLOPs reduction, and show the compatibility of our method with vector-level parallelism on mobile platforms. We implement ConvReLU++ in popular mobile inference frameworks and evaluate it on common deep vision tasks. The results demonstrate that ConvReLU++ can achieve 2.90\% to 8.91\% latency reduction over the original inference framework on edge devices without sacrificing accuracy. Our code can be found at https://github.com/monster119120/conv_relu_plus_plus.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {503–515},
numpages = {13},
keywords = {mobile CPU, early negative detection, lossless acceleration, CNN inference},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596842,
author = {Yi, Rongjie and Cao, Ting and Zhou, Ao and Ma, Xiao and Wang, Shangguang and Xu, Mengwei},
title = {Boosting DNN Cold Inference on Edge Devices},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596842},
doi = {10.1145/3581791.3596842},
abstract = {DNNs are ubiquitous on edge devices nowadays. With its increasing importance and use cases, it's not likely to pack all DNNs into device memory and expect that each inference has been warmed up. Therefore, cold inference, the process to read, initialize, and execute a DNN model, is becoming commonplace and its performance is urgently demanded to be optimized. To this end, we present NNV12, the first on-device inference engine optimizing cold inference. NNV12 is built atop three novel optimization knobs: selecting a proper kernel (i.e., operator implementation) for each DNN operator, bypassing the weights transformation process by caching the post-transformed weights on disk, and pipelined execution of many kernels on asymmetric processors. To tackle with the huge search space, NNV12 employs a heuristic-based scheme to obtain a near-optimal kernel scheduling plan. We fully implement a prototype of NNV12 and evaluate its performance across extensive experiments. It shows that NNV12 achieves up to 15.2\texttimes{} speedup compared to the state-of-the-art DNN engines on edge CPUs and 401.5\texttimes{} speedup on edge GPUs, respectively.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {516–529},
numpages = {14},
keywords = {mobile devices, deep learning inference, DNN cold inference},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596844,
author = {Ouyang, Xiaomin and Xie, Zhiyuan and Fu, Heming and Cheng, Sitong and Pan, Li and Ling, Neiwen and Xing, Guoliang and Zhou, Jiayu and Huang, Jianwei},
title = {Harmony: Heterogeneous Multi-Modal Federated Learning through Disentangled Model Training},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596844},
doi = {10.1145/3581791.3596844},
abstract = {Multi-modal sensing systems are increasingly prevalent in real-world applications such as health monitoring and autonomous driving. Most multi-modal learning approaches need to access users' raw data, which poses significant concerns to users' privacy. Federated learning (FL) provides a privacy-aware distributed learning framework. However, current FL approaches have not addressed the unique challenges of heterogeneous multi-modal FL systems, such as modality heterogeneity and significantly longer training delay. In this paper, we propose Harmony, a new system for heterogeneous multi-modal federated learning. Harmony disentangles the multi-modal network training in a novel two-stage framework, namely modality-wise federated learning and federated fusion learning. By integrating a novel balance-aware resource allocation mechanism in modality-wise FL and exploiting modality biases in federated fusion learning, Harmony improves the model accuracy under non-i.i.d. data distributions and speeds up system convergence. We implemented Harmony on a real-world multi-modal sensor testbed deployed in the homes of 16 elderly subjects for Alzheimer's Disease monitoring. Our evaluation on the testbed and three large-scale public datasets of different applications show that, Harmony outperforms by up to 46.35\% accuracy over state-of-the-art baselines and saves up to 30\% training delay.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {530–543},
numpages = {14},
keywords = {balance-aware resource allocation, modality heterogeneity, multi-modal federated learning systems},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3596865,
author = {Chen, Rui and Wan, Qiyu and Zhang, Xinyue and Qin, Xiaoqi and Hou, Yanzhao and Wang, Di and Fu, Xin and Pan, Miao},
title = {EEFL: High-Speed Wireless Communications Inspired Energy Efficient Federated Learning over Mobile Devices},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3596865},
doi = {10.1145/3581791.3596865},
abstract = {Energy efficiency is essential for federated learning (FL) over mobile devices and its potential prosperous applications. Different from existing communication efficient FL research efforts, which regard communication energy consumption as the bottleneck, we have observed that with ever increasing wireless transmission speed (e.g., Wi-Fi 5 or 5G), the energy consumption of wireless communications for model updates in FL is significantly reduced and sometimes is smaller than that of local on-device training. Motivated by such observations, in this paper, we propose a high-speed wireless communications inspired energy efficient federated learning over mobile devices (EEFL), whose goal is to reduce the overall energy consumption (computing + communication). In particular, we design a novel energy-aware adaptive local update policy for mobile devices by jointly considering FL performance and energy saving of high-speed wireless transmissions. Furthermore, given the device's local update policy in each FL global round, we advance the dynamic voltage and frequency scaling (DVFS) strategy to minimize local training's energy consumption by keeping GPU and CPU working at appropriate frequencies without triggering thermal throttling. Extensive experimental results with various learning models, datasets, and wireless transmission environments demonstrate the proposed EEFL's superiority over the peer designs in terms of energy efficiency.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {544–556},
numpages = {13},
keywords = {DVFS, energy efficiency, mobile devices, federated learning},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597364,
author = {Ruan, Hui and Gong, Qingyuan and Chen, Yang and Chen, Jiong and Li, Ziyue and Su, Xiang},
title = {Poster: A Privacy-preserving Heart Rate Prediction System for Drivers in Connected Vehicles},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597364},
doi = {10.1145/3581791.3597364},
abstract = {The prediction of health metrics for drivers has become increasingly crucial due to the potential impact of drivers' health conditions on traffic accidents. Heart attack is one of the primary causes of health-related traffic tragedies. However, drivers' heart rate (HR) is considered highly-private data, which should not be collected by a centralized server for training the prediction model. To this end, we contribute FedHeart, a novel privacy-preserving federated learning (FL) system for HR prediction. We observe distinct HR changes when drivers are in steady-state and changing-state conditions, and thus we utilize FL to train two separate models for these states. To enhance the prediction accuracy, we incorporate contrastive learning to extract HR features. Through experiments on two real-world datasets, we validate the efficiency of the proposed system in accurately predicting HR during driving scenarios.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {557–558},
numpages = {2},
keywords = {driving scenarios, federated learning, heart rate prediction},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597365,
author = {Lintunen, Milla and Premsankar, Gopika and Tenhunen, Henri and Tarkoma, Sasu and Rao, Ashwin},
title = {Poster: Automatic Mass Power Outage Detection in Radio Access Networks},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597365},
doi = {10.1145/3581791.3597365},
abstract = {Mobile devices are expected to be always connected, and this implies that the mobile network is able to quickly identify and address faults that impact service (for example, due to power outages). In this article, we present our approach for automatically detecting mass power outages. Our solution decreases the number of created trouble tickets in two mobile networks by 4.7\% and 9.3\%.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {559–560},
numpages = {2},
keywords = {fault management, spatio-temporal clustering, mobile networks, alarm correlation},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597366,
author = {Sooriya Patabandige, Pramuka Medaranga and Waskito, Steven Antya Orvala and Li, Kunjun and Leow, Kai Jie and Chakrabarty, Shantanu and Varshney, Ambuj},
title = {Poster: Rethinking Embedded Sensor Data Processing and Analysis with Large Language Models},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597366},
doi = {10.1145/3581791.3597366},
abstract = {An important step in the deployment of wireless embedded systems is the analysis of the sensor data. Traditionally, this requires machine learning models tailored to the application use case. However, this step requires significant expertise from the end user and can be less adaptable to the dynamics of real-world deployments. In recent years, large language models have seen significant developments. These models have been shown to be capable of performing general-purpose tasks. In this work, we explore the hypothesis that large language models can be used to aid in sensor data analysis. Our preliminary findings through real-world experiments show significant promise for two tasks: inferring hand gestures through tracking of light and vibration sensor data. We believe these findings highlight the potential of large language models in sensor data analysis, and thus, it warrants further study.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {561–562},
numpages = {2},
keywords = {sensor data analysis, LLM, IoT, wireless embedded systems},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597367,
author = {Gan, Maolin and Liu, Yimeng and Liu, Li and Wu, Chenshu and Dong, Younsuk and Zeng, Huacheng and Cao, Zhichao},
title = {Poster: mmLeaf: Versatile Leaf Wetness Detection via mmWave Sensing},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597367},
doi = {10.1145/3581791.3597367},
abstract = {Leaf wetness detection is one of the key technologies for preventing plant diseases in agriculture. In this poster, we propose mmLeaf, leveraging a commercial off-the-shelf millimeter-wave (mmWave) radar to detect actual leaf wetness in diverse environments and lighting conditions. mmLeaf captures mmWave signals reflected by monitored leaves with a two-dimensional (2D) scanning system. Then, we use a multiple-input multiple-output (MIMO) array and synthetic aperture radar (SAR) to reconstruct the signal distribution of different planes of the leaves. A deep learning model takes the fused signal distribution as inputs to classify the leaf wetness. We implement mmLeaf using a frequency-modulated continuous-wave (FMCW) radar and evaluate its performance with a potted plant indoors. By exploring the use of mmWave signals, mmLeaf delivers an end-to-end detection framework that achieves up to 90\% accuracy in classifying leaf wetness under different distances.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {563–564},
numpages = {2},
keywords = {deep learning, SAR, near-field radar imaging, leaf wetness, mmWave sensing},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597368,
author = {Wang, Shixin and Xu, Zhaoyuan and Gong, Wei},
title = {Poster: Enhanced ZigBee Backscatter Communication using Fine-Grained Chip-Level Modulation},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597368},
doi = {10.1145/3581791.3597368},
abstract = {Codeword translation is well-known for translating excitation signals into other codewords to provide productive ZigBee backscatter. But the limited throughput of conventional systems using info-rich codewords to transmit a single bit challenge their effectiveness to perform sensor-data transmission. In this paper, we introduce ChipScatter, a novel high-throughput modulation technology that translates excitation codewords into more controllable codewords through fine-grained chip-level modulation. The more controllable categories available, the more bits can be transmitted simultaneously. Evaluation results show that ChipScatter can increase the throughput of productive ZigBee backscatter by up to 8\texttimes{}.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {565–566},
numpages = {2},
keywords = {internet of things, ZigBee, backscatter},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597369,
author = {Shahid, Irtaza and Roy, Nirupam},
title = {Poster: Preventing Fake News through Live Speech Signature},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597369},
doi = {10.1145/3581791.3597369},
abstract = {Malicious editing to alter audiovisual content has become increasingly prevalent in recent years, as it allows for targeted defamation, the dissemination of disinformation, and the incitement of political unrest. Public speeches and statements made by political leaders, public figures, and celebrities are particularly vulnerable to such attacks, as they have the power to sway public opinion. The widespread use of smart devices to record live speeches, combined with unrestricted content sharing and redistribution on social media platforms, makes it difficult to prevent the spread of manipulated media. Existing solutions, which rely on source control over the media, are not effective for live events. This paper presents TalkLock, a speech integrity verification system that can enable live speakers to protect their speeches from malicious alterations even when the speech is recorded by any member of the audience. The core idea is to generate meta-information from the speech signal in real-time and disseminate it through a secure QR code-based screen-camera communication. The QR code when recorded along with the speech embeds the meta-information in the content and it can be used later for independent verification in stand-alone applications or online platforms. A user study with live speech and real-world experiments with different types of voices, languages, environments, and distances show that TalkLock can verify fake content with 94.4\% accuracy.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {567–568},
numpages = {2},
keywords = {QR code, voice features, speech verification, deepfake},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597370,
author = {Garg, Nakul and Roy, Nirupam},
title = {poster: Ultra-low-power Angle-of-Arrival Estimation Using a Single Antenna},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597370},
doi = {10.1145/3581791.3597370},
abstract = {In this poster, we present a new approach to low-power self-localization for IoT nodes called Sirius. With the rise of low-power sensor networks in precision farming, climate monitoring, and surveying, it has become increasingly critical to accurately and robustly localize low-power sensor nodes. However, traditional systems that rely on antenna arrays and time synchronization are too complex for low-power IoT nodes. To overcome this limitation, Sirius utilizes gain-pattern reconfigurable antennas with passive envelope detector-based radios to estimate angle-of-arrival. This is achieved by embedding direction-specific codes in the received signals, which carry angle-of-arrival information. Our prototype has demonstrated a median error of 7 degrees in AoA estimation and 2.5 meters in localization, comparable to state-of-the-art antenna array-based systems. This new approach opens up exciting possibilities for low-power IoT nodes in various fields.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {569–570},
numpages = {2},
keywords = {low-power antenna, embedded AI, IoT, self localization, ultra-low-power sensing},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597371,
author = {Huang, Yushan and Haddadi, Hamed},
title = {Poster: Towards Battery-Free Machine Learning Inference and Model Personalization on MCUs},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597371},
doi = {10.1145/3581791.3597371},
abstract = {Machine learning (ML) is moving towards edge devices. However, ML models with high computational demands and energy consumption pose challenges for ML inference in resource-constrained environments, such as the deep sea. To address these challenges, we propose a battery-free ML inference and model personalization pipeline for microcontroller units (MCUs). As an example, we performed fish image recognition in the ocean. We evaluated and compared the accuracy, runtime, power, and energy consumption of the model before and after optimization. The results demonstrate that, our pipeline can achieve 97.78\% accuracy with 483.82 KB Flash, 70.32 KB RAM, 118 ms runtime, 4.83 mW power, and 0.57 mJ energy consumption on MCUs, reducing by 64.17\%, 12.31\%, 52.42\%, 63.74\%, and 82.67\%, compared to the baseline. The results indicate the feasibility of battery-free ML inference on MCUs.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {571–572},
numpages = {2},
keywords = {resource-constrained, TinyML, IoT, edge computing},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597372,
author = {Wang, Zhili and Yuan, Longzhi and Gong, Wei},
title = {Poster: Image Acquisition and Storage System for Battery-Free WiFi Camera},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597372},
doi = {10.1145/3581791.3597372},
abstract = {Generally, image acquisition and storage requires a considerable amount of energy. To address this issue, we present an innovative approach towards developing a battery-free WiFi camera. Our system uses FRAM and DMA to cache images quickly, select appropriate color modes, and make some optimizations to the code, allowing for the acquisition and storage of a grayscale image of 144 \texttimes{} 176 pixels using only 6mJ of energy in 96ms. Our proposed system provides a promising step towards the realization of a battery-free WiFi camera, enabling energy-efficient image acquisition and storage in applications such as environmental monitoring, surveillance, and IoT.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {573–574},
numpages = {2},
keywords = {internet of things, wifi camera},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597373,
author = {Broner, Matan and Lee, Sangwoo and Jin, Liuyi and Stoleru, Radu},
title = {Poster: Towards Multi-Radio Access in 5G Networks},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597373},
doi = {10.1145/3581791.3597373},
abstract = {This poster presents a multi-access network testbed designed to serve as an essential tool for research on Access Traffic Steering, Switching, and Splitting (ATSSS) in 4G and 5G networks. By integrating Non-3GPP Inter-Working Function (N3IWF) and 5G core from different open-source projects, our testbed enables multiaccess sessions in 4G-LTE, 5G NSA, and 5G SA. Furthermore, our testbed incorporates a transport converter into the 5G core network, allowing User Equipment (UE) to utilize multi-access networks, even in the absence of multi-path TCP (MPTCP) support from external servers. We demonstrated the effectiveness of our testbed by utilizing ATSSS for detecting cybersecurity attacks, marking the first instance of employing ATSSS capabilities to improve cybersecurity in 4G/5G networks.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {575–576},
numpages = {2},
keywords = {experimentation, testbed, multi-radio access, 5G},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597374,
author = {Bae, Kang Min and Moon, Hankyeol and Kim, Song Min},
title = {Poster: Submillimeter Localization for mmWave Backscatter Using Commodity 77 GHz Radar},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597374},
doi = {10.1145/3581791.3597374},
abstract = {Accurate and scalable localization is one of the keys to pervasive interaction with the Internet of Things. mmWave backscatter possesses great potential toward this goal - The abundant bandwidth of mmWave enables high-precision localization, and low-cost and ultra low-power backscatter tags enable massive deployment with minimum deployment cost and maintenance efforts. We present Hawkeye, a new mmWave backscatter that offers (i) submillimeter localization accuracy (ii) at over 2 m range, (iii) while consuming 2.25 μW power. At the heart of our design is the new Hawkeye super-resolution, which exploits the interplay between the tag FSK and FMCW radar to improve the localization performance by \texttimes{}60 over conventional FMCW radar (i.e., c/2BW). Hawkeye readers were implemented on commodity 77 GHz radars and the tags were prototyped on PCB.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {577–578},
numpages = {2},
keywords = {FMCW, localization, backscatter, mmWave, internet-of-things},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597375,
author = {An, Goh Sheen and Varshney, Ambuj},
title = {Poster: VoCopilot: Enabling Voice-Activated Tracking for Everyday Interactions},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597375},
doi = {10.1145/3581791.3597375},
abstract = {Voice plays a crucial role in our daily lives, enabling communication, conveying emotions, and indicating our health. As a result, tracking vocal interactions can provide valuable insights into various aspects of our lives. This poster presents our preliminary work for a novel voice tracker (VoCopilot) that effectively tracks various vocal interactions. For example, the VoCopilot tracker can help document meetings and generate notes, even when participants speak different languages. Additionally, it can serve as a life-logger, monitoring daily conversations and extracting key points to summarize their content. Central to VoCopilot's design is an energy-efficient, co-developed acoustic hardware and firmware combined with a comprehensive integration of VoCopilot tracker with advanced machine learning systems. This harmonious integration ensures precise voice transcription, summarization, and analysis. We present our early thoughts on VoCopilot hardware design and share early results of utilizing Whisper for efficient multilingual transcribing. We acknowledge VoCopilot may raise privacy issues; therefore, we provide early thoughts to address these concerns.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {579–580},
numpages = {2},
keywords = {embedded systems, acoustic, AI, wearable, speech-to-text},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597376,
author = {Qiu, Yanlong and Zhang, Jiaxi and Huang, Kaiyi and Zhang, Jin and Ji, Bo},
title = {Poster: Radar-CA: Radar-Sensing Multiple Access with Collision Avoidance},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597376},
doi = {10.1145/3581791.3597376},
abstract = {We propose a practical and efficient radar interference mitigation system, Radar-CA. Radar-CA overcomes the limitations of requiring any additional equipment or resources. Radar-CA transfers the access time estimation problem to a frequency estimation problem, enabling interference mitigation through a central controller, and our preliminary result shows that Radar-CA is capable of mitigating interference efficiently in a dense radar network.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {581–582},
numpages = {2},
keywords = {interference mitigation, millimeter wave (mmWave)},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597377,
author = {Corbett, Matthew and David-John, Brendan and Shang, Jiacheng and Hu, Y. Charlie and Ji, Bo},
title = {Poster: BystandAR: Protecting Bystander Visual Data in Augmented Reality Systems},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597377},
doi = {10.1145/3581791.3597377},
abstract = {Augmented Reality (AR) devices are set apart from other mobile devices by the immersive experience they offer. While the powerful suite of sensors on modern AR devices is necessary for enabling such an immersive experience, they can create unease in bystanders (i.e., those surrounding the device during its use) due to potential bystander data leaks, which is called the bystander privacy problem. In this poster, we propose BystandAR, the first practical system that can effectively protect bystander visual (camera and depth) data in real-time with only on-device processing. BystandAR builds on a key insight that the device user's eye gaze and voice are highly effective indicators for subject/bystander detection in interpersonal interaction, and leverages novel AR capabilities such as eye gaze tracking, wearer-focused microphone, and spatial awareness to achieve a usable frame rate without offloading sensitive information. Through a 16-participant user study, we show that BystandAR correctly identifies and protects 98.14\% of bystanders while allowing access to 96.27\% of subjects. We accomplish this with average frame rates of 52.6 frames per second without the need to offload unprotected bystander data to another device.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {583–584},
numpages = {2},
keywords = {eye tracking, augmented reality, visual data, bystander privacy},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597378,
author = {Shanbhag, Hailan and Madani, Sohrab and Isanaka, Akhil and Nair, Deepak and Gupta, Saurabh and Hassanieh, Haitham},
title = {Poster: Contactless Material Identification with Millimeter Wave Vibrometry},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597378},
doi = {10.1145/3581791.3597378},
abstract = {This paper introduces RFVibe, a system that enables contactless material and object identification through the fusion of millimeter wave wireless signals with acoustic signals. In particular, RFVibe plays an audio sound next to the object that generates micro-vibrations in the object. These micro-vibrations can be captured by shining a millimeter wave radar signal on the object and analyzing the phase of the reflected wireless signal. RFVibe can then extract several features including resonance frequencies and vibration modes, damping time of vibrations, and wireless reflection coefficients. These features are then used to enable more accurate identification, with a step towards generalizing towards different setups and locations. We implement RFVibe using an off-the-shelf millimeter-wave radar and an acoustic speaker. We evaluate it on 23 objects of 7 material types (Metal, Wood, Ceramic, Glass, Plastic, Cardboard, and Foam), obtaining 81.3\% accuracy for material classification, a 30\% improvement over prior work. RFVibe is able to classify with reasonable accuracy in scenarios that it has not encountered before, including different locations, angles, boundary conditions, and objects.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {585},
numpages = {1},
keywords = {wireless vibrometry, object classification, material classification, millimeter-wave sensing},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597284,
author = {Mukhopadhyay, Shalini and Dey, Swarnava and Ghose, Avik},
title = {Demo: On-device Puff Detection System for Smoking Cessation},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597284},
doi = {10.1145/3581791.3597284},
abstract = {Customized, on-device applications that provide timely interventions about smoking episodes are very helpful for smoking cessation. For this, real-time detection of smoking puffs are necessary through unobtrusive wearable devices. This work demonstrates auto-generated tiny puff detection models for on-device inference on low-power wearable devices.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {586–587},
numpages = {2},
keywords = {NAS, edge computing, smoking cessation, wearable sensing},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597285,
author = {Liao, Jingyi and Ruttik, Kalle and J\"{a}ntti, Riku and Phan-Huy, Dinh-Thuy},
title = {Demo: UE Assisted Ambient IoT in LTE Downlink, in real-time and open source},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597285},
doi = {10.1145/3581791.3597285},
abstract = {Ambient power enabled Internet of Things a.k.a. Ambient IoT is a novel concept connecting battery-free energy autonomous devices to the Internet. In this paper, we demonstrate the feasibility of using the channel estimator at the user equipment (UE) as a receiver for backscatter signals in LTE downlink. Our real-time demonstrator system consists of signal generator that mimics the operation of a base station (BS), a backscatter device (BD) modulating the incidence signal, and a software defined radio receiver that plays the role of the user equipment. The UE channel estimator and BD demodulation software is implemented with C++ and Python, respectively and made open source. Our results indicate that UE can demodulate the BD signal with bit error less than 10-3 when the downlink signal-to-noise ratio is larger than 10 dB when the pathloss between the BD and UE is less than 13 dB.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {588–589},
numpages = {2},
keywords = {LTE, IoT, ambient backscatter communication},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597286,
author = {Cao, Jacky and Lam, Kit Yung and Lee, Lik-Hang},
title = {Demo: Real-Time WebXR Edge-based Object Detection for AR},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597286},
doi = {10.1145/3581791.3597286},
abstract = {Web-based extended reality (WebXR) can enable lightweight, easy-to-access, and cross-platform augmented reality (AR) experiences. Context awareness is one key feature of AR. Supporting this in browser-based WebXR applications is challenging as typical object detection algorithms are too computationally demanding to be run in-browser, leading to slow response times and decreased battery life. In this demo, we show a WebXR AR application that uses a technique of WebRTC-based video streaming to obtain a usable video stream on an edge server to perform object detection.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {590–591},
numpages = {2},
keywords = {edge computing, webxr, augmented reality},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597287,
author = {Li, Dong and Zhang, Kaiyan and Cao, Dongping and Shen, Jing and Kang, Run and Mao, Qiankang and Chen, Jiawei},
title = {Demo: Domino: A High-Precision Performance Monitoring and Analysis Platform for Client Applications},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597287},
doi = {10.1145/3581791.3597287},
abstract = {As client applications evolve with new businesses and features, new performance overheads may be introduced. For example, in the application startup scenario, the initialization of newly connected SDKs and the addition of disk access operations on the main thread can increase the startup time, leading to a decline in user experience. Traditional performance testing detects application indicators through automated testing, video frame splitting, or log tracking, but due to fluctuations in the offline environment, test results often fluctuate, and confidence is not high. To optimize performance in a more refined way, it is necessary to not only evaluate performance through indicators but also to pinpoint the cause of the problem accurately. Domino is a client-side performance testing platform based on Trace analysis. In this demonstration, we will provide two versions of AndroidDemo applications, simulate several performance issues, and use the Domino platform to more precisely locate performance problems and provide development repair suggestions.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {592–593},
numpages = {2},
keywords = {accuracy measurement, performance monitoring, client applications},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597289,
author = {Li, Haoran and Zhang, Qi and Kuldeep, Gajraj},
title = {Demo: 3TierView - A Three-tier Privacy-preserving Live Video Surveillance IoT System},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597289},
doi = {10.1145/3581791.3597289},
abstract = {This demo presents a working prototype of a live video surveillance IoT system that provides multi-class privacy preservation. The system can use a Raspberry Pi or a laptop to perform real-time face detection, compression and encryption on live video feeds. We design and implement novel methods to accelerate face detection and reduce miss detection for fast moving subjects. The implemented prototype demonstrates the feasibility to provide multi-class privacy-preserving feature and fine-grained access control of video content for real-time IoT applications.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {594–595},
numpages = {2},
keywords = {live video compression, multi-class privacy-preserving, secure video surveillance},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597290,
author = {Jin, Liuyi and Liu, Tian and Haroon, Amran and Stoleru, Radu and Middleton, Michael and Zhu, Ziwei and Chaspari, Theodora},
title = {Demo: EMSAssist – An End-to-End Mobile Voice Assistant at the Edge for Emergency Medical Services},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597290},
doi = {10.1145/3581791.3597290},
abstract = {We present EMSAssist, the first end-to-end mobile voice assistant for emergency medical services (EMS). EMSAssist allows Emergency Medical Technicians (EMT) to verbally describe patients' signs and symptoms and uses EMTs' voice input to recommend top-5 EMS protocols. Through this demo, we allow the attendees to evaluate EMSAssist through a pair of Google Glass and a mobile phone. Both mobile devices can collect users' voices as input and output top-5 recommended protocols. A companion youtube video of using EMSAssist on the Google Glass is provided: https://www.youtube.com/watch?v=bj7aQJKf4aE},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {596–597},
numpages = {2},
keywords = {edge computing, emergency medical services, voice assistance},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597291,
author = {Lee, Kichang and Yun, Jonghyuk and Han, Jun and Ko, Jeonggil},
title = {Demo: Exploiting Indices for Man-in-the-Middle Attacks on Collaborative Unpooling Autoencoders},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597291},
doi = {10.1145/3581791.3597291},
abstract = {In this demonstration, we introduce the vulnerability of indices in unpooling autoencoders. We show that this small factor can be maliciously exploited by performing man-in-the-middle attacks to eavesdrop on the victim's data, resulting in reconstruction and adversarial attacks. Such attacks especially make systems that integrate collaborative inference operations vulnerable. This demo presentation will empirically show the feasibility of index-based attacks by launching reconstruction and adversarial attacks on embedded/mobile computing platforms.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {598–599},
numpages = {2},
keywords = {security, collaborative inference, unpooling autoencoders},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597292,
author = {Mages, Tobias and Yan, Wenqing and Varshney, Ambuj and Rohner, Christian},
title = {Demo: An Educational Platform to Learn Radio Frequency Wireless Communication},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597292},
doi = {10.1145/3581791.3597292},
abstract = {Obtaining hands-on experience with wireless communication can be challenging due to the limited configurability of most commercial off-the-shelf transceivers. We present a low-cost and open-source educational platform designed to help students experiment and investigate wireless concepts through real-world testing. Our platform provides students with the ability to control the physical-layer configuration, design and implement their backscatter system, and conduct link quality experiments to investigate the resulting system performance. This platform offers students a unique opportunity to gain practical experience and deepen their understanding of wireless communication, while also providing a valuable tool for researchers and educators in the field.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {600–601},
numpages = {2},
keywords = {backscatter, education, communication, wireless},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597293,
author = {Lauwaerts, Tom and Rojas Castillo, Carlos and Gonzalez Boix, Elisa and Scholliers, Christophe},
title = {Demo: Debugging Constraint Devices with EDWARD},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597293},
doi = {10.1145/3581791.3597293},
abstract = {Debugging embedded systems is difficult due to the restricted resources available, and the hard to reproduce bugs. Moreover, few debugging facilities are available for constrained devices. To address this, we build upon a recent technique for big data applications, called out-of-place debugging.An out-of-place debugger captures a remote process and debugs it locally. However, embedded devices include external resources that are not available locally. We therefore developed a novel hybrid out-of-place debugger, which allows a process running on an embedded device to be partially captured, but still receive data and events produced by the hardware. This has the advantage that we can use all the resources of the local machine to implement advanced debugging features, such as back-in-time debugging.Our demo shows how the EDWARD prototype in VS Code can debug a common hardware issue, and a concurrency bug on an ESP32. We also show how these issues are hard to find with logging or classic remote debuggers.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {602–603},
numpages = {2},
keywords = {webassembly, IoT, debugger, out-of-place debugging},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597294,
author = {Li, Jie and Li, Zhixin and Li, Qiyue and Sun, Wei and Li, Weitao and Wang, Huiyu and Liu, Zhi},
title = {Demo: Landscape: Saliency and Trajectory based Viewport Prediction in Point Cloud Video Streaming},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597294},
doi = {10.1145/3581791.3597294},
abstract = {Efficient point cloud video streaming requires accurate viewport prediction, and research on this topic is still in its infancy. This paper demonstrates a high-precision scheme for viewport prediction in the point cloud video, named Landscape, exploring both video saliency information and viewport trajectory. Specifically, we first propose a novel point cloud video sampling method, which reduces computational load while preserving video features. Furthermore, we introduce a new saliency detection technique that integrates temporal and spatial information to detect dynamic, static geometric, and color salient regions. Finally, we intelligently fuse saliency and trajectory information to achieve more accurate viewport prediction. We verify the performance of our proposed viewport prediction methods over state-of-the-art wireless networks.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {604–605},
numpages = {2},
keywords = {trajectory prediction, saliency detection, FoV, viewport prediction, volumetric video, point cloud video},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597295,
author = {Li, Jie and Wang, Huiyu and Li, Qiyue and Liu, Xin and Li, Zhixin and Liu, Zhi},
title = {Demo: Horizon: a Real-time Point Cloud Video Streaming System over Wireless Networks},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597295},
doi = {10.1145/3581791.3597295},
abstract = {As a popular way of representing holographic video or volumetric video, point cloud video can provide users with a highly immersive viewing experience of 6 degrees of freedom (6DoF) and is expected to become the mainstream video format of the future. However, the real-time transmission of point cloud video faces many challenges due to the huge amount of data and the large search space of the optimization problem with constraints. To this end, we propose Horizon, a novel Dynamic Adaptive Streaming over HTTP (DASH) based real-time point cloud video streaming system, which aims to maximize the user's viewing experience by predicting the next several steps through a rolling framework and uses a Deep Reinforcement Learning (DRL) based algorithm to achieve a real-time solution to the rolling optimization problem. We have prototyped this system and demonstrated its performance on a state-of-the-art wireless network.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {606–607},
numpages = {2},
keywords = {reinforcement learning, rolling optimization, DASH, video streaming, point cloud},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597296,
author = {Ding, Yuchen and Zhou, Pengyuan},
title = {Demo: Near Real-time ChatGPT-AR},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597296},
doi = {10.1145/3581791.3597296},
abstract = {Augmented reality (AR) applications based on conventional approaches lack the adaptability to cater to different scene requirements and address users' personalized demands effectively. This demon presents ChatGPT-AR, a ChatGPT-powered near real-time voice-to-AR mobile application system, that can create different 3D-augmented spaces using voice commands. Further, ChatGPT-AR enables near real-time contextual editions in AR fashion.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {608–609},
numpages = {2},
keywords = {human-computer interaction, augmented reality},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597297,
author = {Gong, Jiahui and Yu, Qiaohong and Li, Tong and Liu, Haoqiang and Zhang, Jun and Fan, Hangyu and Jin, Depeng and Li, Yong},
title = {Demo: Scalable Digital Twin System for Mobile Networks with Generative AI},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597297},
doi = {10.1145/3581791.3597297},
abstract = {Digital Twin brings a new realization approach to the modeling of mobile networks. Mobile networks, as complex systems comprising multiple components, such as mobile users, base stations, and wireless environments, have intricate interactions and relationships with each other. By creating a virtual replica of each physical mobile network entity in a virtual space, we build a scalable digital twin system for mobile networks with generative AI. The system can interact with multiple optimizers to evaluate and display real-time simulation results. A companion video can be accessed using the link below. https://youtu.be/xtcBIXPzvkc},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {610–611},
numpages = {2},
keywords = {simulation, generative AI, mobile networks, digital twins},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597505,
author = {Ouyang, Xiaomin},
title = {Design and Deployment of Multi-Modal Federated Learning Systems for Alzheimer's Disease Monitoring},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597505},
doi = {10.1145/3581791.3597505},
abstract = {Alzheimer's Disease (AD) and related dementia are a growing global health challenge due to the aging population. The prominence of mobile devices and recent breakthroughs in machine learning have enabled an emerging class of new AI-powered health systems for applications like Alzheimer's Disease monitoring. In this paper, we present the first end-to-end system that integrates multi-modal sensors and federated learning algorithms for detecting multidimensional AD digital biomarkers in natural living environments. We recognize several major challenges in designing such a real-world federated learning system, including limited data labels, data heterogeneity, and limited computing resources. We built a compact multi-modality hardware system and deployed it in a four-week clinical trial involving 61 elderly participants. The results indicate that our system can accurately detect a comprehensive set of digital biomarkers with up to 95\% accuracy and identify AD with an average of 87.5\% accuracy.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {612–614},
numpages = {3},
keywords = {semi-supervised learning, federated learning systems, alzheimer's disease monitoring, multi-modal sensing systems},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597506,
author = {Blanco, Alejandro},
title = {Towards Precise, Ubiquitous and Real-Time Positioning},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597506},
doi = {10.1145/3581791.3597506},
abstract = {Positioning is an enabler for many location-based services in the vertical industrial domain such as autonomous driving and robot-to-cobot interaction, to name a few. Industry and academia are actively enabling localization through 5G and WiFi as they are universally deployed. However, the current WiFi and 5G protocols cannot deal with the hard requirements of accuracy, latency, and robustness. To deal with that, we have proposed a series of works to enable precise, pervasive, and real-time positioning.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {615–617},
numpages = {3},
keywords = {wireless networks, ToF, AoA, CSI, indoor localization},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597507,
author = {Oostvogels, Jonathan},
title = {Towards Latency-First Wireless Embedded Networks},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597507},
doi = {10.1145/3581791.3597507},
abstract = {Current physical-layer networking technology primarily optimises for reliability rather than latency, thus unnecessarily impairing latency-sensitive applications such as real-time control in embedded, wireless, and dense networks. This extended abstract introduces a set of novel low-level networking primitives that optimise such networks for latency, pushing latency-inducing failures up the stack. The development of and experiments on a 25-node prototype network show that the resulting symbol-synchronous architecture unlocks application scenarios formerly reserved for wired networks, offering sub-millisecond network latency across multiple hops for real-time control, in-the-loop classification based on distributed data from 10s of nodes in milliseconds, and a 25--75\% traffic reduction when data is subject to large measurement noise.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {618–620},
numpages = {3},
keywords = {network stack, synchronous transmission, internet of things, cyber-physical system, wireless sensor network, bus network},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597508,
author = {Xie, Zhiyuan},
title = {Enhancing Time-of-Flight Sensing in Mobile Systems},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597508},
doi = {10.1145/3581791.3597508},
abstract = {Time-of-flight (ToF) cameras have been increasingly adopted in mobile systems. Although an enormous amount of work focuses on the applications and augmentation of ToF cameras, the ToF cameras only provide depth measurements in mobile sensing systems. In this paper, we introduce two systems (i.e., UltraDepth and Mozart) to expose high-resolution textures from ToF cameras to enhance their performance in mobile systems. The results clearly show that the two systems can effectively reveal texture information of the scene, which can significantly improve the performance of ToF sensing and enable next-generation ToF applications.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {621–623},
numpages = {3},
keywords = {sensing in the dark, advanced sensing system, texture exposure, ToF depth camera},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597509,
author = {Zheng, Tianyue},
title = {Algorithmic Sensing: A Joint Sensing and Learning Perspective},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597509},
doi = {10.1145/3581791.3597509},
abstract = {Sensing hardware technologies and algorithms to interpret sensing data are two main pillars of high-level perception. Existing works either handle these two pillars independently, hence resulting in a loss of efficiency, or plainly adopt deep learning as a one-size-fits-all solution, attempting to directly fit sensor data to desired outputs (e.g., decisions or predictions). Consequently, there are urgent needs for improving sensing efficiency while improving its practicality and robustness in the face of diversified application scenarios that may severely interfere with the sensing data. To this end, we propose algorithmic sensing to integrate these two pillars, and to avoid blindly applying deep-learning algorithms to sensing. In particular, our joint sensing and learning scheme involves designing adaptable sensing platforms for various learning algorithms, as well as adapting algorithms to fit existing sensing infrastructure. We illustrate the two sides of algorithmic sensing by using past work as examples, thus providing a comprehensive framework for designing future algorithmic sensing systems and suggesting open research directions.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {624–626},
numpages = {3},
keywords = {edge computing, federated learning, domain adaptation, deep learning, algorithmic sensing},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597510,
author = {Fomichev, Mikhail},
title = {A Path to Holistic Privacy in Stream Processing Systems},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597510},
doi = {10.1145/3581791.3597510},
abstract = {The massive streams of Internet of Things (IoT) data require a timely analysis to retain data usefulness. Stream processing systems (SPSs) enable this task, deriving knowledge from the IoT data in real-time. Such real-time analytics benefits many applications but can also be used to violate user privacy, as the IoT data collected from users or their vicinity is inherently sensitive. In this paper, we present our systematic look into privacy issues arising from the intersection of SPSs and IoT, identifying key research challenges towards achieving holistic privacy protection in SPSs and proposing the solutions.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {627–628},
numpages = {2},
keywords = {IoT, access control, threat modeling, privacy, stream processing},
location = {Helsinki, Finland},
series = {MobiSys '23}
}
@inproceedings{10.1145/3581791.3597511,
author = {Jia, Hong},
title = {Ubiquitous, Secure, and Efficient Mobile Sensing Systems},
year = {2023},
isbn = {9798400701108},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3581791.3597511},
doi = {10.1145/3581791.3597511},
abstract = {The rapid development of mobile sensors and machine learning techniques has enabled the utilization of diverse sensor data in many applications. However, the design and implementation of these algorithms and systems to achieve ubiquitous, secure, and efficient real-world solutions remains challenging. This paper discusses various effective solutions to overcome these challenges and underscores potential future directions.},
booktitle = {Proceedings of the 21st Annual International Conference on Mobile Systems, Applications and Services},
pages = {629–630},
numpages = {2},
keywords = {efficiency, generalization, security, mobile sensing},
location = {Helsinki, Finland},
series = {MobiSys '23}
}