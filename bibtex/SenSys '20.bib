@inproceedings{10.1145/3384419.3430772,
author = {Wang, Ziqi and Chen, Zhe and Singh, Akash Deep and Garcia, Luis and Luo, Jun and Srivastava, Mani B.},
title = {UWHear: through-wall extraction and separation of audio vibrations using wireless signals},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430772},
doi = {10.1145/3384419.3430772},
abstract = {An ability to detect, classify, and locate complex acoustic events can be a powerful tool to help smart systems build context-awareness, e.g., to make rich inferences about human behaviors in physical spaces. Conventional methods to measure acoustic signals employ microphones as sensors. As signals from multiple acoustic sources are blended during propagation to a sensor, such methods impose a dual challenge of separating the signal for an acoustic event from background noise and from other acoustic events of interest. Recent research has proposed using radio-frequency (RF) signals, e.g., Wi-Fi and millimeter-wave (mmWave), to sense sound directly from source vibrations. Whereas these works allow separating an acoustic event from background noise, they cannot monitor multiple sound sources simultaneously. In this paper, we present UWHear, a system that simultaneously recovers and separates sounds from multiple sources. Unlike previous works using continuous-wave RF, UWHear employs Impulse Radio Ultra-Wideband (IR-UWB) technology, in order to construct an enhanced audio sensing system tackling the above challenges. Further, IR-UWB radios can penetrate light building materials, which enables UWHear to operate in some non-line-of-sight (NLOS) conditions. In addition to providing a theoretical guarantee for audio recovery using RF pulses, we also implement an audio sensing prototype exploiting a commercial-off-the-shelf IR-UWB radar. Our experiments show that UWHear can effectively separate the content of two speakers that are placed only 25cm apart. UWHear can also capture and separate multiple sounds and vibrations of household appliances while being immune to non-target noise coming from other directions.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {1–14},
numpages = {14},
keywords = {wireless vibrometry, audio sensing, RF sensing, IR-UWB radar},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430771,
author = {Xie, Binbin and Xiong, Jie and Chen, Xiaojiang and Fang, Dingyi},
title = {Exploring commodity RFID for contactless sub-millimeter vibration sensing},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430771},
doi = {10.1145/3384419.3430771},
abstract = {Monitoring the vibration characteristics of a machine or structure provides valuable information of its health condition and this information can be used to detect problems in their incipient stage. Recently, researchers employ RFID signals for vibration sensing. However, they mainly focus on vibration frequency estimation and still face difficulties in accurately sensing the other important characteristic of vibration which is vibration amplitude in the scale of sub-millimeter. In this paper, we introduce TagSMM, a contactless RFID-based vibration sensing system which can measure vibration amplitude in sub-millimeter resolution. TagSMM employs the signal propagation theory to deeply understand how the signal phase varies with vibration and proposes a coupling-based method to amplify the vibration-induced phase change to achieve sub-millimeter level amplitude sensing for the first time. We design and implement TagSMM with commodity RFID hardware. Our experiments show that TagSMM can detect a 0.5 mm vibration, 10 times better than the state-of-the-arts. Our field studies show TagSMM can sense a drone's abnormal vibration and can also effectively detect a small 0.2 cm screw loose in a motor at a 100\% accuracy.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {15–27},
numpages = {13},
keywords = {sub-millimeter vibration, passive tag, coupling effect, contactless sensing, RFID},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430714,
author = {Cai, Chao and Chen, Zhe and Pu, Henglin and Ye, Liyuan and Hu, Menglan and Luo, Jun},
title = {AcuTe: acoustic thermometer empowered by a single smartphone},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430714},
doi = {10.1145/3384419.3430714},
abstract = {Though measuring ambient temperature is often deemed as an easy job, collecting large-scale temperature readings in real-time is still a formidable task. The recent boom of network-ready (mobile) devices and the subsequent mobile crowdsourcing applications do offer an opportunity to accomplish this task, yet equipping commodity devices with ambient temperature sensing capability is highly non-trivial and hence has never been achieved. In this paper, we propose Acoustic Thermometer (AcuTe) as the first ambient temperature sensor empowered by a single commodity smartphone. AcuTe utilizes on-board dual microphones to estimate air-borne sound propagation speed, thereby deriving ambient temperature. To accurately estimate sound propagation speed, we leverage the phase of chirp signals to circumvent the low sample rate on commodity hardware. In addition, we propose to use both structure-borne and air-borne propagations to address the multipath problem. Furthermore, to prevent disruptive audible transmissions, we convert chirp signals into white noises and propose a pipeline of signal processing algorithms to denoise received samples. As a mobile, economical, highly accurate sensor, AcuTe may potentially enable many relevant applications, in particular large-scale indoor/outdoor temperature monitoring in real-time. We conduct extensive experiments on AcuTe; the results demonstrate a robust performance, a median accuracy of 0.3° C even at a varying humidity level, and the ability to conduct distributed temperature sensing in real-time.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {28–41},
numpages = {14},
keywords = {phase, multipath problem, mobile computing, acoustic sensing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430729,
author = {Pradhan, Swadhin and Qiu, Lili},
title = {RTSense: passive RFID based temperature sensing},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430729},
doi = {10.1145/3384419.3430729},
abstract = {Passive radio-frequency identification (RFID) tags are attractive because they are low cost, battery-free, and easy to deploy. This technology is traditionally being used to identify tags attached to the objects. In this paper, we explore the feasibility of turning passive RFID tags into battery-free temperature sensors. The impedance of the RFID tag changes with the temperature and this change will be manifested in the reflected signal from the tag. This opens up an opportunity to realize battery-free temperature sensing using a passive RFID tag with already deployed Commercial Off-the-Shelf (COTS) RFID reader-antenna infrastructure in supply chain management or inventory tracking. However, it is challenging to achieve high accuracy and robustness against the changes in the environment. To address these challenges, we first develop a detailed analytical model to capture the impact of temperature change on the tag impedance and the resulting phase of the reflected signal. We then build a system that uses a pair of tags, which respond differently to the temperature change to cancel out other environmental impacts. Using extensive evaluation, we show our model is accurate and our system can estimate the temperature within a 2.9 degree centigrade median error and support a normal read range of 3.5 m in an environment-independent manner.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {42–55},
numpages = {14},
keywords = {temperature sensing, smart spaces, passive rfid, impedance},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430717,
author = {Ghasempour, Yasaman and Yeh, Chia-Yi and Shrestha, Rabi and Amarasinghe, Yasith and Mittleman, Daniel and Knightly, Edward W.},
title = {LeakyTrack: non-coherent single-antenna nodal and environmental mobility tracking with a leaky-wave antenna},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430717},
doi = {10.1145/3384419.3430717},
abstract = {Radio frequency signals have the potential to convey rich information about a node's motion and surroundings. Unfortunately, extracting such information is challenging, previously requiring accurate phase measurement, large antenna array structures, or extensive training. In this paper, we present LeakyTrack, a novel system that enables non-coherent and training-free motion sensing with a single antenna. The key idea is to create unique spectrally coded signals at different spatial directions so that geometric properties of the receiving node, as well as any potential objects in the environment, leave spectral footprints on the collected signal. To do so, we exploit a THz leaky-wave antenna and realize a color-coded scan in which signals with distinct spectral characteristics simultaneously emit across the angular domain. LeakyTrack infers nodal and environmental motion by analyzing the received spectral profile. We evaluate the performance of LeakyTrack via extensive over-the-air experiments.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {56–68},
numpages = {13},
keywords = {wireless sensing, terahertz waves, leaky-wave antenna},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430731,
author = {Xie, Binbin and Xiong, Jie},
title = {Combating interference for long range LoRa sensing},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430731},
doi = {10.1145/3384419.3430731},
abstract = {Wireless sensing has become a hot research topic recently, enabling a large range of applications. However, due to the intrinsic nature of employing weak target-reflection signal for sensing, the sensing range is limited. Another issue is the strong interference from surroundings and therefore a lot of wireless sensing systems assume there is no interferer in the environment. One recent work explored the possibility of employing LoRa signal for long range sensing which is a favorable step in addressing the first issue. However, the interference issue becomes even more severe with LoRa due to its larger sensing range. In this paper, we propose Sen-fence - a LoRa-based sensing system - to significantly increase the sensing range and at the same time mitigate the interference. With careful signal processing, Sen-fence is able to maximize the movement-induced signal variation in software to increase the sensing range. To address the interference issue, we propose the concept of "virtual fence" to constrain sensing only within the area of interest. The location and size of virtual fence can be flexibly controlled in software to meet the requirements of different applications. Sen-fence is able to (i) achieve a 50 m sensing range for fine-grained human respiration, which is twice the state-of-the-art; and (ii) efficiently mitigate the interference to make LoRa sensing work in practice.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {69–81},
numpages = {13},
keywords = {virtual fence, long sensing range, interference, LoRa sensing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430724,
author = {Wang, Weiguo and Li, Jinming and He, Yuan and Liu, Yunhao},
title = {Symphony: localizing multiple acoustic sources with a single microphone array},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430724},
doi = {10.1145/3384419.3430724},
abstract = {Sound recognition is an important and popular function of smart devices. The location of sound is basic information associated with the acoustic source. Apart from sound recognition, whether the acoustic sources can be localized largely affects the capability and quality of the smart device's interactive functions. In this work, we study the problem of concurrently localizing multiple acoustic sources with a smart device (e.g., a smart speaker like Amazon Alexa). The existing approaches either can only localize a single source, or require deploying a distributed network of microphone arrays to function. Our proposal called Symphony is the first approach to tackle the above problem with a single microphone array. The insight behind Symphony is that the geometric layout of microphones on the array determines the unique relationship among signals from the same source along the same arriving path, while the source's location determines the DoAs (direction-of-arrival) of signals along different arriving paths. Symphony therefore includes a geometry-based filtering module to distinguish signals from different sources along different paths and a coherence-based module to identify signals from the same source. We implement Symphony with different types of commercial off-the-shelf microphone arrays and evaluate its performance under different settings. The results show that Symphony has a median localization error of 0.694m, which is 68\% less than that of the state-of-the-art approach.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {82–94},
numpages = {13},
keywords = {voice assistant, multi-source localization, microphone array},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430730,
author = {Cao, Gaoshuai and Yuan, Kuang and Xiong, Jie and Yang, Panlong and Yan, Yubo and Zhou, Hao and Li, Xiang-Yang},
title = {EarphoneTrack: involving earphones into the ecosystem of acoustic motion tracking},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430730},
doi = {10.1145/3384419.3430730},
abstract = {Acoustic motion tracking is an exciting new research area with promising progress in the last few years. Due to the inherent low propagation speed in the air, acoustic signals have the unique advantage of fine sensing granularity compared to RF signals. Speakers and microphones nowadays are pervasively available in devices surrounding us, such as smartphones and voice-controlled smart speakers. Though promising, one fundamental issue hindering the adoption of acoustic-based motion tracking is that the positions of microphones and speakers inside a device are fixed, which greatly limits the flexibility of acoustic motion tracking. In this work, we propose a new modality of acoustic motion tracking using earphones. Earphone-based tracking mitigates the constraints associated with traditional smartphone-based tracking. With novel designs and comprehensive experiments, we show earphone-based motion tracking can achieve a great flexibility and a high accuracy at the same time. We believe this is an important step towards "earable" sensing.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {95–108},
numpages = {14},
keywords = {motion tracking, earphone-based acoustic sensing, earable sensing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430776,
author = {Lu, Chris Xiaoxuan and Saputra, Muhamad Risqi U. and Zhao, Peijun and Almalioglu, Yasin and de Gusmao, Pedro P. B. and Chen, Changhao and Sun, Ke and Trigoni, Niki and Markham, Andrew},
title = {milliEgo: single-chip mmWave radar aided egomotion estimation via deep sensor fusion},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430776},
doi = {10.1145/3384419.3430776},
abstract = {Robust and accurate trajectory estimation of mobile agents such as people and robots is a key requirement for providing spatial awareness for emerging capabilities such as augmented reality or autonomous interaction. Although currently dominated by optical techniques e.g., visual-inertial odometry these suffer from challenges with scene illumination or featureless surfaces. As an alternative, we propose milliEgo, a novel deep-learning approach to robust egomotion estimation which exploits the capabilities of low-cost mm Wave radar. Although mmWave radar has a fundamental advantage over monocular cameras of being metric i.e., providing absolute scale or depth, current single chip solutions have limited and sparse imaging resolution, making existing point-cloud registration techniques brittle. We propose a new architecture that is optimized for solving this challenging pose transformation problem. Secondly, to robustly fuse mmWave pose estimates with additional sensors, e.g. inertial or visual sensors we introduce a mixed attention approach to deep fusion. Through extensive experiments, we demonstrate our proposed system is able to achieve 1.3\% 3D error drift and generalizes well to unseen environments. We also show that the neural architecture can be made highly efficient and suitable for real-time embedded applications.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {109–122},
numpages = {14},
keywords = {millimeter wave radar, indoor localization, egomotion estimation},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430777,
author = {Xie, Pengjin and Li, Lingkun and Wang, Jiliang and Liu, Yunhao},
title = {LiTag: localization and posture estimation with passive visible light tags},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430777},
doi = {10.1145/3384419.3430777},
abstract = {The development of Internet of Things calls for ubiquitous and low-cost localization and posture estimation. We present LiTag, a visible light based localization and posture estimation solution with COTS cameras. The core of LiTag is based on the design of a chip-less and battery-less optical tag which can show different color patterns from different observation directions. After capturing a photo containing the tag, LiTag can calculate the tag position and posture by combining the color pattern and the geometry relation between the camera image plane and the real world. Unlike existing marker-based visible localization and posture estimation approaches, LiTag can work with a single camera without calibration, which significantly reduces the calibration overhead and deployment costs. We implement LiTag and evaluate its performance extensively. Results show that LiTag can provide the tag position with a median error of 1.6 cm in the 2D plane, a median error of 12 cm in the 3D space, and posture estimation with a median error of 1°. We believe that LiTag has a high potential to provide a low-cost and easy-to-use solution for ubiquitous localization and posture estimation with existing widely deployed cameras.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {123–135},
numpages = {13},
keywords = {visible light tag, visible light positioning, indoor localization},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430726,
author = {Zhang, Jinrui and Zhang, Deyu and Xu, Xiaohui and Jia, Fucheng and Liu, Yunxin and Liu, Xuanzhe and Ren, Ju and Zhang, Yaoxue},
title = {MobiPose: real-time multi-person pose estimation on mobile devices},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430726},
doi = {10.1145/3384419.3430726},
abstract = {Human pose estimation is a key technique for many vision-based mobile applications. Yet existing multi-person pose-estimation methods fail to achieve a satisfactory user experience on commodity mobile devices such as smartphones, due to their long model-inference latency. In this paper, we propose MobiPose, a system designed to enable real-time multi-person pose estimation on mobile devices through three novel techniques. First, MobiPose takes a motion-vector-based approach to fast locate the human proposals across consecutive frames by fine-grained tracking of joints of human body, rather than running the expensive human-detection model for every frame. Second, MobiPose designs a mobile-friendly model that uses lightweight multi-stage feature extractions to significantly reduce the latency of pose estimation without compromising the model accuracy. Third, MobiPose leverages the heterogeneous computing resources of both CPU and GPU to execute the pose estimation model for multiple persons in parallel, which further reduces the total latency. We have implemented the MobiPose system on off-the-shelf commercial smartphones and conducted comprehensive experiments to evaluate the effectiveness of the proposed techniques. Evaluation results show that MobiPose achieves over 20 frames per second pose estimation with 3 persons per frame, and significantly outperforms the state-of-the-art baseline, with a speedup of up to 4.5X and 2.8X in latency on CPU and GPU, respectively, and an improvement of 5.1\% in pose-estimation model accuracy. Furthermore, MobiPose achieves up to 62.5\% and 37.9\% energy-per-frame saving on average in comparison with the baseline on mobile CPU and GPU, respectively.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {136–149},
numpages = {14},
keywords = {real time, pose estimation, motion vector, mobile devices, heterogeneous computing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430780,
author = {Li, Dong and Liu, Jialin and Lee, Sunghoon Ivan and Xiong, Jie},
title = {FM-track: pushing the limits of contactless multi-target tracking using acoustic signals},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430780},
doi = {10.1145/3384419.3430780},
abstract = {Contactless acoustic motion tracking enables new opportunities to interact with smart devices, such as smartphones and voice-controlled smart assistants. The speakers and microphones integrated in these devices provide unique opportunities to simultaneously track multiple targets in a fine-grained manner. To this end, we propose a system, namely FM-Track, that enables contactless multi-target tracking using acoustic signals. We first introduce a signal model to characterize the location and motion status of targets by fusing the information from multiple dimensions (i.e., range, velocity, and angle of targets). Then we develop a series of techniques to separate signals reflected from multiple targets and accurately track each individual target. We implement and evaluate FM-Track on both research-purpose hardware platform (i.e., Bela) and commercial devices (i.e., smartphones and smart speakers). Extensive experiments show that FM-Track can successfully differentiate two targets with a spacing as small as 1 cm, and achieve a median tracking accuracy of 0.86 cm and 0.11 cm for absolute range and displacement estimates respectively. For multi-target tracking, FM-Track can accurately track four targets and the tracking range can be up to 3 m.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {150–163},
numpages = {14},
keywords = {multi-target tracking, multi-dimensional estimation, contactless tracking, acoustic motion tracking},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430897,
author = {Oostvogels, Jonathan and Yang, Fan and Michiels, Sam and Hughes, Danny},
title = {Zero-wire: a deterministic and low-latency wireless bus through symbol-synchronous transmission of optical signals},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430897},
doi = {10.1145/3384419.3430897},
abstract = {The performance dichotomy between wired and wireless networks for the Internet of Things primarily arises from the inherent complexity and inefficiency of networking abstractions such as routing, medium access control and store-and-forward packet switching. This paper aims to enable a new class of latency-sensitive applications by breaking all three of these abstractions to deliver a performance envelope that resembles that of a wired bus in terms of deterministic latency and throughput. The essence of this approach is a novel networking paradigm for optical wireless communication, referred to as a symbol-synchronous bus, wherein a mesh of nodes concurrently transmit LED-based signals. This paper realises the paradigm within a platform called Zero-Wire and evaluates it on a 25-node testbed under laboratory conditions. Key end-to-end performance measurements on this physical prototype include 19 kbps of contention-agnostic goodput, interface-level latency under 1 ms for two-byte frames across four hops, jitter on the order of 10s of μs, and a base reliability of 99\%. These first results indicate a bright future for the under-explored area of optical wireless mesh networks in delivering ubiquitous connectivity through a simple and low-cost physical layer.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {164–178},
numpages = {15},
keywords = {wireless sensor networks, visible light communication, synchronous transmission, optical wireless communication, internet of things, cyber-physical systems, cut-through forwarding, concurrent transmission, bus networks},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430715,
author = {Trobinger, Matteo and Vecchia, Davide and Lobba, Diego and Istomin, Timofei and Picco, Gian Pietro},
title = {One flood to route them all: ultra-fast convergecast of concurrent flows over UWB},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430715},
doi = {10.1145/3384419.3430715},
abstract = {Concurrent transmissions (CTX) enable low latency, high reliability, and energy efficiency. Nevertheless, existing protocols typically exploit CTX via the Glossy system, whose fixed-length network-wide floods are entirely dedicated to disseminating a single packet.In contrast, the system we present here, Weaver, enables concurrent dissemination towards a receiver of different packets from multiple senders in a single, self-terminating, network-wide flood.The protocol is generally applicable to any radio supporting CTX; the prototype targets ultra-wideband (UWB), for which a reference network stack is largely missing. Our modular design separates the low-level mechanics of CTX from their higher-level orchestration in Weaver. Other researchers can easily experiment with alternate designs via our open-source implementation, which includes a reusable component estimating UWB energy consumption.Our analytical model and testbed experiments confirm that Weaver disseminates concurrent flows significantly faster and more efficiently than state-of-the-art Glossy-based protocols while achieving higher reliability and resilience to topology changes.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {179–191},
numpages = {13},
keywords = {ultra-wideband, low-power wireless, concurrent transmissions},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430719,
author = {Guo, Xiuzhen and Shangguan, Longfei and He, Yuan and Zhang, Jia and Jiang, Haotian and Siddiqi, Awais Ahmad and Liu, Yunhao},
title = {Aloba: rethinking ON-OFF keying modulation for ambient LoRa backscatter},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430719},
doi = {10.1145/3384419.3430719},
abstract = {Backscatter communication holds potential for ubiquitous and low-cost connectivity among low-power IoT devices. To avoid interference between the carrier signal and the backscatter signal, recent works propose a frequency-shifting technique to separate these two signals in the frequency domain. Such proposals, however, have to occupy the precious wireless spectrum that is already overcrowded, and increase the power, cost, and complexity of the backscatter tag. In this paper, we revisit the classic ON-OFF Keying (OOK) modulation and propose Aloba, a backscatter system that takes the ambient LoRa transmissions as the excitation and piggybacks the in-band OOK modulated signals over the LoRa transmissions. Our design enables the backsactter signal to work in the same frequency band of the carrier signal, meanwhile achieving good tradeoff between transmission range and link throughput. The key contributions of Aloba include: i) the design of a low-power backscatter tag that can pick up the ambient LoRa signals from other signals; ii) a novel decoding algorithm to demodulate both the carrier signal and the backscatter signal from their superposition. The design of Aloba completely unleashes the backscatter tag's ability in OOK modulation and achieves flexible data rate at different transmission range. We implement Aloba and conduct head-to-head comparison with the state-of-the-art LoRa backscatter system PLoRa in various settings. The experiment results show Aloba can achieve 39.5--199.4 Kbps data rate at various distances, 10.4--52.4X higher than PLoRa.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {192–204},
numpages = {13},
keywords = {on-off keying modulation, ambient lora backscatter},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430773,
author = {Bai, Yang and Liu, Jian and Lu, Li and Yang, Yilin and Chen, Yingying and Yu, Jiadi},
title = {BatComm: enabling inaudible acoustic communication with high-throughput for mobile devices},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430773},
doi = {10.1145/3384419.3430773},
abstract = {Acoustic communication is an increasingly popular alternative to existing short-range wireless communication technologies for mobile devices, such as NFC and QR codes. Unlike the current standards, there are no requirements for extra hardware, lighting conditions, or Internet connection. However, the audibility and limited throughput of existing studies hinder their deployment on a wide range of applications. In this paper, we aim to redesign acoustic communication mechanism to push the boundary of potential throughput while keeping the inaudibility. Specifically, we propose BatComm, a high-throughput and inaudible acoustic communication system for mobile devices capable of throughput rates 12X higher than contemporary state-of-the-art acoustic communication for mobile devices. We theoretically model the non-linearity of microphone and use orthogonal frequency division multiplexing (OFDM) to transmit data bits over multiple orthogonal channels with an ultrasound frequency carrier. We also design a series of techniques to mitigate interference caused by sources such as the signal's unbalanced frequency response, ambient noise, and unrelated residual signals created through OFDM, amplitude modulation (AM), and related processes. Extensive evaluations under multiple realistic settings demonstrate that our inaudible acoustic communication system can achieve over 47kbps within a 10cm communication range. We also show the possibility of increasing the communication range to room scale (i.e., around 2m) while maintaining high-throughput and inaudibility. Our findings offer a new direction for future inaudible acoustic communication techniques to pursue in emerging mobile and IoT applications.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {205–217},
numpages = {13},
keywords = {non-linearity, inaudible, high-throughput, acoustic communication},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430723,
author = {Wang, Shuai and Jeong, Woojae and Jung, Jinhwan and Kim, Song Min},
title = {X-MIMO: cross-technology multi-user MIMO},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430723},
doi = {10.1145/3384419.3430723},
abstract = {Multi-user MIMO (MU-MIMO) is a widely-known, fundamental technique to significantly improve the spectrum efficiency. While there is a great demand for spectrum efficiency and massive scalability under explosively increasing IoT, hardware limitations make it particularly challenging for the mechanism to be transferred to the IoT (e.g., ZigBee) domain. This paper presents X-MIMO, a zero-cost, software-only cross-technology MU-MIMO for commodity ZigBee. As the first work to shed the light on the feasibility of MU-MIMO on commodity IoT, X-MIMO leverages on cross-technology communication (CTC) to turn the pervasively-deployed WiFi AP into MU-MIMO transmitter, delivering different packets to multiple ZigBees in parallel. X-MIMO uniquely exploits WiFi CSI to extract the accurate physical layer signal of the ZigBee packet and the WiFi-ZigBee channel coefficient. Rigorous derivation shows that X-MIMO's precoding is inherently immune to the uncertainties of the commodity devices, making X-MIMO highly reliable in practice. Lastly, spectrum-efficient emulation is proposed to maximize the spectrum reuse. We implement and comprehensively evaluate the performance of X-MIMO on commodity devices (Atheros AR9334 WiFi NIC and TelosB CC2420) as well as on USRP B210 for in-depth analysis. Results reveal that X-MIMO achieves 495 Kbps with <1\% symbol error rate (SER) and 704.24 Kbps with 6.1\% SER for two and three streams, respectively. Near-linear increase of the throughput effectively demonstrates the feasibility of X-MIMO.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {218–231},
numpages = {14},
keywords = {wireless communication, cross-tech. communication, MU-MIMO},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430728,
author = {Cui, Minhao and Wang, Qing and Xiong, Jie},
title = {Breaking the limitations of visible light communication through its side channel},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430728},
doi = {10.1145/3384419.3430728},
abstract = {Visible Light Communication (VLC) is a promising technology for future wireless communications. By modulating the visible light---that has about 10,000x larger frequency band than that of radios---to transmit data, VLC has the potential to provide ultra-high-speed wireless connectivities. However, it also has limitations such as i) surrounding objects can easily block VLC links, and ii) intense ambient light can saturate the photodiodes of VLC receivers.In this work, from a different angle compared with state-of-the-art solutions, we utilize the side channel of VLC---a Radio Frequency (RF) channel created unintentionally during the transmission process of VLC---to break the above-mentioned VLC limitations. The key enabler is that the side RF channel also contains the data information transmitted in the VLC link. When the VLC link is blocked or saturated, we can utilize the side channel, capable of penetrating through blockages and not affected by ambient light, to assist VLC transmissions. Thus a user service relying on VLC transmissions will not be interrupted. Besides the simple Single-Input Single-Output (SISO) case, we consider challenging scenarios where multiple VLC chains are synchronized to form Multiple-Input Multiple/Single-Output (MIMO/MISO) transmission strategies. To make our system practical, we address several challenges spanning from hardware to software. Compared to state-of-the-art design, we reduce the size of the receiving coil by nearly 90\%. Experimental evaluations show that our system can decode overlapped RF signals created by a 3X3 MIMO VLC network five meters away, with various blockages in between. Our system also works under intense ambient light conditions (> 100,000 lux).},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {232–244},
numpages = {13},
keywords = {visible light communication, side channel, saturation, implementation, design, blockage},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430713,
author = {Li, Lingkun and Liu, Manni and Yao, Yuguang and Dang, Fan and Cao, Zhichao and Liu, Yunhao},
title = {Patronus: preventing unauthorized speech recordings with support for selective unscrambling},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430713},
doi = {10.1145/3384419.3430713},
abstract = {The widespread adoption and ubiquity of smart devices equipped with microphones (e.g., cellphones, smartwatches, etc.) unfortunately create many significant privacy risks. In recent years, there have been several cases of people's conversations being secretly recorded, sometimes initiated by the device itself. Although some manufacturers are trying to protect users' privacy, to the best of our knowledge, there is not any effective technical solution available. In this work, we present Patronus, a system that can both prevent unauthorized devices from making secret recordings while allowing authorized devices to record conversations. Patronus prevents unauthorized speech recording by emitting what we call a scramble, a low-frequency noise generated by inaudible ultrasonic waves. The scramble prevents unauthorized recordings by leveraging the nonlinear effects of commercial off-the-shelf microphones. The frequency components of the scramble are randomly determined and connected with linear chirps, and the frequency period is fine-tuned so that the scramble pattern is hard to attack. Patronus allows authorized speech recording by secretly delivering the scramble pattern to authorized devices, which can use an adaptive filter to cancel out the scramble. We implement a prototype system and conduct comprehensive experiments. Our results show that only 19.7\% of words protected by Patronus' scramble can be recognized by unauthorized devices. Furthermore, authorized recordings have 1.6x higher perceptual evaluation of speech quality (PESQ) score and, on average, 50\% lower speech recognition error rates than unauthorized recordings.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {245–257},
numpages = {13},
keywords = {privacy protection, nonlinear effects, microphone},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430770,
author = {Wang, Xiong and Kong, Linghe and Wu, Zucheng and Cheng, Long and Xu, Chenren and Chen, Guihai},
title = {SLoRa: towards secure LoRa communications with fine-grained physical layer features},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430770},
doi = {10.1145/3384419.3430770},
abstract = {LoRa, which is considered as an appealing wireless technique for Low-Power Wide-Area Networks (LPWANs), has found wide applications in fields such as smart cities, intelligent agriculture. Despite its popularity, there exists a growing concern about secure communications mainly due to the free frequency band and minimalist design specified in LoRa communications. For example, an attacker can forge messages to launch spoofing attack. To mitigate the threat, an authentication mechanism is needed. In this paper, we propose a lightweight node authentication scheme named SLoRa for LoRa networks by leveraging two physical layer features-Carrier Frequency Offset (CFO) and spatial-temporal link signature. In particular, we propose a novel CFO compensation algorithm, and identify slight CFO variations by adopting linear fitting for received upchirps to mitigate the noise's randomness on fine-grained CFO estimation. Besides, we can obtain fine-grained link signatures without the conventional de-convolution operation based on the theoretical analysis. Then, we show how these two physical-layer features complement each other to conquer the drift challenge brought by weather and environment variations. Combining these two features, SLoRa can distinguish whether the received signal is conveyed from a legitimate LoRa node or not. Experiments covering indoor and outdoor scenarios are conducted to demonstrate a high accuracy for node authentication in SLoRa, which is around 97\% indoors and 90\% outdoors.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {258–270},
numpages = {13},
keywords = {node authentication, multipath effect, cryptographic mechanisms, LoRa communications, CFO},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430718,
author = {Wang, Jie and Wang, Yuewu and Lei, Lingguang and Sun, Kun and Jing, Jiwu and Zhou, Quan},
title = {TrustICT: an efficient trusted interaction interface between isolated execution domains on ARM multi-core processors},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430718},
doi = {10.1145/3384419.3430718},
abstract = {The Trusted Execution Environment (TEE) has been widely used to protect the security-sensitive sensing systems on Internet-of-Thing (IoT) devices. In the TEE systems, the execution environment is securely divided into a normal domain and a higher privileged secure domain which executing sensing systems through hardware. One common way to achieve the protection is implementing the sensitive functions of the sensing systems as trusted applications (TAs) in the well-isolated secure domain. Users in rich OS have to call TAs through the client applications (CAs), and the invocations must pass through the rich OS kernel. However, an untrusted rich OS may launch man-in-the-middle attacks on the communication between the CAs and TAs, and the misuse of cross-domain communication channel is becoming one severe threat on the TEE systems. In this paper, we develop a defense system named TrustICT to construct a lightweight trusted interaction channel between CAs and TAs without modifying existing TEE architecture. The main idea is to block attacks on the cross-domain interactions via dynamically setting the access permission of domain-shared memory, locking it from kernel mode and unlocking it only to legal CAs in the user mode. Particularly, we propose a multi-core scheduling strategy to defeat potential attacks from all privileged cores. Compared to existing cryptography-based methods, TrustICT dramatically reduces the system overhead since it does not require time-consuming cryptographic computation or sophisticated real-time kernel protection. We implement a prototype of TrustICT on a Freescale i.MX6Quad platform with the OP-TEE software system and evaluate its impacts on rich OS and the cross-domain transactions.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {271–284},
numpages = {14},
keywords = {trustzone, trusted interaction interface, multi-core processor},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430775,
author = {Pu, Hongyi and He, Liang and Zhao, Chengcheng and Yau, David K. Y. and Cheng, Peng and Chen, Jiming},
title = {Detecting replay attacks against industrial robots via power fingerprinting},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430775},
doi = {10.1145/3384419.3430775},
abstract = {Industrial robots have been shown to suffer from replay attacks, via which adversaries not only manipulate the robot operation by downloading malicious code, but also prevent the detection of this manipulation by replaying recorded (and normal) movement data to the monitoring system. To protect industrial robots from replay attacks, we design a novel intrusion detection system using the power fingerprint of robots, called PIDS (<u>Po</u>wer-based <u>I</u>ntrusion <u>D</u>etection <u>S</u>ystem), and deliver PIDS as a bump-in-the-wire module installed at the powerline of commodity robots. The foundation of PIDS is the physically-induced dependency between the robot movement and the concomitant electrical power consumption, which PIDS captures via joint physical analysis and (cyber) data-driven modeling. PIDS then fingerprints the robot movements observed by the monitoring system using their expected power consumption, and cross-validates the fingerprints with empirically collected power information --- a mismatch thereof flags anomalies of the observed movements (i.e., evidence of replay attack). We have evaluated PIDS using three models of robots from different vendors --- i.e., ABB IRB120, KUKA KR6 R700, and Universal Robots UR5 robots --- with over 2, 000 operation cycles. The experimental results show that PIDS detects replay attacks with an average rate of 96.5\% (up to 99.9\%) and a 0.1s latency.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {285–297},
numpages = {13},
keywords = {replay attacks, power fingerprinting, intrusion detection systems, industrial robots},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430727,
author = {Sun, Ke and Chen, Chen and Zhang, Xinyu},
title = {"Alexa, stop spying on me!": speech privacy protection against voice assistants},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430727},
doi = {10.1145/3384419.3430727},
abstract = {Voice assistants (VAs) are becoming highly popular recently as a general means of interacting with the Internet of Things. However, the use of always-on microphones on VAs imposes a looming threat on users' privacy. In this paper, we propose MicShield, the first system that serves as a companion device to enforce privacy preservation on VAs. MicShield introduces a novel selective jamming mechanism, which obfuscates the user's private speech while passing legitimate voice commands to the VAs. It achieves this by using a phoneme level jamming control pipeline. Our implementation and experiments demonstrate that MicShield can effectively protect a user's private speech, without affecting the VA's responsiveness.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {298–311},
numpages = {14},
keywords = {voice assistant, selective jamming, privacy protection},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430779,
author = {Li, Huining and Xu, Chenhan and Rathore, Aditya Singh and Li, Zhengxiong and Zhang, Hanbin and Song, Chen and Wang, Kun and Su, Lu and Lin, Feng and Ren, Kui and Xu, Wenyao},
title = {VocalPrint: exploring a resilient and secure voice authentication via mmWave biometric interrogation},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430779},
doi = {10.1145/3384419.3430779},
abstract = {With the continuing growth of voice-controlled devices, voice metrics have been widely used for user identification. However, voice biometrics is vulnerable to replay attacks and ambient noise. We identify that the fundamental vulnerability in voice biometrics is rooted in its indirect sensing modality (e.g., microphone). In this paper, we present VocalPrint, a resilient mmWave interrogation system which directly captures and analyzes the vocal vibrations for user authentication. Specifically, VocalPrint exploits the unique disturbance of the skin-reflect radio frequency (RF) signals around the near-throat region of the user, caused by the vocal vibrations during communication. The complex ambient noise is isolated from the RF signal using a novel resilience-aware clutter suppression approach for preserving fine-grained vocal biometric properties. Afterward, we extract the text-independent vocal tract and vocal source features and input them to an ensemble classifier for user authentication. VocalPrint is practical as it leverages a low-cost, portable, and energy-efficient hardware allowing effortless transition to a smartphone while having sufficient usability as typical voice authentication systems due to its non-contact nature. Our experimental results from 41 participants with different interrogation distances, orientations, and body motions show that VocalPrint can achieve over 96\% authentication accuracy even under unfavorable conditions. We demonstrate the resilience of our system against complex noise interference and spoof attacks of various threat levels.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {312–325},
numpages = {14},
keywords = {voice authentication, mmWave sensing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430778,
author = {Nguyen, Phuc and Kakaraparthi, Vimal and Bui, Nam and Umamahesh, Nikshep and Pham, Nhat and Truong, Hoang and Guddeti, Yeswanth and Bharadia, Dinesh and Han, Richard and Frew, Eric and Massey, Daniel and Vu, Tam},
title = {DroneScale: drone load estimation via remote passive RF sensing},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430778},
doi = {10.1145/3384419.3430778},
abstract = {Drones have carried weapons, drugs, explosives and illegal packages in the recent past, raising strong concerns from public authorities. While existing drone monitoring systems only focus on detecting drone presence, localizing or fingerprinting the drone, there is a lack of a solution for estimating the additional load carried by a drone. In this paper, we present a novel passive RF system, namely DroneScale, to monitor the wireless signals transmitted by commercial drones and then confirm their models and loads. Our key technical contribution is a proposed technique to passively capture vibration at high resolution (i.e., 1Hz vibration) from afar, which was not possible before. We prototype DroneScale using COTS RF components and illustrate that it can monitor the body vibration of a drone at the targeted resolution. In addition, we develop learning algorithms to extract the physical vibration of the drone from the transmitted signal to infer the model of a drone and the load carried by it. We evaluate the DroneScale system using 5 different drone models, which carry external loads of up to 400g. The experimental results show that the system is able to estimate the external load of a drone with an average accuracy of 96.27\%. We also analyze the sensitivity of the system with different load placements with respect to the drone's body, flight modes, and distances up to 200 meters.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {326–339},
numpages = {14},
keywords = {drone security, drone load estimation, RF sensing systems},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430783,
author = {Bansal, Kshitiz and Rungta, Keshav and Zhu, Siyuan and Bharadia, Dinesh},
title = {Pointillism: accurate 3D bounding box estimation with multi-radars},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430783},
doi = {10.1145/3384419.3430783},
abstract = {Autonomous perception requires high-quality environment sensing in the form of 3D bounding boxes of dynamic objects. The primary sensors used in automotive systems are light-based cameras and LiDARs. However, they are known to fail in adverse weather conditions. Radars can potentially solve this problem as they are barely affected by adverse weather conditions. However, specular reflections of wireless signals cause poor performance of radar point clouds. We introduce Pointillism, a system that combines data from multiple spatially separated radars with an optimal separation to mitigate these problems. We introduce a novel concept of Cross Potential Point Clouds, which uses the spatial diversity induced by multiple radars and solves the problem of noise and sparsity in radar point clouds. Furthermore, we present the design of RP-net, a novel deep learning architecture, designed explicitly for radar's sparse data distribution, to enable accurate 3D bounding box estimation. The spatial techniques designed and proposed in this paper are fundamental to radars point cloud distribution and would benefit other radar sensing applications},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {340–353},
numpages = {14},
keywords = {radar perception, object detection, mmWaves, deep learning, autonomous driving, adverse weather},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430781,
author = {Sami, Sriram and Dai, Yimin and Tan, Sean Rui Xiang and Roy, Nirupam and Han, Jun},
title = {Spying with your robot vacuum cleaner: eavesdropping via lidar sensors},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430781},
doi = {10.1145/3384419.3430781},
abstract = {Eavesdropping on private conversations is one of the most common yet detrimental threats to privacy. A number of recent works have explored side-channels on smart devices for recording sounds without permission. This paper presents LidarPhone, a novel acoustic side-channel attack through the lidar sensors equipped in popular commodity robot vacuum cleaners. The core idea is to repurpose the lidar to a laser-based microphone that can sense sounds from subtle vibrations induced on nearby objects. LidarPhone carefully processes and extracts traces of sound signals from inherently noisy laser reflections to capture privacy sensitive information (such as speech emitted by a victim's computer speaker as the victim is engaged in a teleconferencing meeting; or known music clips from television shows emitted by a victim's TV set, potentially leaking the victim's political orientation or viewing preferences). We implement LidarPhone on a Xiaomi Roborock vacuum cleaning robot and evaluate the feasibility of the attack through comprehensive real-world experiments. We use the prototype to collect both spoken digits and music played by a computer speaker and a TV soundbar, of more than 30k utterances totaling over 19 hours of recorded audio. LidarPhone achieves approximately 91\% and 90\% average accuracies of digit and music classifications, respectively.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {354–367},
numpages = {14},
keywords = {lidar, eavesdropping, acoustic side-channel},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430722,
author = {Afanasov, Mikhail and Bhatti, Naveed Anwar and Campagna, Dennis and Caslini, Giacomo and Centonze, Fabio Massimo and Dolui, Koustabh and Maioli, Andrea and Barone, Erica and Alizai, Muhammad Hamad and Siddiqui, Junaid Haroon and Mottola, Luca},
title = {Battery-less zero-maintenance embedded sensing at the mithr\ae{}um of circus maximus},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430722},
doi = {10.1145/3384419.3430722},
abstract = {We present the design and evaluation of a 3.5-year embedded sensing deployment at the Mithr\ae{}um of Circus Maximus, a UNESCO-protected underground archaeological site in Rome (Italy). Unique to our work is the use of energy harvesting through thermal and kinetic energy sources. The extreme scarcity and erratic availability of energy, however, pose great challenges in system software, embedded hardware, and energy management. We tackle them by testing, for the first time in a multi-year deployment, existing solutions in intermittent computing, low-power hardware, and energy harvesting. Through three major design iterations, we find that these solutions operate as isolated silos and lack integration into a complete system, performing suboptimally. In contrast, we demonstrate the efficient performance of a hardware/software co-design featuring accurate energy management and capturing the coupling between energy sources and sensed quantities. Installing a battery-operated system alongside also allows us to perform a comparative study of energy harvesting in a demanding setting. Albeit the latter reduces energy availability and thus lowers the data yield to about 22\% of that provided by batteries, our system provides a comparable level of insight into environmental conditions and structural health of the site. Further, unlike existing energy-harvesting deployments that are limited to a few months of operation in the best cases, our system runs with zero maintenance since almost 2 years, including 3 months of site inaccessibility due to a COVID19 lockdown.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {368–381},
numpages = {14},
keywords = {low-power hardware, intermittent computing, energy harvesting},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430782,
author = {Montanari, Alessandro and Sharma, Manuja and Jenkus, Dainius and Alloulah, Mohammed and Qendro, Lorena and Kawsar, Fahim},
title = {ePerceptive: energy reactive embedded intelligence for batteryless sensors},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430782},
doi = {10.1145/3384419.3430782},
abstract = {For long, we have studied tiny energy harvesters to liberate sensors from batteries. With remarkable progress in embedded deep learning, we are now re-imagining these sensors as intelligent compute nodes. Naturally, we are approaching a crossroad where sensor intelligence is meeting energy autonomy enabling maintenance-free swarm intelligence and unleashing a plethora of applications ranging from precision agriculture to ubiquitous asset tracking to infrastructure monitoring. One of the critical challenges, however, is to adapt intelligence fidelity in response to available energy to maximise the overall system availability. To this end, we present the design and implementation of ePerceptive: a novel framework for best-effort embedded intelligence, i.e., inference fidelity varies in proportion to the instantaneous energy supplied. ePerceptive operates on two core principles. First, it enables training a single deep neural network (DNN) to operate on multiple input resolutions without compromising accuracy or incurring memory overhead. Second, it modifies a DNN architecture by injecting multiple exits to guarantee valid, albeit lower-fidelity inferences in the event of energy interruption. The combination of these techniques offers a smooth adaptation between inference latency and recognition accuracy while matching the computational load to the available power budget. We report the manifestation of ePerceptive in designing batteryless cameras and microphones built with TI MSP430 MCU and off-the-shelf RF and solar energy harvesters. Our evaluation of these batteryless sensors with multiple vision and acoustic workloads suggest that the dynamic adaptation of ePerceptive can increase the inference throughput by up to 80\% compared to a static baseline while ensuring a maximum accuracy drop of less than 6\%.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {382–394},
numpages = {13},
keywords = {energy autonomous, embedded intelligence, batteryless devices},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430769,
author = {Hu, Pan and Im, Junha and Asgar, Zain and Katti, Sachin},
title = {Starfish: resilient image compression for AIoT cameras},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430769},
doi = {10.1145/3384419.3430769},
abstract = {Cameras are key enablers for a wide range of IoT use cases including smart cities, intelligent transportation, AI-enabled farms, and more. These IoT applications require cloud software (including models) to act on the images. However, traditional task oblivious compression techniques are a poor fit for delivering images over low power IoT networks that are lossy and limited in capacity. The key challenge is their brittleness against packet loss; they are highly sensitive to small amounts of packet loss requiring retransmission for transport, which further reduces the available capacity of the network. We propose Starfish, a design that achieves better compression ratios and is graceful with packet loss. In addition to that, Starfish features content-awareness and task-awareness, meaning that we can build specialized codecs for each application scenario and optimized for task objectives, including objective/perceptual quality as well as AI tasks directly. We carefully design the DNN architecture and use an AutoML method to search for TinyML models that work on extremely low power/cost AIoT accelerators. Starfish is not only the first image compress framework that works on a $3 AIoT accelerators but also outperforms JPEG, a well-established baseline, by up to 3x, in terms of bandwidth efficiency and up to 2.5x as efficient in energy consumption. It also features graceful and gradual performance degradation in the presence of packet loss. The application-level simulation indicates that Starfish could deliver 3.7x images while providing better image quality.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {395–408},
numpages = {14},
keywords = {resilient, internet of things, compression, artificial intelligence},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430721,
author = {Zeng, Xiao and Fang, Biyi and Shen, Haichen and Zhang, Mi},
title = {Distream: scaling live video analytics with workload-adaptive distributed edge intelligence},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430721},
doi = {10.1145/3384419.3430721},
abstract = {Video cameras have been deployed at scale today. Driven by the breakthrough in deep learning (DL), organizations that have deployed these cameras start to use DL-based techniques for live video analytics. Although existing systems aim to optimize live video analytics from a variety of perspectives, they are agnostic to the workload dynamics in real-world deployments. In this work, we present Distream, a distributed live video analytics system based on the smart camera-edge cluster architecture, that is able to adapt to the workload dynamics to achieve low-latency, high-throughput, and scalable live video analytics. The key behind the design of Distream is to adaptively balance the workloads across smart cameras and partition the workloads between cameras and the edge cluster. In doing so, Distream is able to fully utilize the compute resources at both ends to achieve optimized system performance. We evaluated Distream with 500 hours of distributed video streams from two real-world video datasets with a testbed that consists of 24 cameras and a 4-GPU edge cluster. Our results show that Distream consistently outperforms the status quo in terms of throughput, latency, and latency service level objective (SLO) miss rate.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {409–421},
numpages = {13},
keywords = {workload adaptive, scheduling, on-device AI, large-scale live video analytics, edge computing, distributed deep learning systems},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430774,
author = {Lan, Guohao and Heit, Bailey and Scargill, Tim and Gorlatova, Maria},
title = {GazeGraph: graph-based few-shot cognitive context sensing from human visual behavior},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430774},
doi = {10.1145/3384419.3430774},
abstract = {In this work, we present GazeGraph, a system that leverages human gazes as the sensing modality for cognitive context sensing. GazeGraph is a generalized framework that is compatible with different eye trackers and supports various gaze-based sensing applications. It ensures high sensing performance in the presence of heterogeneity of human visual behavior, and enables quick system adaptation to unseen sensing scenarios with few-shot instances. To achieve these capabilities, we introduce the spatial-temporal gaze graphs and the deep learning-based representation learning method to extract powerful and generalized features from the eye movements for context sensing. Furthermore, we develop a few-shot gaze graph learning module that adapts the `learning to learn' concept from meta-learning to enable quick system adaptation in a data-efficient manner. Our evaluation demonstrates that GazeGraph outperforms the existing solutions in recognition accuracy by 45\% on average over three datasets. Moreover, in few-shot learning scenarios, GazeGraph outperforms the transfer learning-based approach by 19\% to 30\%, while reducing the system adaptation time by 80\%.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {422–435},
numpages = {14},
keywords = {few-shot learning, eye tracking, cognitive context sensing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430725,
author = {Li, Chenning and Liu, Zheng and Yao, Yuguang and Cao, Zhichao and Zhang, Mi and Liu, Yunhao},
title = {Wi-fi see it all: generative adversarial network-augmented versatile wi-fi imaging},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430725},
doi = {10.1145/3384419.3430725},
abstract = {Wi-Fi imaging has attracted significant interests due to the ubiquitous availability of Wi-Fi devices today. In this paper, we present Wi-Fi See It All (WiSIA), a versatile Wi-Fi imaging system built upon commercial off-the-shelf (COTS) Wi-Fi devices, which is able to simultaneously detect objects and humans, segment their boundaries, and identify them within the image plane. To achieve this, WiSIA utilizes three techniques. First, instead of constructing the image plane at the receiver side using a high-cost antenna array and complex parameter estimation, WiSIA pushes the image plane to the object side with two pairs of transceivers and 2D-IFFT. Second, WiSIA extracts the specific physical signature of the signals reflected from multiple objects to segment their boundaries. Third, WiSIA incorporates a cGAN (conditional Generative Adversarial Network) to enhance the boundary of different objects. We have implemented WiSIA using COTS Wi-Fi devices and evaluated it using a rich set of experiments. Our results demonstrate the efficacy of WiSIA. It outperforms the state-of-the-art vision-based method in dark and occlusion scenarios, demonstrating its superiority in such challenge scenarios.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {436–448},
numpages = {13},
keywords = {wireless sensing, wi-fi imaging, deep learning},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3431159,
author = {Xu, Ran and Zhang, Chen-lin and Wang, Pengcheng and Lee, Jayoung and Mitra, Subrata and Chaterji, Somali and Li, Yin and Bagchi, Saurabh},
title = {ApproxDet: content and contention-aware approximate object detection for mobiles},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3431159},
doi = {10.1145/3384419.3431159},
abstract = {Advanced video analytic systems, including scene classification and object detection, have seen widespread success in various domains such as smart cities and autonomous systems. With an evolution of heterogeneous client devices, there is incentive to move these heavy video analytics workloads from the cloud to mobile devices for low latency and real-time processing and to preserve user privacy. However, most video analytic systems are heavyweight and are trained offline with some pre-defined latency or accuracy requirements. This makes them unable to adapt at runtime in the face of three types of dynamism --- the input video characteristics change, the amount of compute resources available on the node changes due to co-located applications, and the user's latency-accuracy requirements change. In this paper we introduce ApproxDet, an adaptive video object detection framework for mobile devices to meet accuracy-latency requirements in the face of changing content and resource contention scenarios. To achieve this, we introduce a multi-branch object detection kernel, which incorporates a data-driven modeling approach on the performance metrics, and a latency SLA-driven scheduler to pick the best execution branch at runtime. We evaluate ApproxDet on a large benchmark video dataset and compare quantitatively to AdaScale and YOLOv3. We find that ApproxDet is able to adapt to a wide variety of contention and content characteristics and outshines all baselines, e.g., it achieves 52\% lower latency and 11.1\% higher accuracy over YOLOv3. Our software is open-sourced at https://github.com/purdue-dcsl/ApproxDet.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {449–462},
numpages = {14},
keywords = {resource contention, object detection, mobile vision, machine learning, approximate computing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430716,
author = {Zhang, Yu and Gu, Tao and Zhang, Xi},
title = {MDLdroidLite: a release-and-inhibit control approach to resource-efficient deep neural networks on mobile devices},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430716},
doi = {10.1145/3384419.3430716},
abstract = {Mobile Deep Learning (MDL) has emerged as a privacy-preserving learning paradigm for mobile devices. This paradigm offers unique features such as privacy preservation, continual learning and low-latency inference to the building of personal mobile sensing applications. However, squeezing Deep Learning to mobile devices is extremely challenging due to resource constraint. Traditional Deep Neural Networks (DNNs) are usually over-parametered, hence incurring huge resource overhead for on-device learning. In this paper, we present a novel on-device deep learning framework named MDLdroidLite that transforms traditional DNNs into resource-efficient model structures for on-device learning. To minimize resource overhead, we propose a novel Release-and-Inhibit Control (RIC) approach based on Model Predictive Control theory to efficiently grow DNNs from tiny to backbone. We also design a gate-based fast adaptation mechanism for channel-level knowledge transformation to quickly adapt new-born neurons with existing neurons, enabling safe parameter adaptation and fast convergence for on-device training. Our evaluations show that MDLdroidLite boosts on-device training on various PMS datasets with 28x to 50x less model parameters, 4x to 10x less floating number operations than the state-of-the-art model structures while keeping the same accuracy level.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {463–475},
numpages = {13},
keywords = {resource constraint, mobile deep learning, dynamic optimization control, deep neural networks},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430898,
author = {Yao, Shuochao and Li, Jinyang and Liu, Dongxin and Wang, Tianshi and Liu, Shengzhong and Shao, Huajie and Abdelzaher, Tarek},
title = {Deep compressive offloading: speeding up neural network inference by trading edge computation for network latency},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430898},
doi = {10.1145/3384419.3430898},
abstract = {With recent advances, neural networks have become a crucial building block in intelligent IoT systems and sensing applications. However, the excessive computational demand remains a serious impediment to their deployments on low-end IoT devices. With the emergence of edge computing, offloading grows into a promising technique to circumvent end-device limitations. However, transferring data between local and edge devices takes up a large proportion of time in existing offloading frameworks, creating a bottleneck for low-latency intelligent services. In this work, we propose a general framework, called deep compressive offloading. By integrating compressive sensing theory and deep learning, our framework can encode data for offloading into tiny sizes with negligible overhead on local devices and decode the data on the edge server, while offering theoretical guarantees on perfect reconstruction and lossless inference. By trading edge computing resources for data transmission time, our design can significantly reduce offloading latency with almost no accuracy loss. We build a deep compressive offloading system to serve state-of-the-art computer vision and speech recognition services. With comprehensive evaluations, our system can consistently reduce end-to-end latency by 2X to 4X with 1\% accuracy loss, compared to state-of-the-art neural network offloading systems. In conditions of limited network bandwidth or intensive background traffic, our system can further speed up the neural network inference by up to 35X 1.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {476–488},
numpages = {13},
keywords = {offloading, internet of things, edge computing, deep learning, compressive sensing, compressive offloading},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3431158,
author = {Xing, Tianwei and Garcia, Luis and Vilamala, Marc Roig and Cerutti, Federico and Kaplan, Lance and Preece, Alun and Srivastava, Mani},
title = {Neuroplex: learning to detect complex events in sensor networks through knowledge injection},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3431158},
doi = {10.1145/3384419.3431158},
abstract = {Despite the remarkable success in a broad set of sensing applications, state-of-the-art deep learning techniques struggle with complex reasoning tasks across a distributed set of sensors. Unlike recognizing transient complex activities (e.g., human activities such as walking or running) from a single sensor, detecting more complex events with larger spatial and temporal dependencies across multiple sensors is extremely difficult, e.g., utilizing a hospital's sensor network to detect whether a nurse is following a sanitary protocol as they traverse from patient to patient. Training a more complicated model requires a larger amount of data-which is unrealistic considering complex events rarely happen in nature. Moreover, neural networks struggle with reasoning about serial, aperiodic events separated by large quantities in the spatial-temporal dimensions.We propose Neuroplex, a neural-symbolic framework that learns to perform complex reasoning on raw sensory data with the help of high-level, injected human knowledge. Neuroplex decomposes the entire complex learning space into explicit perception and reasoning layers, i.e., by maintaining neural networks to perform low-level perception tasks and neurally reconstructed reasoning models to perform high-level, explainable reasoning. After training the neurally reconstructed reasoning model using human knowledge, Neuroplex allows effective end-to-end training of perception models with an additional semantic loss using only sparse, high-level annotations. Our experiments and evaluation show that Neuroplex is capable of learning to efficiently and effectively detect complex events-which cannot be handled by state-of-the-art neural network models. During the training, Neuroplex not only reduces data annotation requirements by 100x, but also significantly speeds up the learning process for complex event detection by 4x.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {489–502},
numpages = {14},
keywords = {resource-efficient learning, neural symbolic system, neural networks, mobile sensing, complex event detection},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430734,
author = {Fraternali, Francesco and Balaji, Bharathan and Sengupta, Dhiman and Hong, Dezhi and Gupta, Rajesh K.},
title = {Ember: energy management of batteryless event detection sensors with deep reinforcement learning},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430734},
doi = {10.1145/3384419.3430734},
abstract = {Energy management can extend the lifetime of batteryless, energy-harvesting systems by judiciously utilizing the energy available. Duty cycling of such systems is especially challenging for event detection, as events arrive sporadically and energy availability is uncertain. If the node sleeps too much, it may miss important events; if it depletes energy too quickly, it will stop operating in low energy conditions and miss events. Thus, accurate event prediction is important in making this tradeoff. We propose Ember, an energy management system based on deep reinforcement learning to duty cycle event-driven sensors in low energy conditions. We train a policy using historical real-world data traces of motion, temperature, humidity, pressure, and light events. The resulting policy can learn to capture up to 95\% of the events without depleting the node. Without historical data for training when deploying a node at a new location, we propose a self-supervised mechanism to collect ground-truth data while learning from the data at the same time. Ember learns to capture the majority of events within a week without any historical data and matches the performance of the policies trained with historical data in a few weeks. We deployed 40 nodes running Ember for indoor sensing and demonstrate that the learned policies generalize to real-world settings as well as outperform state-of-the-art techniques.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {503–516},
numpages = {14},
keywords = {event-driven sensing, deep reinforcement learning, batteryless},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430735,
author = {Ding, Shuya and Chen, Zhe and Zheng, Tianyue and Luo, Jun},
title = {RF-net: a unified meta-learning framework for RF-enabled one-shot human activity recognition},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430735},
doi = {10.1145/3384419.3430735},
abstract = {Radio-Frequency (RF) based device-free Human Activity Recognition (HAR) rises as a promising solution for many applications. However, device-free (or contactless) sensing is often more sensitive to environment changes than device-based (or wearable) sensing. Also, RF datasets strictly require on-line labeling during collection, starkly different from image and text data collections where human interpretations can be leveraged to perform off-line labeling. Therefore, existing solutions to RF-HAR entail a laborious data collection process for adapting to new environments. To this end, we propose RF-Net as a meta-learning based approach to one-shot RF-HAR; it reduces the labeling efforts for environment adaptation to the minimum level. In particular, we first examine three representative RF sensing techniques and two major meta-learning approaches. The results motivate us to innovate in two designs: i) a dual-path base HAR network, where both time and frequency domains are dedicated to learning powerful RF features including spatial and attention-based temporal ones, and ii) a metric-based meta-learning framework to enhance the fast adaption capability of the base network, including an RF-specific metric module along with a residual classification module. We conduct extensive experiments based on all three RF sensing techniques in multiple real-world indoor environments; all results strongly demonstrate the efficacy of RF-Net compared with state-of-the-art baselines.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {517–530},
numpages = {14},
keywords = {meta-learning, human activity recognition, RF sensing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430712,
author = {Wang, Ju and Li, Jianyan and Mazaheri, Mohammad Hossein and Katsuragawa, Keiko and Vogel, Daniel and Abari, Omid},
title = {Sensing finger input using an RFID transmission line},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430712},
doi = {10.1145/3384419.3430712},
abstract = {We introduce a passive Radio Frequency IDentification (RFID) based system to detect finger gesture input for Human-Computer Interaction applications. The device is simple, inexpensive and does not require calibration to accommodate changes in the device location or the Radio Frequency (RF) environment. This is achieved by connecting the chips of two RFID tags together using a strip transmission line. The key observation is that touching different positions along the transmission line changes the impedance matching between each chip and its antenna, changing Received Signal Strength (RSS) values for each tag. When a finger slides in different directions between key positions along the transmission line, there are relative RSS patterns and trends that are robust to changes in the device location and the RF environment. We implemented and evaluated an detection algorithm and system using a commercial RFID reader and two commercial RFID chips. Results show that precision and recall are greater than 95\% and 94\% when detecting 10 finger gesture inputs across 48 different device locations.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {531–543},
numpages = {13},
keywords = {transmission line, gesture, finger input, RFID},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430720,
author = {Li, Tianxing and Bai, Derek and Prioleau, Temiloluwa and Bui, Nam and Vu, Tam and Zhou, Xia},
title = {Noninvasive glucose monitoring using polarized light},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430720},
doi = {10.1145/3384419.3430720},
abstract = {We propose a compact noninvasive glucose monitoring system using polarized light, where a user simply needs to place her palm on the device for measuring her current glucose concentration level. The primary innovation of our system is the ability to minimize light scattering from the skin and extract weak changes in light polarization to estimate glucose concentration, all using low-cost hardware. Our system exploits multiple wavelengths and light intensity levels to mitigate the effect of user diversity and confounding factors (e.g., collagen and elastin in the dermis). It then infers glucose concentration using a generic learning model, thus no additional calibration is needed. We design and fabricate a compact (17 cm x 10 cm x 5 cm) and low-cost (i.e., <$250) prototype using off-the-shelf hardware. We evaluate our system with 41 diabetic patients and 9 healthy participants. In comparison to a continuous glucose monitor approved by U.S. Food and Drug Administration (FDA), 89\% of our results are within zone A (clinically accurate) of the Clarke Error Grid. The absolute relative difference (ARD) is 10\%. The r and p values of the Pearson correlation coefficients between our predicted glucose concentration and reference glucose concentration are 0.91 and 1.6 x 10-143, respectively. These errors are comparable with FDA-approved glucose sensors, which achieve ≈90\% clinical accuracy with a 10\% mean ARD.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {544–557},
numpages = {14},
keywords = {noninvasive glucose monitoring, light sensing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430732,
author = {Radhakrishnan, Meera and Rathnayake, Darshana and Han, Ong Koon and Hwang, Inseok and Misra, Archan},
title = {ERICA: enabling real-time mistake detection \& corrective feedback for free-weights exercises},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430732},
doi = {10.1145/3384419.3430732},
abstract = {We present ERICA, a digital personal trainer for users performing free weights exercises, with two key differentiators: (a) First, unlike prior approaches that either require multiple on-body wearables or specialized infrastructural sensing, ERICA uses a single in-ear "earable" device (piggybacking on a form factor routinely used by millions of gym-goers) and a simple inertial sensor mounted on each weight equipment; (b) Second, unlike prior work that focuses primarily on quantifying a workout, ERICA additionally identifies a variety of fine-grained exercising mistakes and delivers real-time, in-situ corrective instructions. To achieve this, we (a) design a robust approach for user-equipment association that can handle multiple (even 15) concurrently exercising users; (b) develop a suite of statistical models to detect several commonplace repetition-level mistakes; and (c) experimentally study the efficacy of multiple in-situ corrective feedback strategies. Via an end-to-end evaluation of ERICA with 33 participants naturally performing 3 dumbbell-based exercises, we show that (a) ERICA identifies over 94\% of mistakes during the first 5 repetitions of a set, (b) the resulting feedback is viewed favorably by 78\% of users, and (c) the feedback is effective, reducing mistakes by 10+\% during subsequent repetitions.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {558–571},
numpages = {14},
keywords = {smart gym, personalized feedback, internet of things (IoT), free-weights exercises, earables, digital personal trainer},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430733,
author = {Khamis, Abdelwahed and Kusy, Branislav and Chou, Chun Tung and McLaws, Mary-Louise and Hu, Wen},
title = {RFWash: a weakly supervised tracking of hand hygiene technique},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430733},
doi = {10.1145/3384419.3430733},
abstract = {Each year, hundreds of thousands of people contract Healthcare Associated Infections (HAIs). Poor hand hygiene compliance among healthcare workers is thought to be the leading cause of HAIs and methods were developed to measure compliance. Surprisingly, human observation is still considered the gold standard for measuring compliance by World Health Organization (WHO). Moreover, no automated solutions exist for monitoring hand hygiene techniques, such as "how to hand rub" technique by WHO. In this paper, we introduce RFWash; the first radio-based device-free system for monitoring Hand Hygiene (HH) technique. On the technical level, HH gestures are performed back-to-back in a continuous sequence and pose a significant challenge to conventional two-stage gesture detection and recognition approaches. We propose a deep model that can be trained on unsegmented naturally-performed HH gesture sequences. RFWash evaluation demonstrates promising results for tracking HH gestures, achieving gesture error rate of < 8\% when trained on 10-second segments, which reduces manual labelling overhead by ≈ 67\% compared to fully supervised approach. The work is a step towards practical RF sensing that can reliably operate inside future healthcare facilities.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {572–584},
numpages = {13},
keywords = {radar, millimeter waves, hand hygiene, contactless sensing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430464,
author = {Matsuda, Akihiro and Matsui, Tomokazu and Matsuda, Yuki and Suwa, Hirohiko and Yasumoto, Keiichi},
title = {A method for detecting street parking using dashboard camera videos on an edge device: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430464},
doi = {10.1145/3384419.3430464},
abstract = {Street parking in prohibited areas has become a social problem, especially in urban and tourist areas. In addition, because street parking can cause traffic congestion and accidents, real-time detection is required. The detection of street parking has been previously implemented on the basis of comparisons of videos recorded by fixed-point cameras. However, this approach has a limited detection area and low accuracy. In this demonstration, we present a system that recognizes street parking in real-time using a model trained by dashboard camera videos, which are widely used. The trained model was constructed by collecting data on 1,765 vehicles from dashboard camera videos. We use the Jetson TX2 as an edge device for vehicle recognition and processing. We create and demonstrate a dashboard camera device by attaching a camera and sensor module to the Jetson TX2.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {585–586},
numpages = {2},
keywords = {street parking, real-time sensing, object recognition, edge device, dashboard camera videos},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430422,
author = {Gao, Ye and Ma, Meiyi and Gordon, Kristina and Rose, Karen and Wang, Hongning and Stankovic, John},
title = {A monitoring, modeling, and interactive recommendation system for in-home caregivers: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430422},
doi = {10.1145/3384419.3430422},
abstract = {Family caregivers often report increased anxiety and depression. In order to improve the interactions between in-home patients and caregivers, and reduce strain on caregivers, we build a monitoring, modeling, and interactive recommendation system for caregivers for in-home dementia patient care. The system includes monitoring for mood by speech, building classifiers that work in realistic home settings, and supporting an adaptive recommendation system to reduce stress of the caregiver. This demo shows how our system supports caregivers in practice through several scenarios.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {587–588},
numpages = {2},
keywords = {recommendation, patient caregiver relationship},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430444,
author = {Chen, Wenqiang and Chen, Lin and Wan, Kenneth and Stankovic, John},
title = {A smartwatch product provides on-body tapping gestures recognition: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430444},
doi = {10.1145/3384419.3430444},
abstract = {Smartwatches, which are small and portable, have become dominant devices in the wearable ecosystem. However, due to the limited size of the touch screens, smartwatches typically have a poor interactive experience for users. In our previous work [3, 4], we studied appropriating the human body as a surface to extend the input through tapping-induced vibrations. In this demo, we extend previously published research by presenting a brand-new product: a smartwatch that provides on-body tapping gestures recognition. We design eight tapping gestures for four applications on the new smartwatch: music players, shortcuts, cameras, and phone calls. In 2020, we collaborated with Mad Gaze [1] and launched this smartwatch on a crowdfunding platform. Our smartwatch has exceeded the crowdfunding target amount by 27 times.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {589–590},
numpages = {2},
keywords = {wearable devices, vibration intelligence, on-body finger tapping, gesture controls},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430406,
author = {Yang, Fan and Oostvogels, Jonathan and Michiels, Sam and Hughes, Danny},
title = {Achieving deterministic and low-latency wireless connection with zero-wire: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430406},
doi = {10.1145/3384419.3430406},
abstract = {Despite the ubiquitous deployment and development of wireless technology for the Internet of Things (IoT), contemporary radio frequency (RF)-based solutions still cannot match the performance of a "wire" in terms of latency and throughput. This abstract presents a demonstration of Zero-Wire, a novel optical wireless approach that addresses this gap to enable latency-sensitive IoT applications. The essence of this approach is a new networking paradigm, referred to as a symbol-synchronous bus, wherein a mesh of nodes concurrently transmits optical signals. The demonstration setup is composed of 25 Zero-Wire nodes, forming a mesh network, and the demo showcases the network's behavior during a series of transmissions. End-to-end performance measurements include 19 kbps of contention-agnostic goodput, latency under 1 ms for two-byte frames, jitter on the order of 10s of μs, and a base reliability of 99\%.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {591–592},
numpages = {2},
keywords = {wireless sensor networks, visible light communication, synchronous transmission, optical wireless communication, internet of things, cyber-physical systems, cut-through forwarding, concurrent transmission, bus networks},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430426,
author = {Misaki, Shinya and Stirapongsasuti, Sopicha and Matsui, Tomokazu and Suwa, Hirohiko and Yasumoto, Keiichi},
title = {Activity recognition through intermittent distributed processing by energy harvesting PIR sensors: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430426},
doi = {10.1145/3384419.3430426},
abstract = {As an increasing demand for human activity monitoring in many smart services such as elderly monitoring, there is a keen need of an activities of daily living (ADL) recognition system. which can be easily deployed in ordinary homes and does not require periodic maintenance such as battery replacement for long time. In this paper, we propose an ADL recognition system which can run continuously without feeding power from outlets by intermittent sensing and distributed processing of energy harvesting (EH) sensor modules. Specifically, we have designed and developed an EH sensor node composed of (i) a micro-controller board with an analog PIR sensor which senses human activity as analog signals and form a BLE mesh network with other sensor nodes and (ii) an energy harvest module with solar panels and a rechargeable battery. We have also implemented a simple distributed random forest (RF) classifier consisting of multiple RF classifiers trained independently and running on different nodes which exchange the classification results with each other via BLE and make a final decision based on majority vote. Through experiments with five sensor nodes deployed in our smart home testbed, the distributed RF classifier classified the collected data of up to five different activities with average accuracy of over 90\%.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {593–594},
numpages = {2},
keywords = {wireless sensor network, energy harvest, distributed computing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430399,
author = {Lewicki, Tomasz and Liu, Kaikai},
title = {Aerial sensing system for wildfire detection: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430399},
doi = {10.1145/3384419.3430399},
abstract = {Every day in the summer here in California, we are exposed to extreme wildland firefighting incidents. To fight such wildfires, thousands of firefighters need to spread across hundreds of square miles. Recent years have witnessed an aggressive push towards building Unmanned Aerial Systems (UASs) for helping the fire-fighting missions. In this demo, we present a vision-based aerial sensing system for early fire detection with on-board intelligent processor. We propose a new open source perception system for joint autopiloting and multi-sensory object detection with a tight power budget. The technical approach focuses on developing a robust aerial sensing pipeline for fire detection in low-visible and smoky environments based on multi-cameras and thermal image sensor.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {595–596},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430433,
author = {Lewicki, Tomasz and Liu, Kaikai},
title = {AI thermometer for temperature screening: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430433},
doi = {10.1145/3384419.3430433},
abstract = {Thermal imaging provides a way of measuring the temperature of the subject in a contactless manner and is capable of taking the temperature of multiple subjects at a time. Due to COVID-19, there is a high demand for massive temperature screening for the crowded public in high traffic areas to detect any individual with a fever immediately. In this project, we propose to design an open-source AI thermometer for massive fever screening combining edge-based object detection solution and multi-modal sensor fusion. Different from many recent products that target commercialization and still not accessible for small business owners due to manufacturing delay and high cost, our open source solution can help developers build and assemble the AI thermometer like Lego blocks with off-the-shelf open computing board and components. We hope our solution can help small business owners to quickly utilize our AI technology at the lowest cost without long waiting.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {597–598},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430423,
author = {Nosaka, Yusuke and Hoshino, Yuko and Yamada, Mitsuho},
title = {Analysis of gaze points when looking at paintings and saliency map to improve the accuracy of ROI (region of interest): demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430423},
doi = {10.1145/3384419.3430423},
abstract = {As a preliminary step to improve the accuracy of ROI (Region of Interest) based on human visual characteristics, we measured and analyzed the eye movements when looking at paintings. We assumed that there was regularity in viewers' eye movement when looking at a world-renowned painting. This time, we introduce our experimental method, and compare for gaze points distributions and saliency map.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {599–600},
numpages = {2},
keywords = {saliency map, paintings, gaze point},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430412,
author = {Mendes, Ken and Lemic, Filip and Famaey, Jeroen},
title = {Automated, autonomous, and repeatable wireless experimentation in heterogeneous 3D environments: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430412},
doi = {10.1145/3384419.3430412},
abstract = {The performance of wireless networking approaches degrades under user's mobility. To objectively and reliably establish their performance under mobility, one has to guarantee highly repeatable experimentation with minimized external influences, which is currently a burdensome manual process for 3-dimensional (3D) environments. To address this issue, we propose a drone-based testbed for automated, autonomous, and repeatable experimentation with mobile wireless infrastructures in heterogeneous 3D environments. The developed testbed can be easily deployed in various environments, allows for simple integration of a new System Under Test (SUT), and guarantees the absence of interference with the SUT.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {601–602},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430417,
author = {Chen, Wenqiang and Chen, Lin and Ma, Meiyi and Parizi, Farshid Salemi and Shwetak, Patel and Stankovic, John},
title = {Continuous micro finger writing recognition with a commodity smartwatch: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430417},
doi = {10.1145/3384419.3430417},
abstract = {Input is a significant problem for wearable devices, particularly for head-mounted virtual and augmented reality systems. Contemporary AR/VR systems use in-air gestures or handheld controllers for interactivity. However, mid-air handwriting provides a natural, subtle, and easy-to-use way to input commands and text. In this demo, we propose and investigate ViFin, a new technique for input commands and text entry which tracks continuous micro finger-level writing with a commodity smartwatch through vibrations. Inspired by the recurrent neural aligner and transfer learning, ViFin recognizes continuous finger writing and works across different users and achieves an accuracy of 90\% and 91\% for recognizing numbers and letters, respectively. Finally, a real-time writing system with two specific applications using AR smartglasses are implemented.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {603–604},
numpages = {2},
keywords = {wearable devices, vibration intelligence, text input, micro finger writing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430431,
author = {Samyoun, Sirat and Mondol, Abu Sayeed and Stankovic, John A.},
title = {CoPED: a smartwatch based voice cognitive assistant for the pandemic and beyond: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430431},
doi = {10.1145/3384419.3430431},
abstract = {The COVID-19 pandemic has brought significant changes in daily activities, such as, washing hands and wearing masks regularly. During a pandemic, it is crucial to follow the recommendations from physicians and experts for mental and physical well-being. Also, it is important to know the latest information on the pandemic situation. Although smartwatches are very popular for monitoring and assisting daily life activities, existing systems are not directed towards coping up with the "new normal" life during pandemic. Towards achieving this goal, we present CoPED, a comprehensive voice cognitive assistant on a smartwatch that reminds and assists people for different daily activities during the pandemic and beyond.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {605–606},
numpages = {2},
keywords = {voice interaction, smartwatch, pandemic, cognitive assistant},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430429,
author = {Ke, Wenkang and Cheng, Siyao},
title = {CSI assisted channel selection for BLE protocol in integrated chips: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430429},
doi = {10.1145/3384419.3430429},
abstract = {The appearance of the integrated chips with multiple communication modules and cross-technology communication (CTC) methods make it possible to improve the quality of wireless communication by utilizing the cooperation of different protocols. In this paper, we took the cooperation of WiFi and Bluetooth Low Energy (BLE) as an example, and proposed a method to optimize the channel selection of BLE on condition that the CSI of related WiFi is fully used. The real experiments based on USRP were carried out. Both theoretical analysis and experimental results verify that our method has better performance in terms of RSSI and SNR.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {607–608},
numpages = {2},
keywords = {wireless communication protocols, frequency hopping, channel state information},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430468,
author = {Fraternali, Francesco and Balaji, Bharathan and Barrow, Michael and Hong, Dezhi and Gupta, Rajesh K.},
title = {Ember - energy management of batteryless event detection sensors with deep reinforcement learning: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430468},
doi = {10.1145/3384419.3430468},
abstract = {Batteryless sensors avoid battery replacement at the cost of slowing down or stopping their operations when there is not sufficient energy to harvest in the environment. While this strategy can work for some applications, event-based applications still remain a challenge as events arrive sporadically and energy availability is uncertain. One solution is to only turn On a sensor right before an event is happening to both detect the event and save as much energy as possible. Therefore, the system has to correctly predict events while managing limited resource availability. In this demo, we present Ember, an energy management system based on deep reinforcement learning to duty cycle event-driven sensors in low-energy conditions. We show how our system learns environmental patterns over time and makes decisions to maximize the event detection rate for batteryless energy-harvesting sensor nodes subject to low energy availability. Furthermore, we show a novel self-supervised data collection algorithm that helps Ember in discovering new environmental patterns over time. For more details, we refer readers to the full paper of Ember [2].},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {609–610},
numpages = {2},
keywords = {energy management, deep reinforcement learning, batteryless},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3431191,
author = {Marathe, Sumukh and Nambi, Akshay and Shrivastava, Nishant and Swaminathan, Manohar and Sutaria, Ronak},
title = {Fault diagnosis system for low-cost air pollution sensors: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3431191},
doi = {10.1145/3384419.3431191},
abstract = {Fine-grained air pollution monitoring is a fundamental step towards curbing pollution levels. This is sought to be achieved by the large-scale deployment of low-cost sensors at high spatio-temporal resolution. Due to the nature of these deployments, in-the-wild and in harsh environments, sensors are prone to failures and hence ensuring data reliability is challenging. Furthermore, detecting a fault by analyzing the sensor data using existing data-centric approaches is non-trivial. This demonstration presents a sensor fault diagnosis system that employs the current signature of the sensor to address data reliability issues. The current signature captures the electrical characteristics of the hardware components enabling accurate detection and isolation of faults in low-cost pollution sensors.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {611–612},
numpages = {2},
keywords = {fault detection and isolation, air pollution, PM 2.5 faults},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430446,
author = {He, Xiaoxin and Su, Xiang and Chen, Yang and Hui, Pan},
title = {Federated learning on wearable devices: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430446},
doi = {10.1145/3384419.3430446},
abstract = {Wearable devices collect user information about their activities and provide insights to improve their daily lifestyles. Smart health applications have achieved great success by training Machine Learning (ML) models on a large quantity of user data from wearables. However, user privacy and scalability are becoming critical challenges for training ML models in a centralized way. Federated learning (FL) is a novel ML paradigm with the goal of training high quality models while distributing training data over a large number of devices. In this demo, we present FL4W, a FL system with wearable devices enabling training a human activity recognition classifier. We also perform preliminary analytics to investigate the model performance with increasing computation of clients.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {613–614},
numpages = {2},
keywords = {wearable devices, human activity recognition, federated learning},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430447,
author = {Fukuda, Shuichi and Choi, Hyuckjin and Matsuda, Yuki and Yasumoto, Keiichi},
title = {Fishing activity sensing and visualization system using sensor-equipped fishing rod: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430447},
doi = {10.1145/3384419.3430447},
abstract = {In recent years, many studies and development of Cyber Physical Systems (CPS) have been carried out to feed back analysis results to human users in a physical space by using machine learning, aiming to analyze a huge amount of information obtained from physical space in a cyber space. To apply CPS to sports, a lot of studies have been conducted on sensing and recognizing actions and movements of athletes using machine learning. In this study, we focus on fishing as a sport, and propose a fishing CPS that recognizes anglers' actions in real-time and provides information on the past useful actions that are linked to fishing results depending on time and place as a decision support when the anglers do not make catch. In addition, this paper reports on the development of an IoT (Internet of Things) device that acquires positional information, acceleration and gyroscope information, and a web system that displays results of real-time activity recognition along with the place and time by animation for realizing the fishing CPS. We have evaluated the developed IoT device and web system from the viewpoint of practical use. As a result, we have confirmed that the GPS and acceleration sensors, in the actual breakwater environment, were constantly transmitting data to a server via UDP communication for 4 hours and 40 minutes.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {615–616},
numpages = {2},
keywords = {fishing, activity recognition, IoT, CPS},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430452,
author = {Fang, Shiwei and Munir, Sirajum and Nirjon, Shahriar},
title = {Fusing wifi and camera for fast motion tracking and person identification: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430452},
doi = {10.1145/3384419.3430452},
abstract = {Human sensing, motion tracking, and identification are at the center of numerous applications such as customer analysis, public safety, smart cities, and surveillance. To enable such capabilities, existing solutions mostly rely on vision-based approaches, e.g., facial recognition that is perceived to be too privacy invasive. Other camera-based approaches using body appearances lack long-term re-identification capability. WiFi-based approaches require the installation and maintenance of multiple units. We propose a novel system - called EyeFi [2] - that overcomes these limitations on a standalone device by fusing camera and WiFi data. We use a three-antenna WiFi chipset to measure WiFi Channel State Information (CSI) to estimate the Angle of Arrival (AoA) using a neural network trained with a novel student-teacher model. Then, we perform cross modal (WiFi, camera) trajectory matching to identify individuals using the MAC address of the incoming WiFi packets. We demonstrate our work using real-world data and showcase improvements over traditional optimization-based methods in terms of accuracy and speed.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {617–618},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430461,
author = {Lu, Chenghong and Wang, Jiangkun and Jing, Lei},
title = {Hand motion capture system based on multiple inertial sensors: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430461},
doi = {10.1145/3384419.3430461},
abstract = {It is important for many applications to capture hand movements with high accuracy to achieve the natural human-computer interaction, such as games, robotics, rehabilitation, and virtual reality (VR). An ideal hand motion capture solution requires good mobility, unobtrusiveness, and high accuracy. In this demo, we show a hand motion capture system including inertial sensor based data gloves with the square-root cubature Kalman Filter multi-sensor fusion algorithm and a biomechanics sensor-to-segment calibration method. The absolute error of the joint angle is measured. As the result, the proposed system shows good accuracy in both static (RMSE = 1.5°) and dynamic (RMSE = 6.6°) conditions.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {619–620},
numpages = {2},
keywords = {inertial sensors, hand motion capture, data glove},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430451,
author = {Rahman, M Arif and Preum, Sarah and Stankovic, John A. and Jia, Leon and Mirza, Eimara and Williams, Ronald and Alemzadeh, Homa},
title = {IMACS - an <u>i</u>nteractive cognitive assistant <u>m</u>odule for <u>c</u>ardiac <u>a</u>rrest cases in emergency medical <u>s</u>ervice: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430451},
doi = {10.1145/3384419.3430451},
abstract = {IMACS is an intelligent, interactive cognitive assistant dedicated to cardiac arrest cases in Emergency Medical Service (EMS). EMS providers deal with many cardiac cases. IMACS interacts with EMS providers in real-time and collects vital information from the providers' conversation, including names of interventions, timestamps of interventions, and dosage amount. Throughout the process, IMACS provides necessary reminders and creates a summary report afterward. Using the dynamic behavioral model of two different cardiac arrest recovery protocols, we have developed a critical risk-index based approach to provide time-sensitive feedback and suggest alternatives to the providers in real-time. Our experiments reveal an F1-score of 83\% with 300 test cases. A qualitative study also reflects that seven out of ten of the EMS providers rate the system as very helpful in correctly executing cardiac arrest EMS protocols.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {621–622},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430421,
author = {Dai, Zhuangzhuang and Saputra, Muhamad Risqi U. and Lu, Chris Xiaoxuan and Trigoni, Niki and Markham, Andrew},
title = {Indoor positioning system in visually-degraded environments with millimetre-wave radar and inertial sensors: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430421},
doi = {10.1145/3384419.3430421},
abstract = {Positional estimation is of great importance in the public safety sector. Emergency responders such as fire fighters, medical rescue teams, and the police will all benefit from a resilient positioning system to deliver safe and effective emergency services. Unfortunately, satellite navigation (e.g., GPS) offers limited coverage in indoor environments. It is also not possible to rely on infrastructure based solutions. To this end, wearable sensor-aided navigation techniques, such as those based on camera and Inertial Measurement Units (IMU), have recently emerged recently as an accurate, infrastructure-free solution. Together with an increase in the computational capabilities of mobile devices, motion estimation can be performed in real-time. In this demonstration, we present a real-time indoor positioning system which fuses millimetre-wave (mmWave) radar and IMU data via deep sensor fusion. We employ mmWave radar rather than an RGB camera as it provides better robustness to visual degradation (e.g., smoke, darkness, etc.) while at the same time requiring lower computational resources to enable runtime computation. We implemented the sensor system on a handheld device and a mobile computer running at 10 FPS to track a user inside an apartment. Good accuracy and resilience were exhibited even in poorly illuminated scenes.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {623–624},
numpages = {2},
keywords = {millimeter-wave sensor, indoor positioning, deep learning, IMU},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430409,
author = {Daryani, Karan and Chitroda, Aakash and Mulani, Aquib and Tanniru, Venkatesh and Liu, Kaikai},
title = {Intelligent and autonomous wheelchair design: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430409},
doi = {10.1145/3384419.3430409},
abstract = {Many people have difficulty walking, and the percentage of people with this challenge increases with age. The "mobility challenge," which we address in this project, centers on one's ability to independently move through the world. Enabling individuals to maintain their independence of mobility has significant social importance for society as a whole. While research in sensing and autonomous technology has made great strides in recent years, affordable fully autonomous systems are still a distant goal, primarily because of a lack of sensing accuracy and robustness based on off-the-shelf low-cost sensors. Self-driving vehicles being tested by companies rely heavily on expensive 3D LiDAR to locate themselves on the detailed maps they need to get around, and to identify things like pedestrians and other vehicles. In this project, we investigate an efficient sensing and perception hardware and software system design for autonomous and intelligent wheelchairs. The goal is to develop an experimental testbed with multi-modal sensors, computing systems, control and mobility systems. This affordable testbed will be a full-fledged modular platform to test and deploy latest deep learning-based algorithm without expensive hardware components.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {625–626},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430425,
author = {Wu, Chenshu and Wang, Beibei and Liu, K. J. Ray},
title = {Large-scale decimeter-level indoor tracking using a single access point: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430425},
doi = {10.1145/3384419.3430425},
abstract = {Existing indoor location systems do not easily scale at low cost while maintaining high accuracy. We present EasiTrack, an indoor tracking system that achieves decimeter accuracy using a single commodity WiFi Access Point (AP) under Non-Line-Of-Sight conditions and can deploy at scale with (almost) zero cost. We build a fully functional real-time system with a satellite-like architecture, which enables EasiTrack to support an unlimited number of clients. We have demonstrated EasiTrack in a number of different scenarios to track both humans and machines. The results reveal that EasiTrack achieves a decimeter median accuracy and a <2m maximum error and supports a broad coverage of 50 m\texttimes{}60 m using a single AP.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {627–628},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430440,
author = {Gomez, Andres},
title = {On-demand communication with the batteryless MiroCard: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430440},
doi = {10.1145/3384419.3430440},
abstract = {Over the last decade, energy harvesting has seen significant growth as different markets incorporate green and sustainable electrical energy production. Even though costs have fallen, few products in the Internet-of-Things marketplace have embraced solutions based on energy harvesting. This is partly due to a mismatch in both the power density and timeliness of energy production and consumption. Until recently, harvesting-based systems required a battery or supercapacitor to be functional. After years of research, advances in energy management techniques have enabled the design of fully batteryless sensing devices. This demo introduces the batteryless MiroCard, a novel smart-card powered by light. Its fast wake-up times and energy-efficient operation allow the MiroCard to emit BLE beacons even in low ambient light conditions.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {629–630},
numpages = {2},
keywords = {low power communication, energy harvesting, batteryless systems},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430420,
author = {Mori, Taiga and Otomo, Takahide and Ishii, Eriko and Hoshino, Yuko and Yamada, Mitsuho},
title = {Proposal of an interest word presentation system when browsing the web using eye movements: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430420},
doi = {10.1145/3384419.3430420},
abstract = {In recent years, eye tracking technology has received a lot of attention. This time, as a basic study of interaction that can extract user's interest information, we tried to develop a user interaction system using a low-cost, non-contact eye-gaze input device. Our system uses the user's gaze point and gaze time when browsing a web page to extract words that the user may be interested in and display the information on the screen.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {631–632},
numpages = {2},
keywords = {web, interaction system, gaze},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430458,
author = {Chandel, Vivek and Saha, Jayeeta and Bhattacharyya, Chirayata and Ghose, Avik},
title = {Real-time robust estimation of breathing rate from PPG using commercial-grade smart devices: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430458},
doi = {10.1145/3384419.3430458},
abstract = {In this work, we present a solution for an accurate and real-time monitoring of breathing rate (BR) from photoplethysmogram (PPG) signal on both smartphone and smartwatch. Respiration induces multiple modulations in a PPG signal which are difficult to extract from low-quality PPG signal collected using consumer devices. We present an effective method of validating the breathing signal data which is evaluated and compared on an open dataset. The solution is also implemented as a smartphone and smartwatch app to provide an on-device real-time BR, and evaluated on multiple subjects. For the demonstration, we shall show breathing rate and breathing pattern both on smartphone and smartwatch, which can be visualized in real-time on a dashboard.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {633–634},
numpages = {2},
keywords = {smartwatch, smartphone, ppg, breathing rate, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430434,
author = {Sagar, Subhash and Mahmood, Adnan and Sheng, Quan Z. and Siddiqui, Sarah Ali},
title = {SCaRT-SIoT: towards a scalable and robust trust platform for social internet of things: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430434},
doi = {10.1145/3384419.3430434},
abstract = {Recently, the convergence of the paradigm of the Internet of Things (IoT) with social networking has been widely recognized as an emerging interdisciplinary area, lately, referred to as the Social Internet of Things (SIoT). SIoT enables the object-to-object interaction and provides the platform for these objects to autonomously socialize with the other objects in the network in a bid to overcome the key challenges of IoT, i.e., data discovery and composition, network navigability, trust management, etc. Trust plays a significant role while establishing these inter-object social relationships and it is also essential to observe the trustworthiness of an object before relying on information provided by them. A number of trust evaluation models for SIoT have been proposed in the literature, nevertheless, most of these models suffer in validating and testing their respective models due to lack of appropriate datasets. To address this issue, this paper proposes a scalable plug and play trust platform referred to as SCalable and Robust Trust platform for SIoT (SCaRT-SIoT) to provide the dataset to test and analyze various SIoT-based trust models of the research community.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {635–636},
numpages = {2},
keywords = {trustworthiness management, trust platform, social similarity, social internet of things, packet delivery ratio, friendship, community-of-interest},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430436,
author = {Liou, Jung-Chang and Jain, Sajal and Singh, Sooraj Randhir and Taksinwarajan, Dhit and Seneviratne, Suranga},
title = {Side-channel information leaks of Z-wave smart home IoT devices: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430436},
doi = {10.1145/3384419.3430436},
abstract = {Z-Wave is one of the key access protocols of the Internet of Things (IoT). It is highly popular in home automation and security system applications due to its minimum power consumption, reliability, and cost effectiveness. With an estimate of over 100 million deployed Z-Wave devices around the globe, it is essential to understand their security landscape. For instance, Z-Wave devices can leak personal information about the home dwellers as well as their possessions and buglers can use compromised Z-Wave devices to disable security systems or even to feed incorrect information. In this paper, we present an experiment setup and early results of side-channel information leaks of Z-Wave. We show that Z-Wave traffic despite being encrypted, leaks information through side-channels and an attacker who can passively capture Z-Wave frames by simply being in the vicinity of a house can identify Z-Wave devices inside the house.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {637–638},
numpages = {2},
keywords = {smart home, network traffic monitoring, Z-wave, IoT},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430400,
author = {Shinde, Sujit and Agarwal, Swapna and Jaiswal, Dibyanshu and Ghose, Avik and Kimbahune, Sanjay and Pillai, Pravin},
title = {ThermoTrak: smartphone based real-time fever screening: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430400},
doi = {10.1145/3384419.3430400},
abstract = {In this paper, we present "ThermoTrak", a smartphone accessory based, real-time and accurate temperature measurement mechanism, which can be used to screen for fever, which is a manifestation of infectious diseases including the symptoms caused by SARS-CoV-2. Our system accurately identifies face and forehead region from a safe distance of one meter, calculates accurate temperature of forehead with accuracy of ±0.5° C on a linear scale. An AI based algorithm is employed for the purpose of accurately detecting the Region of interest (ROI) (Face \& point near center of Forehead) and calculate the absolute temperature within 300 milliseconds.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {639–640},
numpages = {2},
keywords = {thermal screening, temperature screening, smartphone, face detection, automated temperature screening, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430460,
author = {Isoda, Shogo and Hidaka, Masato and Matsuda, Yuki and Suwa, Hirohiko and Yasumoto, Keiichi},
title = {User decision support system for on-site tourism navigation on smartphone: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430460},
doi = {10.1145/3384419.3430460},
abstract = {In recent years, there has been a growing interest in travel applications that provide on-site personalized tourist spot recommendations. While they are generally useful, most of the available apps are focused on helping tourists make decisions only on the next spot to visit. This may cause that the tourists miss attractive spots to visit in the future. Due to the lack of awareness on the spots to go afterwards, they are unable to visit the spots they wanted to visit later, hence their overall tourism satisfaction decreases. In this study, we introduce an on-site tourism recommendation system, ISO-Tour, which can be used on the spot during the tour and allows users to consider multiple spots to visit next taking into account the trade-off between satisfaction of the next spot and that of the subsequent spots visited in the future.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {641–642},
numpages = {2},
keywords = {sightseeing recommendation, on-site planning, decision making, context awareness},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430435,
author = {Zhao, Yang and Tkaczyk, Eric and Pan, Feng},
title = {Visual and inertial sensor fusion for mobile X-ray detector tracking: demo abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430435},
doi = {10.1145/3384419.3430435},
abstract = {Robust 3D pose tracking of an object is a critical technique for various mobile sensing applications. Computer vision-based pose tracking method provides a cost-effective solution, but it is sensitive to occlusion and illumination change issues. In this work, we propose a novel visual-inertial sensor fusion framework and demonstrate the real-time implementation of a tightly-coupled sensor fusion algorithm: inertial perspective-n-point (IPNP) algorithm. With measurements from an inertial measurement unit (IMU), the prototype system only needs to detect two keypoints to track all six degrees of freedom of a planar object, e.g., a mobile X-ray detector, a 50\% reduction on required number of keypoints, compared with the vision-based perspective-n-point algorithm.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {643–644},
numpages = {2},
keywords = {sensor fusion, pose estimation, mobile sensing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430448,
author = {Kawasaki, Takafumi and Okoshi, Tadashi and Nakazawa, Jin},
title = {A mobility-aware pub/sub architecture for short-lived data in smart cities: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430448},
doi = {10.1145/3384419.3430448},
abstract = {With an increase in the number of IoT devices, the amount of data transferred between the devices and applications is becoming huge. To ensure that these data are properly used, a new IoT data transfer system is needed to better control the timing and the content of the data to transmit. One of the promising means for such a large-scale city-data transfer is the publish/subscribe messaging model, which can separate data senders and receivers so that they can run independently. However, existing pub/sub systems cannot cope well with the mobility of senders and receivers, thereby limiting its applicability to real-world uses. In concrete, they don't consider Time-to-live (TTL) of data. Users can use the data anytime and within TTL of it. IoT platforms can improve controlling data transmission by used to this characteristic. In this paper, we focus on the Time-to-Live of data (data-TTL). Our system can control data transmission by using data-TTL and combine with the user's movement information. We have constructed a system, that is capable of control data transmission for mobility aware.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {645–646},
numpages = {2},
keywords = {smart city, mobility, internet of things, data transfer},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430459,
author = {Harada, Koji and Arai, Ismail and Kashihara, Shigeru and Fujikawa, Kazutoshi},
title = {A performance investigation of thermal infrared camera and optical camera for searching victims with an unmanned aerial vehicle: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430459},
doi = {10.1145/3384419.3430459},
abstract = {In search and rescue (SAR) operation, the potential of Unmanned Aerial Vehicles (UAVs) gathers great attention. Existing studies have made various experiments to find victims by a UAVs with a single sensor, e.g., one of an optical camera, a thermal infrared camera, and a radio wave signal. However, the experimental environments are limited to show the performance of the sensor. Since there are various SAR missions, it is difficult to choose the best sensor for all environments. Then, to enhance the UAV performance, we need to consider multiple sensors to find a victim efficiently. In the paper, we investigate optical camera and thermal infrared camera for finding a victim helpfully. In the investigation, we observed the differences between their images by distance and brightness to find a human.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {647–648},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430394,
author = {Kumar, Arjun and Song, Junehwa},
title = {A scalable, data-driven approach for estimating battery health degradation of IoT devices: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430394},
doi = {10.1145/3384419.3430394},
abstract = {Life cycle management of battery powered-IoT devices in large scale deployments is difficult due to the non-existence of a compatible approach to estimate their battery health. Most existing approaches require either battery parameters, determination of which is beyond IoT devices' capability due to hardware limitation, or special applicable conditions that do not always hold due to devices' dynamic operating environments. In this paper, we propose a novel approach for facilitating the life cycle management of large-scale deployments through online estimation of battery health. Our approach is based on V-edge dynamics which capture and characterize instantaneous voltage drops. Our evaluation carried out on a dataset of battery discharge measurements demonstrate that our approach is capable of estimating the battery health up to 80\% accuracy.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {649–650},
numpages = {2},
keywords = {power models, lithium battery, internet of things, battery health},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430437,
author = {Sitanayah, Lanny and Angdresey, Apriandy and Kristalino, Evander},
title = {A sensor-based application for road conditions detection: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430437},
doi = {10.1145/3384419.3430437},
abstract = {Road conditions affect the safety of road users as potholes may cause traffic accidents. We design and implement a sensor-based application for road conditions detection. The sensor device includes a GPS NEO-6M module to get the pothole locations and an MPU-92/65 module as accelerometer and gyroscope sensor, which are attached to a NodeMCU ESP8266. We use REST API as the web service to connect the sensor device and users, who will access the information using the Android application on their smartphones. To cluster the acquired data, we use the k-means clustering algorithm. The algorithm clusters data into deep, medium and shallow potholes.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {651–652},
numpages = {2},
keywords = {sensor device, data mining, android application, k-means clustering algorithm},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430407,
author = {Narayanan, S Deepak and Patel, Zeel B and Agnihotri, Apoorv and Batra, Nipun},
title = {A toolkit for spatial interpolation and sensor placement: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430407},
doi = {10.1145/3384419.3430407},
abstract = {Sensing is central to the SenSys and related communities. However, fine-grained spatial sensing remains a challenge despite recent advancements, owing to cost, maintenance, among other factors. Thus, estimating the sensed phenomenon at unmonitored locations and strategically installing sensors is of prime importance. In this work, we introduce Polire - an open-source tool that provides a suite of algorithms for spatial interpolation and near-field passive sensor placements. We replicate two existing papers on these two tasks to show the efficacy of Polire. We believe that Polire is an essential step towards lowering entry barriers towards sensing and scientific reproducibility.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {653–654},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430393,
author = {Chen, Mingkang and Sun, Jingtao and Saga, Kazushige and Tanjo, Tomota and Aida, Kento},
title = {An adaptive noise removal tool for IoT image processing under influence of weather conditions: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430393},
doi = {10.1145/3384419.3430393},
abstract = {As the foundation of intelligent algorithms and applications, data collection from the real world faces the problem that there is serious data degradation under various complex environments. As a typical situation, the visual degradation of images under different weather conditions only can be utilized after arduous image noise removal by application developers previously. To overcome the challenges, previous approaches cannot handle with comprehensive situations. In this paper, we will briefly describe an adaptive image noise removal tool, which can classify multiple weather conditions and enhance image quality with optimized algorithms. Further, we constructed a recognition application using YOLO-3, and validated the effect of our tool through recognition results of real-world images.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {655–656},
numpages = {2},
keywords = {image processing, deep learning, cloud computing, IoT, AI},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430457,
author = {Ma, Ge and Xue, Rongsheng and Gu, Weixi},
title = {An incentive mechanism design for resource collection in crowdsourced CDN: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430457},
doi = {10.1145/3384419.3430457},
abstract = {To meet the content delivery requirement of the sky-rocketing increase in video requests, crowdsourced content delivery network (crowdsourced CDN) provides a new promising paradigm for low-cost and low-latency video distribution. However, due to the low contribution of storage and upload bandwidth resources from edge network owners, the resources in crowdsourced CDN are always scare. So how to incentivize crowdsourced resource supply from edge network owners are the key in the crowdsourced CDN paradigm. In this paper, we propose an incentive mechanism to address the challenge. More specifically, a Stackelberg game is formulated to model the \^{a}\u{A}IJbargain\^{a}\u{A}undefined interaction between owners and content provides (CPs). With the game, we propose a genetic algorithm to reach the equibibrium. Finally, trace-driven experiments show that effectiveness of our design.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {657–658},
numpages = {2},
keywords = {stackelberg game, resourcee collection, CDN},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430443,
author = {Kepka, Michal and \v{C}ern\'{y}, Luk\'{a}\v{s} and Brada, Premek},
title = {An open system for monitoring environmental phenomena: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430443},
doi = {10.1145/3384419.3430443},
abstract = {Monitoring of environment conditions on a farm using the concepts of Smart Farming is able to bring benefits, by providing analyses backed by data aggregated from previously unavailable breadth of sources. However, it introduces several technical challenges in terms of integrating very heterogeneous data (sensors, vehicles, etc.), validating and fusing these types of data, and turning them into useful information for farmers and agronomists. We describe an open integration architecture designed to address the above challenges and needs, including components we developed and used in validation demonstrators that provide sensor data integration (SensLog) and external systems interoperability (OGC SensorThings API connector).},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {659–660},
numpages = {2},
keywords = {sensor, SensLog, OGC SensorThingsAPI, IoT, AFarCloud},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430413,
author = {Shinohara, Miho and Yamada, Mitsuho and Hoshino, Yuko},
title = {Analysis of healing effects caused by changes in display resolution using biosensors: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430413},
doi = {10.1145/3384419.3430413},
abstract = {In this study, we measured the biomedical signals when subjects viewing videos and examined whether the high-definition videos like 4K resolution videos give the healing effects. We constructed an experimental environment which subjects feel less stressed, and measured heart rates, respiratory rates, cerebral blood flow dynamics, and skin temperature as biomedical signals.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {661–662},
numpages = {2},
keywords = {high-definition image, healing effect, cerebral blood flow},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430439,
author = {Ma, Ge and Yu, Tao and Zhu, Guowei and Lv, Kan and Huang, Qiyang and Gu, Weixi},
title = {APPLE: a new compression scheme for bitmap indexes: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430439},
doi = {10.1145/3384419.3430439},
abstract = {Compressed bitmap indexes are increasingly used in databases and search engines. By exploiting bit-level parallelism and bitwise operations, e.g. AND/OR operations, they can significantly accelerate the development of many areas. The Word Aligned Hybrid (WAH) bitmap compression scheme using run-length encoding (RLE), is commonly recognized as the most efficient scheme in terms of CPU-performance. This paper presents a new form of compressed bitmap indexes named Adaptive Partitioned Position List Encoding (APPLE), which uses packed position lists for compression. For experiments, we compare it with Huffman encoding, and two enhanced variants of WAH : Concise and COMPAX. Our empirical results show this scheme achieves significant improvement.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {663–664},
numpages = {2},
keywords = {query processing, compression, bitmap index},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430466,
author = {Lee, Euihyeok and Kim, Dongwoo and Min, Chulhong and Kang, Seungwoo},
title = {Automatic recognition of vocal reactions in music listening using smart earbuds: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430466},
doi = {10.1145/3384419.3430466},
abstract = {We propose an in-ear sensing method that automatically detects vocal reactions that people often exhibit when listening to music. We observe what kind of vocal reactions are often brought during music listening and investigate the challenges of applying an existing representative acoustic classification model to vocal reaction recognition. We present our vocal reaction recognition method and the preliminary evaluation to assess its performance.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {665–666},
numpages = {2},
keywords = {vocal reaction, reaction classification, musing listening},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430465,
author = {Mukhandi, Munkenyi and Andrade, Eduardo and Dami\~{a}o, Francisco and Granjal, Jorge and Vilela, Jo\~{a}o P.},
title = {Blockchain-based scalable authentication for IoT: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430465},
doi = {10.1145/3384419.3430465},
abstract = {Device identity management and authentication are one of the critical and primary security challenges in IoT. In order to decrease the IoT attack surface and provide protection from security threats such as introduction of fake IoT nodes and identity theft, IoT requires scalable device identity management systems and resilient device authentication mechanisms. Existing mechanisms for device identity management and device authentication were not designed for huge number of devices and therefore are not suitable for IoT environments. This work presents results of a blockchain-based identity management approach with consensus authentication, as a scalable solution for IoT device authentication management. Our identity management approach relies on having a blockchain secure tamper proof registry and lightweight consensus-based identity authentication.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {667–668},
numpages = {2},
keywords = {internet of things, identity management},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430410,
author = {Chen, Chen and Sun, Ke and Zhang, Xinyu},
title = {CapTag: toward printable ubiquitous internet of things: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430410},
doi = {10.1145/3384419.3430410},
abstract = {Many human activities involve interactions with passive objects. By wirelessly sensing human interactions with such "things", one can infer activities at a fine resolution, enabling a new wave of ubiquitous applications. This forms the basis of the tangible user interface allowing individual to use omnipresent objects as a control interface to the digital world. Existing works have tendencies to create such interface with complicated circuitry, leading to overwhelm complexities. To conquer these, we propose the inkjet printable capacitive tags (CapTags), empowering a new paradigm of printable communications and sensing modality. We use discrete capacitive and inductive components to simulate the tag-interrogator system, and prove the feasibility of proposed hardware featurization and high frequency sweeping strategy where the information can be encoded in the resonating spikes. This enables the touch points to be detected by searching resonating detune effects. Although this work only includes the designs and simulations, we believe this new sensing modality would truly realize the vision of printable ubiquitous computing.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {669–670},
numpages = {2},
keywords = {tags, internet of things, capacitive sensing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430427,
author = {Cruz, Susana B. and Soares, Eduardo and Machado, Diogo and Meireles, Paula and Ribeiro, Jo\~{a}o Niza and Barros, Henrique and Faria, Sara and Queir\'{o}s, Cristina and Rodrigues, Jo\~{a}o and Aguiar, Ana},
title = {Crowdsensing spatial data to follow epidemic evolution: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430427},
doi = {10.1145/3384419.3430427},
abstract = {Covidmonitor is a crowdsensing tool to support epidemologists and public health authorities in monitoring the covid-19 pandemic. The tool collects data to support transdisciplinary studies aiming at improving the knowledge of the pandemic evolution as well as monitor the citizens' behaviour and mental health. Covidmonitor leverages a previously existing mobile crowdsensing platform, SenseMyCity, adapted in collaboration with epidemology, public health and psychology researchers. Our biggest challenge was to identify the relevant metrics for the target trans-disciplinary studies and map them to collectable data. Covidmonitor explores the concept of citizens as probes to sample collective behaviour. The mobile application launches questionnaires about hygiene practices, use of personal protection equipment, health and emotional state. The questionnaires are triggered by different logic, adequate to the multi-dimensional perspectives of the target studies. Covidmonitor also seamlessly collects relevant mobility data without significant battery consumption. Finally, it enables voluntary sharing of location and symptom history, to facilitate tracing in case of infection. The tool considers user privacy and data minimisation by design, and is currently under preliminary scrutiny of the data protection regulator in Portugal.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {671–672},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430463,
author = {Kim, Wonjung and Chang, Youngjae and Song, Junehwa},
title = {DeepPower: fast and scalable energy assessment of mobile sensing applications: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430463},
doi = {10.1145/3384419.3430463},
abstract = {Energy-efficiency is a key performance metric of mobile sensing applications. However, assessment of energy-efficiency is greatly limited in practice. The main difficulty is that it requires assessment of power consumption in various user's real-life situation in the long term. This poster presents DeepPower, a system for assessing energy-efficiency of mobile sensing applications in fast and scalable manner. DeepPower introduces a sensor trace-based power use prediction technique, which significantly reduces the cost of assessing power consumption compared to existing power emulation techniques. Our experiments with three mobile sensing applications and five 1-hour-long sensor traces show that DeepPower can predict hardware usage of 1-hour-long sensor traces in less than a second, achieving average error rate of 4.6\%.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {673–674},
numpages = {2},
keywords = {smartphone, power estimation, energy assessment},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430418,
author = {Cai, Haofan and Qian, Chen},
title = {Enabling identity-aware tracking by vision-RFID fusion: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430418},
doi = {10.1145/3384419.3430418},
abstract = {Person identification and tracking (PIT) is an essential research topic in computer vision (CV). A CV-based system typically needs to identify, locate, and track persons appearing in its sight. In this work, we propose RFTrack, an RFID and CV fushion system that enables cameras in public areas (like surveillance cameras) to 'recognize' the physical-identity(ID) of persons in the fields of view and track the persons with specific IDs with no training efforts. By asking the users to perform a simple authentication, the system will be aware of the targets' IDs in its sensing range. Later through comparing the motion trajectories derived from both camera videos and RF signal, we can associate RFID-tagged human objects in videos with their physical IDs. A preliminary study conducted shows that RFTrack can actively identify and track the RFID-tagged target objects using commercial RFID devices and cameras, in complex indoor environments where various multipath reflectors exist.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {675–676},
numpages = {2},
keywords = {wireless sensor network, human tracking, RFID},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430403,
author = {Lee, Seungchul and Won, Jeongho and Choi, Seungpyo and Song, Junehwa},
title = {Exploring drivers' embarrassing moments in using automotive navigation: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430403},
doi = {10.1145/3384419.3430403},
abstract = {The automotive navigation often embarrasses drivers by providing guidance that is awkward, incomprehensible, or almost impossible to follow. We point out the lack of on-the-spot awareness as the key reason behind this situation. The current navigation does not consider a driver's characteristics such as driving ability, as well as the detailed conditions of the current driving environment. In this paper, we explore the cases of embarrassment related to navigation usage. We collected a total of 56 cases of embarrassing moments from three drivers' experiences and derived 8 categories of embarrassing moments.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {677–678},
numpages = {2},
keywords = {embarrassment, driver, car navigation},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430402,
author = {Takayama, Yuki and Yokota, Yusuke},
title = {Exploring effectiveness of a predictive light control mechanism for wireless sensor networks: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430402},
doi = {10.1145/3384419.3430402},
abstract = {Light management for buildings or streets is important for safety, security and comfort. However, it is not economical to keep the lights on in places without people. Although there is a lighting system with power-saving feature that lights up automatically when it detects moving objects, it has a problem that it does not light up unless the objects approach the immediate vicinity of the lights. In this work, we aim to realize the system that collects motion detection data of objects using a wireless sensor network, predicts the approach of a person from a position farther than before, and appropriately controls lighting on / off. In this system, data is exchanged between neighboring nodes, and each node autonomously judges lighting control. We discussed a predictive control method and made experiments for an adequacy confirmation. First, we constructed a system to verify the predictive control method and made a data acquisition experiment using PIR motion sensors. Next, we examined methods for a movement prediction and lighting control based on the acquired data, and confirmed that control results provide sufficient utility.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {679–680},
numpages = {2},
keywords = {wireless sensor networks, prediction mechanism, light control, distributed processing, cooperative processing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430469,
author = {Zhang, Jin and Wei, Bo and Cheng, Jun},
title = {HARaaS: HAR as a service using wifi signal in IoT-enabled edge computing: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430469},
doi = {10.1145/3384419.3430469},
abstract = {Human activity recognition (HAR) is an important component in context awareness IoT applications such smart home, smart building etc. With the proliferation of WiFi-integrated devices, researchers exploit WiFi signals to recognize various human activities. In this work, we introduce a HAR as a Service (HARaaS) model for activity recognition services applied in IoT areas. HARaaS proposes a novel edge computing model in the concept of the Sensing as a Service (S2aaS) architecture to offer accurate and real-time activities recognition services with good energy efficiency. HARaaS distributes the resource-hungry computing workload i.e. training recognition model to edge terminals, and exploits the built-in intelligence of IoT devices. A WiFi-based activity recognition service is designed following the HARaaS architecture, and the lightweight machine learning and deep learning model are incorporated in the service for accurate activity recognition. Experiments are conducted and demonstrate the service achieves an activity recognition accuracy of 95\% with extremely low latency and high energy efficiency.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {681–682},
numpages = {2},
keywords = {wifi, human activity recognition, edge computing, IoT, CSI},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430462,
author = {Rathore, Hemant and Sahay, Sanjay K. and Sewak, Mohit},
title = {How robust are malware detection models for Android smartphones against adversarial attacks? poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430462},
doi = {10.1145/3384419.3430462},
abstract = {Android-based smartphones and IoT devices have grown at an exponential rate in the last decade. Meanwhile, malicious applications have also increased dramatically, which threaten the Android ecosystem. The anti-malware community has proposed data mining based malware detection models which have shown encouraging results. However, these detection models are vulnerable to adversarial attacks. In this work, we first acted as an adversary and performed adversarial attacks on eight different malware detection models. We found all the eight detection models vulnerable to adversarial attacks and fooling rate of more than 90\% was achieved against each of them. We also propose defence against these attacks by adversarial retraining and accomplish encouraging results to improve the overall robustness of malware detection models.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {683–684},
numpages = {2},
keywords = {smartphones, malware analysis and detection, machine learning, adversarial learning},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430453,
author = {Pathak, Rachna and Agrawal, Shalu and Adhikary, Rishiraj and Batra, Nipun and Ganesan, Karthik},
title = {Impact of COVID19 lockdown on household energy consumption on two Indian cities: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430453},
doi = {10.1145/3384419.3430453},
abstract = {COVID-19 has severely impacted millions of lives around the world. In this note, we explore the impact of COVID-19 on the electricity consumption of 93 households across two tier-2 cities in India. Given the work from home restrictions, we would expect electricity consumption to increase as people spend more time at home. Contrary to the expectations, we found that electricity consumption decreased during the lockdown as compared to previous years. On further follow-up with households, we found several reasons for decreased usage: i) inability to get air conditioners serviced due to movement restriction, ii) advisories on minimising AC usage, and iii) reducing energy to compensate for reduced income.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {685–686},
numpages = {2},
keywords = {energy consumption, deployment},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430442,
author = {Chen, Xingyu and Xu, Chenhan and Chen, Baicheng and Li, Zhengxiong and Xu, Wenyao},
title = {In-ear thermometer: wearable real-time core body temperature monitoring: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430442},
doi = {10.1145/3384419.3430442},
abstract = {Core body temperature is an important indicator of medical treatment. Sudden changes in core body temperature can be a precursor to neurodegenerative diseases such as Parkinson's disease. These diseases have the potential to strike at any time, therefore, long-term monitoring of core body temperature and alerting to sudden changes in temperature become important. In this paper, we designed an in-ear thermometer to monitor the core body temperature with the help of smartphone.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {687–688},
numpages = {2},
keywords = {wearable, thermometer, temperature monitoring, smart health, mobile, core body temperature},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430424,
author = {Xu, Weitao and Li, Zhenjiang and Xue, Wanli and Yu, Xiaotong and Wang, Jia and Luo, Chengwen and Li, Wei and Zomaya, Albert Y.},
title = {Inaudible acoustic signal based key agreement system for IoT devices: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430424},
doi = {10.1145/3384419.3430424},
abstract = {Secure Device-to-Device (D2D) communication is becoming increasingly important with the ever-growing number of Internet-of-Things (IoT) devices in our daily life. To achieve secure D2D communication, the key agreement between different IoT devices without any prior knowledge is becoming desirable. Although various approaches have been proposed in the literature, they suffer from a number of limitations, such as low key generation rate and short pairing distance. In this paper, we present an inaudible acoustic signal based key generation protocol for mobile devices. Based on acoustic channel reciprocity, our system exploits channel frequency response of two legitimate devices as a common secret to generate keys. Extensive experiments are conducted to evaluate the proposed system in different real environments. Evaluation results show that the proposed system can generate the same secret key for two mobile devices with high probability.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {689–690},
numpages = {2},
keywords = {key generation, device pairing, acoustic signal, IoT device},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430471,
author = {Arakadakis, Konstantinos and Fragkiadakis, Alexandros},
title = {Incremental firmware update using an efficient differencing algorithm: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430471},
doi = {10.1145/3384419.3430471},
abstract = {Modern IoT solutions require minimisation of the transmitted data during a firmware update, in order to save energy for the constrained devices. To accommodate this requirement, IoT nodes can be updated incrementally using only parts of the current firmware, which is already stored in their flash memory in order to reconstruct the new firmware locally. This the role of the so-called differencing algorithm that executes in a firmware server and aims to detect common segments between the current and the new firmware, producing an encoded small delta script, which is finally transmitted to the IoT nodes. In this work, we present a differencing algorithm that operates in byte-level and can compute optimal, in terms of size, delta scripts in O(nlogn) time and O(n) space complexity.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {691–692},
numpages = {2},
keywords = {over-the-air-programming, internet-of-things (IoT), firmware update, differencing algorithm, delta script},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430456,
author = {Ho, Yao-Hua and Li, Pei-En and Chen, Ling-Jyh and Liu, Yu-Lun},
title = {Indoor air quality monitoring system for proactive control of respiratory infectious diseases: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430456},
doi = {10.1145/3384419.3430456},
abstract = {Disease surveillance is essential for the control of flu and respiratory infectious diseases including the novel coronavirus disease (COVID-19). Indoor air quality monitoring has been shown effective in understanding the effectiveness of airflow and circulation indoors to reduce the risk of infectious diseases. In this project, we developed low-cost indoor air quality monitoring devices and systems to tackle the disease surveillance problem. The monitoring device consists of a set of air quality sensors. By strategic deployment and real-time data analysis, the system is able to yield insightful air circulation information indoors. The real-time data analysis is performed on air quality for the indoor ventilation using Long Short-Term Memory (LSTM) on sensed data. A series of user-friendly visualization interfaces and chatbot applications are designed to interact with users and ensure the successful delivery of infection control information. Finally, we work closely with the Taiwan Centers for Disease Control (CDC) and conduct field experiments in 15 locations including hospitals, long-term care centers, schools with total of 144 IAQ devices.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {693–694},
numpages = {2},
keywords = {respiratory disease, internet of thing, indoor air quality},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430432,
author = {Aldeer, Murtadha and Florentine, Joseph and Yu, Justin and Ryan, Liam and Qi, Zhenzhou and Kolodziejski, Jakub and Haberland, Mike and Howard, Richard E. and Martin, Richard P.},
title = {Investigating the biological impacts of radio transmissions: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430432},
doi = {10.1145/3384419.3430432},
abstract = {The past 40 years have seen an explosion of Radio Frequency (RF) transmitters, which motivates understanding their impacts on the natural world. The European honeybee, Apis Mellifera, has been shown to sense the Earth's magnetic field. Human Radio Frequency (RF) transmitters alter this field. For example, recent work demonstrated that human-created RF interferes with the common robin's ability to orient themselves. This work proposes an experimental design to determine if honeybees can sense RF transmissions in frequencies from 1 MHz (AM radio) to 6 GHz (WiFi). We deployed a custom-designed RF bee feeder near bee hives to test honeybees' RF sensing ability.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {695–696},
numpages = {2},
keywords = {sensing, honeybee, biological impacts, bee feeder, RF},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430395,
author = {Takahashi, Ryo and Hayashi, Kenta and Mitsukude, Yudai and Futamata, Masanori and Inoue, Shunei and Matsuo, Shuta and Ishida, Shigemi and Arakawa, Yutaka and Takano, Shigeru},
title = {Itocon - a system for visualizing the congestion of bus stops around Ito campus in real-time: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430395},
doi = {10.1145/3384419.3430395},
abstract = {Due to the spread of COVID-19, we are desired to avoid crowded places including public transportation. Kyushu University has the largest campus in Japan, called "Ito campus", and the population there is about 20,000 in which 23\% of students and 46\% of staff use a bus for reaching the campus. The lectures in the first half of 2020 have been conducted online, but we plan to resume face-to-face lectures gradually. At that time, we expect the bus stops and buses to be crowded, especially during rush hour. In this paper, we introduce a system, called Itocon, to visualize the human congestion of bus stops around the campus.Itocon aggregates the sensing data from various sensors deployed around the target bus stops, and calculate and visualize the congestion degrees in real-time. Itocon is developed as a web application to avoid requesting the application install. We hope all the people who use a bus change their moving time based on the congestion information for avoiding human crowds. We explain the details and the future prospects of Itocon.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {697–698},
numpages = {2},
keywords = {visualization, social distancing, congestion sensing, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430467,
author = {Zhao, Kaifeng and Gao, Liren and Pi, Ruoyan and Xu, Xingyuan and Sun, Sijin and Li, Guang},
title = {IWannaPlay - an eye-tracking based AI tutoring chinese chess system: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430467},
doi = {10.1145/3384419.3430467},
abstract = {In this poster, we present IWannaPlay, an eye-tracking based Artificial Intelligence (AI) tutoring Chinese chess system. Through ordinary webcams, the IWannaPlay system captures the player's sight and facial expressions to acquire his/her gaze points and emotional status. Combining this information with the game situation, the system intelligently provides AI suggestions with visualizations. With the guidance of the AI, the player can strategize more thoroughly and thus make better decisions, achieving a better training outcome. When playing Chinese chess on IWannaPlay, the system interface displays a real-time game analysis and warns against potentially dangerous pieces within the game. Upon detection of the user's anxiety or after a period of long contemplation, the system intelligently provides graphic visualizations of dynamic multi-step strategies to assist the user in making decisions. We conducted experiments to verify the usability of our system, the user feedback demonstrated that IWannaPlay does provide effective guidance to players.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {699–700},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430430,
author = {Sami, Sriram and Tan, Sean Rui Xiang and Dai, Yimin and Roy, Nirupam and Han, Jun},
title = {LidarPhone: acoustic eavesdropping using a lidar sensor: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430430},
doi = {10.1145/3384419.3430430},
abstract = {Private conversations are an attractive target for malicious actors intending to conduct audio eavesdropping attacks. Previous works discovered unexpected vectors for these attacks, such as analyzing high-speed video of objects adjacent to sound sources, or using WiFi signal information. We propose LidarPhone, a novel side-channel attack that exploits the lidar sensors in commodity robot vacuum cleaners to perform acoustic eavesdropping attacks. LidarPhone is able to detect the minute vibrations induced on objects that are near audio sources, and extract meaningful signals from inherently noisy raw lidar returns. We evaluate a realistic scenario for potential victims: recovering privacy-sensitive digits (e.g., credit card numbers, social security numbers) emitted by computer speakers during teleconferencing calls. We implement LidarPhone on a Xiaomi Roborock vacuum cleaning robot and perform a comprehensive series of real-world experiments to determine its performance. LidarPhone achieves up to 91\% accuracy for digit classification.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {701–702},
numpages = {2},
keywords = {lidar, eavesdropping, acoustic side-channel},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430404,
author = {Papst, Franz and Stricker, Naomi and Saukh, Olga},
title = {Localization from activity sensor data: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430404},
doi = {10.1145/3384419.3430404},
abstract = {In this work, we show that sensor data may leak a sensor's location even if the latter is not explicitly included in the data set. The sensors are localized by linking sensor data, in particular activity data, with publicly available environmental data such as weather data. We show that using a linkage attack a cow can be localized within an entire country with an average accuracy of up to 32.6 km solely from activity traces recorded with a tracker in the cow's stomach.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {703–704},
numpages = {2},
keywords = {sensor data, location privacy, localization},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430398,
author = {Wei, Peter and Yang, Chenye and Jiang, Xiaofan},
title = {Low-cost multi-person continuous skin temperature sensing system for fever detection: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430398},
doi = {10.1145/3384419.3430398},
abstract = {With the recent societal impact of COVID-19, businesses and government agencies have turned to thermal camera based skin temperature sensing technology to help detect affected civilians. However, cost and deployment restrictions limit the widespread use of these thermal sensing technologies. In this work, we present a low cost system based on an RGB-thermal camera for continuously detecting and estimating facial temperature features for multiple people. This system detects and tracks heads in the RGB and thermal domains, constructs temperature models of individual facial features, and models environmental and surface effects on thermal sensing to reduce temperature measurement error.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {705–706},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430419,
author = {Antsfeld, Leonid and Chidlovskii, Boris and Borisov, Dmitrii},
title = {Magnetic sensor based indoor positioning by multi-channel deep regression: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430419},
doi = {10.1145/3384419.3430419},
abstract = {Modern smartphones are equipped with built-in magnetometers that capture disturbances of the Earth's magnetic field induced by ferromagnetic objects. In indoor environment, using magnetic field data turns to be a strong alternative to conventional localization techniques as requiring no special infrastructure. We revise the state of the art methods based on landmark classification [5] and propose a novel approach. We represent magnetic data time series as image sequences and compose multi-channel input to a deep neural network. We use four methods, Recurrence plots, Gramian Angular Fields and Markov Transition Fields, to capture different patterns in magnetic data stream. We complete the landmark-based classification with deep regression on the user's position and combine convolutional and recurrent layers in the deep network. We evaluate our methods on the recently published MagPie dataset [3] and show that they outperform the state of the art methods.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {707–708},
numpages = {2},
keywords = {mobile computing, magnetic field sensor, indoor localization},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430449,
author = {Wu, Sheng-Chun and Wu, Dong-Yi and Ching, Fu-Hsiang and Chen, Ling-Jyh},
title = {Participatory sound meter calibration system for mobile devices: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430449},
doi = {10.1145/3384419.3430449},
abstract = {Noise exposure has been the emerging environmental factor for human health. Yet an accurate and large-scale sound monitoring network is not available due to the expense of high-quality professional sound level meters and poorly-calibrated low-cost noise sensors. In this work, we propose a participatory sound meter calibration using smartphones. The system employs a low-cost and open-sourced calibration station to conduct side-by-side sound measurements, and all the measurement data are uploaded to the open data portal to build calibration models for different phone brands and models. We show that, using our calibration models, the MAE of calibration performance can be reduced significantly from 12.4 dbA to 2.8 dbA for the same device and 3.3 dbA for the other device of the same phone model. The results of this study can benefit crowdsourcing-based large-scale sound measurements and facilitate noise exposure, public health, and smart city researches in the future.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {709–710},
numpages = {2},
keywords = {sound meter calibration, smartphone, crowdsourcing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430445,
author = {Ma, Meiyi and Bartocci, Ezio and Stankovic, John and Feng, Lu},
title = {Predictive monitoring with uncertainty for deep learning enabled smart cities: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430445},
doi = {10.1145/3384419.3430445},
abstract = {In order to prevent safety violations, predictive monitoring with uncertainty is crucial for deep learning-enabled services in smart cities. We develop a novel predictive monitoring system for smart city applications, which consists of an RNN-based predictor with uncertainty estimation and a new specification language, named Signal Temporal Logic with Uncertainty. The solution first predicts a sequence of distributions representing city's future states with uncertainty estimation and then checks the predicted results against STL-U specified safety and performance requirements. The system supports decision making by providing a quantitative satisfaction degree with confidence guarantees. We receive promising results from evaluations on two large-scale city datasets, and on a case study on real-time predictive monitoring in a simulated smart city.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {711–712},
numpages = {2},
keywords = {uncertainty, smart cities, predictive monitoring, deep learning},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430411,
author = {Yamazaki, Azusa and Akatsu, Ryo and Okada, Yukihiko and Zempo, Keiichi},
title = {Real-time reassurance monitoring shopping basket in retail store: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430411},
doi = {10.1145/3384419.3430411},
abstract = {In this study, we propose a sensor network to estimate service reassurance in a store by estimating customer stress level based on a pulse wave. We developed a basket that can calculate an RR interval (RRI) with sufficient accuracy to estimate customer reassurance from the measured pulse wave under in-store conditions. Two processes were applied to the measurement values based on the assumption that certain circumstances may interfere with measuring pulse waves. Furthermore, the authors conducted pulse wave measurement experiments under simulated store conditions. The results showed RRIs' values with an error rate of 4.9\% compared to the true value.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {713–714},
numpages = {2},
keywords = {service evaluation, service encounter, sensor network, reassurance, pulse wave, RRI, LF/HF},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430405,
author = {Choi, Seungpyo and Kim, Seonghoon and Lee, Taegyeong and Song, Junehwa},
title = {Scenario-based energy estimation for continuous mobile sensing applications: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430405},
doi = {10.1145/3384419.3430405},
abstract = {Continuous mobile sensing applications (CMSAs) run 24 hours in the background, consuming a significant amount of energy. Due to CMSA's dynamic behavior according to the users' context, it is very difficult to predict the energy consumption of CMSA. User trace-based solutions have been proposed to effectively estimate the energy consumption of CMSA, but they suffer burdensome user trace collection. We propose Scenethesizer, a scenario-based energy estimation system, which generates and augments the user traces for unseen application usage scenarios and estimate the energy consumption of CMSA based on the generated user traces.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {715–716},
numpages = {2},
keywords = {user trace, smartphone, power estimation, continuous sensing},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430416,
author = {Wu, Yi and Li, Zhuohang and Van Nostrand, Nicholas and Liu, Jian},
title = {Security and privacy in the age of cordless power world: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430416},
doi = {10.1145/3384419.3430416},
abstract = {In this work, we conduct the first study to explore the potential security and privacy vulnerabilities of cordless power transfer techniques, particularly Qi wireless charging for mobile devices. We demonstrate the communication established between the charger and the charging device could be easily interfered with and eavesdropped. Specifically, through stealthily placing an adversarial coil on the wireless charger, an adversary can hijack the communication channel and inject malicious data bits which can take control of the charging process. Moreover, by simply taping two wires on the wireless charger, an adversary can eavesdrop Qi messages, which carry rich information highly correlated with the charging device's activities, from the measured primary coil voltage. We examine the extent to which this side-channel leaks private information about the smartphone's activities while being charged (e.g., detect and identify incoming calls and messages from different apps). Experimental results demonstrate the capability of an adversary to inject any desired malicious packets to take over the charging process, and the primary coil voltage side channel can leak private information of the smartphone's activities while being charged.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {717–718},
numpages = {2},
keywords = {wireless charging, side-channel attack, man-in-the-middle attack},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430455,
author = {Yan, Wenqing and Rohner, Christian},
title = {Sensitivity of radiometric fingerprint against wireless channel: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430455},
doi = {10.1145/3384419.3430455},
abstract = {Radiometric signatures have been shown effective in identifying wireless devices, also known as fingerprinting, which refers to imperfections in their electronics. Previous work mainly considered static channel conditions. In this work, we systematically and experimentally study the impact of dynamic and complex channel conditions on the radiometric signatures. The results show a threat to identification accuracy for modulation error-based fingerprinting that was considered channel-resilient.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {719–720},
numpages = {2},
keywords = {radio frequency (RF) fingerprint, physical-layer security, authentication},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3431254,
author = {Lei, Haibo and Liu, Jinyuan and Zou, Yongpan and Wu, Kaishun},
title = {Smart earpieces that know who you are quietly: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3431254},
doi = {10.1145/3384419.3431254},
abstract = {User authentication and identification on smart devices has great significance in keeping data privacy and recommending personalized services. Existing few research works propose active sensing systems that emit and receive inaudible acoustic signals to authenticate users. But they share shortcomings of intrusiveness to users, high power consumption, and purely focusing on authentication. Instead, in this paper, we propose a passive sensing system called EarID with low-cost customized earpieces which attains user authentication and identification simultaneously. It makes use of a embedded microphone to sense body sounds spread out through ear canals and extract 'fingerprints' as a novel biometric feature. With self-designed earpieces, we design a deep learning-based real-time data processing pipeline. Extensive experiments under different real-world settings show that EarID can achieve a rather low false acceptance rate less than 5\% for user authentication and a high F1 score of 96\% for user identification.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {721–722},
numpages = {2},
keywords = {smart earphones, biometric authentication},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430438,
author = {Xu, Xingyuan and Gao, Weiwei and Guo, Nannan and Pi, Ruoyan and Ni, Wanchun and Sun, Sijin and Li, Guang},
title = {SmartEye - a wearable device that help visually impaired people during on-site banking: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430438},
doi = {10.1145/3384419.3430438},
abstract = {This poster presents a device, SmartEye, which can help visually impaired people to read documents and sign on it on their own during on-site banking. With the help of Optical Character Recognition, gesture recognition, pen-tip recognition, Text to Speech, the wearable device can finish the tasks that we found in the bank. We tested SmartEye with visually impaired subjects on tasks including capturing information from documents and signing on forms. The result provided the effectiveness of SmartEye on assisting visually impaired people to reduce their inconvenience.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {723–724},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430401,
author = {Chandio, Yasra and Anwar, Fatima M.},
title = {Spatiotemporal security in mixed reality systems},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430401},
doi = {10.1145/3384419.3430401},
abstract = {This paper exhaustively explores the threat landscape of coordinated spatiotemporal attacks in mixed reality systems. Novel devicelevel and cross-device time translation and spatial shift attacks are launched, and their impact on deep learning based sensor fusion is evaluated. A major focus of this work is to establish stealthiness in the presence of sophisticated security mechanisms with an added constraint that mixed reality systems allow minimal time durations for covert operation. The efficacy of proposed attacks is evaluated through a preliminary study on inertial and visual data streams.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {725–726},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3431187,
author = {Yuan, Baojie and Hong, Shicong and Zou, Yongpan and Wu, Kaishun},
title = {Tap it and you know what it is: a surface identification system based on acoustic dispersion: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3431187},
doi = {10.1145/3384419.3431187},
abstract = {Surface identification provides contextual services during humancomputer interaction, which is important for target detection and scene understanding. A robust and ubiquitous surface recognition system has a wide range of applications such as context awareness and robot operation. Existing methods have shortcomings of requiring specialized devices and limited usage scenarios. In this paper, we introduce Surtify, a surface identification system based on acoustic dispersion with a smartphone. By combining the intrinsic physical phenomenon (i.e., acoustic dispersion) with a deep learning model, Surtify can identify eleven kinds of surfaces with accuracies up to 96\%, even in cross-person and cross-location scenarios.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {727–728},
numpages = {2},
keywords = {touch interface, material recognition, acoustics},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430450,
author = {Mishra, Rahul and Gupta, Hari Prabhat and Dutta, Tanima},
title = {Teacher, trainee, and student based knowledge distillation technique for monitoring indoor activities: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430450},
doi = {10.1145/3384419.3430450},
abstract = {Recent years have witnessed unprecedented growth in sensors-based indoor activity recognition. Further, a significant improvement in recognition performance of indoor activities is observed by incorporating Deep Neural Network (DNN) model. In this paper, we propose knowledge distillation based economic and efficient indoor activity recognition approach for low-cost resource constraint devices. Here, we adopt knowledge from teacher and trainee (cumbersome DNN models) for training student (compressed DNN model). Initially, student and trainee both are beginner and trainee helps the student in learning from the teacher. The student, after certain steps, is mature enough for directly learning from the teacher. We introduce an early halting mechanism for simultaneously reducing floating-point operations and training time of the student model.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {729–730},
numpages = {2},
keywords = {sensors, knowledge distillation, deep neural network},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430441,
author = {Cao, Joshua and Chong, Jesse and Lafreniere, Marissa and Yang, Owen and Pappachan, Primal and Mehrotra, Sharad and Venkatasubramanian, Nalini},
title = {The ZotBins solution to waste management using internet of things: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430441},
doi = {10.1145/3384419.3430441},
abstract = {The growing use of Internet of Things (IoT) technologies has the potential to improve waste management. In this work, we present ZotBins, a system that facilitates sustainable practices for individuals and improves waste management efficiency for organizations. ZotBins consists of smart bins fitted with sensors, a waste recognition framework, and a variety of user applications. Currently, eight smart bins have been deployed in University of California, Irvine (UCI) campus and the preliminary estimates show that it improves the diversion rate (percentage of waste diverted from landfills through methods such as recycling) by about 20\% while generating tens of thousands of dollars in revenue over the course of next ten years for the university.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {731–732},
numpages = {2},
keywords = {waste management, user applications, internet of things},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430408,
author = {Takaie, K. and Tamura, K. and Kawakita, Y. and Yokogawa, S. and Tobe, Y. and Ichikawa, H.},
title = {Toward efficient power delivery using USB power delivery hub: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430408},
doi = {10.1145/3384419.3430408},
abstract = {Power delivery (PD) to computing and sensing devices in an indoor environment is as important as data communication between them. We are developing a USB-PD-based DC power supply system called VGHub. As the power loss at each input and output port of VGHub depends on the incoming or outgoing power at the port, the power distribution among all the ports needs to be optimized to maximize the power efficiency of VGHub. In this poster paper, we describe the formulation of a power distribution control in VGHub.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {733–734},
numpages = {2},
keywords = {quantification of power loss, power loss, power efficiency, optimization, lagrange's method of undetermined multiplier},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430414,
author = {Maali, Eman and Boyle, David and Haddadi, Hamed},
title = {Towards identifying IoT traffic anomalies on the home gateway: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430414},
doi = {10.1145/3384419.3430414},
abstract = {The number of IoT devices continues to grow despite the alarming rate of identification of security and privacy issues. There is widespread concern that development of IoT devices is performed without sufficient attention paid to security and privacy issues. Consequently, networks have a higher probability of incorporating vulnerable IoT devices that may be easy to compromise to launch cyber attacks. Inclusion of IoT devices paves the way for a new category of anomalies to be introduced to networks. Traditional anomaly detection techniques (e.g., semi-supervised and signature-based methods), however, are likely inefficient in detecting IoT-based anomalies. This is because these techniques require static signatures of known attacks, specialized hardware, or full packet inspection. They are also expensive, and may be inaccurate or unscalable. Vulnerable IoT devices can be used to perform destructive attacks or invade privacy. The ability to find anomalies in IoT traffic has the potential to assist with early detection and deployment of countermeasures to thwart such attacks. Thus, new techniques for detecting infected IoT devices are needed to mitigate the associated security and privacy risks. In this research, we investigate the possibility to identify IoT traffic using a combination of behavioural profile, predefined blocklist and device fingerprint. Such a system may be able to detect anomalous and/or malicious devices and/or traffic reliably and quickly. Initial results show that for our implementation of such a system, IoT traffic can be identified using device behaviour profile, fingerprint, and contacted destinations. This work takes the first step towards designing and evaluating iDetector, a framework that can detect anomalous behaviour within IoT networks. In our experiments, iDetector was able to correctly identify 80--90\% of all captured traffic traversing a home gateway.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {735–736},
numpages = {2},
keywords = {traffic analysis, internet of things, anomaly detection, IoT},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430454,
author = {Tavallaie, Omid and Taheri, Javid and Zomaya, Albert Y.},
title = {Towards optimizing time-slotted channel hopping scheduling on 6TiSCH networks: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430454},
doi = {10.1145/3384419.3430454},
abstract = {Time-Slotted Channel Hopping (TSCH) is defined in the IEEE 802.15.4e standard as a share medium access control technology to address reliability and timeliness requirements of low-power Internet of Things (IoT) applications. While standards define mechanisms for the basic configuration and communication of TSCH nodes, the adaptation of the TSCH schedule to traffic dynamics has been left as an open research problem. In this poster, we propose an Optimized Adaptive TSCH Scheduling Function (OA-TSCH) to dynamically adjust the TSCH schedule to the changes in the data traffic loads. We implement OA-TSCH on Zolerita Firefly IoT motes and the Contiki-NG operating system to evaluate its performance. Evaluation results show that our proposed scheduling function can improve the packet delivery ratio and throughput significantly.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {737–738},
numpages = {2},
keywords = {time-slotted channel hopping (TSCH), internet of things (IoT)},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430428,
author = {Kim, Dongwoo and Min, Chulhong and Kang, Seungwoo},
title = {Towards recognizing perceived level of understanding for online lectures using earables: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430428},
doi = {10.1145/3384419.3430428},
abstract = {We envision that our earbuds recognize how much we understand learning materials while taking online lectures for effective learning and teaching, e.g., to pinpoint the part for which we need to put more effort to learn. To this end, we explore the feasibility of recognizing the perceived level of understanding of online learners based on IMU sensor data from earbuds. We present an exploratory study to identify head-related behaviors that can be detected by in-ear IMU data, which are associated with the perceived level of understanding for online lectures.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {739–740},
numpages = {2},
keywords = {understanding level, recognition, online learning, head motions and postures},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430415,
author = {Voigt, Thiemo and Rohner, Christian and Yan, Wenqing and Joseph, Laya and Hylamia, Sam and Asan, Noor Badariah and Mandal, Bappaditya and Perez, Mauricio and Augustine, Robin},
title = {Towards secure backscatter-based in-body sensor networks: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430415},
doi = {10.1145/3384419.3430415},
abstract = {In the near future more and more people will have multiple implants to handle their diseases. The implants benefit from being connected using in-body sensor networks. We have previously shown that RF communication through human adipose (fat) tissue is feasible. In this poster, we argue why we believe that backscatter communication within this fat channel is possible. As security is of utmost importance for in-body communication, we also discuss how backscatter-based in-body networks can be secured.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {741–742},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430595,
author = {Stirapongsasuti, Sopicha and Thonglek, Kundjanasith and Misaki, Shinya and Usawalertkamol, Bunyapon and Nakamura, Yugo and Yasumoto, Keiichi},
title = {A nudge-based smart system for hand hygiene promotion in private organizations: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430595},
doi = {10.1145/3384419.3430595},
abstract = {In response to the Coronavirus 2019 (COVID-19) pandemic, the World Health Organization (WHO) has published preventive measures such as performing hand hygiene frequently, wearing a medical mask, trying to avoid touching face and so on. This paper presents a nudge-based system to promote hand hygiene in a private organization. The proposed system consists of a hand sanitizer station equipped with a magnetic sensor to sense user presses. We conducted 4 case studies to compare the effects of nudging on the frequency of hand sanitizer use: no nudging, traditional nudging, non-personalized nudging, and personalized nudging. The results reveal that using nudge-based methods offer a significant increase in the frequency hand sanitizer use.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {743–744},
numpages = {2},
keywords = {hand hygiene, edge computing, behavior change, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430594,
author = {August, Michael and Davison, Christopher and Diallo, Mamadou and Ghosh, Dhrubajyoti and Gupta, Peeyush and Graves, Christopher and Han, Shanshan and Holstrom, Michael and Khargonekar, Pramod and Kline, Megan and Mehrotra, Sharad and Sharma, Shantanu and Venkatasubramanian, Nalini and Wang, Guoxi and Yus, Roberto},
title = {A privacy-enabled platform for COVID-19 applications: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430594},
doi = {10.1145/3384419.3430594},
abstract = {We present our experiences in adapting and deploying TIPPERS1, a novel privacy-enabled IoT data collection and management system for smart spaces, to facilitate the monitoring of adherence to COVID-19 regulations in a university campus and a military facility.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {745–746},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430613,
author = {Long, Yan and Curtiss, Alexander and Rampazzi, Sara and Hester, Josiah and Fu, Kevin},
title = {Automating decontamination of N95 masks for frontline workers in COVID-19 pandemic: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430613},
doi = {10.1145/3384419.3430613},
abstract = {In response to the N95 mask shortage caused by the COVID-19 pandemic, the US CDC has recognized moist-heat as one of the most effective and accessible methods for decontaminating N95 masks for reuse. However, it is challenging to reliably deploy this technique in healthcare settings due to a lack of specialized equipment capable of ensuring proper decontamination conditions. To this end, we developed a wireless sensor platform for moist-heat decontamination process verification, capable of monitoring hundreds of masks simultaneously in commercially available heating systems. Our easy-to-use, low-power, low-cost, scalable platform can be broadly deployed to protect front-line healthcare workers by lowering their risk of infection from reused N95 masks.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {747–749},
numpages = {3},
keywords = {wireless sensor, N95 masks decontamination, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430601,
author = {Arun, Aditya and Gupta, Agrim and Bhatka, Shivani and Komatineni, Saikiran and Bharadia, Dinesh},
title = {BluBLE, space-time social distancing to monitor the spread of COVID-19: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430601},
doi = {10.1145/3384419.3430601},
abstract = {Social distancing has been the key factor which has helped control the COVID-19 pandemic spread. We present BluBLE, which utilizes Bluetooth Low Energy (BLE) based mobile sensing to help monitor these social distancing protocols. Specifically, we formulate the problem in two parts - spatial and temporal social distancing. The spatial distancing formulation aims to enforce the 6 feet distance recommended by various public health organization around the world. The temporal distancing formulation aims to inform and prevent users from entering high-occupancy regions (hotspots) in buildings. BluBLE achieved more than 80 \% classification accuracy in both the tasks, that is, predicting if a user is within '6' feet of another user as well as characterizing the user's location within a particular hotspot.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {750–751},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430612,
author = {Yoshida, Kenichi and Sato, Akira and Sannomiya, Shuji},
title = {Contact analysis on COVID-19 using a campus network: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430612},
doi = {10.1145/3384419.3430612},
abstract = {In 2020, the COVID-19 pandemic is causing significant problems for our society. Although contact tracing is an essential countermeasure for minimizing exposure, its applications are not widely used in Japan. We have developed a Wi-fi based contact tracing system for use in our campus network to protect students and staff. Although the area covered by Wi-fi technology is too wide to accurately analyze contacts, it can still be used for comparative analysis. We conducted preliminary experiments as an example to compare the effects of countermeasures. Our results show that by making 30\% of classrooms safe, we can reduce the number of potential exposures by over 90\%. This paper summarizes 1) the system design to acquire necessary information while maintaining the privacy of students, and 2) the results of preliminary experiments that compare the effect of countermeasures.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {752–753},
numpages = {2},
keywords = {wi-fi, contact tracing, campus network, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430604,
author = {Yin, Yuqing and Li, Peihao and Yang, Xu and Yan, Faren and Niu, Qiang and Chen, Pengpeng},
title = {COVID-19 tracer: passive close-contacts searching through wi-fi probes: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430604},
doi = {10.1145/3384419.3430604},
abstract = {COVID-19 outbreaks rapidly around the world, which is the enemy faced by all humankind. Since COVID-19 is mainly spread through close personal contact, searching close-contacts is key to controlling this virus's spread. This paper designs COVID-19 Tracer, a novel low-cost passive system for searching COVID-19 patients' close-contacts. Utilizing ubiquitous Wi-Fi probe requests, COVID-19 Tracer can quickly determine whether a person stays in one small space with a COVID-19 patient in the same period. Furthermore, it seeks to find out a close-contact with a novel rang-free judgment algorithm for location similarity. Finally, extensive experiments conducted in a school office building show our system's good performance, and the accuracy in finding out close-contacts is more than 98\%.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {754–755},
numpages = {2},
keywords = {wi-fi probe, tracking, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430611,
author = {Onami, Jun-ichi and Sakaguchi, Koji and Arita, Masanori and Yamaji, Kazutsuna},
title = {Development of the portal site of COVID-19 data in Japan: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430611},
doi = {10.1145/3384419.3430611},
abstract = {The data sharing started from the early phase of the COVID-19 pandemic. Although a large amount of publicly available research data of COVID-19 have been created, their discoverability remains unsolved. The European bioinformatics institute (EMBL-EBI) aims to develop the database catalog site named COVID-19 Data Portal by collecting and organizing the relevant research data and tools information to comply with the FAIR data principles. In Japan, the lack of such venues to exemplify international efforts make the data sharing difficult. In order to facilitate the Japanese contribution and make it more findable, we developed the "COVID-19 Data Portal JAPAN" in collaboration with the original site. This site contains 75 types of research data and related information on COVID-19 from 13 research institutions. Each content is shown with a short description so as to provide user-friendly navigation. This site offers comprehensive access to research data and related information on COVID-19, mainly produced in Japan.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {756–757},
numpages = {2},
keywords = {open science, open data, data sharing, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430600,
author = {Woodward, Kieran and Kanjo, Eiman and Anderez, Dario Ortega and Anwar, Amna and Johnson, Thomas and Hunt, John},
title = {DigitalPPE: low cost wearable that acts as a social distancingreminder and contact tracer: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430600},
doi = {10.1145/3384419.3430600},
abstract = {The novel coronavirus, designated by the World Health Organization as COVID-19 has required many countries around the world to close work spaces, schools and public venues. This has required policy makers and venue managers to investigate practical mitigation strategies using technology to exit the lockdown safely and enable the reopening of public spaces. This paper introduces Digital personal protective equipment (PPE), a dynamic and affordable wearable approach that remind people to keep their distance and keep track of their contact traces. This IoT based BLE probing technique approach empowers employers, city and venue managers to encourage social-distancing and trigger a friendly alert using vibration when social distancing is violated in privacy-preserving manner.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {758–759},
numpages = {2},
keywords = {wearable, social distancing, contact tracing, bluetooth, IoT, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430614,
author = {Istomin, Timofei and Leoni, Elia and Molteni, Davide and Murphy, Amy L. and Picco, Gian Pietro},
title = {Dual-radio discovery and ranging for infrastructure-less social distancing with Janus: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430614},
doi = {10.1145/3384419.3430614},
abstract = {Devices to support social distancing must be energy-efficient and accurate. Bluetooth Low Energy (BLE) meets the first criteria but falls short on the latter. Ultra-wideband (UWB) measures distances with <10 cm error but with relatively high consumption. Therefore, we built Janus, a dual-radio protocol that uses the strengths of each.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {760–761},
numpages = {2},
keywords = {social distancing, ranging, proximity, discovery, UWB, BLE},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430602,
author = {Nakagawa, Yuri and Sripian, Peeraya and Sugaya, Midori},
title = {Evaluation of distance learning on concentration and relax by EEG and HRV: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430602},
doi = {10.1145/3384419.3430602},
abstract = {Distance learning, for which the demand is increasing due to the recent expansion of the COVID-19 pandemic, pointed out the problem of less communication level that it would reduce student's concentration level in the study. However, there is no clear and objective evidence about such effect on the concentration level. In this work, we propose a method to objectively evaluate distance learning with the biometric information to understand the difference of the student's concentration level during the study. We measure the student's electroencephalography (EEG) and heart rate variability (HRV) to evaluate the concentration level by observing the change of student's emotion based on different communication condition during distance learning. In the experiment, we measured EEG and HRV of the students, while turning on and off face-to-face (FTF) video camera. The analysis of EEG and HRV results show that different communication condition effect student's concentration level. We found that their emotional states are different when the video is turned on and off and also found that it could be due to their preferences of the subject.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {762–763},
numpages = {2},
keywords = {heart rate, electroencephalography, distance learning, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430605,
author = {Abid, Amal and Cheikhrouhou, Saoussen and Kallel, Slim and Jmaiel, Mohamed},
title = {How blockchain helps to combat trust crisis in COVID-19 pandemic? poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430605},
doi = {10.1145/3384419.3430605},
abstract = {The COVID-19 pandemic is sweeping across the world and causing widespread death and disruption. To this effect, nations have struggled to use technologies to detect and to monitor COVID-19 cases and related information. Unfortunately, both inconsistent and inaccurate information from "trustless" sources, and "mistrust" in effectively monitoring and reporting patients symptoms and condition have highlighted the failure of existing infrastructures to preserve human healthcare while maintaining patient's privacy and to slow down the widespread of the pandemic. This paper provides an insight of the perceived benefits of Blockchain to expectations of the COVID-19 pandemic in terms of providing "trust" in addressing information sharing in health systems while maintaining privacy. This paper exhibits a Blockchain-based COVID-19 Smart Healthcare approach that embraces Blockchain's benefits in healthcare systems.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {764–765},
numpages = {2},
keywords = {blockchain, COVID-19 pandemic},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430593,
author = {Isoda, Shogo and Kawanaka, Shogo and Matsuda, Yuki and Suwa, Hirohiko and Yasumoto, Keiichi},
title = {How much does human mobility behavior affect the COVID-19 infection spread? poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430593},
doi = {10.1145/3384419.3430593},
abstract = {In this paper, we aim to reveal the relationship between the number of people infected with COVID-19 in each ward in Tokyo and the changes in human mobility behavior using demographic information (population density, number of restaurants, etc.) and mobility data collected from GPS data of residents in Tokyo's 23 wards. The results confirmed that changes in human mobility behavior extracted from mobility data in each ward were an important feature related to the number of people infected by COVID-19 on the previous day's difference. These results suggest that the transition of the number of infected people in COVID-19 is largely due to human mobility behavior.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {766–767},
numpages = {2},
keywords = {location data, human mobility, epidemic, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430597,
author = {Kishino, Yasue and Shirai, Yoshinari and Yanagisawa, Yutaka and Ohara, Kazuya and Mizutani, Shin and Suyama, Takayuki},
title = {Identifying human contact points on environmental surfaces using heat traces to support disinfect activities: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430597},
doi = {10.1145/3384419.3430597},
abstract = {The disinfection of environmental surfaces is an effective countermeasure for COVID-19. In this paper, we use a thermographic camera and lightweight background image processing and propose a method that detects and visualizes the places touched by a person. Our method will support effective disinfection activities.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {768–769},
numpages = {2},
keywords = {thermographic camera, heat trace visualization, camera sensor},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430599,
author = {Chen, Bo-Rong and Hu, Yih-Chun},
title = {Mitigating denial-of-service attacks on digital contact tracing: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430599},
doi = {10.1145/3384419.3430599},
abstract = {Due to the COVID-19 pandemic, many researchers have proposed privacy-preserving smartphone proximity tracing. Current projects, based on ephemeral IDs, are vulnerable to DoS attacks. In this paper, we present BlindSignedIDs that can be verified in-place through a TESLA server. We will demonstrate our BlindSignedIDs can effectively mitigate such DoS attacks.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {770–771},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430591,
author = {Tachibana, Yuriko and Segawa, Norihisa},
title = {Physical distance monitoring system for COVID-19 using raspberry Pi and a monocular camera: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430591},
doi = {10.1145/3384419.3430591},
abstract = {During the global pandemic of coronavirus disease 2019 (COVID-19), it is crucial to minimize the spread of the infection until effective drugs and vaccines are developed. Therefore, close contact must be reduced to prevent human-to-human transmission. We propose a simplified inexpensive system using a monocular camera combined with Raspberry Pi, a small single-board computer, to measure physical distancing and warn people of their proximity with others.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {772–773},
numpages = {2},
keywords = {raspberry pi, physical distancing, neural networks, monocular camera, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430603,
author = {Zhang, Yanping and Wang, Chenghong and Pujol, David and Bater, Johes and Lentz, Matthew and Machanavajjhala, Ashwin and Nayak, Kartik and Vasudevan, Lavanya and Yang, Jun},
title = {Poirot: private contact summary aggregation: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430603},
doi = {10.1145/3384419.3430603},
abstract = {Physical distancing between individuals is key to preventing the spread of a disease such as COVID-19. On the one hand, having access to information about physical interactions is critical for decision makers; on the other, this information is sensitive and can be used to track individuals. In this work, we design Poirot, a system to collect aggregate statistics about physical interactions in a privacy-preserving manner. We show a preliminary evaluation of our system that demonstrates the scalability of our approach even while maintaining strong privacy guarantees.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {774–775},
numpages = {2},
keywords = {private data aggregation, multi-party computation, differential privacy, bluetooth tracing, COVID19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430596,
author = {Kim, Hyunjun and Ko, JeongGil},
title = {Privacy-preserving contact tracing using homomorphic encryption: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430596},
doi = {10.1145/3384419.3430596},
abstract = {Digital contact tracing is an essential countermeasure for an epidemic as a society, and balancing the surveillance resolution and user privacy for contact tracing remains an open challenge. Existing contact tracing schemes are primarily based on proximity tracing, which uses Bluetooth to detect coexistence. Proximity tracing has a strong advantage in anonymizing the users, but shows low epidemiological resolution and lacks the flexibility to be integrated with other data sources. To address this problem, we propose an alternative scheme we phrase as context tracing. Our scheme achieves strong performance in both surveillance resolution and user privacy protection by integrating multi-modal sensor fusion and homomorphic encryption. While this advantage comes at the cost of high computational overhead, we discuss possible optimization strategies for reducing energy consumption on mobile devices.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {776–777},
numpages = {2},
keywords = {homomorphic encryption, epidemic, contact tracing, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430608,
author = {Patel, Kavit and Massa, Kyle and Raghunathan, Nithin and Zhang, Heng and Iyer, Ananth and Bagchi, Saurabh},
title = {Proactive privacy-preserving proximity prevention through bluetooth transceivers: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430608},
doi = {10.1145/3384419.3430608},
abstract = {Many activities in laboratories at Purdue require user movement that cannot be carefully orchestrated or planned out, e.g., in our hardware, manufacturing, or propulsion labs. In such environments, it is challenging for users to consciously maintain the required safe social distance. This project provides a technical approach to proactively monitor the distance between users utilizing the Bluetooth transmission-reception signal strength (RSSI). We use a lightweight machine learning model to map the signal strength to the distance and infer the direction of motion between any two users. The technology builds on a long line of research in the area of wireless signals, some of which has been carried out in our lab. It is lightweight (can be easily carried as a lanyard worn by users), low cost (less than $15 when produced in bulk), privacy preserving (no data need to be shared to any other organizations), proactive (provides warning messages prior to approaching unsafe distance). We have shown its effectiveness in our preliminary experiments.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {778–779},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430592,
author = {Nishiyama, Yuuki and Yonezawa, Takuro and Sezaki, Kaoru},
title = {SelfGuard: semi-automated activity tracking for enhancing self-protection against the COVID-19 pandemic: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430592},
doi = {10.1145/3384419.3430592},
abstract = {Contagious diseases like COVID-19 spread periodically and threaten our lives. Self-protection, such as washing hands, wearing a mask, and staying home, are simple and practical solutions to safeguard against these diseases. Most governments and health departments recommend that people maintain self-protection. Although continuous self-protection effectively prevents the spread of infection, only the intent to self-protect is unsustainable in the long term. In this study, we design, develop, and deploy an application to track users' daily activities semi-automatically and enhance self-protection behavior using mobile sensing and gamified feedback techniques. Currently, more than 324 people have installed the app via AppStore, and 52 users have shared their activity data to our research group.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {780–781},
numpages = {2},
keywords = {self-tracking, mobile sensing, GPS, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430610,
author = {Yang, Lishan and Schmedding, Anna and Pinciroli, Riccardo and Smirni, Evgenia},
title = {Simulating COVID-19 containment measures using the South Korean patient data: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430610},
doi = {10.1145/3384419.3430610},
abstract = {As the COVID-19 outbreak evolves around the world, the World Health Organization (WHO) and its Member States have been heavily relying on staying at home and lock down measures to control the spread of the virus. In last months, various signs showed that the COVID-19 curve was flattening, but the premature lifting of some containment measures (e.g., school closures and telecommuting) are favouring a second wave of the disease. The accurate evaluation of possible countermeasures and their well-timed revocation are therefore crucial to avoid future waves or reduce their duration. In this paper, we analyze patient and route data collected by the Korea Centers for Disease Control \& Prevention (KCDC). We extract information from real-world data sets and use them to parameterize simulations and evaluate different what-if scenarios.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {782–783},
numpages = {2},
keywords = {simulation, geographic information system (GIS), data analysis, coronavirus, agent-based model (ABM), SARS-CoV-2, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430607,
author = {Takezawa, Tomomi and Katahira, Kenji and Kanki, Yuna and Sugimoto, Masashi and Shibuta, Kazuo and Nagata, Noriko and Chiba, Masayoshi and Hamaoka, Kazuki and Fukatsu, Megumi and Kataoka, Satoshi},
title = {Structure of psychological stress during the COVID-19 pandemic and effects of essential oil odor exposure: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430607},
doi = {10.1145/3384419.3430607},
abstract = {This research investigated the psychological stressors during the COVID-19 pandemic and the effects of essential oil odor exposure. In Japan, a stay-at-home restriction order was implemented in May 2020. We sent essential oils to the homes of 30 participants. The participants received emails 5 times a day for 6 days and reported how they felt before and after the essential oil odor exposure. They also reported their circumstances and intentions. Results showed that the vitality and stability levels increased after essential oil odor exposure. Besides, four psychological stress structures were obtained. Some of the participants felt conflicted about balancing housework, childcare, and work. They were the most stressed, and their vitality and stability levels increased considerably.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {784–785},
numpages = {2},
keywords = {stay-at-home restriction order, psychological stress, essential oil odor exposure, COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430606,
author = {Vitello, Piergiorgio and Capponi, Andrea and Klopp, Pol and Connors, Richard D. and Viti, Francesco and Fiandrino, Claudio},
title = {The CORONA business in modern cities: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430606},
doi = {10.1145/3384419.3430606},
abstract = {As a response to the global outbreak of the SARS-COVID-19 pandemic, authorities have enforced a number of measures including social distancing, travel restrictions that lead to the "temporary" closure of activities stemming from public services, schools, industry to local businesses. In this poster we draw the attention to the impact of such measures on urban environments and activities. For this, we use crowdsensed information available from datasets like Google Popular Times and Apple Maps to shed light on the changes undergone during the outbreak and the recovery.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {786–787},
numpages = {2},
keywords = {urban computing, data collection, crowdsensing, SARS-COVID-19},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430609,
author = {Takano, Shigeru and Hori, Maiya and Arakawa, Yutaka and Taniguchi, Rin-ichiro},
title = {Towards ICT based mobility support system with in the COVID-19 era: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430609},
doi = {10.1145/3384419.3430609},
abstract = {Our objective is to achieve a city where everyone can move safely and comfortably by developing and implementing ICT-based mobile support system at the actual transport hub. Our system uses cameras installed at the transport hub to detect people who have difficulty moving, and notifies this information to the transportation staff in real time to help them move more smoothly. This system makes it possible to aggregate and provide information on places that is useful for COVID-19 measures, such as measuring the congestion of places and the social distances of the people who gather there.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {788–789},
numpages = {2},
keywords = {object detection, mobility support system, bus location system},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430615,
author = {Sun, Ruoxi and Wang, Wei and Xue, Minhui and Tyson, Gareth and Ranasinghe, Damith C.},
title = {VenueTrace: a privacy-by-design COVID-19 digital contact tracing solution: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430615},
doi = {10.1145/3384419.3430615},
abstract = {Rapid spread of the COVID-19 pandemic is making traditional manual contact tracing challenging; in response, digital contact tracing mobile apps have been developed by the software industry and promoted by governments and health authorities worldwide. However, deploying contact tracing apps across a population at scale have raised many privacy concerns. In this paper, we propose a venue-access-based contact tracing solution, VenueTrace, which preserves user privacy by designs by: (i) enabling the contact tracing of venue-to-user, instead of user-to-user; (ii) avoiding information exchanges between users; and (iii) ensuring no private data is exposed to back-end servers, while enabling proximity contact tracing.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {790–791},
numpages = {2},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430598,
author = {Cecchet, Emmanuel and Acharya, Amrita and Molom-Ochir, Tergel and Trivedi, Amee and Shenoy, Prashant},
title = {WiFiMon: a mobility analytics platform for building occupancy monitoring and contact tracing using wifi sensing: poster abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430598},
doi = {10.1145/3384419.3430598},
abstract = {With the current COVID-19 pandemic, contact tracing and building occupancy tracking are key components of re-opening policies and quickly containing virus outbreaks. WiFiMon is a network-centric contact tracing method that uses enterprise WiFi networks logs for tracking devices and inferring building occupancy and building contact tracing reports in office and campus settings.We have built WiFiMon on an analytics platform that leverages the popular open source ELK stack (Elasticsearch, Logstash and Kibana) to process syslog data at large scale and offer users dashboards to quickly monitor building occupancy and generate contract tracing reports.WiFiMon has been deployed at several UMass campuses gathering daily data from over 5,000 WiFi access points and tens of thousands of users. Our software is freely available for anyone to use and can be found at https://github.com/umassos/elastic-wifitrace.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {792–793},
numpages = {2},
keywords = {wifi sensing, mobility analytics, contact tracing, ELK stack},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430567,
author = {Boi-Ukeme, Joseph},
title = {A robust discrete event method for the design of cyber-physical systems: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430567},
doi = {10.1145/3384419.3430567},
abstract = {The technological advancement in Cyber-Physical Systems (CPS) has evolved into sophisticated hardware, leading to systems that are complex and interconnected. This trend has made modern CPS susceptible to faults. We present a discrete event method developed using the Discrete Event System Specification (DEVS) to detect, diagnose, and accommodate CPS faults in Real-time. This includes Fault Detection and Diagnosis (FDD), Fault Tolerance (FT) in the control system, and Sensor Fusion in the Sensor system called SAFE},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {794–795},
numpages = {2},
keywords = {fault tolerance, cyber-physical systems, FDD},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430576,
author = {Rathore, Hemant},
title = {Adversarial attacks on malware detection models for smartphones using reinforcement learning: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430576},
doi = {10.1145/3384419.3430576},
abstract = {Malware analysis and detection is a rat race between malware designer and anti-malware community. Most of the current Smartphone antivirus(s) are based on the signature, heuristic and behaviour based mechanisms which are unable to detect advanced polymorphic and metamorphic malware. Recently, researchers have developed state-of-the-art Android malware detection systems based on machine learning and deep learning. However, these models are prone to adversarial attacks which threaten the anti-malware ecosystem. Therefore in this work, we are investigating the robustness of Android malware detection models against adversarial attacks. We crafted adversarial attacks using reinforcement learning against detection models built using a variety of machine learning (classical, bagging, boosting) and deep learning algorithms. We are designing two adversarial attack strategies, namely single-policy and multi-policy attack for white-box and grey-box scenarios which are based on adversary's knowledge about the system. We designed the attack using Q-learning where a malicious application(s) is modified to generate variants which will force the detection models to misclassify them. The goal of the attack policy is to convert maximum Android applications (such that they are misclassified) with minimum modifications while maintaining the functional and behavioural integrity of applications. Preliminary results show an average fooling rate of around 40\% across twelve distinct detection models based on different classification algorithms. We are also designing defence against these adversarial attack using model retraining and distillation.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {796–797},
numpages = {2},
keywords = {smartphones, reinforcement learning, malware analysis and detection, machine learning, adversarial learning},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430574,
author = {Imteaj, Ahmed},
title = {Distributed machine learning for collaborative mobile robots: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430574},
doi = {10.1145/3384419.3430574},
abstract = {The Internet-of-things (IoT) devices and technologies led to a revolutionary breakthrough over the data collection procedure and Machine Learning (ML) approaches of a distributed network. It is preferable to store sensitive data on-device without sharing with a centralized computation agent and carry-out computation at the edge devices to ensure security and privacy. A recently invented distributed ML technique, Federated Learning (FL) holds the same theme that allows the edge devices to perform training on their edges and obtains a final model by learning from the model information of all the distributed edge clients. As the clients' raw data remain at local and models are generated on clients' edge, so it enhances security, privacy, and reduces computation cost in large-scale ML problems. The FL technique deals with various distributed clients that may have statistical heterogeneity and systems heterogeneity. This paper aims at dealing with such heterogeneity within an FL environment by monitoring each client's activities and leveraging resources based on the required computation during the model training phase. For each training round, we consider the proficient and trustworthy client by inspecting their resource-availability and previous history. We assign a trust score to each client based on their performance and update that score after each training period. To bring systems heterogeneity within our FL environment, we consider distributed mobile robots as FL clients with heterogeneous system configurations in terms of memory, processor, bandwidth, or battery life to understand their performance and resource-constraint behavior in a real-world setting. We filter-out the weak clients who cannot perform computation based on their available resources and exclude the untrustworthy clients who has previous record of repeatedly infusing incorrect or diverge model information, or, become stragglers during FL training. After eliminating the stragglers and untrustworthy FL clients, we conduct local training on each selected FL clients. To further mitigate the straggler issue, we enable asynchronous FL technique that can handle the clients' variant response time and continue FL training without waiting for a particular client for a long period.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {798–799},
numpages = {2},
keywords = {straggler, resource-limitations, federated learning (FL), distributed mobile robots, client activity, IoT},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430579,
author = {Hong, Zhiqing},
title = {Generating location data with generative adversarial networks for sensing applications: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430579},
doi = {10.1145/3384419.3430579},
abstract = {The availability of large amounts of data has driven the fast development of many research fields such as computer vision. However, the sharing of location data has been limited due to the concern of data privacy. Cellular location data contains user location information which reflects human mobility patterns. Therefore, in this study, we propose a novel Generative Adversarial Network (GAN) and apply the model to generate cellular location data as a case study for location-based sensing applications. The key insight of this study is that individual mobility correlates with user-specific information, e.g., age, gender. Therefore, to better capture the underlying pattern of human mobility, we design a soft-label conditional GAN which utilizes user-specific information to generate individual movement trajectories. This work plans to train a generator on a large real-world cellular location dataset and evaluate the synthetic data in terms of both utility and privacy.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {800–801},
numpages = {2},
keywords = {location data, human mobility, GANs},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430568,
author = {Bannis, Adeola},
title = {Improving cyber-physical system performance through actuator-sensor interactions: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430568},
doi = {10.1145/3384419.3430568},
abstract = {Cyber-physical systems are used both for sensing the environment around them as well as making changes to that environment (actuation). Interactions between actuators and sensors can create interference or uncertainty, but can also be leveraged to improve the sensing coverage, sensing resolution or capability of a cyber-physical system. The challenge in modifying actuator behavior in a system is to avoid degrading the actuation range or responsiveness. The acceptable range of actuator adaptation can be modelled and tested using physics-based, data-driven, or combination approaches.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {802–804},
numpages = {3},
keywords = {sensing, embodied, cyber-physical, actuation},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430580,
author = {Hu, Zhizhang},
title = {Inferring finer-grained human information with multi-modal cross-granularity learning: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430580},
doi = {10.1145/3384419.3430580},
abstract = {Existing machine learning algorithms for human information inference are typically data-driven models trained on carefully labeled datasets. Given the significant labeling effort, traditional pure data-driven approaches are challenging to implement for emerging smart applications requiring long-term finer-grained information. Taking activities of daily life (ADL) tracking for elders as an example, prior work mostly focused on context-level information learning such as cooking and cleaning. [8]. However, new applications such as evaluating elders' cognitive impairments progress by tracking their ADL engagement requires finer-grained, i.e., action-level information [7]. In practice, labeling the day-length data at such granularity can be very expensive and requires a lot of human efforts [9]. My research focuses on the inference problems in the scope of human physical condition monitoring and activity recognition with limited labeled data. To alleviate the effort of labeling large amounts of data, prior works on semi-supervised learning combine a small amount of labeled data with a large amount of unlabeled data to train the model. However, as the label granularity (number of classes) increasing, the difficulty to distinguish nuance distinctions between finer-grained classes escalates as well. This makes training a robust semi-supervised model for finer-grained classification with less labels difficult if not impossible. Fortunately, coarse-grained (context-level) labels is usually available or cheaper to obtain in practice. In this case, the multi-granularity hierarchy between finer and coarse labels follows the aggregation relation defined in [5]. This hierarchical relation can be leveraged in the tasks of inferring finer-grained information. In addition, it is illustrated by the previous study that co-located multi modality sensing systems capture complementary aspects of the same event [6]. The research question I focus on is how to infer finer-grained human information with coarse-grained labeled data leveraging complementary multi-modal sensing? I target three directions: 1) a cross-granularity semi-supervised setting: how to utilize coarse-grained labeled data with a small amount of finer-grained labeled data to infer finer-grained human information, 2) cross-granularity relationship learning: how to learn the multi-granularity class hierarchy from data and further help the finer-grained human information acquisition, 3) enhancing inference granularity by leveraging multi-model sensing: how to leverage the complimentary co-located multiple sensing modalities to accurately infer finer-grained human information?},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {805–806},
numpages = {2},
keywords = {semi-supervised learning, multimodal learning, human information inference, cross-granularity learning},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430577,
author = {Hamdhana, Defry},
title = {Mobile application for caregiver in collecting statistical data of BPSD attack focused on macro activities: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430577},
doi = {10.1145/3384419.3430577},
abstract = {BPSD affects Dementia patients often and varies. It is needed a best and suit treatment from doctors to handle BPSD attack toward Dementia patients. Therefore, to obtain accurate data of patients in daily care, caregivers are expected to conduct monitoring activities by recording the disorders attack through a mobile application. This study will be focused on several macro activities of BPSD, namely Agitation, Hallucination, Depression, Sleep, Anxiety, and Apathy. The monitoring will be about the duration and the quantity of the disorder happened. It will be recorded based on real-time. Every seven days, the data will be collected and processed into statistical data showing the inclination of BPSD attack. This statistical data will be the basis for doctors in providing and deciding further treatments for the next seven days.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {807–808},
numpages = {2},
keywords = {monitoring activities, macro activities, dementia, caregiver, BPSD},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430578,
author = {Faiz, Farina},
title = {Multilabel classification in human activity recognition: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430578},
doi = {10.1145/3384419.3430578},
abstract = {Human activities become very difficult to handle when they appear without proper temporal information. A smarter approach is to handle this problem is using multilabel classification. However, most of the multilabel methods are suitable for text data which is very different from activity data. Our research focuses on finding some discriminative approach to make the efficient use of multilabel methods. Our intuition is that a relevance between labels and features is needed to be explored in case of predicting multiple labels, as features are the most important aspects that increase model's performance. In this paper, we proposed a feature selection approach based on feature label relevance method (FLRM) that outperforms an existing feature selection method. We utilized feature-label relevance so that we could find the best fitted features associated with each label.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {809–810},
numpages = {2},
keywords = {multilabel classification, feature-label relevance},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430571,
author = {Bonde, Amelie},
title = {Noise-tolerant and context-aware structural vibration based activity monitoring: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430571},
doi = {10.1145/3384419.3430571},
abstract = {Automated monitoring of humans and animals can facilitate better health and productivity. Prior monitoring approaches use video, which requires line-of-sight and high processing power, or motion detection, which has difficulty separating subtle activities. Wearable sensors can address these issues but are vulnerable to animal destructiveness and human forgetfulness. We present a system that uses structural vibration to monitor animal or human behavior. We use domain knowledge to adapt this system to different environments, and evaluate it on humans in a home office environment and on pigs at an operational pig farm.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {811–812},
numpages = {2},
keywords = {vibration, ubiquitous sensing, human monitoring, animal monitoring},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430566,
author = {Papst, Franz},
title = {Privacy-preserving machine learning for time series data: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430566},
doi = {10.1145/3384419.3430566},
abstract = {Machine learning has a lot of potential when applied to time series sensor data, yet a lot of this potential is currently not utilized, due to privacy concerns of parties in charge of this data. In this work I want to apply privacy-preserving techniques to machine learning for time series data, in order to unleash the dormant potential of this type of data.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {813–814},
numpages = {2},
keywords = {time series data, sensor data, privacy preserving machine learning},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430572,
author = {Fikry, Muhammad},
title = {Requirements analysis for reminder system in daily activity recognition dementia: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430572},
doi = {10.1145/3384419.3430572},
abstract = {Technology assistance refers to all tools or systems that allow a people with dementia to carry out their daily activities in order to increase convenience and security in these activities. Dementia is a condition of a collection of symptoms of irreversible brain damage that occurs over a relatively long time period, resulting in problems concentrating, planning or organizing daily activities. This paper is focused on estimating daily activity recognition time by considering the feasibility of activity types, feature extraction techniques for speech recognition, and the design effectiveness of a system that is easy to use by people with dementia. The results from activity recognition need to be further analyzed to find the best pattern for people with dementia. After that, monitoring applications can develop into prevention of abnormal activity in dementia.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {815–816},
numpages = {2},
keywords = {text to speech, technology assistance, speech recognition, reminder system, activity recognition},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430569,
author = {Liu, Jingxiao},
title = {Scalable bridge health monitoring using drive-by vehicles: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430569},
doi = {10.1145/3384419.3430569},
abstract = {The objective of my thesis work is to develop physics-guided data-driven approaches for drive-by bridge health monitoring (BHM) that are scalable and eliminate the need of acquiring training data from every bridge. BHM allows us to detect bridge damage in earlier stages, which is essential for preventing more severe damage and collapses that may lead to significant business and human losses. Using vibrations from drive-by vehicles for BHM has various advantages, such as: economical and no need for on-site maintenance of equipment on bridges. However, many such approaches face analysis challenges for monitoring multiple bridges because 1) they either require labeled data from each bridge, which is expensive and time-consuming to collect, or 2) if we directly apply the supervised model trained for one bridge to other bridges, damage diagnostic accuracy could significantly reduce because of distribution mismatch between different bridges' data. In this work, I overcome the first challenge by leveraging physical insights about the vehicle-bridge interaction (VBI) to guide the data-driven approach and diagnose damage in a semi-supervised way. Also, I overcome the second challenge through a domain adversarial training and multi-task learning framework. The framework extracts features that are sensitive to damages and invariant across bridges to monitor multiple bridges without the need for training data from every bridge.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {817–818},
numpages = {2},
keywords = {vehicle-bridge interaction, multi-task learning, domain adversarial training, bridge health monitoring},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430565,
author = {Mammen, Priyanka Mary},
title = {Scalable mHealth technologies for public health monitoring: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430565},
doi = {10.1145/3384419.3430565},
abstract = {The proliferation of mobile sensing devices due to advances in the Internet of Things has the potential to transform the individual-centric health monitoring to community-scaled health monitoring. Contrary to the state-of-the-art mobile health sensing, which focuses on individuals, my research focuses on scaling mobile health technologies to community scale, where we monitor the health of an entire community or population of users. The benefits of adopting community-scale sensing are two folds; firstly, it enables aggregate public health monitoring of large groups which can answer broader health problems; secondly, it improves personalized health monitoring with fine-grain monitoring of individuals.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {819–820},
numpages = {2},
keywords = {mHealth, IoT},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430573,
author = {Yan, Wenqing},
title = {Towards robust and low-complexity radiometric fingerprint: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430573},
doi = {10.1145/3384419.3430573},
abstract = {Authentication is challenging in the IoT because most advanced cryptographic algorithms are difficult to afford by constrained devices expected to run many months or years. Radiometric signatures have been used effectively to identify wireless devices based on imperfections in electronic circuits. This technique is also known as Radio frequency (RF) fingerprinting. Previous work proves the feasibility of this technique but mainly considered static channel conditions. In our current work, we systematically and experimentally study the impact of dynamic and complex channel conditions on the radiometric signatures. The results show a threat to identification accuracy for modulation error-based fingerprinting that was considered channel-resilient. Next step, my research aims at improving the robustness of RF fingerprint systems and make this authentication solution ready for widespread implementation.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {821–822},
numpages = {2},
keywords = {radio frequency (RF) fingerprint, physical-layer security, authentication},
location = {Virtual Event, Japan},
series = {SenSys '20}
}
@inproceedings{10.1145/3384419.3430570,
author = {Park, Jung Wook},
title = {Uncovering opportunities for energy harvesting technologies: PhD forum abstract},
year = {2020},
isbn = {9781450375900},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3384419.3430570},
doi = {10.1145/3384419.3430570},
abstract = {Many ubiquitous computing technologies have been developed, but we are not yet living in the world Mark Weiser envisioned---seamless integration of electronics into everyday objects. One of the reasons is that the systems being developed have various energy constraints. I propose one approach to solve this problem, a concept called Compute-proximal Energy Harvesting, and applied it to the automobiles. In carrying out this work, I realized various barriers associated with energy harvesting, and I propose a comprehensive energy harvesting tools to overcome them.},
booktitle = {Proceedings of the 18th Conference on Embedded Networked Sensor Systems},
pages = {823–824},
numpages = {2},
keywords = {toolkit, energy harvesting, compute-proximal energy harvesting},
location = {Virtual Event, Japan},
series = {SenSys '20}
}