
@INPROCEEDINGS{10577411,
  author={Yu, Xiaofan and Thomas, Anthony and Moreno, Ivannia Gomez and Gutierrez, Louis and Rosing, Tajana Šimunić},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Intelligence Beyond the Edge using Hyperdimensional Computing}, 
  year={2024},
  volume={},
  number={},
  pages={1-13},
  abstract={On-device learning has emerged as a prevailing trend that avoids the slow response time and costly communication of cloud-based learning. The ability to learn continuously and indefinitely in a changing environment, and with resource constraints, is critical for real sensor deployments. However, existing designs are inadequate for practical scenarios with (i) streaming data input, (ii) lack of supervision and (iii) limited on-board resources. In this paper, we design and deploy the first on-device lifelong learning system called LifeHD for general IoT applications with limited supervision. LifeHD is designed based on a novel neurally-inspired and lightweight learning paradigm called Hyperdimensional Computing (HDC). We utilize a two-tier associative memory organization to intelligently store and manage high-dimensional, low-precision vectors, which represent the historical patterns as cluster centroids. We additionally propose two variants of LifeHD to cope with scarce labeled inputs and power constraints. We implement LifeHD on off-the-shelf edge platforms and perform extensive evaluations across three scenarios. Our measurements show that LifeHD improves the unsupervised clustering accuracy by up to 74.8% compared to the state-of-the-art NN-based unsupervised lifelong learning baselines with as much as 34.3x better energy efficiency. Our code is available at https://github.com/Orienfish/LifeHD.},
  keywords={Accuracy;Merging;Artificial neural networks;Organizations;Energy efficiency;Vectors;Sensor systems;Edge Computing;Lifelong Learning;Hyperdimensional Computing},
  doi={10.1109/IPSN61024.2024.00005},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577334,
  author={Dai, Yimin and Tan, Rui},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={FedCFC: On-Device Personalized Federated Learning with Closed-Form Continuous-Time Neural Networks}, 
  year={2024},
  volume={},
  number={},
  pages={14-26},
  abstract={Closed-form continuous-time (CFC) neural networks have superior expressivity in modeling time series data compared with recurrent neural networks. CFC’s lower training and inference overheads also make it appealing for microcontroller-based platforms. This paper proposes FedCFC, which advances CFC from the centralized learning setting to the federated learning paradigm. FedCFC features a novel and communication-efficient aggregation strategy to address the problem of class distribution skews across clients’ training data. The strategy is designed based on a new empirical property of CFC identified in this paper, i.e., involatility of a sub-network of CFC with respect to training data’s class distribution. Extensive evaluation based on multiple time series datasets shows that FedCFC achieves higher or similar accuracy with 7.6× to 11× reduction in communication overhead, compared with recent federated learning approaches designed to address the class distribution skew problem. Implementations of FedCFC on four microcontroller platforms show its portability to low-end computing devices with 256kB memory and even less.},
  keywords={Training;Performance evaluation;Recurrent neural networks;Federated learning;Microcontrollers;Time series analysis;Memory management;Continuous-time neural network;federated learning;time series processing;edge computing},
  doi={10.1109/IPSN61024.2024.00006},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577356,
  author={Jiang, Siyang and Shuai, Xian and Xing, Guoliang},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={ArtFL: Exploiting Data Resolution in Federated Learning for Dynamic Runtime Inference via Multi-Scale Training}, 
  year={2024},
  volume={},
  number={},
  pages={27-38},
  abstract={Federated Learning (FL) has emerged as a prominent paradigm for distributed machine learning, crucial for mission-critical applications such as autonomous driving and smart health. However, existing FL systems have not adequately addressed the dynamic real-time requirements of these applications due to stringent inference deadlines and resource limitations on edge devices. In this paper, we propose ArtFL, a novel federated learning system designed to support dynamic runtime inference through multi-scale training. The key idea of ArtFL is to utilize the data resolution, i.e., frame resolution of videos, as a knob to accommodate dynamic inference latency requirements. Specifically, we initially propose data-utility-based multi-scale training, allowing the trained model to process data of varying resolutions during inference. Subsequently, we introduce an innovative strategy for frame resolution selection in inference, based on the similarity of adjacent frames. Finally, leveraging latency-based dynamic data dropping, we propose a systematic scheme to reduce the overall training time by shortening the waiting time in FL. For evaluation, we build two real-world FL testbeds for smart vehicles and healthcare applications, utilizing a heterogeneous edge platform. Extensive experiments across our testbeds and three public datasets show that ArtFL outperforms state-of-the-art baselines in overall accuracy and system performance up to 36.36% and 47.81%, respectively. A demo video of ArtFL on our smart vehicle testbed is available at https://youtu.be/eeK6yRVEG3U, and our code is available at https://github.com/siyang-jiang/ArtFL.git.CCS CONCEPTS• Computing methodologies → Machine learning.},
  keywords={Training;Runtime;Systematics;Federated learning;System performance;Smart healthcare;Real-time systems;Federated Learning System;Multi-Scale Training;Real-time System},
  doi={10.1109/IPSN61024.2024.00007},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577304,
  author={Rostami, Mohammad and Liu, Alan and Sundaresan, Karthikeyan},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Scalable Acoustic IoT through Composable Distributed Beamforming Tags}, 
  year={2024},
  volume={},
  number={},
  pages={39-50},
  abstract={With the proliferation of smart acoustic devices in everyday environments, low-power acoustic tags offer a promising choice for IoT applications. However, their highly limited operational range, throughput, and energy efficiency significantly restrict their viability for practical applications. In this work, we propose a first-of-its-kind distributed acoustic system called Disco. It consists of several low-power acoustic tags that can be flexibly composed on-demand to create an aperture array capable of distributed beamforming. The innovation of Disco lies in creating a ‘virtual’ distributed 2-speaker system that serves to wirelessly synchronize and enable distributed temporal beamforming at the tags independently. The low-power tags of Disco are prototyped with simple acoustic and analog-digital elements to create arrays comprising up to 8 tags. The beamforming performance of Disco scales with the number of tags in the array, delivering a multiple-fold increase in range, throughput, and energy efficiency. This advancement brings acoustic IoT applications closer to practical implementation.},
  keywords={Wireless communication;Wireless sensor networks;Technological innovation;Array signal processing;Throughput;Acoustic arrays;Acoustics},
  doi={10.1109/IPSN61024.2024.00008},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577348,
  author={Wang, Haoyu and Wang, Jiazhao and Gao, Demin and Jiang, Wenchao},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={NNCTC: Physical Layer Cross-Technology Communication via Neural Networks}, 
  year={2024},
  volume={},
  number={},
  pages={51-62},
  abstract={Cross-technology communication (CTC) enables seamless interactions between diverse wireless technologies. Most existing work is based on reversing the transmission path to identify the appropriate payload to generate the waveform that the target devices can recognize. However, this method suffers from many limitations, including dependency on specific technologies and the necessity for intricate algorithms to mitigate distortion. In this work, we present NNCTC, a Neural-Network-based Cross-Technology Communication framework inspired by the adaptability of trainable neural models in wireless communications. By converting signal processing components within the CTC pipeline into neural models, the NNCTC is designed for end-to-end training without requiring labeled data. This enables the NNCTC system to autonomously derive the optimal CTC payload, which significantly eases the development complexity and showcases the scalability potential for various CTC links. Particularly, we construct a CTC system from Wi-Fi to ZigBee. The NNCTC system outperforms the well-recognized WEBee and WIDE design in error performance, achieving an average packet reception rate (PRR) of 92.3% and an average symbol error rate (SER) as low as 1.3%.},
  keywords={Wireless communication;Training;Adaptation models;Wireless sensor networks;Target recognition;Zigbee;Symbols;Cross-Technology Communication;Neural Network;Physical Layer;WiFi OFDM},
  doi={10.1109/IPSN61024.2024.00009},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577311,
  author={Chávez Tapia, Miguel A. and Xu, Talia and Zamalloa, Marco Zúñiga},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Sol-Fi: Enabling Joint Illumination and Communication in Enclosed Areas with Sunlight}, 
  year={2024},
  volume={},
  number={},
  pages={63-74},
  abstract={Consider an enclosed area, such as a room without windows. During the day, artificial light can provide illumination and communication thanks to advances in Visible Light Communication (VLC). Artificial lighting, however, has some drawbacks compared to using daylight in enclosed spaces. First, using sunlight consumes less power. Second, the use of natural light improves the health and comfort of the occupants. We propose a system, dubbed Sol-Fi, to provide joint illumination and communication in enclosed spaces using sunlight. Sol-Fi relies on two main components: commercial sunlight collectors and a novel transmitter to modulate ambient light. The sunlight collectors utilize optical fibers to guide natural light from open to enclosed spaces, and our transmitter modulates the incoming light providing two novel features. First, to analyze the pros and cons of the optical devices used in the literature for ambient light communication, Sol-Fi examines the properties of Liquid Crystals (LCs) and Digital Micro Mirror Devices (DMDs). Second, to investigate the trade-off between single- and multi-band communication, Sol-Fi proposes an optical design that can modulate the entire spectrum or divide it into different (individually modulated) bands. Our evaluation shows that, depending on the number of bands (single or dual) and the type of modulator (LC or DMD), Sol-Fi provides a data rate between 0.8 to 80 kbps, a range between 0.5 to 5 m, and a field-of-view between 30° to 60°.},
  keywords={Wireless communication;Optical design;Modulation;Information processing;Artificial light;Liquid crystal devices;Optical transmitters},
  doi={10.1109/IPSN61024.2024.00010},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577385,
  author={Hu, Jiawei and Wang, Yanxiang and Jia, Hong and Jiang, Cheng and Hassan, Mahbub and Kusy, Brano and Hu, Wen},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={LiDARSpectra: Synthetic Indoor Spectral Mapping with Low-cost LiDARs}, 
  year={2024},
  volume={},
  number={},
  pages={75-87},
  abstract={We introduce LiDARSpectra, a novel approach utilizing mobile-integrated commodity Light Detection and Ranging (LiDAR) signals for synthetic indoor light spectral mapping. Our method incorporates an innovative material estimation algorithm into the LiDAR signal processing pipeline, accurately simulating reflected wavelengths from indoor surfaces. Utilizing low-resolution LiDAR scans enriched with material information, it eliminates the need for deploying dedicated spectral sensors, greatly simplifying the spectral mapping process. We validate our synthetic spectral maps against real sensor data and demonstrate their utility in applications such as indoor localization and solar energy provisioning. This presents an efficient solution for indoor spectral mapping with wide-ranging potential across fields like lighting design, indoor planting, environmental monitoring, and location-based services.},
  keywords={Location awareness;Solid modeling;Technological innovation;Laser radar;Three-dimensional displays;Surface waves;Computational modeling;LiDAR;Synthetic Spectral Indoor Mapping;Visible Light Based Sensing},
  doi={10.1109/IPSN61024.2024.00011},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577357,
  author={Duan, Lin and Chen, Ying and Qu, Zhehan and McGrath, Megan and Ehmke, Erin and Gorlatova, Maria},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={BiGuide: A Bi-level Data Acquisition Guidance for Object Detection on Mobile Devices}, 
  year={2024},
  volume={},
  number={},
  pages={88-100},
  abstract={Object detection (OD) is crucial for numerous emerging visual sensing applications. As OD models trained on unrepresentative data usually yield poor performance, collecting high-quality data in the local environment is recognized to be essential for improving model accuracy. Yet, the question of how to collect this data is currently largely overlooked; unsupported data collection tends to produce datasets with a significant proportion of redundant or uninformative data, hindering effective model training. To address this challenge, we design a real-time data importance estimation method and integrate it into BiGuide, a bi-level image data acquisition system we create for OD tasks. BiGuide assesses the importance of the captured images in real-time based on informativeness and diversity estimations and dynamically guides users in collecting useful data via image-level and object instance-level guidance. We prototype BiGuide in an edge-based architecture using commodity smartphones as mobile clients, and evaluate its performance via an IRB-approved study with 20 users. Our evaluation demonstrates that OD models trained on the data collected by BiGuide outperform models trained on the data collected by two baseline systems, achieving detection accuracy improvements of up to 33.07% and 14.57%, respectively. Over 85% of the users found BiGuide fast, helpful, and easy to understand and follow.},
  keywords={Training;Accuracy;Image edge detection;Data acquisition;Estimation;Object detection;Data models;Data acquisition;visual sensing;informativeness and diversity estimation;user guidance;object detection},
  doi={10.1109/IPSN61024.2024.00012},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577378,
  author={Jiang, Jinyan and Wang, Jiliang and Liu, Yihao and Chen, Yijie and Liu, Yunhao},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={WiCloak: Protect Location Privacy of WiFi Devices}, 
  year={2024},
  volume={},
  number={},
  pages={101-112},
  abstract={The rapid development of WiFi localization poses a serious privacy threat, as eavesdroppers can locate WiFi devices without their consent. In this paper, we present WiCloak, the first system that protects WiFi device location privacy while supporting normal WiFi communication simultaneously. The high-level idea of WiCloak is to inject a fake channel into WiFi CSI at the transmitter, which renders the CIR and time information obtained by eavesdroppers meaningless. We mathematically prove that the injected fake channel is effective in any wireless environment and can strictly protect the location privacy of WiFi devices. To simultaneously support communication for commercial WiFi receivers, we propose a method to cancel out the fake channel impacts in decoding and prove that the method should not impact communication performance. WiCloak can work on commercial WiFi devices without any hardware modification. We evaluate the communication performance of WiCloak on commercial WiFi receivers (e.g., MacBook and Mac Studio) and demonstrate that it achieves the same packet reception rate as normal WiFi. We show that WiCloak increases the localization error by 22× to normal WiFi.},
  keywords={Location awareness;Performance evaluation;Wireless communication;Privacy;Transmitters;Receivers;Reflection;WiFi Sensing;Location Privacy},
  doi={10.1109/IPSN61024.2024.00013},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577309,
  author={Yan, Haotian and Hu, Haibo and Ye, Qingqing},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Time-Specific Integrity Service in MQTT Protocol}, 
  year={2024},
  volume={},
  number={},
  pages={113-125},
  abstract={Message Queuing Telemetry Transport (MQTT) is a classic transmission protocol in IoT scenarios, where a subscriber subscribes to the messages, and a publisher publishes the message to the broker, who then sends the message to the subscriber. In MQTT, it is essential to ensure its security in the temporal domain. On one hand, some messages are time-sensitive, so their integrity should only be valid in a determined time interval. On the other hand, when the subscriber is out of the service, his key should not be able to verify the message, which is known as subscriber validity. This paper discusses the time-specific integrity service in the MQTT protocol. To solve the problem, we propose Time-specific Signcryption (TSSC) and the Dynamic Time-specific Signature (DTSS). Furthermore, a Progressive Dynamic Time-specific Signature scheme (Pro-DTSS) is proposed to save communication costs. The theoretical and experimental results show that our proposed schemes are more efficient than the existing solutions.},
  keywords={Surveys;Lead acid batteries;Protocols;Costs;Production;Information processing;Companies;Internet of Things;Message Queuing Telemetry Transport;Timed Integrity;Message Integrity;Subscriber Validity},
  doi={10.1109/IPSN61024.2024.00014},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577355,
  author={Watson, Jean-Luc and Agrawal, Saharsh and Tsang, Ryan and Luo, Sherry and Popa, Raluca Ada and Dutta, Prabal},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Retcon: Live Updates for Embedded Event-Driven Applications}, 
  year={2024},
  volume={},
  number={},
  pages={126-137},
  abstract={Embedded systems are deeply integrated into critical applications but, despite their importance, lack an effective means to apply over-the-air software patches without significant downtime. Standard mechanisms for firmware updates require device reboots that wipe important in-memory state. Prior efforts have proposed "live" updates to address this problem, applying patches to an embedded application without a reset, but they tackle a limited set of applications or propose a clean-slate design. In this paper, we present Retcon, a live update toolchain for embedded systems that supports a familiar event-driven programming model and does not require application code changes. Retcon leverages static analysis at compile time to determine when it will be safe to update a device. To find safe update points in the presence of complex asynchronous behavior, we define a novel system state, asynchronous quiescence, in which an update can be applied. We evaluate Retcon on a set of embedded event-driven applications – a dual-chamber pacemaker model, a programmable logic controller runtime, an artificial pancreas system, and a sensing node – and demonstrate Retcon’s ability to make low-overhead updates in less than one millisecond.},
  keywords={Performance evaluation;Runtime;Embedded systems;Wireless networks;Programmable logic devices;Static analysis;Software;Live updates;Embedded systems;Static analysis;Embedded OS;Firmware update},
  doi={10.1109/IPSN61024.2024.00015},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577421,
  author={Brunner, Hannah and de Winkel, Jasper and Boano, Carlo Alberto and Pawełczak, Przemysław and Römer, Kay},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Simba: A Unified Framework to Explore and Facilitate the Design of Battery-Free Systems}, 
  year={2024},
  volume={},
  number={},
  pages={138-150},
  abstract={Battery-free sensing devices have gained growing popularity as they can operate relying solely on harvested energy and environmentally friendly capacitors. However, despite the increasing number of battery-free solutions, their design remains a difficult task. In fact, the limited energy storage capacity and the resulting coupling between energy supply and demand introduce new design trade-offs that cannot be explored using conventional tools that consider a constant power supply. To enable fast design space exploration and facilitate the development of battery-free systems, we introduce Simba, an open-source simulation framework that allows to investigate in detail the complex interplay between various device components. We demonstrate the benefits of Simba in two case studies, evaluated experimentally, targeting real-world, state-of-the-art battery-free devices. First, we illustrate how Simba can explore the dependencies between different component configurations and assess their impact on the overall system performance. Among others, we show that changing the storage capacity or slightly modifying the load behavior can improve data throughput by a factor of up to 5.1x and 9.7x, respectively. Second, we present how Simba allows to automatically select key parameters that optimize the operations of a battery-free system (e.g., its checkpointing mechanism), and showcase how Simba enables performance evaluations based on real-world energy harvesting traces.CCS CONCEPTS• Computer systems organization → Embedded systems.},
  keywords={Performance evaluation;Supply and demand;Power supplies;System performance;Organizations;Throughput;Space exploration;Battery-Free Systems;Sensor Nodes;Simulator},
  doi={10.1109/IPSN61024.2024.00016},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577374,
  author={Li, Yin and Reddy, Rohan and Zhang, Cheng and Nandakumar, Rajalakshmi},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Beyond-Voice: Towards Continuous 3D Hand Pose Tracking on Commercial Home Assistant Devices}, 
  year={2024},
  volume={},
  number={},
  pages={151-162},
  abstract={The surging popularity of home assistants and their voice user interface (VUI) have made them an ideal central control hub for smart home devices. However, current form factors heavily rely on VUI, which poses accessibility and usability issues; some latest ones are equipped with additional cameras and displays, which are costly and raise privacy concerns. These concerns jointly motivate Beyond-Voice, a novel high-fidelity acoustic sensing system that allows commodity home assistant devices to track and reconstruct hand poses continuously. It transforms the home assistant into an active sonar system using its existing onboard microphones and speakers. We feed a high-resolution range profile to the deep learning model that can analyze the motions of multiple body parts and predict the 3D positions of 21 finger joints, bringing the granularity for acoustic hand tracking to the next level. It operates across different environments and users without the need for personalized training data. A user study with 11 participants in 3 different environments shows that Beyond-Voice can track joints with an average mean absolute error of 16.47mm without any training data provided by the testing subject.},
  keywords={Three-dimensional displays;Tracking;Training data;Transforms;User interfaces;Acoustics;Sensors;acoustic sensing;wireless perception;hand pose estimation},
  doi={10.1109/IPSN61024.2024.00017},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577316,
  author={Sen, Argha and Das, Anirban and Pradhan, Swadhin and Chakraborty, Sandip},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Continuous Multi-user Activity Tracking via Room-Scale mmWave Sensing}, 
  year={2024},
  volume={},
  number={},
  pages={163-175},
  abstract={Continuous detection of human activities and presence is essential for developing a pervasive interactive smart space. Existing literature lacks robust wireless sensing mechanisms capable of continuously monitoring multiple users’ activities without prior knowledge of the environment. Developing such a mechanism requires simultaneous localization and tracking of multiple subjects. In addition, it requires identifying their activities at various scales, some being macro-scale activities like walking, squats, etc., while others are micro-scale activities like typing or sitting, etc. In this paper, we develop a holistic system called MARS using a single Commercial off-the-shelf (COTS) Millimeter Wave (mmWave) radar, which employs an intelligent model to sense both macro and micro activities. In addition, it uses a dynamic spatial time-sharing approach to sense different subjects simultaneously. A thorough evaluation of MARS shows that it can infer activities continuously with an accuracy of > 93% and an average response time of ≈ 2 sec, with 5 subjects and 19 different activities.},
  keywords={Wireless communication;Mars;Wireless sensor networks;Accuracy;Millimeter wave radar;Radar tracking;Sensors;mmWave;FMCW Radar;Multi-user Activity Recognition},
  doi={10.1109/IPSN61024.2024.00018},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577404,
  author={Ahn, Junick and Kim, Daeyong and Cha, Hojung},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Split Learning-based Sound Event Detection in Energy-Constrained Sensor Devices}, 
  year={2024},
  volume={},
  number={},
  pages={176-187},
  abstract={Sound event detection (SED) using lightweight sensor device has recently gained attention as a practical means to capture context and activities especially in domestic environments. However, SED applications running on sensor device are severely constrained by device’s energy capacity. One solution is to offload a portion of inference to server for reducing runtime complexity, i.e., energy consumption, of sensor device. Offloading should consider the trade-off between computation and data transmission costs adequately; more computation on sensor device reduces data to be transmitted and vice versa. To address this challenge, we propose SEDAC (Sound Event Detection with Attention-based audio Compression), a novel technique for split learning in SED that compresses data from sensor device to offload less data. SEDAC compresses the input of SED models, or Mel spectrograms, with minimal computation in sensor device. Rather than directly compressing the input, SEDAC achieves data compression by selectively capturing the key parts of sound events using an attention mechanism. The scheme also modifies an existing loss function and employs knowledge distillation to mitigate potential loss of SED accuracy due to data compression. Our evaluation shows that SEDAC outperforms the state-of-the-art data compressive split learning schemes, up to about 30%. Furthermore, our real-world deployment demonstrates that sensor devices with SEDAC successfully operate with minimal energy and memory overhead.},
  keywords={Training;Performance evaluation;Runtime;Event detection;Information processing;Libraries;Hardware;Sound event detection;Model compression;Split learning;Sensor application;Energy-efficient system},
  doi={10.1109/IPSN61024.2024.00019},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577321,
  author={Deng, Yongheng and Wang, Guanbo and Yue, Sheng and Rao, Wei and Zu, Qin and Wang, Wenjie and Chen, Shuai and Ren, Ju and Zhang, Yaoxue},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={RelayRec: Empowering Privacy-Preserving CTR Prediction via Cloud-Device Relay Learning}, 
  year={2024},
  volume={},
  number={},
  pages={188-199},
  abstract={Click-through rate (CTR) prediction holds paramount importance across numerous applications, profoundly impacting user experience and business profitability. The freshness of a CTR prediction model significantly influences its performance, since users’ needs and interests may be changing over time, thereby requiring the model to be updated frequently. However, stringent data protection regulations have constrained the collection of users’ personal data, posing challenges to traditional model refreshing strategies that rely on centralized data collection. On-device learning techniques, such as federated learning (FL), offer a viable solution by enabling model training on devices without compromising user privacy. Nevertheless, the scarcity of training data with diverse distributions among devices presents considerable obstacles to on-device learning effectiveness. To address these challenges, we introduce RelayRec, a cloud-device relay learning framework designed for privacy-preserving CTR prediction. To establish competent initial models for devices, RelayRec categorizes pre-regulation cloud data into user preference groups, training preference-specific models for devices. Furthermore, a cloud-based automated model selector is developed to identify suitable initial models for devices. To elevate the relay learning performance of these initial models, we incorporate a personalized collaborative learning mechanism that aggregates device models based on user preferences. Extensive experimental evaluations underscore RelayRec’s superior performance compared to state-of-the-art benchmarks, affirming its efficacy in privacy-preserving CTR prediction.},
  keywords={Performance evaluation;Training;Cloud computing;Federated learning;Training data;Predictive models;Data models},
  doi={10.1109/IPSN61024.2024.00020},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577323,
  author={Sun, Tong and Li, Borui and Teng, Yixiao and Gao, Yi and Dong, Wei},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={dTEE: A Declarative Approach to Secure IoT Applications Using TrustZone}, 
  year={2024},
  volume={},
  number={},
  pages={200-212},
  abstract={Internet of Things (IoT) applications have recently been widely used in safety-critical scenarios. To prevent sensitive information leaks, IoT device vendors provide hardware-assisted protections, called Trusted Execution Environments (TEEs), like ARM Trust-Zone. Programming a TEE-based application requires separate code for two components, significantly slowing down the development process. Existing solutions tackle this issue by automatic code partition while not successfully applying it in two complicated scenarios: adding trusted logic and interactions with secure peripherals.We propose dTEE, a declarative approach to secure IoT applications based on TrustZone. dTEE proposes a rapid approach that enables developers to declare tiered-sensitive variables and functions of existing applications. Besides, dTEE automatically transforms device drivers into trusted ones. We evaluate dTEE on four real-world IoT applications and seven micro-benchmarks. Results show that dTEE achieves high expressiveness for supporting 50% more applications than existing approaches and reduces 90% of the lines of code against handcrafted development.},
  keywords={Codes;Transforms;Information processing;Programming;Internet of Things;Logic;Security;Internet of Things;ARM TrustZone;declarative language},
  doi={10.1109/IPSN61024.2024.00021},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577345,
  author={Oostvogels, Jonathan and Michiels, Sam and Hughes, Danny},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Twofer: Ambiguous Transmissions for Low-Latency Sensor Networks Facing Noise, Privacy and Loss}, 
  year={2024},
  volume={},
  number={},
  pages={213-224},
  abstract={Today’s wireless sensor networks focus on achieving reliable data transfer over a lossy medium at the expense of latency. However, sensor data are often noisy and thus only lossily characterise real-world phenomena, rendering their exact transfer wasteful. Furthermore, many next-generation privacy-sensitive applications, such as smart grid control, real-time distributed object tracking, and inter-vehicle federated learning face latency and traffic bottlenecks due to the sheer amount of data collection required to overcome noise. We tackle this problem by introducing Twofer, a communication approach which reduces latency and traffic in high-noise or high-privacy settings by abandoning the focus on reliable networking. Twofer empowers developers to tune networks for latency-bound rather than reliability-bound performance; the system coordinates ambiguous transmissions, which are used to estimate the network-wide distribution of data, rather than to reliably communicate exact data from individual nodes. Twofer’s full-stack design maintains black-box compatibility with existing application code, but advocates for, and shows the value of, uncommon physical-layer features such as symbol-synchronous communication. The system is therefore implemented and evaluated on a prototype low-latency wireless mesh network called Zero-Wire. Experiments using state-of-the-art local differential privacy protocols show 25–75% latency reductions relative to conventional approaches. The results are also future-proof, with performance advantages increasing with the strength of the privacy guarantees that are offered.},
  keywords={Privacy;Wireless sensor networks;Noise;Wireless mesh networks;Prototypes;Rendering (computer graphics);Real-time systems;bus network;synchronous transmission;symbol-synchronous;network stack;multiple-access channel;local differential privacy;over-the-air;quantisation;dithering;semantic communication},
  doi={10.1109/IPSN61024.2024.00022},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577322,
  author={Chen, Weiwei and Zhang, Jiefeng and Xia, Xianjin and Wang, Shuai and Wang, Shuai and He, Tian},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Hitting the Sweet Spot: An SF-any Coding Paradigm for Empowering City-Wide LoRa Communications}, 
  year={2024},
  volume={},
  number={},
  pages={225-236},
  abstract={LoRa technology has garnered significant attention for its exceptional performance in city-wide applications. LoRa encodes data across multiple samples to enable long-range communication, with the level of redundancy controlled by the Spreading Factor (SF). However, practical limitations restrict how high the SF can be set. To overcome communication challenges at the highest allowable SF settings, we introduce SF-any, a software-based coding paradigm that extends an SFk packet to a quasi-SF(k + m) packet. SF-any encodes a quasi-SF(k + m) symbol with 2m SFk symbols. Hardware imperfections introduce time-varying frequency drifts and phase offsets, resulting in frequency leakage during quasi-SF(k +m) packet decoding. To mitigate this, we strategically insert pilots into the packet for imperfection estimation and compensation. Additionally, to maintain and exploit the coding structure in LoRa PHY, we employ a grouped repetition code at the transmitter and a joint demodulation and decoding scheme at the receiver. Comprehensive evaluations demonstrate that SF-any’s performance seamlessly scales with increasing SF, achieving up to a 14dB improvement over SF12 packets (the highest SF in LoRa PHY), and up to a 12dB improvement compared with state-of-the-art approaches.},
  keywords={Time-frequency analysis;Codes;Transmitters;Symbols;Termination of employment;Encoding;Decoding;LoRa;Reliability;Low SNR;Coherent Combining},
  doi={10.1109/IPSN61024.2024.00023},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577420,
  author={Lee, Geonhee and Park, Eunjeong and Park, Mingyu and Paek, Jeongyeup and Bahk, Saewoong},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={BIC-LoRa: Bits in Chirp Shapes to Boost Throughput in LoRa}, 
  year={2024},
  volume={},
  number={},
  pages={237-248},
  abstract={LoRa is a low-power long-range radio technology for wide-area IoT connectivity with exceptional receiver sensitivity thanks to its chirp spread spectrum (CSS) modulation. However, insufficient data rate has always been an Achilles’ heel of LoRa. This paper proposes a novel PHY-layer design, BIC-LoRa, that leverages non-linear chirp shapes as pictograph to enhance LoRa’s data rate. It employs multiple non-linear chirps for modulation whose shapes encode additional bits to boost data rate while maintaining resilience to low SINR scenarios. To the best of our knowledge, this is the first attempt to enhance the data rate of LoRa by embedding bits in the chirp shapes. Furthermore, BIC-LoRa fully leverages the characteristics of non-linear chirps, allowing it to deal with packet collisions and increase network throughput. We implement BIC-LoRa in GNURadio and MATLAB, and compare its performance against CurveALOHA and standard LoRaWAN through real experiments on USRP B210 software-defined radios. Evaluation results demonstrate that BICLoRa achieves up to 29.4% improvement in data rate for a single link and 32% improvement in overall network throughput while retaining the low SNR robustness of LoRa in real-world scenarios.},
  keywords={Chirp;Shape;Modulation;Symbols;Throughput;Usability;Standards;LoRa;Chirp Spread Spectrum (CSS);PHY-layer;Non-linear chirp},
  doi={10.1109/IPSN61024.2024.00024},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577379,
  author={Hsia, Chen-Chun and Xu, Yanggang and Ren, Jiyuan and Chen, Xinlei},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Demo Abstract: CARL: Collaborative Altitude-Adaptive Reinforcement Learning for Active Search with UAV Swarms}, 
  year={2024},
  volume={},
  number={},
  pages={249-250},
  abstract={Sensing noise and complex decision-making pose critical challenges to active search for lost persons amid disasters, impeding efficient rescue efforts. We introduce CARL, a collaborative altitude-adaptive reinforcement learning framework for UAV swarms. CARL integrates confidence-informed assessment with Sparse Bayesian Learning to diminish the noise impact on sensor performance, and an altitude-adaptive planner for collaborative active search strategy. Simulation experiments with up to 50 targets and 10 UAVs demonstrate CARL’s superior performance compared to baseline methods in lost person active search scenarios.},
  keywords={Disasters;Noise;Decision making;Collaboration;Reinforcement learning;Information processing;Autonomous aerial vehicles;Reinforcement learning;Bayesian learning;Collaborative UAV swarms;Active search framework},
  doi={10.1109/IPSN61024.2024.00025},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577389,
  author={Wang, Tao and Zhao, Yang and Liu, Jie and Zhuang, Yujie},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Demo Abstract: Underground Potato Root Tuber Sensing via a Wireless Network}, 
  year={2024},
  volume={},
  number={},
  pages={251-252},
  abstract={We propose to demonstrate a novel underground potato root tuber sensing framework using deep learning algorithms. We build a data acquisition system for capturing the ground truth of the tuber shape and location underground as well as the received signal strength (RSS) measurements from a wireless network. Then we design a two-stage neural network to reconstruct the cross-section images of potato tubers. Our initial experimental results show that the reconstructed images can be used to predict the size and location of various potato tubers buried underground with high accuracy. We will demonstrate the real-time performance of our prototype.},
  keywords={Wireless sensor networks;Shape;Wireless networks;Shape measurement;Neural networks;Prototypes;Information processing;wireless network;deep learning;underground wireless sensing},
  doi={10.1109/IPSN61024.2024.00026},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577298,
  author={Wang, Haoyu and Wang, Jiazhao and Lv, Xin and Gao, Demin and Jiang, Wenchao},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Demo Abstract: An Interpretable and Trainable CTC Framework}, 
  year={2024},
  volume={},
  number={},
  pages={253-254},
  abstract={Cross-technology communication (CTC) enables seamless interactions between diverse wireless technologies. Most existing work is based on reversing the transmission path to identify the appropriate payload to generate the waveform that the target devices can recognize. However, this method suffers from many limitations, including dependency on specific technologies and the necessity for intricate algorithms to mitigate distortion. To address these challenges, we present NNCTC, a Neural-Network-based Cross-Technology Communication framework which can achieve reliable and interpretable Cross-Technology Communication through a training process with an example of WiFi (OFDM and CCK) to both known and unknown modulation schemes.},
  keywords={Wireless communication;Training;Wireless sensor networks;Target recognition;OFDM;Modulation;Information processing;Cross-Technology Communication;Neural Network},
  doi={10.1109/IPSN61024.2024.00027},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577394,
  author={Wu, Haiyang and Liu, Kaiwei and Jiang, Siyang and Zhao, Zhihe and Yan, Zhenyu and Xing, Guoliang},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Demo Abstract: CaringFM: An Interactive In-home Healthcare System Empowered by Large Foundation Models}, 
  year={2024},
  volume={},
  number={},
  pages={255-256},
  abstract={The demand for fully on-device health monitoring is huge and urgent. However, deploying Large Foundation Models conventionally relies on cloud-based computing services, which poses privacy concerns. Driven by the belief of delivering personalised healthcare to family members, this study presents the development of an innovative on-device machine learning system, CaringFM. This family caring system utilizes privacy-protecting sensors and an edge-deployed Foundation Model(FM) to offer a convenient and low-cost solution for chronic disease prediction and health condition monitoring at home. In particular, CaringFM provides general health suggestions and personalized medical information while ensuring high privacy by processing and preserving all data locally.},
  keywords={Privacy;Computational modeling;Knowledge based systems;Medical services;Machine learning;Information processing;Predictive models;Large Foundation Model;Human Activity Recognition},
  doi={10.1109/IPSN61024.2024.00028},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577390,
  author={Fu, Heming and Chen, Hongkai and Xing, Guoliang},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Demo Abstract: AD-CLIP: Privacy-Preserving, Low-Cost Synthetic Human Action Dataset for Alzheimer’s Patients via CLIP-based Models}, 
  year={2024},
  volume={},
  number={},
  pages={257-258},
  abstract={With the increasing demand for smart health applications that emphasize privacy and efficiency, we introduce AD-CLIP, a synthetic data generation framework using CLIP-based models for Alzheimer’s patients. Leveraging the public dataset and data we collected from Alzheimer’s patients, AD-CLIP synthesizes human action videos featuring Alzheimer’s disease. To address privacy concerns, labeling cost, and imbalanced data distribution, AD-CLIP generates a comprehensive labeled human action skeleton dataset from depth cameras with balanced data distribution. Our preliminary experiments confirm the effectiveness of the synthesized dataset by improving the accuracy of human activity recognition up to 76.56%, which demonstrates AD-CLIP’s potential to enhance smart health applications.},
  keywords={Data privacy;Accuracy;Smart healthcare;Information processing;Skeleton;Human activity recognition;Labeling;Synthesis dataset;Alzheimer’s disease (AD);Human Action dataset},
  doi={10.1109/IPSN61024.2024.00029},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577409,
  author={Liu, Yi and Jian, Zhuozhu and Tan, Junbo and Liang, Lunfei and Liu, Houde and Chen, Xinlei},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Demo Abstract: Range-SLAM: UWB based Realtime Indoor Location and Mapping}, 
  year={2024},
  volume={},
  number={},
  pages={259-260},
  abstract={Simultaneous localization and mapping (SLAM) systems frequently employ LiDAR and cameras as essential sensing components. However, these sensors are proved to be unreliable in environments with poor visibility or reflective surfaces. And UWB (Ultra Wide Band) sensor with a longer wavelength shows better potential to achieve perception tasks. However, since UWB sensors can only obtain distance information from the anchors, it is difficult to densely construct the geometric structure of the environment. In this paper, We propose Range-SLAM, a method based on received signal strength indicator (RSSI) recognition and binary filtering to complete the mapping task and enhance positioning based on the map, and only require UWB as external perception sensor. Real-world experiments are conducted and prove the effectiveness, real-time performance and robustness of the Range-SLAM algorithm.},
  keywords={Location awareness;Simultaneous localization and mapping;Laser radar;Surface waves;Information processing;Robustness;Real-time systems;Simultaneous localization and mapping;RSSI;UWB},
  doi={10.1109/IPSN61024.2024.00030},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577295,
  author={Zhao, Chenyu and Ruan, Ciyu and Wang, Shengbo and Zha, Jirong and Wang, Haoyang and Li, Jiaqi and Liu, Yuxuan and Wang, Xuzhe and Chen, Xinlei},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Demo Abstract: Bio-inspired Tactile Sensing for MAV Landing with Extreme Low-cost Sensors}, 
  year={2024},
  volume={},
  number={},
  pages={261-262},
  abstract={MAV (Micro Aerial Vehicle) requires landing on a docking platform for recharging during or after missions due to their limited energy capacity. Inspired by biological tactile sensing, we propose a proprioceptive sensing system that allows MAV to "touch", recognize, and locate the landing platform even when visual or other positioning systems are not functioning properly. We leverage a physical phenomenon: as the MAV approaches a beneath obstacle, it experiences attitude disturbances caused by the airflow generated by the rotor’s reflections from the ground. By employing traditional signal processing and learning-based techniques to analyze signals from the IMU (Inertial Measurement Unit) and motors, the MAV can sense the edges of the platform and further calculate the precise landing coordinates. With a power consumption of less than 40 mW, our system achieves an edge detection error of less than 2 cm and a landing success rate exceeding 90%.CCS CONCEPTS• Applied computing → Aerospace; • Computing methodologies → Machine learning approaches; • Computer systems organization → Sensors and actuators.},
  keywords={Visualization;Power demand;Image edge detection;Propioception;Organizations;Signal processing;Sensor systems;Micro Aerial Vehicle;Ground Effect;Landing;Low-cost Sensing},
  doi={10.1109/IPSN61024.2024.00031},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577308,
  author={Wang, Xuzhe and Gao, Chen and Zhang, Weichen and Yu, Chengzhao and Zhao, Chenyu and Chen, Xinlei},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Demo Abstract: A Spatio-Temporal System for Public Transit-Guided Volunteer Task Matching}, 
  year={2024},
  volume={},
  number={},
  pages={263-264},
  abstract={Volunteer activity often undergoes unique transformations with the constant changes in society. The information behind volunteer data was created to enhance public welfare efficiently and boost governmental organization productivity. This research aims to utilize public transit systems for volunteer services, reducing inequality in volunteer service provision across different regions and improving overall service efficiency. We collected and processed large-scale data related to public transit and volunteer services, conducting in-depth analysis using data mining techniques and deep learning methods. Through LDA, we annotated a large amount of volunteer data, and via data analysis, discovered patterns related to population distribution, spatial distribution, and temporal distribution. Combining public transit data and the mined features, we propose a novel spatio-temporal embedding model based on the transformer architecture, which can effectively classify and predict the matching between volunteer service demands and public transit systems. Studying the coupling between volunteer services and transportation systems helps establish a new data-driven mindset, better utilize urban resources, and provide high-quality volunteer services to the public.},
  keywords={Productivity;Graphical models;Sociology;Transportation;Organizations;Information processing;Predictive models},
  doi={10.1109/IPSN61024.2024.00032},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577302,
  author={Zhang, Weichen and Liu, Yuxuan and Wang, Xuzhe and Chen, Xuecheng and Gao, Chen and Chen, Xinlei},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Demo Abstract: Embodied Aerial Agent for City-level Visual Language Navigation Using Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={265-266},
  abstract={As unmanned aerial vehicles (UAVs) become more prevalent in smart cities, their capacity for visual language navigation (VLN) is garnering increasing interest. VLN in cities has significant applications in delivery, rescue, and security patrol, among other fields. One of the most representative tasks is to navigate to specific locations following the language instructions. While some current methods have achieved notable results in indoor settings, challenges persist outdoors, including agents’ inaccurate spatial understanding and ambiguous language instructions. In this work, we explore an embodied navigation agent design, in which a fine-grained spatial verbalizer and a history path memory are proposed to guarantee accurate VLN in open 3D urban environments.},
  keywords={Visualization;Three-dimensional displays;Accuracy;Navigation;Smart cities;Information processing;Autonomous aerial vehicles;Visual language navigation;urban;embodied navigation agent},
  doi={10.1109/IPSN61024.2024.00033},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577359,
  author={Chuai, Xinyuan and Li, Yaoyi and Li, Xin and Zhang, Daxing and Hu, Guobiao and Liao, Wei-Hsin},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Demo Abstract: A Battery-free Wireless Keyboard}, 
  year={2024},
  volume={},
  number={},
  pages={267-268},
  abstract={This demonstration showcases a battery-free wireless keyboard that utilizes the kinetic energy generated from key presses to generate electrical power. Each key incorporates a Quasi-Static Toggling harvester, which employs potential energy pre-charging to ensure a consistently reliable energy output. Extensive practical testing has confirmed that this keyboard exhibits responsiveness and low latency comparable to traditional wireless keyboards. This study represents a significant improvement over previous battery-free IoT applications that often compromised service quality, as it offers a stable energy-harvesting mechanism and provides a dependable framework for designing battery-free devices.},
  keywords={Wireless communication;Potential energy;Wireless sensor networks;Presses;Keyboards;Reliability;Kinetic energy;Battery-free IoT;human-computer interaction;motion energy harvesting},
  doi={10.1109/IPSN61024.2024.00034},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577306,
  author={Sen, Argha and Das, Anirban and Pradhan, Swadhin and Chakraborty, Sandip},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Demo Abstract: MARS -An mmWave-based Multi-user Activity Tracking Solution}, 
  year={2024},
  volume={},
  number={},
  pages={269-270},
  abstract={Developing robust wireless sensing mechanisms for continuously monitoring human activities and presence is crucial for creating pervasive interactive intelligent spaces. The existing literature lacks solutions that continuously monitor multiple users’ activities without prior knowledge of the environment. This requires simultaneous localization and tracking of multiple subjects and identifying their activities at various scales, including macro-scale activities like walking and squats and micro-scale activities like typing or sitting. In this demo, we present MARS , a holistic system using a single off-the-shelf mmWave radar. MARS employs an intelligent model to sense both macro and micro activities and uses a dynamic spatial time-sharing approach to sense different subjects simultaneously. Our thorough evaluation demonstrates that MARS can continuously infer activities with over 93% accuracy and an average response time of approximately 2 seconds, even with five subjects performing 19 different activities.},
  keywords={Wireless communication;Location awareness;Legged locomotion;Wireless sensor networks;Radar;Radar tracking;Sensors;mmWave;FMCW Radar;Multi-user Activity Recognition},
  doi={10.1109/IPSN61024.2024.00035},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577362,
  author={Li, Kunjun and Gulati, Manoj and Shah, Dhairya and Waskito, Steven and Chakrabarty, Shantanu and Varshney, Ambuj},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Demo Abstract: PixelGen: Rethinking Embedded Camera Systems for Mixed-Reality}, 
  year={2024},
  volume={},
  number={},
  pages={271-272},
  abstract={A confluence of advances in several fields has led to the emergence of mixed-reality headsets. They can enable us to interact with and visualize our environments in novel ways. Nonetheless, mixed-reality headsets are constrained today as their camera systems only capture a narrow part of the visible spectrum. Our environment contains rich information that cameras do not capture. It includes phenomena captured through sensors, electromagnetic fields beyond visible light, acoustic emissions, and magnetic fields. We demonstrate our ongoing work, PixelGen, to redesign cameras for low power consumption and to be able to visualize our environments in a novel manner, making some of the invisible phenomena visible. Pixel-Gen combines low-bandwidth sensors with a monochrome camera to capture a rich representation of the world. This design choice ensures information is communicated energy-efficiently. This information is then combined with diffusion-based image models to generate unique representations of the environment, visualizing the otherwise invisible fields. We demonstrate that together with a mixed reality headset, it enables us to observe the world uniquely.},
  keywords={Headphones;Visualization;Power demand;Magnetic sensors;Mixed reality;Virtual reality;Sensor phenomena and characterization;Embedded Camera Systems;Mixed Reality;Multimodal AI;Low-power Systems},
  doi={10.1109/IPSN61024.2024.00036},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577370,
  author={Lin, Changyao and Chen, Zhenming and Liu, Jie},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Xpi: Real-Time Progressive Inference Serving with Explainable AI in Edge-Cloud Systems}, 
  year={2024},
  volume={},
  number={},
  pages={273-274},
  abstract={The constrained computing and memory resources at the edge pose challenges for satisfying different service-level objectives (SLOs) of deep learning inference requests. In this paper, we propose a novel edge-cloud progressive inference framework Xpi, which integrates explainable AI technique to facilitate early-exit, and learning-based online execution control to satisfy different SLOs and optimize edge resource overheads. We implement Xpi on an edge-cloud platform, and conduct partial experiments on two datasets. Xpi outperforms several advanced edge-cloud progressive inference frameworks in terms of accuracy and deadline satisfaction rate.},
  keywords={Deep learning;Accuracy;Explainable AI;Information processing;Real-time systems;edge computing;progressive inference;explainable AI;reinforcement learning},
  doi={10.1109/IPSN61024.2024.00037},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577352,
  author={Wang, Pengfei and Zhao, Zhiwei},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Ayaligo: A Programming Framework for Fast IoT System Integration}, 
  year={2024},
  volume={},
  number={},
  pages={275-276},
  abstract={Developing a holistic IoT application that integrates multiple IoT devices is not an easy task. Developers not only need to program the server and multiple embedded boards, but also need to connect them using designated data formats (e.g., JSON) and communication protocols (e.g., MQTT). Besides, programming frameworks are also different for different hardware (e.g., Arduino framework for Arduino UNO and Python scripts for Raspberry Pi), which also increases the development workload. In this regard, this paper presents Ayaligo, a system integration and code generation tool for IoT systems, which allows developers to directly program IoT applications as a whole, using the same syntax for framework-independent and protocol-independent programming. The tool then automatically generate codes that fit different frameworks and protocols by simply modifying the corresponding configurations, and thus can greatly boost the development life-cycle of IoT applications.},
  keywords={Protocols;Codes;System integration;Information processing;Programming;Syntactics;Internet of Things;System integration;IoT;Programming framework},
  doi={10.1109/IPSN61024.2024.00038},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577343,
  author={Zhang, Enqi and Liang, Lei and You, Lizhao and Wang, Zhaorui},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Enabling Concurrent Random Access in Underwater Acoustic Networks}, 
  year={2024},
  volume={},
  number={},
  pages={277-278},
  abstract={Uncoordinated random-access protocols are especially suitable for underwater acoustic networks with long propagation delays due to their simplicity. However, their performance is limited by severe collisions caused by uncoordinated access, and the current modulations cannot handle the collisions under the multipath environment. In this paper, we propose a new modulation and a new demodulation algorithm to resolve collisions. In particular, we adopt a Zadoff-Chu (ZC) sequence with cyclic shifts as the modulation, and assign users with different ZC sequences to minimize inter-user interference. To combat the multipath challenge, we leverage the insight that the multipath interference pattern is almost constant within the same packet and the modulated data only shifts the pattern, and develop a pattern-based demodulation algorithm. Trace-driven simulation results show that our new approach allows at least five users, and outperforms the existing approach by at least 8dB. In the future, we intend to develop a real-time system in a realistic environment.},
  keywords={Protocols;Simulation;Interference;Information processing;Real-time systems;Underwater acoustics;Demodulation},
  doi={10.1109/IPSN61024.2024.00039},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577422,
  author={Xiao, Zijian and Luo, Ji and Chen, Xuecheng and Cheng, Yuhan and Wang, Haoyang and Chen, Xinlei},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Sprinkler-UAV Cooperative Active Scheduling System}, 
  year={2024},
  volume={},
  number={},
  pages={279-280},
  abstract={Urban particulate pollution presents considerable public health hazards, underscoring the need for effective control measures in various cities. A prevalent approach involves employing mobile sprinkling trucks. This paper proposes a Sprinkler-UAV Cooperative Active Scheduling System for enhanced efficiency in reducing particulate pollution. The system employs ground-based sprinkler trucks and airborne air pollution detection drones to actively explore and reduce PM2.5 in environments with dynamic and unknown pollution distributions. Preliminary experiments have demonstrated the effectiveness of using sprinklers for urban particulate matter control.},
  keywords={Processor scheduling;Atmospheric measurements;Urban areas;Information processing;Particle measurements;Air pollution;Hazards;Sprinkling;Mobile computing;Scheduling system},
  doi={10.1109/IPSN61024.2024.00040},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577381,
  author={Xu, Yanggang and Jian, Zhuozhu and Zha, Jirong and Chen, Xinlei},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Emergency Networking Using UAVs: A Reinforcement Learning Approach with Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={281-282},
  abstract={Utilizing unmanned aerial vehicles (UAVs) as mobile access points can assist urban communication systems in establishing emergency networks in disaster scenarios. In this paper, to organize UAVs in large-scale environments for networking purposes, we propose a multi-agent reinforcement learning (MARL) model, in which the design of a selective parameter sharing mechanism and a grouping strategy enhances the model’s scalability. Furthermore, the model adopts a reward mechanism based on intrinsic motivation, using the Large Language Model (LLM), to accelerate the optimization process. Numerical results demonstrate that this algorithm outperforms existing alternatives.},
  keywords={Communication systems;Scalability;Disasters;Reinforcement learning;Information processing;Autonomous aerial vehicles;Numerical models;Multi-agent reinforcement learning;Large language model;UAV network},
  doi={10.1109/IPSN61024.2024.00041},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577317,
  author={Li, Zongjie and Qiu, Wenying and Ma, Pingchuan and Li, Yichen and Li, You and He, Sijia and Jiang, Baozheng and Wang, Shuai and Gu, Weixi},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: On the Accuracy and Robustness of Large Language Models in Chinese Industrial Scenarios}, 
  year={2024},
  volume={},
  number={},
  pages={283-284},
  abstract={Recent studies have demonstrated that large language models (LLMs) exhibit exceptional performance across various natural language processing tasks, rivaling or even exceeding human competencies in certain areas [1] – [5] . Typically, LLMs undergo pre-training on extensive text corpora, usually using billions of tokens to develop a foundational model. To better align LLMs with human preferences and directives or to fulfill specific application needs, methods such as supervised fine-tuning (SFT), reinforcement learning from human feedback (RLHF), and direct preference optimization (DPO) have been introduced and demonstrated to be effective. These advancements facilitate more intuitive and efficient human-AI interactions. However, the substantial resource requirements throughout the training process pose challenges for individual users and smaller organizations.},
  keywords={Training;Accuracy;Reinforcement learning;Organizations;Information processing;Robustness;Natural language processing;Large language model;AI reliability},
  doi={10.1109/IPSN61024.2024.00042},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577402,
  author={Chang, Yen Cheng and Codling, Jesse and Dong, Yiwen and Zhang, Jiale and Shulkin, Jeffrey and Latapie, Hugo and Joe-Wong, Carlee and Noh, Hae Young and Zhang, Pei},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Listen and Then Sense: Vibration-based Sports Crowd Monitoring by Pre-training with Public Audio Datasets}, 
  year={2024},
  volume={},
  number={},
  pages={285-286},
  abstract={This paper addresses challenges in monitoring human behavior in crowds through floor vibration sensing, overcoming limitations like subjective manual observation, visual occlusions, and audio interference. Our approach involves tackling limited-data vibration signal tasks by conducting pre-training across modalities, leveraging publicly available audio datasets. By leveraging self-supervised representation learning to pre-train on publicly available audio datasets, our approach reduces data requirements, improves robustness, and minimizes the need for human labeling efforts. Evaluation using in-game stadium vibration data with YouTube audio dataset demonstrates up to 5.8 × error reduction for crowd behavior.},
  keywords={Vibrations;Visualization;Video on demand;Self-supervised learning;Robustness;Sensors;Web sites;crowd monitoring;floor vibration;sports game},
  doi={10.1109/IPSN61024.2024.00043},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577349,
  author={Li, Yixin and Sui, Ning and Xu, Chenhan and Gehi, Anil and Guo, Zhishan},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Real-Time Cardiovascular Disease Detection via Abnormal Electrocardiogram Cycles on Embedded Systems}, 
  year={2024},
  volume={},
  number={},
  pages={287-288},
  abstract={CCS CONCEPTS• Applied computing → Health informatics.},
  keywords={Embedded systems;Information processing;Real-time systems;Cardiovascular diseases;Bioinformatics;Deep Learning;ECG Signal Processing;Real-time System},
  doi={10.1109/IPSN61024.2024.00044},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577312,
  author={Li, Yin and Reddy, Rohan and Zhang, Cheng and Nandakumar, Rajalakshmi},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Beyond-Voice - Towards Continuous 3D Hand Pose Tracking on Commercial Home Assistant Devices}, 
  year={2024},
  volume={},
  number={},
  pages={289-290},
  abstract={The surging popularity of home assistants and their voice user interface (VUI) have made them an ideal central control hub for smart home devices. However, current form factors heavily rely on VUI, which poses accessibility and usability issues; some latest ones are equipped with additional cameras and displays, which are costly and raise privacy concerns. These concerns jointly motivate Beyond-Voice, a novel high-fidelity acoustic sensing system that allows commodity home assistant devices to track and reconstruct hand poses continuously. It transforms the device into an active sonar system using its existing onboard microphones and speakers. By feeding a high-resolution range profile to the deep learning model, we can localize 21 finger joints in 3D, bringing the granularity for acoustic hand tracking to the next level. A user study with 11 participants in 3 different environments shows that Beyond-Voice can track joints with an average mean absolute error of 16.47mm for unseen environments and users.},
  keywords={Solid modeling;Privacy;Three-dimensional displays;Sonar;Transforms;Smart homes;User interfaces;acoustic sensing;wireless perception;hand pose estimation},
  doi={10.1109/IPSN61024.2024.00045},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577398,
  author={Zhuo, Yan and Li, Han and Wang, Chenlong and Chen, Xinlei},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Adaptive Chirps Domain Window Order of MM-Wave Radar for UAV Motion Capture}, 
  year={2024},
  volume={},
  number={},
  pages={291-292},
  abstract={Accurate motion capture of aerial robots in 3D is a key enabler for autonomous operation. Recently, some research considers using MM-Wave radar sensors for drone motion capture. However, due to the high noise and difficulty in capturing the center of an object in MM-Wave radar, the existing traditional methods have achieved unsatisfactory results. We develop a novel adaptive chirps domain window order method for MM-Wave radar data and customize a neural network architecture.},
  keywords={Adaptive systems;Three-dimensional displays;Chirp;Noise;Neural networks;Information processing;Autonomous aerial vehicles;Unmanned Aerial Vehicle;MM-Wave Radar;Neural Network},
  doi={10.1109/IPSN61024.2024.00046},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577336,
  author={Zhang, Yuyang and Weng, Xu and Ling, KV},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: UarLogger: Logging Measurements from UWB and AR Sensors on iOS Devices}, 
  year={2024},
  volume={},
  number={},
  pages={293-294},
  abstract={The multi-user Augmented Reality (AR) is powered by shared mapping and localization obtained from Visual Inertial Odometry (VIO) using AR sensors, including cameras and Inertial Measurement Units (IMU). However, VIO is vulnerable to sparse environment features, low lighting conditions, and dynamic motions. The Ultra-Wideband (UWB) transceiver, as a radio-sensing modality robust to visual and dynamic defects, has been considered as a formfitting patch on VIO to flatter multi-user AR. Nevertheless, like other wireless sensors, UWB suffers from noise and interference. Therefore, how to fuse UWB and VIO for multi-user AR is a promising but challenging research direction. To facilitate this process, we designed and released a tool, UarLogger, to log the relative location measurements from UWB and AR sensors mounted on iOS devices, as well as context-related data. We provide two examples–environmental condition evaluation and sensor fusion–to demonstrate its usefulness and showcase how it can boost the development of new algorithms with daily devices in hand.},
  keywords={Wireless communication;Visualization;Wireless sensor networks;Measurement units;Dynamics;Noise;Transceivers;Ultra-Wideband;Augmented Reality;Localization;Sensor Fusion;iOS Development},
  doi={10.1109/IPSN61024.2024.00047},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577392,
  author={Wang, Chenlong and Zhuo, Yan and Li, Han and Chen, Xinlei},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: TCT: Zero-training two staged Contrastive Transformer network for SSVEP classification}, 
  year={2024},
  volume={},
  number={},
  pages={295-296},
  abstract={Steady-State Evoked Potential (SSVEP) is a brain response to specific frequency visual stimuli, used in brain-computer interfaces due to its robust and easily detectable signals. Researchers have long applied methods like Canonical Correlation Analysis and deep learning for SSVEP signal decomposition and classification. However, those methods struggle to classify SSVEP signals without new subject’s data, and calibration is time-consuming. In this paper, we propose a two-stage, two-Transformer streams network to address the challenge of classifying SSVEP signals from new subjects. We utilize hierarchical contrastive learning to project features into a more discriminable feature space before classification. The comparative experiment demonstrates that our approach exhibits superior performance relative to alternative methods in processing SSVEP signals from new subjects.},
  keywords={Deep learning;Visualization;Correlation;Information processing;Transformers;Steady-state;Calibration;Steady-state Visual Evoked Potential (SSVEP);Brain-computer interface;Zero-training},
  doi={10.1109/IPSN61024.2024.00048},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577369,
  author={Yang, Huanqi and Li, Xinyue and Chen, Jiahuan and Han, Mingda and Xu, Weitao},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Uncovering Mobile User Gait Patterns Through Contactless RF Channels}, 
  year={2024},
  volume={},
  number={},
  pages={297-298},
  abstract={Gait-based authentication has risen to prominence for its distinctive advantages, becoming an essential security mechanism for mobile devices. These devices typically employ Inertial Measurement Units (IMUs) to capture intricate gait patterns for confirming the identity of users. However, our research highlights a vulnerability: the user’s gait data on mobile devices is susceptible to interception through a radio frequency (RF) side-channel, potentially allowing unauthorized access. We introduce Gait-Snoop as aproof-of-concept for this novel side-channel attack. Gait-Snoop utilizes the RF signals reflected during a user’s walk to extract gait information. It then correlates these RF signal patterns with IMU-derived gait data and employs a robotic arm to replicate the gait, aiming to deceive and unlock the targeted mobile devices. Our comprehensive evaluation of Gait-Snoop on smartphones demonstrates its capability to mimic IMU gait signals, underscoring the effectiveness and potential risks of such side-channel attacks.},
  keywords={Radio frequency;Measurement units;RF signals;Authentication;Side-channel attacks;Information processing;Robot sensing systems},
  doi={10.1109/IPSN61024.2024.00049},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577391,
  author={Li, Han and Zhuo, Yan and Wang, Chenlong and Wang, Huandong and Chen, Xinlei},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Generative Modeling of Post-Disaster POI Visits Recovery}, 
  year={2024},
  volume={},
  number={},
  pages={299-300},
  abstract={The development of Internet of Things (IoT) systems has enabled disaster perception and prediction to be highly accurate. On this basis, high-quality post-disaster Point of Interest (POI) visit data can help city decision-makers develop more sophisticated recovery plans to minimize the cost of recovery. This work focuses on the problem of POI visits generation in post-disaster recovery scenarios, utilizing diffusion model to generate visit recovery curves base on the data from sensor networks. We take the disaster severity as condition and propose a disaster mapping method to map the sensor data to each POI.},
  keywords={Costs;Accuracy;Disasters;Urban areas;Information processing;Internet of Things},
  doi={10.1109/IPSN61024.2024.00050},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577293,
  author={Tileutay, Laura and Park, Jiwoong and Ko, Young-Bae},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: UWB Ranging with Scheduled Broken Packet Reception}, 
  year={2024},
  volume={},
  number={},
  pages={301-302},
  abstract={Ultra-wideband technology has the potential to provide precise real-world localization. However, due to Non-Line-of-Sight propagation, the transmitted packet can be incomplete or lost during the ranging, which may lead to communication failure. To minimize this, we propose the scheduled signal reception technique. The proposed approach is tested in a real-world environment with Qorvo DWM3001C modules. The experimental results verify its efficiency, offering a practical solution for UWB-based localization, particularly in dynamic circumstances.},
  keywords={Location awareness;Information processing;Distance measurement;Ultra wideband technology;Localization;Ultra-Wideband;Preamble detection},
  doi={10.1109/IPSN61024.2024.00051},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577415,
  author={Xie, Qipeng and Zhao, Zhihe and Jiang, Linshan and Jiang, Siyang and Khan, Salabat and Wang, Weizheng and Wu, Kaishun},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Threshold Cryptography-based Authentication Protocol for Remote Healthcare}, 
  year={2024},
  volume={},
  number={},
  pages={303-304},
  abstract={With the advancement of the Internet of Medical Things (IoMT) and cryptographic technologies, remote healthcare services have become more widespread, presenting new challenges for patient privacy and data security. Conventional security mechanisms, such as centralized authentication and key distribution systems, are susceptible to single points of failure and significant management burdens, potentially leading to compromised authentication centers and internal security threats. In response, this study presents a threshold signature algorithm, it uses Distributed Key Generation (DKG) that distributes private keys without the need for a trusted key distributor, requiring the cooperative signature of at least two nodes for authentication. This approach not only circumvents the risk of single points of failure but also enhances the system’s robustness and efficiency. The experimental results validate its prospective utility in safeguarding remote healthcare data.},
  keywords={Data privacy;Protocols;Authentication;Internet of Medical Things;Information processing;Robustness;Cryptography;Threshold Cryptography;Authentication Protocol;IoMT},
  doi={10.1109/IPSN61024.2024.00052},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577332,
  author={Mohamed Nishar, Abbaas Alif and Paul, Sonipriya and Ashok, Ashwin},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Joint Optical Wireless Communication and Sensing using Neuromorphic Cameras}, 
  year={2024},
  volume={},
  number={},
  pages={305-306},
  abstract={In this work, we propose a novel re-use of neuromorphic (event) cameras for joint sensing and communications. Event cameras work on the principle of capturing changes in the light intensities, essentially capturing events that lead to such changes. This makes them operable at low power and sample events at fast rates (equivalent to about 40K frames-per-second compared to RGB cameras). We propose a system design to leverage the time-sampling nature of events for optical wireless communication and the ability to sample a collective area of physical space for imaging. In particular, we propose to address the challenges to achieve passive optical wireless (backscatter) communication as well as computer vision functions such as object and path detection using a single neuromorphic camera device. We posit that such an integrated functioning through a single low-power device opens new avenues for visible/invisible light communication and visual scene processing.CCS CONCEPTS•Networks → Mobile networks;•Hardware → Signal processing systems;•Computing methodologies → Computer vision.},
  keywords={Wireless communication;Computer vision;Wireless sensor networks;Visualization;Neuromorphics;Cameras;Optical imaging;VLC;VLC backscatter;VLC natural backscatter;Neuromorphic Cameras;Event Cameras;Joint Sensing and Communication},
  doi={10.1109/IPSN61024.2024.00053},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577341,
  author={Zhang, Xiaotong and Wang, Kun and Li, Zhenjiang and Zhang, Jin},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Enhancing Human Motion Sensing with synthesized Millimeter-Waves}, 
  year={2024},
  volume={},
  number={},
  pages={307-308},
  abstract={This poster introduces SynMotion, a novel mmWave-based human motion sensing system addressing the scarcity of training datasets. By synthesizing mmWave signals using existing vision-based human motion datasets, this system overcomes the challenge of collecting and labeling mmWave data, facilitating wider adoption of mmWave technology for applications like activity recognition, skeleton tracking and radar placement recommendation.},
  keywords={Training;Tracking;Information processing;Millimeter wave radar;Activity recognition;Radar tracking;Skeleton;Human Motion Sensing;Millimeter Wave;Body Skeleton Tracking;Activity Recognition},
  doi={10.1109/IPSN61024.2024.00054},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577305,
  author={Cao, Ruide and He, Qinyang and Wang, Yi and Qi, Zhuyun},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Extending Schedule-Abstraction Graph for Event-Triggered Response-Time Analysis}, 
  year={2024},
  volume={},
  number={},
  pages={309-310},
  abstract={For cyber-physical systems, the predictability of their physical behaviors needs to be ensured by the determinism of cyberspace. Response-time analysis (RTA) can theoretically provide this determinism by analyzing the temporal properties of demands. However, the state-space explosion problem makes it challenging to do exact and sustainable RTA for non-preemptive systems where both release jitter and execution time variation exist, particularly when the system has event-triggered (ET) jobs. To address this issue, we propose an ET-enabled RTA based on the schedule-abstraction graph and preliminarily verify its effectiveness and scalability.},
  keywords={Scalability;Cyberspace;Information processing;Jitter;Cyber-physical systems;Explosions;Event-triggered;response-time analysis;schedule-abstraction graph},
  doi={10.1109/IPSN61024.2024.00055},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577418,
  author={Bhadauria, Yuvraj Singh and Thaddeus, Lim Chang Quan and Reddy, C. Rajashekar and Gulati, Manoj and Shah, Dhairya and Varshney, Ambuj},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Enabling Non-contact, Low-Power Sensing using Tunnel Diodes}, 
  year={2024},
  volume={},
  number={},
  pages={311-312},
  abstract={Tracking movements in the environment of macroscopic objects enables numerous applications, from monitoring vital signs through body movements to inferring hand gestures. However, current systems overwhelmingly rely on contact-based sensors or energy-consuming radio frequency mechanisms that necessitate complex radio transceivers for receptions. We present ongoing research on a novel low-power sensor that leverages the unique characteristics of tunnel diodes. This sensor can detect minute changes in its vicinity and communicate these changes over radio waves, all while consuming under 150 microwatts of power consumption. Notably, the transmitted radio waves are processed using low-cost, off-the-shelf radio transceivers, resulting in low cost and power consumption. The sensor’s functionality stems from the sensitivity of the resonant frequency of the tunnel diode oscillators to changes in their electromagnetic surroundings. Our early work exhibits its potential for detecting a person’s breathing patterns, and hand gestures.},
  keywords={Radio transceivers;Power demand;Sensitivity;Tracking;Resonant frequency;Information processing;Sensor phenomena and characterization;Low-power Sensing;FM backscatter;FM transmitter;Tunnel Diodes;Radio Frequency},
  doi={10.1109/IPSN61024.2024.00056},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577397,
  author={Fan, Guiyun and Zhang, Yongkui and Jin, Haiming},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Shallowly Buried Trash Detection in Sandy Land Based on IR-UWB Radar}, 
  year={2024},
  volume={},
  number={},
  pages={313-314},
  abstract={Fast and accurate sand trash detection and localization is extremely important for trash cleaning, and at present, it still mainly depends on sanitation workers to carry out manual detection. Existing computer vision-based methods cannot detect the shallowly-buried trash. Besides, it is difficult and costly to use ground penetrating radar to detect. To overcome these limitations, we design and implement a novel detection system for shallowly buried trash in sandy land, which integrates the commercial IR-UWB radar into the intelligent unmanned vehicle. By controlling the movement of the vehicle, the radar scans the targeted sandy land and synthesizes the signal into the radar heat-map to detect and locate the shallowly buried trash. Experimental results show that the detection accuracy of the system reaches 92.3% with the radar is 75cm from the ground and the angle perpendicular to the ground is 20°. In the direction parallel to the ground, the farthest trash can be detected is 4.2m away from the radar. Within the range of 4.5m2, it can detect and locate up to 9 trash at the same time.},
  keywords={Location awareness;Heating systems;Ground penetrating radar;Accuracy;Radar detection;Manuals;Information processing;Trash detection;Sandy land;Radar Sensing},
  doi={10.1109/IPSN61024.2024.00057},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577301,
  author={Marefat, Alireza and Mohamed Nishar, Abbaas Alif and Ashok, Ashwin},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={Poster Abstract: Text2Net: Transforming Plain Text into Dynamic, Interactive Network Simulations}, 
  year={2024},
  volume={},
  number={},
  pages={315-316},
  abstract={This paper introduces Text2Net, an innovative system designed to transform plain English descriptions into dynamic, interactive network simulations within the Emulator Virtual Engine–Next Generation (Eve-NG) environment. By integrating SOTA technologies from Natural Language Processing (NLP), Large Language Models (LLMs), and proposed adaptor software, Text2Net bridges the technical knowledge gap, enabling both technical and non-technical users to effortlessly create and interact with complex network topologies within a simulation environment. The system architecture combines an intuitive chat interface, GPT4 LLM to interpret user inputs, NLP key-value extraction, a simulation adaptor, and the EVE-NG engine. TextNet democratizes network emulation, empowering educators to efficiently construct simulations for interactive learning. It also benefits industrial prototyping and testing configurations.CCS CONCEPTS•Applied computing → Interactive learning environments; Computer-assisted instruction; IT architectures;•Networks → Network design principles; Programming interfaces; Topology analysis and generation; Logical / virtual topologies; Network manageability; Programmable networks; Network management; Network monitoring.},
  keywords={Adaptation models;Automation;Computational modeling;Systems architecture;Transforms;Complex networks;Natural language processing;Network Simulation;Large Language Models;Natural Language Processing;Emulator Virtual Engine–Next Generation (Eve-NG);Domain-specific models;Dynamic Network Automation},
  doi={10.1109/IPSN61024.2024.00058},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577351,
  author={Sen Gupta, Pranjol},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={PhD Forum Abstract: Knowledge From Noise: EMI-Guided Power Monitoring}, 
  year={2024},
  volume={},
  number={},
  pages={317-318},
  abstract={Server-level power monitoring is essential for efficient data center management. However, high expense of individual power meter for each server has hindered widespread adoption, resulting in a concentration on UPS and cluster-level monitoring in most data centers. We introduce an innovative and cost-effective power monitoring method, which utilizes a single sensor to derive power consumption data from all servers by tapping into the conducted electromagnetic interference (EMI) emitted by server power supplies. This enables the measurement of power consumption through non-invasive single-point voltage measurements. Our approach, tested with a set of ten servers from two different brands, can estimate individual server power with less than ∼7% mean absolute error.},
  keywords={Meters;Knowledge engineering;Data centers;Voltage measurement;Power demand;Power measurement;Electromagnetic interference;Power Monitoring;Data Center;EMI},
  doi={10.1109/IPSN61024.2024.00059},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577335,
  author={Wang, Yanxiang},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={PhD Forum Abstract: Advancing Solar Cells: Beyond Energy Harvesting to Positioning and Communication}, 
  year={2024},
  volume={},
  number={},
  pages={319-320},
  abstract={Extensively studied for energy harvesting, solar cells present a sustainable and renewable solution for producing Internet of Things (IoT) devices that operate autonomously without the need for battery replacement. Our goal is to augment solar cells with positioning and communication capabilities, aiming to further diminish the size, weight, power consumption, and cost of IoT products. This approach leverages the photocurrent signals generated by solar cells, which are influenced by various factors, including the angle of light incidence, light intensity, and environmental reflections—attributes that can vary with location. Furthermore, by modulating the light source, we can alter the solar photocurrent, enabling the reception of data. This research explores the capability of solar cells to discern light spectral information, offering a nuanced response to illumination. This enhanced sensitivity has the potential to significantly improve localization precision and communication effectiveness.CCS CONCEPTS•Human-centered computing Ubiquitous and mobile computing.},
  keywords={Location awareness;Renewable energy sources;Sensitivity;Power demand;Photovoltaic cells;Lighting;Internet of Things;Indoor Localization;Solar Cells;Spectral Information;Visible Light Communication},
  doi={10.1109/IPSN61024.2024.00060},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577338,
  author={Li, Yao},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={PhD Forum Abstract: Sensor Fusion for Vehicle-side and Roadside 3D Object Detection and Tracking}, 
  year={2024},
  volume={},
  number={},
  pages={321-322},
  abstract={We focus on the sensor fusion for vehicle-side and roadside 3D object detection and tracking. Although quite a few sensor fusion algorithms have been proposed, some of which are top-ranked on various leaderboards, a systematic study on how to integrate three crucial sensors (LiDAR, camera and millimeter-wave Radar sensors) to develop effective multi-modal 3D object detection and tracking for vehicle-side perception is still missing. Therefore, we first study the three sensors’ strengths and weaknesses carefully, then compare several different fusion strategies to maximize their utility. Finally, based on the lessons learnt, we propose a simple yet effective multi-modal 3D object detection and tracking framework (namely EZFusion). Without fancy network modules, our proposed EZFusion makes remarkable improvements over the LiDAR-only baseline, and achieves comparable performance. For intelligent transportation, far-range perception with roadside sensors is vital. The main challenge of far-range perception is performing accurate object detection and tracking under far distances (e.g., > 150m) at a low cost. To cope with such challenges, deploying both millimeter wave Radars and high-definition cameras, and fusing their data has become a common practice. Towards this goal, the first question is to conduct the association on the 2D image plane or the BEV plane. We argue that the former is more suitable because the magnitude of location errors in the perspective projection points is smaller at far distances on the 2D plane, leading to more accurate association. Thus, we first project the Radar points to the 2D plane and then associate them with the camera-based 2D object locations. Subsequently, we map the camera-based object locations to the BEV plane through inverse projection mapping (IPM) with the corresponding depth information from the Radar data. Finally, we engage a BEV tracking module to generate target trajectories. Our system is capable of achieving an average location accuracy of 1.3m when we extend the detection range up to 500m.},
  keywords={Three-dimensional displays;Accuracy;Target tracking;Transportation;Object detection;Sensor fusion;Millimeter wave radar},
  doi={10.1109/IPSN61024.2024.00061},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577300,
  author={Li, Jiarong},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={PhD Forum Abstract: Ubiquitous Sensing System for Activity and Gesture Recognition via Optical and Energy-Harvesting Technologies}, 
  year={2024},
  volume={},
  number={},
  pages={323-324},
  abstract={This research focuses on ubiquitous sensing systems for activity and gesture recognition through novel optical sensing and energy harvesting technologies such as triboelectric nanogenerators (TENG), solar cells, and visible light communication (VLC). The primary goal is to address the limitations of existing sensing systems by creating a low-cost, energy-efficient, comprehensive solution that enhances sensor integration and communication. Thus, this study utilizes TENG for contact sensing, solar cells for non-contact sensing, and VLC for spatial sensing. The applied methodologies achieve activity and gesture recognition, with accuracies up to 99.4% and 97.3%, respectively. This work has potential applications in smart home automation, health monitoring, and intelligent control by providing a more sustainable and user-friendly approach to ubiquitous sensing.},
  keywords={Photovoltaic cells;Nanogenerators;Gesture recognition;Smart homes;Optical fiber networks;Optical sensors;Triboelectricity;Ubiquitous Sensing;Optical Sensing;Energy Harvesting;Human-Computer Interaction},
  doi={10.1109/IPSN61024.2024.00062},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577405,
  author={Ren, Haojie},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={PhD Forum Abstract: Cooperative Perception System with Roadside Assistance}, 
  year={2024},
  volume={},
  number={},
  pages={325-326},
  abstract={In this paper, we mainly focus on cooperative perception systems for vehicle-road coordination. Specifically, this paper encompasses two main aspects: 1) discussing the spatio-temporal synchronization issues among roadside multiple LiDARs. In this part, we design a method to synchronize the spatio-temporal data among multiple LiDARs by matching trajectory points between them; 2) designing a cooperative perception system based on uncertainty. In this part, we design a scheme to reduce the communication volume of cooperative perception by lowering the communication frequency.},
  keywords={Laser radar;Uncertainty;Design methodology;Information processing;Trajectory;Synchronization;Cooperative perception;Spatio-temporal synchronization;Roadside multiple LiDARs;Uncertainty;Communication volume reduction},
  doi={10.1109/IPSN61024.2024.00064},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577424,
  author={Liang, Yuzhu},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={PhD Forum Abstract:Exploring Service Placement and Request Scheduling Based on Cooperative Edge Computing in AIoT}, 
  year={2024},
  volume={},
  number={},
  pages={329-330},
  abstract={The rapid growth in data generated by the Artificial Internet of Things (AIoT) necessitates an increase in computational power and presents challenges to cloud infrastructure, including traffic congestion and latency issues in AIoT systems. This trend has fostered a shift toward edge-layer computation, with cooperative edge computing emerging as a potent solution to these challenges. However, the diversity and heterogeneity of AIoT systems present significant challenges with regard to service placement, cross-regional request scheduling, and efficient resource caching. My research aims to enhance cooperative edge computing by designing an optimized clustering algorithm for efficient service placement and data processing, developing a cooperative edge request scheduling method using digital twin technology to minimize system transmission delays, and devising a resource caching method employing deep reinforcement learning in cooperative game scenarios to optimize resource allocation. This research endeavors to enhance service placement and request scheduling efficiency, thereby offering substantial computational support to AIoT systems.},
  keywords={Processor scheduling;Information processing;Games;Market research;Scheduling;Digital twins;Resource management;Cooperative edge computing;Service placement;Request scheduling;Deep reinforcement learning},
  doi={10.1109/IPSN61024.2024.00065},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577383,
  author={Wang, Xuanzhi},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={PhD Forum Abstract: Understanding and Controlling the Sensing Coverage in WiFi Sensing System}, 
  year={2024},
  volume={},
  number={},
  pages={329-330},
  abstract={In the last decade, the employment of ubiquitous WiFi/4G/5G signals for wireless sensing has seen remarkable advancements, opening new vistas in the realm of wireless sensing. Despite these technological strides, the exploration into the fundamental theoretical aspects of wireless sensing, particularly concerning the sensing coverage and the mechanisms for its control, remains relatively uncharted. Addressing this critical gap, this paper introduces an innovative conceptual framework centered around the sensing signal-to-noise ratio and the application of diffraction theory to ubiquitous wireless sensing. This framework not only provides a quantitative characterization of the sensing coverage but also offers theoretical insights into controlling the sensing coverage. Understanding and adjusting sensing coverage paves the way for future innovations in sophisticated wireless signal-based sensing applications.},
  keywords={Wireless communication;Wireless sensor networks;Technological innovation;Diffraction;Employment;Information processing;Ubiquitous computing;WiFi sensing;sensing signal-to-noise-ratio;sensing coverage;diffraction model},
  doi={10.1109/IPSN61024.2024.00066},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10577303,
  author={Zou, Haodong},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={PhD Forum Abstract: Multi-View Service Provisioning in Cloud-Edge-End Networks with Hierarchical Resources}, 
  year={2024},
  volume={},
  number={},
  pages={333-334},
  abstract={With the surge of end devices and intelligent services, computing resource has begun to migrate from the cloud to end devices to meet the growing demand of users, forming a hierarchical resource distribution pattern in cloud-edge-end networks. Existing research work focuses on using edge computing technique to build a cloud-edge collaborative service offloading and task scheduling method to reduce service delay or energy consumption. However, different user groups and application scenarios may have different preferences for service quality requirements even for the same kind of service. For example, video analysis in autonomous driving focuses more on delay while video analysis in surveillance focuses more on accuracy. Meanwhile, heterogeneous cloud-edge-end devices have significant differences in the amount of resources, which poses great challenges for efficient provisioning of services. To solve this problem, we intend to propose multi-view service provisioning method in cloud-edge-end networks with hierarchically distributed resources. Firstly, we design a mapping scheme between service quality and heterogeneous resource occupation to estimate the amount of resources required for a given requirement. Secondly, we utilize model compression methods to customize powerful large models into smaller and lighter one according to the requirements of tasks. Thirdly, as resources are distributed hierarchically in cloud-edge-end networks, efficient service placement should be carried out with the goal of achieving diverse needs. The effectiveness of the proposed method is demonstrated through numerical simulations compared to state-of-the-art baselines and experiments on an implemented prototype system.},
  keywords={Cloud computing;Processor scheduling;Surveillance;Service computing;Prototypes;Numerical simulation;Delays;Service Provisioning;Multi-View Requirements;Heterogeneous Resources;Cloud-Edge-End Networks},
  doi={10.1109/IPSN61024.2024.00067},
  ISSN={},
  month={May},}
@INPROCEEDINGS{10697426,
  author={Xu, Changfu},
  booktitle={2024 23rd ACM/IEEE International Conference on Information Processing in Sensor Networks (IPSN)}, 
  title={PhD Forum Abstract: Diffusion-based Task Scheduling for Efficient AI-Generated Content in Edge Networks}, 
  year={2024},
  volume={},
  number={},
  pages={333-334},
  abstract={The Artificial Intelligence-Generated Content (AIGC) technique has gained significant popularity in creating diverse content. However, the current deployment of AIGC services is a centralized framework, thus leading to high response times. To address this issue, we propose a diffusion-based task scheduling method that considers the integration of the diffusion model, Deep Reinforcement Learning (DRL), and Mobile Edge Computing (MEC) technique to improve the AIGC efficiency. This challenges efficient server selection without prior information in dynamic MEC systems. We formulate our problem as an online integer linear programming problem aiming to minimize task offloading delay. Furthermore, we propose a novel AIGC Task Scheduling (DDRL-ATS) algorithm based on Diffusion DRL (DDRL) that effectively addresses this problem. The DDRL-ATS algorithm achieves efficient AIGC tailored for heterogeneous MEC environments. Additionally, an online Adaptive Multi-server Selection and Allocation (DDRL-AMSA) algorithm based on DDRL is proposed to further enhance the AIGC efficiency. Moreover, our DDRL-AMSA algorithm achieves near-optimal solutions within approximate linear time complexity bounds. Finally, experimental results validate the effectiveness of our method by showcasing at least a reduction of 13.54% in task offloading delay compared to state-of-the-art methods.},
  keywords={Multi-access edge computing;Processor scheduling;Heuristic algorithms;Approximation algorithms;Scheduling;Delays;Time factors;Servers;Resource management;Time complexity;AIGC;Collaborative MEC;Diffusion model;Task scheduling;Deep reinforcement learning},
  doi={10.1109/IPSN61024.2024.10697426},
  ISSN={},
  month={May},}
