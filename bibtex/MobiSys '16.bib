@inproceedings{10.1145/3257196,
author = {Cuervo, Eduardo},
title = {Session details: Session I: Smart Environments},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257196},
doi = {10.1145/3257196},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906400,
author = {Jayarajah, Kasthuri and Balan, Rajesh Krishna and Radhakrishnan, Meera and Misra, Archan and Lee, Youngki},
title = {LiveLabs: Building In-Situ Mobile Sensing \&amp; Behavioural Experimentation TestBeds},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906400},
doi = {10.1145/2906388.2906400},
abstract = {In this paper, we present LiveLabs, a first-of-its-kind testbed that is deployed across a university campus, convention centre, and resort island and collects real-time attributes such as location, group context etc., from hundreds of opt-in participants. These venues, data, and participants are then made available for running rich human-centric behavioural experiments that could test new mobile sensing infrastructure, applications, analytics, or more social-science type hypotheses that influence and then observe actual user behaviour. We share case studies of how researchers from around the world have and are using LiveLabs, and our experiences and lessons learned from building, maintaining, and expanding Live-Labs over the last three years.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {1–15},
numpages = {15},
keywords = {testbed, mobile sensing, experimentation},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906402,
author = {Grosse-Puppendahl, Tobias and Dellangnol, Xavier and Hatzfeld, Christian and Fu, Biying and Kupnik, Mario and Kuijper, Arjan and Hastall, Matthias R. and Scott, James and Gruteser, Marco},
title = {Platypus: Indoor Localization and Identification through Sensing of Electric Potential Changes in Human Bodies},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906402},
doi = {10.1145/2906388.2906402},
abstract = {Platypus is the first system to localize and identify people by remotely and passively sensing changes in their body electric potential which occur naturally during walking. While it uses three or more electric potential sensors with a maximum range of 2 m, as a tag-free system it does not require the user to carry any special hardware. We describe the physical principles behind body electric potential changes, and a predictive mathematical model of how this affects a passive electric field sensor. By inverting this model and combining data from sensors, we infer a method for localizing people and experimentally demonstrate a median localization error of 0.16 m. We also use the model to remotely infer the change in body electric potential with a mean error of 8.8 \% compared to direct contact-based measurements. We show how the reconstructed body electric potential differs from person to person and thereby how to perform identification. Based on short walking sequences of 5 s, we identify four users with an accuracy of 94 \%, and 30 users with an accuracy of 75 \%. We demonstrate that identification features are valid over multiple days, though change with footwear.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {17–30},
numpages = {14},
keywords = {localization, identification, electric potential sensing, capacitive sensing},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906417,
author = {Shangguan, Longfei and Jamieson, Kyle},
title = {The Design and Implementation of a Mobile RFID Tag Sorting Robot},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906417},
doi = {10.1145/2906388.2906417},
abstract = {Libraries, manufacturing lines, and offices of the future all stand to benefit from knowing the exact spatial order of RFID-tagged books, components, and folders, respectively. To this end, radio-based localization has demonstrated the potential for high accuracy. Key enabling ideas include motion-based synthetic aperture radar, multipath detection, and the use of different frequencies (channels). But indoors in real-world situations, current systems often fall short of the mark, mainly because of the prevalence and strength of multipath reflections of the radio signal off nearby objects. In this paper we describe the design and implementation of MobiTagbot, an autonomous wheeled robot reader that conducts a roving survey of the above such areas to achieve an exact spatial order of RFID-tagged objects in very close (1--6 cm) spacings. Our approach leverages a serendipitous correlation between the changes in multipath reflections that occur with motion and the effect of changing the carrier frequency (channel) of the RFID query. By carefully observing the relationship between channel and phase, MobiTagbot detects if multipath is likely prevalent at a given robot reader location. If so, MobiTagbot excludes phase readings from that reader location, and generates a final location estimate using phase readings from other locations as the robot reader moves in space. Experimentally, we demonstrate that cutting-edge localization algorithms including Tagoram are not accurate enough to exactly order items in very close proximity, but MobiTagbot is, achieving nearly 100\% ordering accuracy for items at low (3--6 cm) spacings and 86\% accuracy for items at very low (1--3 cm) spacings.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {31–42},
numpages = {12},
keywords = {localization, multipath propagation, order tracking, rfid},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906406,
author = {Kodeswaran, Palanivel A. and Kokku, Ravi and Sen, Sayandeep and Srivatsa, Mudhakar},
title = {Idea: A System for Efficient Failure Management in Smart IoT Environments},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906406},
doi = {10.1145/2906388.2906406},
abstract = {IoT enabled smart environments are expected to proliferate significantly in the near future, particularly in the context of monitoring services for wellness living, patient healthcare and elderly care. Timely maintenance of failed sensors is of critical importance in such deployments to ensure minimal disruption to monitoring services. However, maintenance of large and geographically spread deployments can be a significant challenge. We present Idea that significantly increases the vtime-before-repair for a smart home deployment, thereby reducing the maintenance overhead. Specifically, our approach leverages the facts that (a) there is inherent sensor redundancy when combinations of sensors monitor activities of daily living (ADLs) in smart environments, and (b) the impact of each sensor failure depends on the activities being monitored and the functional redundancy afforded by rest of the heterogeneous sensors available for detecting the activities. Consequently, Idea identifies homes that need to be fixed based on expected degradation in ADL detection performance, and optimizes maintenance scheduling accordingly. We demonstrate that our approach leads to 3--40 times fewer maintenance personnel than a scheme in which failed sensors are fixed without considering their impact.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {43–56},
numpages = {14},
keywords = {activities of daily living, adl mining, assisted living, failure impact analysis, fault diagnostics, internet of things, iot, maintenance scheduling, sensor failure detection, smart homes},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/3257197,
author = {Kotz, David},
title = {Session details: Session II: Frontiers in Sensing},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257197},
doi = {10.1145/3257197},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906415,
author = {Roy, Nirupam and Roy Choudhury, Romit},
title = {Listening through a Vibration Motor},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906415},
doi = {10.1145/2906388.2906415},
abstract = {This paper demonstrates the feasibility of using the vibration motor in mobile devices as a sound sensor, almost like a microphone. We show that the vibrating mass inside the motor -- designed to oscillate to changing magnetic fields -- also responds to air vibrations from nearby sounds. With appropriate processing, the responses become intelligible, to the extent that humans can understand the vibra-motor recorded words with greater than 80\% average accuracy. Even off-the-shelf speech recognition softwares are able to decode at 60\% accuracy, without any training or machine learning. We present our overall techniques and results through a system called VibraPhone, and discuss implications to both sensing and security.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {57–69},
numpages = {13},
keywords = {communication through physical vibration, nirupam roy, ripple, smartphone, smartphone privacy, smartphone security, sound recording, speech, speech processing, vibra-motor, vibration, vibration motor, vibratory communication},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906401,
author = {Li, Tianxing and Liu, Qiang and Zhou, Xia},
title = {Practical Human Sensing in the Light},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906401},
doi = {10.1145/2906388.2906401},
abstract = {We present StarLight, an infrastructure-based sensing system that reuses light emitted from ceiling LED panels to reconstruct fine-grained user skeleton postures continuously in real time. It relies on only a few (e.g., 20) photodiodes placed at optimized locations to passively capture low-level visual clues (light blockage information), with neither cameras capturing sensitive images, nor on-body devices, nor electromagnetic interference. It then aggregates the blockage information of a large number of light rays from LED panels and identifies best-fit 3D skeleton postures. StarLight greatly advances the prior light-based sensing design by dramatically reducing the number of intrusive sensors, overcoming furniture blockage, and supporting user mobility. We build and deploy StarLight in a 3.6 m x 4.8 m office room, with customized 20 LED panels and 20 photodiodes. Experiments show that StarLight achieves 13.6 degree mean angular error for five body joints and reconstructs a mobile skeleton at a high frame rate (40 FPS). StarLight enables a new unobtrusive sensing paradigm to augment today's mobile sensing for continuous and accurate behavioral monitoring.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {71–84},
numpages = {14},
keywords = {localization, sensing, skeleton tracking, visible light communication},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906407,
author = {Shen, Sheng and Wang, He and Roy Choudhury, Romit},
title = {I am a Smartwatch and I can Track my User's Arm},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906407},
doi = {10.1145/2906388.2906407},
abstract = {This paper aims to track the 3D posture of the entire arm - both wrist and elbow - using the motion and magnetic sensors on smartwatches. We do not intend to employ machine learning to train the system on a specific set of gestures. Instead, we aim to trace the geometric motion of the arm, which can then be used as a generic platform for gesture-based applications. The problem is challenging because the arm posture is a function of both elbow and shoulder motions, whereas the watch is only a single point of (noisy) measurement from the wrist. Moreover, while other tracking systems (like indoor/outdoor localization) often benefit from maps or landmarks to occasionally reset their estimates, such opportunities are almost absent here.While this appears to be an under-constrained problem, we find that the pointing direction of the forearm is strongly coupled to the arm's posture. If the gyroscope and compass on the watch can be made to estimate this direction, the 3D search space can become smaller; the IMU sensors can then be applied to mitigate the remaining uncertainty. We leverage this observation to design ArmTrak, a system that fuses the IMU sensors and the anatomy of arm joints into a modified hidden Markov model (HMM) to continuously estimate state variables. Using Kinect 2.0 as ground truth, we achieve around 9.2 cm of median error for free-form postures; the errors increase to 13.3 cm for a real time version. We believe this is a step forward in posture tracking, and with some additional work, could become a generic underlay to various practical applications.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {85–96},
numpages = {12},
keywords = {tracking, smartwatch, kinematics, hidden markov model, gesture, arm posture, anatomy, accelerometer},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906411,
author = {Fang, Biyi and Lane, Nicholas D. and Zhang, Mi and Boran, Aidan and Kawsar, Fahim},
title = {BodyScan: Enabling Radio-based Sensing on Wearable Devices for Contactless Activity and Vital Sign Monitoring},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906411},
doi = {10.1145/2906388.2906411},
abstract = {Wearable devices are increasingly becoming mainstream consumer products carried by millions of consumers. However, the potential impact of these devices is currently constrained by fundamental limitations of their built-in sensors. In this paper, we introduce radio as a new powerful sensing modality for wearable devices and propose to transform radio into a mobile sensor of human activities and vital signs. We present BodyScan, a wearable system that enables radio to act as a single modality capable of providing whole-body continuous sensing of the user. BodyScan overcomes key limitations of existing wearable devices by providing a contactless and privacy-preserving approach to capturing a rich variety of human activities and vital sign information. Our prototype design of BodyScan is comprised of two components: one worn on the hip and the other worn on the wrist, and is inspired by the increasingly prevalent scenario where a user carries a smartphone while also wearing a wristband/smartwatch. This prototype can support daily usage with one single charge per day. Experimental results show that in controlled settings, BodyScan can recognize a diverse set of human activities while also estimating the user's breathing rate with high accuracy. Even in very challenging real-world settings, BodyScan can still infer activities with an average accuracy above 60\% and monitor breathing rate information a reasonable amount of time during each day.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {97–110},
numpages = {14},
keywords = {activity recognition, channel state information (csi), radio-based sensing, vital signs, wearables},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/3257198,
author = {Flinn, Jason},
title = {Session details: Session III: Next Gen Mobile OS},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257198},
doi = {10.1145/3257198},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906414,
author = {Levy, Amit A. and Hong, James and Riliskis, Laurynas and Levis, Philip and Winstein, Keith},
title = {Beetle: Flexible Communication for Bluetooth Low Energy},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906414},
doi = {10.1145/2906388.2906414},
abstract = {The next generation of computing peripherals will be low-power ubiquitous computing devices such as door locks, smart watches, and heart rate monitors. Bluetooth Low Energy is a primary protocol for connecting such peripherals to mobile and gateway devices. Current operating system support for Bluetooth Low Energy forces peripherals into vertical application silos. As a result, simple, intuitive applications such as opening a door with a smart watch or simultaneously logging and viewing heart rate data are impossible. We present Beetle, a new hardware interface that virtualizes peripherals at the application layer, allowing safe access by multiple programs without requiring the operating system to understand hardware functionality, fine-grained access control to peripheral device resources, and transparent access to peripherals connected over the network. We describe a series of novel applications that are impossible with existing abstractions but simple to implement with Beetle.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {111–122},
numpages = {12},
keywords = {bluetooth low energy, device drivers, gateway, internet of things, low-powered devices, mobile phones, sensor networks},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906396,
author = {Han, Seungyeop and Shen, Haichen and Philipose, Matthai and Agarwal, Sharad and Wolman, Alec and Krishnamurthy, Arvind},
title = {MCDNN: An Approximation-Based Execution Framework for Deep Stream Processing Under Resource Constraints},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906396},
doi = {10.1145/2906388.2906396},
abstract = {We consider applying computer vision to video on cloud-backed mobile devices using Deep Neural Networks (DNNs). The computational demands of DNNs are high enough that, without careful resource management, such applications strain device battery, wireless data, and cloud cost budgets. We pose the corresponding resource management problem, which we call Approximate Model Scheduling, as one of serving a stream of heterogeneous (i.e., solving multiple classification problems) requests under resource constraints. We present the design and implementation of an optimizing compiler and runtime scheduler to address this problem. Going beyond traditional resource allocators, we allow each request to be served approximately, by systematically trading off DNN classification accuracy for resource use, and remotely, by reasoning about on-device/cloud execution trade-offs. To inform the resource allocator, we characterize how several common DNNs, when subjected to state-of-the art optimizations, trade off accuracy for resource use such as memory, computation, and energy. The heterogeneous streaming setting is a novel one for DNN execution, and we introduce two new and powerful DNN optimizations that exploit it. Using the challenging continuous mobile vision domain as a case study, we show that our techniques yield significant reductions in resource usage and perform effectively over a broad range of operating conditions.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {123–136},
numpages = {14},
keywords = {approximation, dnn, recognition, video},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906397,
author = {Du, Yuyang and Haezebrouck, Sebastien and Cui, Jin and Muralidhar, Rajeev and Seshadri, Harinarayanan and Rudramuni, Vishwesh and Chalhoub, Nicole and Chua, YongTong and Quinzio, Richard},
title = {TaskFolder: Dynamic and Fine-Grained Workload Consolidation for Mobile Devices},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906397},
doi = {10.1145/2906388.2906397},
abstract = {Despite the resource-constrained environment associated with mobile devices, the Android task scheduler tries to spread the workload equally among all CPU cores. While this is a sensible use of resources in desktop or server environments, it is inefficient for mobile devices, because they usually have lower computing demand and require single-user-perceptible performance guaran-tees. As a result, spreading tasks to all cores does not improve per-formance, increases energy consumption, and can cause perfor-mance issues when multiple mobile virtual machines attempt to engage as many cores as possible. To address this problem, we propose TaskFolder, a multi-core management scheme implemented on top of the task scheduler. TaskFolder attempts to compute the minimum number of cores required to perform the current workload without sacrificing per-formance, and schedules tasks to only that minimal number of cores. This number is called the Core Concurrency and is calculated based on past task dynamics. Experimental results of a case study show that TaskFolder saves an average of 19\% and up to 48\% of CPU power over a set of mobile applications on the latest Intel mobile platform.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {137–149},
numpages = {13},
keywords = {core concurrency, mobile device, multi-core management, operating system, power efficiency, scheduler, task consolidation, task scheduling, workload consolidation},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906398,
author = {Liu, Renju and Lin, Felix Xiaozhu},
title = {Understanding the Characteristics of Android Wear OS},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906398},
doi = {10.1145/2906388.2906398},
abstract = {Interactive wearable devices bring dramatic changes to apps and hardware, leaving operating system (OS) design in the mist. To this end, we thoroughly examine the execution efficiency of Android Wear, a popular wearable OS. By running a suite of fifteen benchmarks, we profile four system aspects: CPU usage, idle episodes, thread-level parallelism, and microarchitectural behaviors. We present the discovered inefficiencies and their root causes, together with a series of widespread, yet unknown OS design flaws. Towards designing future wearable OSes, our study has yielded a generic lesson, key insights, and specific action items.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {151–164},
numpages = {14},
keywords = {android wear, mobile systems, operating systems, wearables},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/3257199,
author = {Kravets, Robin},
title = {Session details: Session IV: Transit and Mapping},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257199},
doi = {10.1145/3257199},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906408,
author = {Yang, Zidong and Hu, Ji and Shu, Yuanchao and Cheng, Peng and Chen, Jiming and Moscibroda, Thomas},
title = {Mobility Modeling and Prediction in Bike-Sharing Systems},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906408},
doi = {10.1145/2906388.2906408},
abstract = {As an innovative mobility strategy, public bike-sharing has grown dramatically worldwide. Though providing convenient, low-cost and environmental-friendly transportation, the unique features of bike-sharing systems give rise to problems to both users and operators. The primary issue among these problems is the uneven distribution of bicycles caused by the ever-changing usage and (available) supply. This bicycle imbalance issue necessitates efficient bike re-balancing strategies, which depends highly on bicycle mobility modeling and prediction. In this paper, for the first time, we propose a spatio-temporal bicycle mobility model based on historical bike-sharing data, and devise a traffic prediction mechanism on a per-station basis with sub-hour granularity. We extensively evaluated the performance of our design through a one-year dataset from the world's largest public bike-sharing system (BSS) with more than 2800 stations and over 103 million check in/out records. Evaluation results show an 85 percentile relative error of 0.6 for both check in and check out prediction. We believe this new mobility modeling and prediction approach can advance the bike re-balancing algorithm design and pave the way for the rapid deployment and adoption of bike-sharing systems across the globe.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {165–178},
numpages = {14},
keywords = {bike sharing, flow prediction, mobility modeling, rebalancing, sharing economy},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906420,
author = {Wang, Gang and Wang, Bolun and Wang, Tianyi and Nika, Ana and Zheng, Haitao and Zhao, Ben Y.},
title = {Defending against Sybil Devices in Crowdsourced Mapping Services},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906420},
doi = {10.1145/2906388.2906420},
abstract = {Real-time crowdsourced maps such as Waze provide timely updates on traffic, congestion, accidents and points of interest. In this paper, we demonstrate how lack of strong location authentication allows creation of software-based Sybil devices that expose crowdsourced map systems to a variety of security and privacy attacks. Our experiments show that a single Sybil device with limited resources can cause havoc on Waze, reporting false congestion and accidents and automatically rerouting user traffic. More importantly, we describe techniques to generate Sybil devices at scale, creating armies of virtual vehicles capable of remotely tracking precise movements for large user populations while avoiding detection. We propose a new approach to defend against Sybil devices based on co-location edges, authenticated records that attest to the one-time physical co-location of a pair of devices. Over time, co-location edges combine to form large proximity graphs that attest to physical interactions between devices, allowing scalable detection of virtual vehicles. We demonstrate the efficacy of this approach using large-scale simulations, and discuss how they can be used to dramatically reduce the impact of attacks against crowdsourced mapping services.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {179–191},
numpages = {13},
keywords = {crowdsourcing, mobile maps, sybil attack},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906395,
author = {Elhamshary, Moustafa and Youssef, Moustafa and Uchiyama, Akira and Yamaguchi, Hirozumi and Higashino, Teruo},
title = {TransitLabel: A Crowd-Sensing System for Automatic Labeling of Transit Stations Semantics},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906395},
doi = {10.1145/2906388.2906395},
abstract = {We present TransitLabel, a crowd-sensing system for automatic enrichment of transit stations indoor floorplans with different semantics like ticket vending machines, entrance gates, drink vending machines, platforms, cars' waiting lines, restrooms, lockers, waiting (sitting) areas, among others. Our key observations show that certain passengers' activities (e.g., purchasing tickets, crossing entrance gates, etc) present identifiable signatures on one or more cell-phone sensors. TransitLabel leverages this fact to automatically and unobtrusively recognize different passengers' activities, which in turn are mined to infer their uniquely associated stations semantics. Furthermore, the locations of the discovered semantics are automatically estimated from the inaccurate passengers' positions when these semantics are identified. We evaluate TransitLabel through a field experiment in eight different train stations in Japan. Our results show that TransitLabel can detect the fine-grained stations semantics accurately with 7.7\% false positive rate and 7.5\% false negative rate on average. In addition, it can consistently detect the location of discovered semantics accurately, achieving an error within 2.5m on average for all semantics. Finally, we show that TransitLabel has a small energy footprint on cell-phones, could be generalized to other stations, and is robust to different phone placements; highlighting its promise as a ubiquitous indoor maps enriching service.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {193–206},
numpages = {14},
keywords = {activity recognition, automatic floorplans construction, crowdsourcing, indoor location-based service, railway stations},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906410,
author = {Bregu, Endri and Casamassima, Nicola and Cantoni, Daniel and Mottola, Luca and Whitehouse, Kamin},
title = {Reactive Control of Autonomous Drones},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906410},
doi = {10.1145/2906388.2906410},
abstract = {Aerial drones, ground robots, and aquatic rovers enable mobile applications that no other technology can realize with comparable flexibility and costs. In existing platforms, the low-level control enabling a drone's autonomous movement is currently realized in a time-triggered fashion, which simplifies implementations. In contrast, we conceive a notion of reactive control that supersedes the time-triggered approach by leveraging the characteristics of existing control logic and of the hardware it runs on. Using reactive control, control decisions are taken only upon recognizing the need to, based on observed changes in the navigation sensors. As a result, the rate of execution dynamically adapts to the circumstances. Compared to time-triggered control, this allows us to: i) attain more timely control decisions, ii) improve hardware utilization, iii) lessen the need to over-provision control rates. Based on 260+ hours of real-world experiments using three aerial drones, three different control logic, and three hardware platforms, we demonstrate, for example, up to 41\% improvements in control accuracy and up to 22\% improvements in flight time.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {207–219},
numpages = {13},
keywords = {aerial drones, autonomous drones, reactive control, reactive programming},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/3257200,
author = {Greenstein, Ben},
title = {Session details: Session V: No More Leaks},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257200},
doi = {10.1145/3257200},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906419,
author = {Huang, Peng and Xu, Tianyin and Jin, Xinxin and Zhou, Yuanyuan},
title = {DefDroid: Towards a More Defensive Mobile OS Against Disruptive App Behavior},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906419},
doi = {10.1145/2906388.2906419},
abstract = {The mobile app market is enjoying an explosive growth. Many people, including teenagers, set about developing mobile apps. Unfortunately, due to developers' inexperience and the unique mobile programming paradigms, a growing number of immature apps are released to users. Despite having useful functionalities, these apps exhibit disruptive behaviors that are inconsiderate to the mobile system as a whole, e.g.,, retrying network connections too aggressively, waking up the device too frequently, or holding resources for unnecessarily long. These behaviors adversely affect other apps running on the same device and frustrate users with battery drain, excessive cellular data consumption, storage overuse, etc.In this paper, we investigate Disruptive App Behavior (DAB) with a study on 287 real-world DAB issues. Guided by the study, we present DefDroid, a mobile OS designed to protect users from the negative impact of DAB at runtime. DefDroid monitors important app activities and tries to adjust app behaviors using fine-grained actions (e.g., enforce back-off to continuous retries, decrease aggressive timer frequency) without breaking app main functionality. Our experiments show that DefDroid effectively curbs 125 real-world DAB cases with small overhead and marginal impact to the usability of both the misbehaving apps and normal apps. During a small-scale user trial, DefDroid also found 6 new DAB issues. We further deployed DefDroid to 185 real users through the PhoneLab testbed for 43 days and found DAB issues from at least 57 apps.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {221–234},
numpages = {14},
keywords = {defensive actions, mobile apps, operating system},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906412,
author = {Aditya, Paarijaat and Sen, Rijurekha and Druschel, Peter and Joon Oh, Seong and Benenson, Rodrigo and Fritz, Mario and Schiele, Bernt and Bhattacharjee, Bobby and Wu, Tong Tong},
title = {I-Pic: A Platform for Privacy-Compliant Image Capture},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906412},
doi = {10.1145/2906388.2906412},
abstract = {The ubiquity of portable mobile devices equipped with built-in cameras have led to a transformation in how and when digital images are captured, shared, and archived. Photographs and videos from social gatherings, public events, and even crime scenes are commonplace online. While the spontaneity afforded by these devices have led to new personal and creative outlets, privacy concerns of bystanders (and indeed, in some cases, unwilling subjects) have remained largely unaddressed. We present I-Pic, a trusted software platform that integrates digital capture with user-defined privacy. In I-Pic, users choose alevel of privacy (e.g., image capture allowed or not) based upon social context (e.g., out in public vs. with friends vs. at workplace). Privacy choices of nearby users are advertised via short-range radio, and I-Pic-compliant capture platforms generate edited media to conform to privacy choices of image subjects. I-Pic uses secure multiparty computation to ensure that users' visual features and privacy choices are not revealed publicly, regardless of whether they are the subjects of an image capture. Just as importantly, I-Pic preserves the ease-of-use and spontaneous nature of capture and sharing between trusted users. Our evaluation of I-Pic shows that a practical, energy-efficient system that conforms to the privacy choices of many users within a scene can be built and deployed using current hardware.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {235–248},
numpages = {14},
keywords = {location-based services, mobile computing, pervasive computing, privacy, proximity-based services, social networking},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906405,
author = {Raval, Nisarg and Srivastava, Animesh and Razeen, Ali and Lebeck, Kiron and Machanavajjhala, Ashwin and Cox, Lanodn P.},
title = {What You Mark is What Apps See},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906405},
doi = {10.1145/2906388.2906405},
abstract = {Users are increasingly vulnerable to inadvertently leaking sensitive information through cameras. In this paper, we investigate an approach to mitigating the risk of such inadvertent leaks called privacy markers. Privacy markers give users fine-grained control of what visual information an app can access through a device's camera. We present two examples of this approach: PrivateEye, which allows a user to mark regions of a two-dimensional surface as safe to release to an app, and WaveOff, which does the same for three-dimensional objects. We have integrated both systems with Android's camera subsystem. Experiments with our prototype show that a Nexus 5 smartphone can deliver near realtime frame rates while protecting secret information, and a 26-person user study elicited positive feedback on our prototype's speed and ease-of-use.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {249–261},
numpages = {13},
keywords = {computer vision, mobile computing, privacy},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906391,
author = {Mirzamohammadi, Saeed and Amiri Sani, Ardalan},
title = {Viola: Trustworthy Sensor Notifications for Enhanced Privacy on Mobile Systems},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906391},
doi = {10.1145/2906388.2906391},
abstract = {Modern mobile systems such as smartphones, tablets, and wearables contain a plethora of sensors such as camera, microphone, GPS, and accelerometer. Moreover, being mobile, these systems are with the user all the time, e.g., in user's purse or pocket. Therefore, mobile sensors can capture extremely sensitive and private information about the user including daily conversations, photos, videos, and visited locations. Such a powerful sensing capability raises important privacy concerns.To address these concerns, we believe that mobile systems must be equipped with trustworthy sensor notifications, which use indicators such as LED to inform the user unconditionally when the sensors are on. We present Viola, our design and implementation of trustworthy sensor notifications, in which we leverage two novel solutions. First, we deploy a runtime monitor in low-level system software, e.g., in the operating system kernel or in the hypervisor. The monitor intercepts writes to the registers of sensors and indicators, evaluates them against checks on sensor notification invariants, and rejects those that fail the checks. Second, we use formal verification methods to prove the functional correctness of the compilation of our invariant checks from a high-level language.We demonstrate the effectiveness of Viola on different mobile systems, such as Nexus 5, Galaxy Nexus, and ODROID XU4, and for various sensors and indicators, such as camera, microphone, LED, and vibrator. We demonstrate that Viola incurs almost no overhead to the sensor's performance and incurs only small power consumption overhead.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {263–276},
numpages = {14},
keywords = {indicators, invariants, mobile systems, notifications, sensors, verification, virtualization},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/3257201,
author = {Hwang, Inseok},
title = {Session details: Session VI: Better Mobile Interfaces},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257201},
doi = {10.1145/3257201},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906394,
author = {Tung, Yu-Chih and Shin, Kang G.},
title = {Expansion of Human-Phone Interface By Sensing Structure-Borne Sound Propagation},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906394},
doi = {10.1145/2906388.2906394},
abstract = {ForcePhone is a novel system that enables commodity phones to recognize the force applied to their touch screen and body. Researchers have shown the usefulness and importance of this expressive input interface (especially for the one-hand operation), but this advanced function has not yet been realized and deployed in most state-of-the-art smartphones. Instead of employing or augmenting specialized/proprietary sensors, ForcePhone uses only the phone's built-in sensors to measure the applied force via a physical property called structure-borne sound propagation. ForcePhone has been implemented and evaluated on both iOS and Android phones. Multiple demo applications, such as getting the option menu by hard-pressing a button or surfing the previous webpage by squeezing the phone, have been implemented and tested successfully. The estimated force is shown highly correlated to the real applied force and the estimation error is less than 54g when the phone is stationary. Users can easily control the applied force at two different levels with a 97\% accuracy. Moreover, ForcePhone can detect the squeeze of the phone body with a higher than 90\% accuracy. Most participants in our usability study were able to master the ForcePhone-based apps and find them very useful.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {277–289},
numpages = {13},
keywords = {force sensing, mobile phones, sound, structure-borne sound},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906418,
author = {Boos, Kevin and Chu, David and Cuervo, Eduardo},
title = {FlashBack: Immersive Virtual Reality on Mobile Devices via Rendering Memoization},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906418},
doi = {10.1145/2906388.2906418},
abstract = {Virtual reality head-mounted displays (VR HMDs) are attracting users with the promise of full sensory immersion in virtual environments. Creating the illusion of immersion for a near-eye display results in very heavy rendering workloads: low latency, high framerate, and high visual quality are all needed. Tethered VR setups in which the HMD is bound to a powerful gaming desktop limit mobility and exploration, and are difficult to deploy widely. Products such as Google Cardboard and Samsung Gear VR purport to offer any user a mobile VR experience, but their GPUs are too power-constrained to produce an acceptable framerate and latency, even for scenes of modest visual quality.We present FLASHBACK, an unorthodox design point for HMD VR that eschews all real-time scene rendering. Instead, FLASHBACK aggressively precomputes and caches all possible images that a VR user might encounter. FLASHBACK memoizes costly rendering effort in an offline step to build a cache full of panoramic images. During runtime, FLASHBACK constructs and maintains a hierarchical storage cache index to quickly lookup images that the user should be seeing. On a cache miss, FLASHBACK uses fast approximations of the correct image while concurrently fetching more closely-matching entries from its cache for future requests. Moreover, FLASHBACK not only works for static scenes, but also for dynamic scenes with moving and animated objects.We evaluate a prototype implementation of FLASHBACK and report up to a 8x improvement in framerate, 97x reduction in energy consumption per frame, and 15x latency reduction compared to a locally-rendered mobile VR setup. In some cases, FLASHBACK even delivers better framerates and responsiveness than a tethered HMD configuration on graphically complex scenes.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {291–304},
numpages = {14},
keywords = {caching, memoization, mobile device, rendering, virtual reality},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906416,
author = {Azim, Tanzirul and Riva, Oriana and Nath, Suman},
title = {uLink: Enabling User-Defined Deep Linking to App Content},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906416},
doi = {10.1145/2906388.2906416},
abstract = {Web deep links are instrumental to many fundamental user experiences such as navigating to one web page from another, bookmarking a page, or sharing it with others. Such experiences are not possible with individual pages inside mobile apps, since historically mobile apps did not have links equivalent to web deep links. Mobile deep links, introduced in recent years, still lack many important properties of web deep links. Unlike web links, mobile deep links need significant developer effort, cover a small number of predefined pages, and are defined statically to navigate to a page for a given link, but not to dynamically generate a link for a given page. We propose uLink, a novel deep linking mechanism that addresses these problems. uLink is implemented as an application library, which transparently tracks data- and UI-event-dependencies of app pages, and encodes the information in links to the pages; when a link is invoked, the information is utilized to recreate the target page quickly and accurately. uLink also employs techniques, based on static and dynamic analysis of the app, that can provide feedback to users about whether a link may break in the future due to, e.g., modifications of external resources such as a file the link depends on. We have implemented uLink on Android. Our evaluation with 34 (of 1000 most downloaded) Android apps shows that compared to existing mobile deep links, uLink requires minimal developer effort, achieves significantly higher coverage, and can provide accurate user feedback on a broken link.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {305–318},
numpages = {14},
keywords = {application library, mobile applications, mobile deep links, user experiences.},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/3257202,
author = {Zhou, Xia},
title = {Session details: Session VII: Small and Large Scale Networking},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257202},
doi = {10.1145/3257202},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906399,
author = {Hermans, Frederik and McNamara, Liam and S\"{o}r\"{o}s, G\'{a}bor and Rohner, Christian and Voigt, Thiemo and Ngai, Edith},
title = {FOCUS: Robust Visual Codes for Everyone},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906399},
doi = {10.1145/2906388.2906399},
abstract = {Visual codes are used to embed digital data in physical objects, or they are shown in video sequences to transfer data over screen/camera links. Existing codes either carry limited data to make them robust against a range of channel conditions (e.g., low camera quality or long distances), or they support a high data capacity but only work over a narrow range of channel conditions. We present FOCUS, a new code design that does not require this explicit trade-off between code capacity and the reader's channel quality. Instead, FOCUS builds on concepts from OFDM to encode data at different levels of spatial detail. This enables each reader to decode as much data from a code as its channel quality allows. We build a prototype of FOCUS devices and evaluate it experimentally. Our results show that FOCUS gracefully adapts to the reader's channel, and that it provides a significant performance improvement over recently proposed designs, including Strata and PixNet.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {319–332},
numpages = {14},
keywords = {automatic identification, bar codes, screen/camera links, smart phones, visual codes},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906403,
author = {Albazrqaoe, Wahhab and Huang, Jun and Xing, Guoliang},
title = {Practical Bluetooth Traffic Sniffing: Systems and Privacy Implications},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906403},
doi = {10.1145/2906388.2906403},
abstract = {With the prevalence of personal Bluetooth devices, potential breach of user privacy has been an increasing concern. To date, sniffing Bluetooth traffic has been widely considered an extremely intricate task due to Bluetooth's indiscoverable mode, vendor-dependent adaptive hopping behavior, and the interference in the open 2.4 GHz band. In this paper, we present BlueEar -a practical Bluetooth traffic sniffer. BlueEar features a novel dual-radio architecture where two Bluetooth-compliant radios coordinate with each other on learning the hopping sequence of indiscoverable Bluetooth networks, predicting adaptive hopping behavior, and mitigating the impacts of RF interference. Experiment results show that BlueEar can maintain a packet capture rate higher than 90\% consistently in real-world environments, where the target Bluetooth network exhibits diverse hopping behaviors in the presence of dynamic interference from coexisting Wi-Fi devices. In addition, we discuss the privacy implications of the BlueEar system, and present a practical countermeasure that effectively reduces the packet capture rate of the sniffer to 20\%. The proposed countermeasure can be easily implemented on the Bluetooth master device while requiring no modification to slave devices like keyboards and headsets.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {333–345},
numpages = {13},
keywords = {bluetooth channel classification, bluetooth security and privacy, bluetooth traffic sniffing, selective jamming},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906393,
author = {Sui, Kaixin and Zhou, Mengyu and Liu, Dapeng and Ma, Minghua and Pei, Dan and Zhao, Youjian and Li, Zimu and Moscibroda, Thomas},
title = {Characterizing and Improving WiFi Latency in Large-Scale Operational Networks},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906393},
doi = {10.1145/2906388.2906393},
abstract = {WiFi latency is a key factor impacting the user experience of modern mobile applications, but it has not been well studied at large scale. In this paper, we design and deploy WiFiSeer, a framework to measure and characterize WiFi latency at large scale. WiFiSeer comprises a systematic methodology for modeling the complex relationships between WiFi latency and a diverse set of WiFi performance metrics, device characteristics, and environmental factors. WiFiSeer was deployed on Tsinghua campus to conduct a WiFi latency measurement study of unprecedented scale with more than 47,000 unique user devices. We observe that WiFi latency follows a long tail distribution and the 90th (99th) percentile is around 20 ms (250 ms). Furthermore, our measurement results quantitatively confirm some anecdotal perceptions about impacting factors and disapprove others. We deploy three practical solutions for improving WiFi latency in Tsinghua, and the results show significantly improved WiFi latencies. In particular, over 1,000 devices use our AP selection service based on a predictive WiFi latency model for 2.5 months, and 72\% of their latencies are reduced by over half after they re-associate to the suggested APs.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {347–360},
numpages = {14},
keywords = {measurement, wifi latency, wireless network},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906392,
author = {Ren, Jingjing and Rao, Ashwin and Lindorfer, Martina and Legout, Arnaud and Choffnes, David},
title = {ReCon: Revealing and Controlling PII Leaks in Mobile Network Traffic},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906392},
doi = {10.1145/2906388.2906392},
abstract = {It is well known that apps running on mobile devices extensively track and leak users' personally identifiable information (PII); however, these users have little visibility into PII leaked through the network traffic generated by their devices, and have poor control over how, when and where that traffic is sent and handled by third parties. In this paper, we present the design, implementation, and evaluation of ReCon: a cross-platform system that reveals PII leaks and gives users control over them without requiring any special privileges or custom OSes. ReCon leverages machine learning to reveal potential PII leaks by inspecting network traffic, and provides a visualization tool to empower users with the ability to control these leaks via blocking or substitution of PII. We evaluate ReCon's effectiveness with measurements from controlled experiments using leaks from the 100 most popular iOS, Android, and Windows Phone apps, and via an IRB-approved user study with 92 participants. We show that ReCon is accurate, efficient, and identifies a wider range of PII than previous approaches.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {361–374},
numpages = {14},
keywords = {machine learning, mobile privacy, personally identifiable information},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/3257203,
author = {Cox, Landon},
title = {Session details: Session VIII: App Security \&amp; Privacy},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3257203},
doi = {10.1145/3257203},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906413,
author = {Zhu, Suwen and Lu, Long and Singh, Kapil},
title = {CASE: Comprehensive Application Security Enforcement on COTS Mobile Devices},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906413},
doi = {10.1145/2906388.2906413},
abstract = {Without violating existing app security enforcement, malicious modules inside apps, such as a library or an external class, can steal private data and abuse sensitive capabilities meant for other modules inside the same apps. These so-called "module-level attacks" are quickly emerging, fueled by the pervasive use of third-party code in apps and the lack of module-level security enforcement on mobile platforms.To systematically thwart the threats, we build CASE, an automatic app patching tool used by app developers to enable module-level security in their apps built for COTS Android devices. During runtime, patched apps enforce developer-supplied security policies that regulate interactions among modules at the granularity of a Java class. Requiring no changes or special support from the Android OS, the enforcement is complete in covering inter-module crossings in apps and is robust against malicious Java and native app modules. We evaluate CASE with 420 popular apps and a set of Android's unit tests. The results show that CASE is fully compatible with the tested apps and incurs an average performance overhead of 4.9\%.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {375–386},
numpages = {12},
keywords = {concealed handler, dual-layer interception, module-level security, native-safe pages},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906404,
author = {Khan, Hassan and Hengartner, Urs and Vogel, Daniel},
title = {Targeted Mimicry Attacks on Touch Input Based Implicit Authentication Schemes},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906404},
doi = {10.1145/2906388.2906404},
abstract = {Touch input implicit authentication (``touch IA'') employs behavioural biometrics like touch location and pressure to continuously and transparently authenticate smartphone users. We provide the first ever evaluation of targeted mimicry attacks on touch IA and show that it fails against shoulder surfing and offline training attacks. Based on experiments with three diverse touch IA schemes and 256 unique attacker-victim pairs, we show that shoulder surfing attacks have a bypass success rate of 84\% with the majority of successful attackers observing the victim's behaviour for less than two minutes. Therefore, the accepted assumption that shoulder surfing attacks on touch IA are infeasible due to the hidden nature of some features is incorrect. For offline training attacks, we created an open-source training app for attackers to train on their victims' touch data. With this training, attackers achieved bypass success rates of 86\%, even with only partial knowledge of the underlying features used by the IA scheme. Previous work failed to find these severe vulnerabilities due to its focus on random, non-targeted attacks. Our work demonstrates the importance of considering targeted mimicry attacks to evaluate the security of an implicit authentication scheme. Based on our results, we conclude that touch IA is unsuitable from a security standpoint.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {387–398},
numpages = {12},
keywords = {shoulder surfing attacks, mimicry attacks, implicit authentication, continuous authentication},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906409,
author = {Herbster, Raul and DellaTorre, Scott and Druschel, Peter and Bhattacharjee, Bobby},
title = {Privacy Capsules: Preventing Information Leaks by Mobile Apps},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906409},
doi = {10.1145/2906388.2906409},
abstract = {Preventing the leakage of user information via untrusted third-party apps is a key challenge in mobile privacy. We propose and evaluate privacy capsules (PCs), a platform execution model for mobile apps that prevents the flow of private information to untrusted parties by design. With PCs, apps execute in two sequential phases. In the unsealed phase, the app has no access to sensitive input but full access to untrusted network resources. In the sealed state, the untrusted app has access to sensitive input, but can no longer communicate with untrusted resources. Privacy capsules are implemented by the mobile platform, are language independent, and require few changes to apps. Using a prototype PC implementation in Android, we show that PCs have low performance and energy overhead, and are suitable for a large class of apps.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {399–411},
numpages = {13},
keywords = {privacy, mobile apps, android},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

@inproceedings{10.1145/2906388.2906390,
author = {Brasser, Ferdinand and Kim, Daeyoung and Liebchen, Christopher and Ganapathy, Vinod and Iftode, Liviu and Sadeghi, Ahmad-Reza},
title = {Regulating ARM TrustZone Devices in Restricted Spaces},
year = {2016},
isbn = {9781450342698},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2906388.2906390},
doi = {10.1145/2906388.2906390},
abstract = {Smart personal devices equipped with a wide range of sensors and peripherals can potentially be misused in various environments. They can be used to exfiltrate sensitive information from enterprises and federal offices or be used to smuggle unauthorized information into classrooms and examination halls. One way to prevent these situations is to regulate how smart devices are used in such restricted spaces. In this paper, we present an approach that robustly achieves this goal for ARM TrustZone-based personal devices. In our approach, restricted space hosts use remote memory operations to analyze and regulate guest devices within the restricted space. We show that the ARM TrustZone allows our approach to obtain strong security guarantees while only requiring a small trusted computing base to execute on guest devices.},
booktitle = {Proceedings of the 14th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {413–425},
numpages = {13},
keywords = {restricted spaces, mobile device security, arm trustzone},
location = {Singapore, Singapore},
series = {MobiSys '16}
}

