@inproceedings{10.1145/3560905.3568546,
author = {Apicharttrisorn, Kittipat and Chen, Jiasi and Sekar, Vyas and Rowe, Anthony and Krishnamurthy, Srikanth V.},
title = {Breaking Edge Shackles: Infrastructure-Free Collaborative Mobile Augmented Reality},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568546},
doi = {10.1145/3560905.3568546},
abstract = {Collaborative AR applications are gaining popularity, but have heavy computing requirements for identifying and tracking AR devices and objects in the ecosystem. Prior AR frameworks typically rely on edge infrastructure to offload AR's compute-heavy tasks. However, such infrastructure may not always be available, and continuously running AR computations on user devices can rapidly drain battery and impact application longevity. In this work, we enable infrastructure-free mobile AR with a low energy footprint, by using collaborative time slicing to distribute compute-heavy AR tasks across user devices. Realizing this idea is challenging because distributed execution can result in inconsistent synchronization of the AR virtual overlays. Our framework, FreeAR, tackles this with novel lightweight techniques for tightly synchronized virtual overlay placements across user views, and low latency recovery upon disruptions. We prototype FreeAR on Android and show that it can improve the virtual overlay positioning accuracy (with respect to the IOU metric) by up to 78\%, relative to state-of-the-art collaborative AR systems, while also reducing power by up to 60\% relative to a direct application of those prior solutions.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1–15},
numpages = {15},
keywords = {energy efficiency, mobile augmented reality, object detection and tracking, simultaneous localization and mapping},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568519,
author = {He, Yuze and Ma, Li and Cui, Jiahe and Yan, Zhenyu and Xing, Guoliang and Wang, Sen and Hu, Qintao and Pan, Chen},
title = {AutoMatch: Leveraging Traffic Camera to Improve Perception and Localization of Autonomous Vehicles},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568519},
doi = {10.1145/3560905.3568519},
abstract = {Traffic camera is one of the most ubiquitous traffic facilities, providing high coverage of complex, accident-prone road sections such as intersections. This work leverages traffic cameras to improve the perception and localization performance of autonomous vehicles at intersections. In particular, vehicles can expand their range of perception by matching the images captured by both the traffic cameras and on-vehicle cameras. Moreover, a traffic camera can match its images to an existing high-definition map (HD map) to derive centimeter-level location of the vehicles in its field of view. To this end, we propose AutoMatch - a novel system for real-time image registration, which is a key enabling technology for traffic camera-assisted perception and localization of autonomous vehicles. Our key idea is to leverage landmark keypoints of distinctive structures such as ground signs at intersections to facilitate image registration between traffic cameras and HD maps or vehicles. By leveraging the strong structural characteristics of ground signs, AutoMatch can extract very few but precise landmark keypoints for registration, which effectively reduces the communication/compute overhead. We implement AutoMatch on a testbed consisting of a self-built autonomous car, drones for surveying and mapping, and real traffic cameras. In addition, we collect two new multi-view traffic image datasets at intersections, which contain images from 220 real operational traffic cameras in 22 cities. Experimental results show that AutoMatch achieves pixel-level image registration accuracy within 88 milliseconds, and delivers an 11.7\texttimes{} improvement in accuracy, 1.4\texttimes{} speedup in compute time, and 17.1\texttimes{} data transmission saving over existing approaches.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {16–30},
numpages = {15},
keywords = {cooperative sensing, infrastructure-assisted autonomous driving, perception fusion, vehicle-infrastructure cooperative system},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568540,
author = {Zhang, Ding and Zhou, Puqi and Han, Bo and Pathak, Parth},
title = {M5: Facilitating Multi-User Volumetric Content Delivery with Multi-Lobe Multicast over mmWave},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568540},
doi = {10.1145/3560905.3568540},
abstract = {Multi-user volumetric content delivery can enable numerous appealing applications, such as online education, telehealth, multiuser AR/VR training, immersive collaborative analytics, etc. However, the bandwidth-intensive nature of volumetric video streaming makes existing systems for single-user experiences hard to scale to multi-user scenarios. To address this critical issue, in this paper, we first perform a scaling experiment on mmWave networks that offer the needed multi-Gbps throughput and identify two key challenges of streaming high-quality volumetric videos to multiple users: frequent blockages of mmWave links and high transmission redundancy among users. To solve these problems, we propose a first-of-its-kind, agile, and cross-layer system, dubbed M5, for improving the performance and quality of experience for multi-user volumetric video streaming. M5 utilizes the 6DoF motion prediction of users to proactively adapt mmWave beams and prefetch frames to mitigate the blockage effects. Furthermore, it takes advantage of the multicast transmission to deliver the overlapped common content within users' viewports to reduce the bandwidth requirement. Our extensive experiments on a real testbed and with a trace-driven simulator show that M5 can effectively improve the frame rate by 44.1\% and volumetric video quality by 62.3\% compared to the state-of-the-art system.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {31–46},
numpages = {16},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568513,
author = {Zhang, Shujie and Zheng, Tianyue and Wang, Hongbo and Chen, Zhe and Luo, Jun},
title = {Quantifying the Physical Separability of RF-Based Multi-Person Respiration Monitoring via SINR},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568513},
doi = {10.1145/3560905.3568513},
abstract = {Recent years have witnessed a growing interest in contact-free respiration monitoring leveraging radio-frequency (RF) technologies. However, the proposed solutions mostly consider single-person scenarios, whereas a few multi-person monitoring proposals simply apply blind source separation to handle inter-person interference, without drawing a clear line between physical and algorithmic separability. In this paper, we set out to answer: under what condition(s) one may physically separate multiple respiration signals sensed by diversified RF technologies? Drawing inspiration from conventional signal processing, we propose respiration-to-interference-plus-noise ratio (RINR) as a novel metric, taking into account the impact from both background noise and various interfering sources. Instead of attenuation in Euclidean distance, RINR has to be evaluated upon range/angle bins where physical separation actually take place. As signal attenuation has never been modeled in this manner, we rise to this challenge by levering a deep learning model to fit a spread function upon range/angle bins. The resulting RINR model allows us to concretely indicate the limit of physical separability of RF-based multi-person respiration monitoring. Our extensive experiments firmly validate the RINR model, thus evidently demonstrating the benefits of employing RINR model as a guideline for conducting respiration monitoring with different RF technologies.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {47–60},
numpages = {14},
keywords = {RF-sensing, SINR, contact-free sensing, respiration monitoring},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568500,
author = {Yan, Zhenyu and Tan, Rui and Song, Qun and Lu, Chris Xiaoxuan},
title = {Telesonar: Robocall Alarm System by Detecting Echo Channel and Breath Timing},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568500},
doi = {10.1145/3560905.3568500},
abstract = {Massive fraudulent and phishing robocalls present threats to societies. The integration of artificial intelligence technologies, including dialogue and voice generation systems, renders the robocalls more deceptive. Existing countermeasures such as caller ID, call provenance, voiceprint, and fake voice detection have respective limitations and are heavyweight for end users' smartphones. This paper studies detecting the acoustic echo channel on the remote end of a call based on the received voice. The positive detection result evidencing the physical setup of an audio system is indicative of a human caller. However, the acoustic echo cancellation mechanisms of most audio systems and the use of earphone/headset diminish echoes significantly. To address these issues, the proposed Telesonar transmits short chirps during the vulnerable time of echo cancellation, detects the tiny echo remnants from the received voice, and passively analyzes the timing of caller's breath sounds to confirm a human caller. Extensive real experiments under a wide range of settings show that Telesonar correctly recognizes human callers with a rate of over 95\%, while wrongly recognizing voice robots as human with a rate of 3.8\%.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {61–74},
numpages = {14},
keywords = {internet-of-things systems, mobile systems, robocall detection},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568523,
author = {Zhang, Junbo and Balakrishnan, Gaurav and Srinidhi, Sruti and Bhat, Arnav and Kumar, Swarun and Bettinger, Christopher},
title = {NFCapsule: An Ingestible Sensor Pill for Eosinophilic Esophagitis Detection Based on near-Field Coupling},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568523},
doi = {10.1145/3560905.3568523},
abstract = {This paper presents NFCapsule, a light-weight, battery-free, and ingestible biomedical sensor that can potentially enable non-invasive detection of active eosinophilic esophagitis (EoE). EoE is an allergen-induced inflammatory condition of the esophagus; its diagnosis generally involves invasive, wired, and time-consuming endoscopy. In contrast, NFCapsule aims to wirelessly detect active EoE by tracking tissue impedance through an ingestible pill that the patient swallows. Specifically, recent biomedical research has shown that active EoE induces observable changes in the electrochemical impedance of the esophagus tissue due to an increase in its intercellular spacing. We design the NFCapsule pill based on RLC resonant circuits and model the target tissue as an impedance component that changes the resonant properties of the pill circuit. Further, the NFCapsule reader identifies the resonant properties of the pill by consistently monitoring the amount of energy transferred to the pill as it goes through the esophagus, and converts this information to estimates of bio-impedance. We implement NFCapsule pill prototypes with flexible polyimide PCBs and gelatin capsules (27 mm in height and 10 mm in diameter) and evaluated NFCapsule with both ionic agarose hydrogel models and ex vivo porcine esophageal tissues (no human patients involved). We show that NFCapsule maintains high classification accuracy under various practical scenarios (e.g., blockage, bending, movement, etc.) and achieves 85\% average accuracy between healthy and unhealthy tissue samples.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {75–90},
numpages = {16},
keywords = {inductive coupling, ingestible electronics, near-field, resonant circuit, wireless systems},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568520,
author = {Ling, Neiwen and Huang, Xuan and Zhao, Zhihe and Guan, Nan and Yan, Zhenyu and Xing, Guoliang},
title = {BlastNet: Exploiting Duo-Blocks for Cross-Processor Real-Time DNN Inference},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568520},
doi = {10.1145/3560905.3568520},
abstract = {In recent years, Deep Neural Network (DNN) has been increasingly adopted by a wide range of time-critical applications running on edge platforms with heterogeneous multiprocessors. To meet the stringent timing requirements of these applications, heterogeneous CPU and GPU resources must be efficiently utilized for the inference of multiple DNN models. Such a cross-processor real-time DNN inference paradigm poses major challenges due to the inherent performance imbalance among different processors and the lack of real-time support for cross-processor inference from existing deep learning frameworks. In this work, we propose a new system named BlastNet that exploits duo-block - a new model inference abstraction to support highly efficient cross-processor real-time DNN inference. Each duo-block has a dual model structure, enabling efficient fine-grained inference alternatively across different processors. BlastNet employs a novel block-level Neural Architecture Search (NAS) technique to generate duo-blocks, which accounts for computing characteristics and communication overhead. The duo-blocks are optimized at design time and then dynamically scheduled to achieve high resource utilization of heterogeneous CPU and GPU at runtime. BlastNet is implemented on an indoor autonomous driving platform and three popular edge platforms. Extensive results show that BlastNet achieves 35.07 \% less deadline missing rate with a mere 1.63\% of model accuracy loss.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {91–105},
numpages = {15},
keywords = {CPU-GPU heterogeneous platform, edge artificial intelligence, multi-DNN concurrent execution, neural architecture search, on-device deep learning, real-time scheduling},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568538,
author = {Sun, Jingwei and Li, Ang and Duan, Lin and Alam, Samiul and Deng, Xuliang and Guo, Xin and Wang, Haiming and Gorlatova, Maria and Zhang, Mi and Li, Hai and Chen, Yiran},
title = {FedSEA: A Semi-Asynchronous Federated Learning Framework for Extremely Heterogeneous Devices},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568538},
doi = {10.1145/3560905.3568538},
abstract = {Federated learning (FL) has attracted increasing attention as a promising technique to drive a vast number of edge devices with artificial intelligence. However, it is very challenging to guarantee the efficiency of a FL system in practice due to the heterogeneous computation resources on different devices. To improve the efficiency of FL systems in the real world, asynchronous FL (AFL) and semi-asynchronous FL (SAFL) methods are proposed such that the server does not need to wait for stragglers. However, existing AFL and SAFL systems suffer from poor accuracy and low efficiency in realistic settings where the data is non-IID distributed across devices and the on-device resources are extremely heterogeneous. In this work, we propose FedSEA - a semi-asynchronous FL framework for extremely heterogeneous devices. We theoretically disclose that the unbalanced aggregation frequency is a root cause of accuracy drop in SAFL. Based on this analysis, we design a training configuration scheduler to balance the aggregation frequency of devices such that the accuracy can be improved. To improve the efficiency of the system in realistic settings where the devices have dynamic on-device resource availability, we design a scheduler that can efficiently predict the arriving time of local updates from devices and adjust the synchronization time point according to the devices' predicted arriving time. We also consider the extremely heterogeneous settings where there exist extremely lagging devices that take hundreds of times as long as the training time of the other devices. In the real world, there might be even some extreme stragglers which are not capable of training the global model. To enable these devices to join in training without impairing the systematic efficiency, Fed-SEA enables these extreme stragglers to conduct local training on much smaller models. Our experiments show that compared with status quo approaches, FedSEA improves the inference accuracy by 44.34\% and reduces the systematic time cost and local training time cost by 87.02\texttimes{} and 792.9\texttimes{}. FedSEA also reduces the energy consumption of the devices with extremely limited resources by 752.9\texttimes{}.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {106–119},
numpages = {14},
keywords = {device heterogeneity, edge intelligence, federated learning},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568548,
author = {Liu, Miaomiao and Yang, Sikai and Chomsin, Wyssanie and Du, Wan},
title = {Real-Time Tracking of Smartwatch Orientation and Location by Multitask Learning},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568548},
doi = {10.1145/3560905.3568548},
abstract = {Arm posture tracking is essential for many applications, such as gesture recognition, fitness training, and motion-based controls. Smartwatches with Inertial Measurement Unit (IMU) sensors (i.e., accelerometer, gyroscope, and magnetometer) provide a convenient way to track the orientation and location of the wrist. Existing orientation estimations are based on predefined data fusion methods that do not consider the variations in the data quality of different IMU sensors. Existing location estimations rely on the estimated orientation results. A small orientation estimation error may cause high inaccuracy in location estimation. Moreover, these location estimation algorithms, e.g., Hidden Markov Model and Particle Filters, cannot provide real-time tracking on commercial mobile devices due to high computation overhead. This paper presents RTAT, a Real-Time Arm Tracking system that tackles the above limitations in a data-driven way. RTAT estimates both orientation and location simultaneously using a multitask learning neural network. It also incorporates a unique attention layer and a dedicated loss function to learn the dynamic relationship among IMU sensors. RTAT supports real-time tracking by performing model inference on smartphones. Finally, to train RTAT's neural network, we develop an easy-to-use labeled data collection system that uses a low-cost virtual reality system to provide orientation and location labels for the smartwatch. Extensive experiments show RTAT significantly outperforms existing state-of-the-art solutions in both accuracy and latency.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {120–133},
numpages = {14},
keywords = {arm tracking, inertial measurement unit, multitask learning},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568537,
author = {Chen, Ruirong and Huang, Kai and Gao, Wei},
title = {AiFi: AI-Enabled WiFi Interference Cancellation with Commodity PHY-Layer Information},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568537},
doi = {10.1145/3560905.3568537},
abstract = {Interference could result in significant performance degradation in WiFi networks. Most existing solutions to interference cancellation require extra RF hardware, which is usually infeasible in many low-power wireless scenarios. In this paper, we present AiFi, a new interference cancellation technique that can be applied to commodity WiFi devices without using any extra RF hardware. The key idea of AiFi is to retrieve knowledge about interference from the locally available physical-layer (PHY) information at the WiFi receiver, including the pilot information (PI) and the channel state information (CSI). AiFi leverages the power of AI to address the possible ambiguity when estimating interference from these PHY information, and incorporates the domain knowledge about WiFi PHY to minimize the neural network complexity. Experiment results show that AiFi can correct 80\% of bit errors due to interference and improves the MAC frame reception rate by 18x, with <1ms latency for interference cancellation in each frame.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {134–148},
numpages = {15},
keywords = {artificial intelligence, channel state information, interference cancellation, pilot information, wifi},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568508,
author = {Xu, Chenhan and Chen, Tianyu and Li, Huining and Gherardi, Alexander and Weng, Michelle and Li, Zhengxiong and Xu, Wenyao},
title = {Hearing Heartbeat from Voice: Towards Next Generation Voice-User Interfaces with Cardiac Sensing Functions},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568508},
doi = {10.1145/3560905.3568508},
abstract = {Voice user interfaces (VUIs) have been adopted in many IoT and mobile devices in daily life. VUIs provide a good user experience with lower-cost hardware (i.e., microphone) and higher throughput (compared with keyboard and touchscreen). Currently, identity authentication and receiving commands are the two most common interactions through VUIs, leaving physiological information in the voice unexploited. Recognizing this untapped potential, we propose VocalHR to extend VUIs beyond voice commands to heart activity sensing without additional hardware. VocalHR is built upon the voice-heart modulation effect, which is rooted in the cardiac activities' impacts on the behavior of the vocal organ during voice production. VocalHR captures voice features of cardiac activity in multiple voice organs and proposes a deep learning pipeline to transform features into cardiac activities. As this is the first study exploring voice-based heart activity sensing, we conducted extensive experiments on 43 demographically diverse subjects to verify the intrinsic link between voice and heart activities. On average, VocalHR can achieve less than 11.1\% normalized sensing error on the heart event timing. Our further evaluation shows VocalHR is robust to different microphone specifications and varying speech rates.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {149–163},
numpages = {15},
keywords = {contactless sensing, healthcare, voice biometrics, voice-user interface},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568531,
author = {Jiang, Linshan and Song, Qun and Tan, Rui and Li, Mo},
title = {PriMask: Cascadable and Collusion-Resilient Data Masking for Mobile Cloud Inference},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568531},
doi = {10.1145/3560905.3568531},
abstract = {Mobile cloud offloading is indispensable for inference tasks based on large-scale deep models. However, transmitting privacy-rich inference data to the cloud incurs concerns. This paper presents the design of a system called PriMask, in which the mobile device uses a secret small-scale neural network called MaskNet to mask the data before transmission. PriMask significantly weakens the cloud's capability to recover the data or extract certain private attributes. The MaskNet is cascadable in that the mobile can opt in to or out of its use seamlessly without any modifications to the cloud's inference service. Moreover, the mobiles use different MaskNets, such that the collusion between the cloud and some mobiles does not weaken the protection for other mobiles. We devise a split adversarial learning method to train a neural network that generates a new MaskNet quickly (within two seconds) at run time. We apply PriMask to three mobile sensing applications with diverse modalities and complexities, i.e., human activity recognition, urban environment crowdsensing, and driver behavior recognition. Results show PriMask's effectiveness in all the three applications.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {164–178},
numpages = {15},
keywords = {cloud inference, dynamic neural networks, privacy-preserving techniques},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568533,
author = {Pirayesh, Hossein and Zhang, Shichen and Sangdeh, Pedram Kheirkhah and Zeng, Huacheng},
title = {MaLoRaGW: Multi-User MIMO Transmission for LoRa},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568533},
doi = {10.1145/3560905.3568533},
abstract = {LoRa has emerged as a key wireless communication technology for a gateway to provide geographically-distributed IoT devices with low-rate, long-range connections. In this paper, we present MaLoRaGW, the first-of-its-kind Multi-antenna LoRa GateWay that enables multi-user MIMO (MU-MIMO) LoRa communications in both uplink and downlink. MaLoRaGW was inspired by the success of MU-MIMO in cellular and Wi-Fi networks. The key component of MaLoRaGW is a joint baseband PHY design for uplink packet detection and downlink beamforming. Its innovation lies in three modules: spatial signal projection, accurate channel estimation, and implicit beamforming, all of which reside only in a LoRa gateway and require no modification on LoRa client devices. We have built a prototype of two-antenna MaLoRaGW on a USRP device and extensively evaluated its performance with commercial LoRa dongles in three scenarios: lab, office building, and university campus. Our experimental results show that, compared to the state-of-the-art, the two-antenna MaLoRaGW increases uplink throughput by 10\% and downlink throughput by 95\%.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {179–192},
numpages = {14},
keywords = {LoRa, beamforming, chirp spread spectrum, collision recovery, multi-user MIMO, throughput},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568547,
author = {Yang, Kang and Du, Wan},
title = {LLDPC: A Low-Density Parity-Check Coding Scheme for LoRa Networks},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568547},
doi = {10.1145/3560905.3568547},
abstract = {Low-density parity-check (LDPC) codes have been widely used for Forward Error Correction (FEC) in wireless networks because they can approach the capacity of wireless links with lightweight encoding complexity. Although LoRa networks have been developed for many applications, they still adopt simple FEC codes, i.e., Hamming codes, which provide limited FEC capacity, causing unreliable data transmissions and high energy consumption of LoRa nodes. To close this gap, this paper develops LLDPC, which realizes LDPC coding in LoRa networks. Three challenges are addressed. 1) LoRa employs Chirp Spread Spectrum (CSS) modulation, which only provides hard demodulation results without soft information. However, LDPC requires the Log-Likelihood Ratio (LLR) of each received bit for decoding. We develop an LLR extractor for LoRa CSS. 2) Some erroneous bits may have high LLRs (i.e., wrongly confident in their correctness), significantly affecting the LDPC decoding efficiency. We use symbol-level information to fine-tune the LLRs of some bits to improve the LDPC decoding efficiency. 3) Soft Belief Propagation (SBP) is typically used as the LDPC decoding algorithm. It involves heavy iterative computation, resulting in a long decoding latency, which prevents the gateway from sending timely an acknowledgment. We take advantage of recent advances in graph neural networks for fast belief propagation in LDPC decoding. Extensive simulations on a large-scale synthetic dataset and in-filed experiments reveal that LLDPC can extend the lifetime of the default LoRa by 86.7\% and reduce the decoding latency of the SBP algorithm by 58.09\texttimes{}.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {193–206},
numpages = {14},
keywords = {LoRa, forward error correction, low-power wide-area networks, wireless systems},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568561,
author = {Bakar, Abu and Goel, Rishabh and de Winkel, Jasper and Huang, Jason and Ahmed, Saad and Islam, Bashima and Pawe\l{}czak, Przemys\l{}aw and Y\i{}ld\i{}r\i{}m, Kas\i{}m Sinan and Hester, Josiah},
title = {Protean: An Energy-Efficient and Heterogeneous Platform for Adaptive and Hardware-Accelerated Battery-Free Computing},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568561},
doi = {10.1145/3560905.3568561},
abstract = {Battery-free and intermittently powered devices offer long lifetimes and enable deployment in new applications and environments. Unfortunately, developing sophisticated inference-capable applications is still challenging due to the lack of platform support for more advanced (32-bit) microprocessors and specialized accelerators---which can execute data-intensive machine learning tasks, but add complexity across the stack when dealing with intermittent power. We present Protean to bridge the platform gap for inference-capable battery-free sensors. Designed for runtime scalability, meeting the dynamic range of energy harvesters with matching heterogeneous processing elements like neural network accelerators. We develop a modular "plug-and-play" hardware platform, SuperSensor, with a reconfigurable energy storage circuit that powers a 32-bit ARM-based microcontroller with a convolutional neural network accelerator. An adaptive task-based runtime system, Chameleon, provides intermittency-proof execution of machine learning tasks across heterogeneous processing elements. The runtime automatically scales and dispatches these tasks based on incoming energy, current state, and programmer annotations. A code generator, Metamorph, automates conversion of ML models to intermittent safe execution across heterogeneous compute elements. We evaluate Protean with audio and image workloads and demonstrate up to 666x improvement in inference energy efficiency by enabling usage of modern computational elements within intermittent computing. Further, Protean provides up to 166\% higher throughput compared to non-adaptive baselines.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {207–221},
numpages = {15},
keywords = {energy harvesting platform, intermittent computing, protean},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568543,
author = {de Winkel, Jasper and Hoefnagel, Tom and Blokland, Boris and Pawe\l{}czak, Przemys\l{}aw},
title = {DIPS: Debug Intermittently-Powered Systems Like Any Embedded System},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568543},
doi = {10.1145/3560905.3568543},
abstract = {Debugging and testing battery-free intermittently-powered systems is notoriously difficult. This is not only due to the additional complexity of maintaining state through power failures but also due to the lack of proper tools to test and debug these systems. As a solution, we present DIPS: a fully-featured hardware debugger for battery-free intermittently-powered systems capable of automatically verifying memory and peripheral state between power failures. Our solution seamlessly integrates an emulator allowing for emulation of any power scenario to the device under test. This allows our debugger to pause emulation and program execution when debugging or when state restoration issues are detected. Our new system is built around GNU Debugger (GDB): a widely-used debugging tool. Therefore, DIPS allows for a debugging process identical to state-of-the-art debuggers for continuously-powered devices. User studies found that our debugger is easy and intuitive to use. It allows embedded system developers to find bugs quicker in code written for battery-free devices. With our debugger we found unseen errors in state-of-the-art software frameworks for intermittently-powered systems.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {222–235},
numpages = {14},
keywords = {debugging, emulation, intermittent systems, software testing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568512,
author = {Bakar, Abu and Rahman, Tousif and Shafik, Rishad and Kawsar, Fahim and Montanari, Alessandro},
title = {Adaptive Intelligence for Batteryless Sensors Using Software-Accelerated Tsetlin Machines},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568512},
doi = {10.1145/3560905.3568512},
abstract = {Tsetlin Machine (TM) is a new machine learning algorithm that encodes propositional logic into learning automata---a set of logical expressions composed of boolean input features---to recognise patterns. The simplicity, efficiency, and accuracy of this logic-based algorithm encourage rethinking the application of traditional arithmetic-based neural networks (NNs) in intelligent sensors design. Indeed, TM is a promising candidate for embedding intelligence into tiny batteryless sensors with the potential to address two critical challenges: (1) computing under resource constraints and (2) demand for dynamic adaptation to the unpredictable nature of harvested energy. However, its structural model complexity manifests in two conflicting issues: large memory footprint and long latency. This paper addresses these shortcomings by proposing adaptive compression techniques exploiting the inherent redundancies observed in trained models. Through dynamically scaling the computational complexity based on available energy, our techniques significantly reduce the memory footprint and speed up the runtime execution. We evaluate our techniques against standard TMs and binarized neural networks (BNNs) for vision and acoustic workloads deployed on a TI MSP430 MCU operating under intermittent power supply conditions. We show that our techniques can achieve up to 99\% compression of TM models and offer 13.5\texttimes{} latency and energy reductions when compared with the most efficient neural network configuration without compromising accuracy.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {236–249},
numpages = {14},
keywords = {battery-free, energy efficiency, intermittent computing, neural networks, tsetlin machines},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568526,
author = {Cui, Minhao and Wang, Qing and Xiong, Jie},
title = {Bracelet+: Harvesting the Leaked RF Energy in VLC with Wearable Bracelet Antenna},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568526},
doi = {10.1145/3560905.3568526},
abstract = {Visible Light Communication (VLC) is widely considered a promising technology for the coming 6G networks. Recent studies show that a VLC transmitter not only emits visible light signals but also leaks RF signals during the transmission. In this work, we devote effort to harvesting the free leaked RF energy from VLC transmissions. We observe that the surrounding objects could help a coil antenna harvest significantly more RF energy. Based on this observation, we propose our system Bracelet+, which involves the human body in the harvesting system to increase the harvested power. After careful analysis of the influence of the human body on the harvested power, we prototype the coil antenna as a bracelet that achieves both high harvested power and convenience for wearing. The average power of the RF energy harvested by our design is 10\texttimes{} larger than that of the conventional coil antenna, without causing any interference to the communication of VLC systems. The harvested power can reach up to micro-watts in our tested scenarios. Such a micro-watt level of harvested energy has the potential to power up ultra-low-power sensors such as temperature sensors and glucose sensors.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {250–262},
numpages = {13},
keywords = {RF leakage, energy harvesting, human body-augmented, side channel, visible light communication},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568501,
author = {Lu, Yan and Jiang, Shiqi and Cao, Ting and Shu, Yuanchao},
title = {Turbo: Opportunistic Enhancement for Edge Video Analytics},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568501},
doi = {10.1145/3560905.3568501},
abstract = {Edge computing is being widely used for video analytics. To alleviate the inherent tension between accuracy and cost, various video analytics pipelines have been proposed to optimize the usage of GPU on edge nodes. Nonetheless, we find that GPU compute resources provisioned for edge nodes are commonly under-utilized due to video content variations, subsampling and filtering at different places of a video analytics pipeline. As opposed to model and pipeline optimization, in this work, we study the problem of opportunistic data enhancement using the non-deterministic and fragmented idle GPU resources. In specific, we propose a task-specific discrimination and enhancement module, and a model-aware adversarial training mechanism, providing a way to exploit idle resources to identify and transform pipeline-specific, low-quality images in an accurate and efficient manner. A multi-exit enhancement model structure and a resource-aware scheduler is further developed to make online enhancement decisions and fine-grained inference execution under latency and GPU resource constraints. Experiments across multiple video analytics pipelines and datasets reveal that our system boosts DNN object detection accuracy by 7.27 -- 11.34\% by judiciously allocating 15.81 -- 37.67\% idle resources on frames that tend to yield greater marginal benefits from enhancement.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {263–276},
numpages = {14},
keywords = {deep neural networks, edge computing, object detection, opportunistic enhancement, video analytics},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568534,
author = {Li, Shuheng and Shang, Jingbo and Gupta, Rajesh K. and Hong, Dezhi},
title = {SQEE: A Machine Perception Approach to Sensing Quality Evaluation at the Edge by Uncertainty Quantification},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568534},
doi = {10.1145/3560905.3568534},
abstract = {Cyber-physical systems are starting to adopt neural network (NN) models for a variety of smart sensing applications. While several efforts seek better NN architectures for system performance improvement, few attempts have been made to study the deployment of these systems in the field. Proper deployment of these systems is critical to achieving ideal performance, but the current practice is largely empirical via trials and errors, lacking a measure of quality. Sensing quality should reflect the impact on the performance of NN models that drive machine perception tasks. However, traditional approaches either evaluate statistical difference that exists objectively, or model the quality subjectively via human perception.In this work, we propose an efficient sensing quality measure requiring limited data samples using smart voice sensing system as an example. We adopt recent techniques in uncertainty evaluation for NN to estimate audio sensing quality. Intuitively, a deployment at better sensing location should lead to less uncertainty in NN predictions. We design SQEE, Sensing Quality Evaluation at the Edge for NN models, which constructs a model ensemble through Monte-Carlo dropout and estimates posterior total uncertainty via average conditional entropy. We collected data from three indoor environments, with a total of 148 transmitting-receiving (t-r) locations experimented and more than 7,000 examples tested. SQEE achieves the best performance in terms of the top-1 ranking accuracy---whether the measure finds the best spot for deployment, in comparison with other uncertainty strategies. We implemented SQEE on a ReSpeaker to study SQEE's real-world efficacy. Experimental result shows that SQEE can effectively evaluate the data collected from each t-r location pair within 30 seconds and achieve an average top-3 ranking accuracy of over 94\%. We further discuss generalization of our framework to other sensing schemes.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {277–290},
numpages = {14},
keywords = {sensing quality evaluation, speech sensing, uncertainty quantification},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568527,
author = {Paul, Sibendu and Rao, Kunal and Coviello, Giuseppe and Sankaradas, Murugan and Po, Oliver and Hu, Y. Charlie and Chakradhar, Srimat},
title = {Enhancing Video Analytics Accuracy via Real-time Automated Camera Parameter Tuning},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568527},
doi = {10.1145/3560905.3568527},
abstract = {In Video Analytics Pipelines (VAP), Analytics Units (AUs) such as object detection and face recognition running on remote servers critically rely on surveillance cameras to capture high-quality video streams in order to achieve high accuracy. Modern IP cameras come with a large number of camera parameters that directly affect the quality of the video stream capture. While a few of such parameters, e.g., exposure, focus, white balance are automatically adjusted by the camera internally, the remaining ones are not. We denote such camera parameters as non-automated (NAUTO) parameters. In this paper, we first show that environmental condition changes can have significant adverse effect on the accuracy of insights from the AUs, but such adverse impact can potentially be mitigated by dynamically adjusting NAUTO camera parameters in response to changes in environmental conditions. We then present CamTuner, to our knowledge, the first framework that dynamically adapts NAUTO camera parameters to optimize the accuracy of AUs in a VAP in response to adverse changes in environmental conditions. CamTuner is based on SARSA reinforcement learning and it incorporates two novel components: a light-weight analytics quality estimator and a virtual camera that drastically speed up offline RL training. Our controlled experiments and real-world VAP deployment show that compared to a VAP using the default camera setting, CamTuner enhances VAP accuracy by detecting 15.9\% additional persons and 2.6\%--4.2\% additional cars (without any false positives) in a large enterprise parking lot and 9.7\% additional cars in a 5G smart traffic intersection scenario, which enables a new usecase of accurate and reliable automatic vehicle collision prediction (AVCP). CamTuner opens doors for new ways to significantly enhance video analytics accuracy beyond incremental improvements from refining deep-learning models.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {291–304},
numpages = {14},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568502,
author = {Wang, Chaowei and Zhu, Huadi and Li, Ming},
title = {SpeechQoE: A Novel Personalized QoE Assessment Model for Voice Services via Speech Sensing},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568502},
doi = {10.1145/3560905.3568502},
abstract = {Quality of Experience (QoE) assessment is a long-lasting but yet-to-be-resolved task. Existing approaches, especially for conversational voice services, are restricted to leveraging network-centric parameters. However, their performances are hardly satisfactory due to the failure to consider comprehensive QoE-related factors. Moreover, they develop a one-for-all model that is uniform for all individuals and thus incapable of handling user diversity in QoE perception. This paper proposes a personalized QoE assessment model, namely SpeechQoE. It exploits speaker's speech signals to infer individual's perceived quality in voice services. SpeechQoE fundamentally addresses the drawback of conventional models. Instead of enumerating and incorporating unlimited QoE-related factors, SpeechQoE takes as input speech signals that inherently bear rich information needed for QoE assessment of the speaker. SpeechQoE employs an efficient few-shot learning framework to adapt the model to a new user quickly. We additionally design a lightweight data synthetic scheme to minimize the overhead of data collection needed for model adaption. A modular integration with a conventional parametric model is further implemented to avoid issues caused by the clean-slate data-driven approach. Our experiments show that SpeechQoE achieves an accuracy of 91.4\% in QoE assessment which outperforms the state-of-the-art solutions by a clear margin. As another contribution of this work, we build a dataset that would be the first source of annotated audio tracks for QoE assessment of conversational calls.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {305–319},
numpages = {15},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568544,
author = {Cao, Jiani and Lin, Chengdong and Liu, Yang and Li, Zhenjiang},
title = {Gaze Tracking on Any Surface with Your Phone},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568544},
doi = {10.1145/3560905.3568544},
abstract = {This paper introduces ASGaze, a new gaze tracking system designed using the common RGB camera from mobile phones. In addition to improving the accuracy of existing RGB camera-based gaze tracking methods, a novelty of ASGaze is that it can be configured to track gaze points on various surface areas commonly required in different applications, such as mobile phone screens, computer displays or even non-electronic surfaces like whiteboards or paper - a situation that is difficult for existing RGB camera-based methods to handle. To achieve the design of ASGaze, we revisit the 3D geometric model of the eye, which is widely adopted by high-end and commercial gaze trackers, and it has the potential to achieve our design goals. To avoid the high cost of commercial solutions, we identify three key issues to be addressed when processing the eye model with an RGB camera, including how to first accurately extract eye iris boundary that is the meta-information in our gaze tracking design, and then how to remove gaze ambiguity from iris boundary to gaze point transformation, and finally how to precisely map gaze points to the target tracking surface. In this paper, we propose a series of effective techniques to address these issues. We develop a prototype system and conduct extensive experiments on three different typical tracking surfaces to show promising performance gains compared to the recent solution.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {320–333},
numpages = {14},
keywords = {eye model, gaze tracking, mobile sensing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568504,
author = {Wang, Ziqi and Sarker, Ankur and Wu, Jason and Hua, Derek and Dong, Gaofeng and Singh, Akash Deep and Srivastava, Mani},
title = {Capricorn: Towards Real-Time Rich Scene Analysis Using RF-Vision Sensor Fusion},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568504},
doi = {10.1145/3560905.3568504},
abstract = {Video scene analysis is a well-investigated area where researchers have devoted efforts to detect and classify people and objects in the scene. However, real-life scenes are more complex: the intrinsic states of the objects (e.g., machine operating states or human vital signals) are often overlooked by vision-based scene analysis. Recent work has proposed a radio frequency (RF) sensing technique, wireless vibrometry, that employs wireless signals to sense subtle vibrations from the objects and infer their internal states. We envision that the combination of video scene analysis with wireless vibrometry form a more comprehensive understanding of the scene, namely "rich scene analysis". However, the RF sensors used in wireless vibrometry only provide time series, and it is challenging to associate these time series data with multiple real-world objects. We propose a real-time RF-vision sensor fusion system, Capricorn, that efficiently builds a cross-modal correspondence between visual pixels and RF time series to better understand the complex natures of a scene. The vision sensors in Capricorn model the surrounding environment in 3D and obtain the distances of different objects. In the RF domain, the distance is proportional to the signal time-of-flight (ToF), and we can leverage the ToF to separate the RF time series corresponding to each object. The RF-vision sensor fusion in Capricorn brings multiple benefits. The vision sensors provide environmental contexts to guide the processing of RF data, which helps us select the most appropriate algorithms and models. Meanwhile, the RF sensor yields additional information that is originally invisible to vision sensors, providing insight into objects' intrinsic states. Our extensive evaluations show that Capricorn real-timely monitors multiple appliances' operating status with an accuracy of 97\%+ and recovers vital signals like respirations from multiple people. A video (https://youtu.be/b-5nav3Fi78) demonstrates the capability of Capricorn.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {334–348},
numpages = {15},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568524,
author = {Xie, Binbin and Ganesan, Deepak and Xiong, Jie},
title = {Embracing LoRa Sensing with Device Mobility},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568524},
doi = {10.1145/3560905.3568524},
abstract = {Wireless sensing is an emerging technology that can obtain rich context information of human targets in a contact-free manner. Though promising, a missing component of current wireless sensing is sensing under device motions. In this work, we propose to integrate wireless sensing with the mobility of a robot. This is non-trivial because we find that device motions can severely degrade the sensing performance and even completely fail existing wireless sensing systems. In this paper, we propose novel signal processing schemes to address the impact of device motions to enable sensing with device mobility. For the first time, we integrate the robot's mobility with LoRa sensing to enlarge the sensing coverage. Comprehensive experiments demonstrate the effectiveness of the proposed system. We employ two representative sensing applications, i.e., fine-grained respiration monitoring and coarse-grained human walking sensing, to showcase the performance of our system. The proposed system is able to achieve accurate sensing in the presence of device motions, moving wireless sensing one step forward towards truly ubiquitous sensing for real-life adoption.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {349–361},
numpages = {13},
keywords = {LoRa sensing, device motion removal, integration of wireless sensing and device mobility, interference mitigation},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568536,
author = {Wang, Yichao and Ren, Yili and Chen, Yingying and Yang, Jie},
title = {Wi-Mesh: A WiFi Vision-Based Approach for 3D Human Mesh Construction},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568536},
doi = {10.1145/3560905.3568536},
abstract = {In this paper, we present, Wi-Mesh, a WiFi vision-based 3D human mesh construction system. Our system leverages the advances of WiFi to visualize the shape and deformations of the human body for 3D mesh construction. In particular, it leverages multiple transmitting and receiving antennas on WiFi devices to estimate the two-dimensional angle of arrival (2D AoA) of the WiFi signal reflections to enable WiFi devices to "see" the physical environment as we humans do. It then extracts only the images of the human body from the physical environment, and leverages deep learning models to digitize the extracted human body into a 3D mesh representation. Experimental evaluation under various indoor environments shows that Wi-Mesh achieves an average vertices location error of 2.81cm and joint position error of 2.4cm, which is comparable to the systems that utilize specialized and dedicated hardware. The proposed system has the advantage of reusing the WiFi devices that already exist in the environment for potential mass adoption. It can also work in non-line of sight (NLoS), poor lighting conditions, and baggy clothes, where the camera-based systems do not work well.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {362–376},
numpages = {15},
keywords = {3D human mesh, channel state information (CSI), deep learning, wifi sensing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568542,
author = {Zhang, Xiaotong and Li, Zhenjiang and Zhang, Jin},
title = {Synthesized Millimeter-Waves for Human Motion Sensing},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568542},
doi = {10.1145/3560905.3568542},
abstract = {Millimeter-wave (mmWave)-based human motion sensing, such as activity recognition and skeleton tracking, enables many useful applications. However, it suffers from a scarcity issue of training datasets, which fundamentally limits a widespread adoption of this technology in practice, as collecting and labeling such datasets are difficult and expensive. This paper presents SynMotion, a new mmWave-based human motion sensing system. Its novelty lies in harvesting available vision-based human motion datasets, for knowing the coordinates of body skeletal points under different motions, to synthesize mmWave sensing signals that bounce off the human body, so that the synthesized signals could inherit labels (skeletal coordinates and the name of each motion) from vision-based datasets directly. SynMotion demonstrates the ability to generate such labeled synthesized data at high quality to address the training-data scarcity issue and enable two sensing services that can work with commercial radars, including 1) zero-shot activity recognition, where the classifier reads real mmWaves for recognition, but it is only trained on synthesized data; and 2) body skeleton tracking with few/zero-shot learning on real mmWaves. To design SynMotion, we address the challenges of both the inherent complication of mmWave synthesis and the micro-level differences compared to real mmWaves. Extensive experiments show that SynMotion outperforms the latest zero-shot mmWave-based activity recognition method. For skeleton tracking, SynMotion achieves comparable performance to the state-of-the-art mmWave-based method trained on the labeled mmWaves, and SynMotion can further outperform it for the unseen users.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {377–390},
numpages = {14},
keywords = {activity recognition, body skeleton tracking, human motion sensing, millimeter wave},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568545,
author = {Xue, Hongfei and Cao, Qiming and Ju, Yan and Hu, Haochen and Wang, Haoyu and Zhang, Aidong and Su, Lu},
title = {M4esh: mmWave-Based 3D Human Mesh Construction for Multiple Subjects},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568545},
doi = {10.1145/3560905.3568545},
abstract = {The recent proliferation of various wireless sensing systems and applications demonstrates the advantages of radio frequency (RF) signals over traditional camera-based solutions that are faced with various challenges, such as occlusions and poor lighting conditions. Towards the ultimate goal of imaging human body using RF signals, researchers have been exploring the possibility of constructing the human mesh, a structure capturing not only the pose but also the shape of the human body, from RF signals. In this paper, we introduce M4esh, a novel system that utilizes commercial millimeter wave (mmWave) radar for multi-subject 3D human mesh construction. Our M4esh system can detect and track the subjects on a 2D energy map by predicting the subject bounding boxes on the map, and tackle the subjects' mutual occlusion through utilizing the location, velocity and size information of the subjects' bounding boxes from the previous frames as a clue to estimate the bounding box in the current frame. Through extensive experiments on a real-world COTS millimeter-wave testbed, we show that our proposed M4esh system can accurately localize the subjects and generate their human meshes, which demonstrate the superior effectiveness of the proposed M4esh system.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {391–406},
numpages = {16},
keywords = {deep learning, human mesh estimation, millimeter wave, multiple subjects, point cloud, wireless sensing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568529,
author = {Wang, Kailong and Shi, Cong and Cheng, Jerry and Wang, Yan and Xie, Minge and Chen, Yingying},
title = {Solving the WiFi Sensing Dilemma in Reality Leveraging Conformal Prediction},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568529},
doi = {10.1145/3560905.3568529},
abstract = {With the wide deployment of smart environments and IoT devices, WiFi sensing has demonstrated its great convenience and contactless sensing capabilities in supporting a broad array of applications. However, designing a ubiquitous WiFi sensing system for heterogeneous scenarios in practice is still a big dilemma as the system performs poorly when the testing data is significantly different from the training data caused by domain variations. To address this dilemma, existing studies involve extra efforts to develop new features or even to retrain the original model under environmental variations. However, none of them can resolve the dilemma completely. In this work, we conduct a comprehensive study on the domain variation problem to make WiFi sensing robust and accurate in reality. Our definition of domains is comprehensive and includes environments, surrounding settings, user differences, user's facing directions, user's positions relative to WiFi sensors, and user participating time frames. Our innovation is to achieve reliable WiFi sensing across all the domains based on the conformal prediction framework. Our approach quantifies the conformity (i.e., similarity) between the testing WiFi samples and the training samples, then labels the testing samples with the most probable class(es). We develop a novel cross-domain transformal prediction scheme based on the multivariate kernel density estimation to effectively assess and learn the conformity of each domain in the training data. To meet various application-specific requirements, we further develop two approaches to fuse the knowledge of conformity derived from the training domains to perform predictions. Extensive experiments with both self-collected and public datasets show that our framework can improve prediction accuracies from 30\% to 74\% improvements in three most representative WiFi-based applications across six types of domain variations.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {407–420},
numpages = {14},
keywords = {conformal prediction, domain variations, wifi sensing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568525,
author = {Feng, Yuda and Xie, Yaxiong and Ganesan, Deepak and Xiong, Jie},
title = {LTE-Based Low-Cost and Low-Power Soil Moisture Sensing},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568525},
doi = {10.1145/3560905.3568525},
abstract = {Soil moisture sensing is a basic function required by applications like precision irrigation. Recently, RF based soil moisture sensing solutions [10, 43] have been proposed, which, however, can hardly support large scale deployment in challenging outdoor environments, since they must have dedicated signal emitters and also require power supply for either the signal emitters (WiFi or RFID reader) or both the transceivers (WiFi AP and client). LTE signal provides a unique opportunity for soil moisture sensing as the ubiquitously deployed base stations are naturally always-on signal emitters, eliminating the need for deploying extra hardware. In this paper, we implement a low-cost LTE based soil moisture sensor using commercial off-the-shelf hardware. We also realize duty-cycled soil sensing by automatically self-calibrating the phase offset after powering on the devices, significantly reducing the overall power consumption of the sensor. Extensive experiments show that our low-cost sensor ($55) achieves a high accuracy (3.15\%) which is comparable to high-end soil moisture sensors ($850), wide coverage (2.4 km from the base station) and low power consumption (lasting 16 months using batteries).},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {421–434},
numpages = {14},
keywords = {LTE sensing, low-power and low-cost sensing, pervasive sensing, smart agriculture, soil moisture sensing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568549,
author = {Hewage, Kasun and Voigt, Thiemo},
title = {Harmony: A Time Synchronisation System for Visible Light Communication Access Points},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568549},
doi = {10.1145/3560905.3568549},
abstract = {High-speed visible light communication (VLC) is a complementary technology to conventional radio frequency communication in wireless networks. One of the essential traits of VLC systems is the ability to provide wireless communication and illumination seamlessly. High-speed VLC systems use high-power LEDs as transmitters in their access points (APs). In real-world deployments, overlapping light beams from multiple APs are necessary to avoid unlit areas. However, overlapping light beams could cause interference in each other's communication at the receiver; hence APs must synchronise their communication. This paper presents Harmony, a time synchronisation system for VLC APs to synchronise their transmissions. Internally, Harmony uses synchronous transmissions in the infrared frequency spectrum to reach nodes over multiple hops. The evaluation of a prototype implementation of Harmony on a small-scale testbed shows that it can synchronise nodes up to nine hops with a maximum error of a few 100s of nanoseconds. While the enduring work on high-speed VLC systems primarily focuses on improving the performance of individual APs, Harmony provides an infrastructure for enhancing system-wide performance.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {435–447},
numpages = {13},
keywords = {access points, concurrent transmissions, optical wireless communication, synchronous transmissions, time synchronisation, visible light communication},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568507,
author = {Xu, Kenuo and Gong, Chen and Liang, Bo and Wu, Yue and Di, Boya and Song, Lingyang and Xu, Chenren},
title = {Low-Latency Visible Light Backscatter Networking with RetroMUMIMO},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568507},
doi = {10.1145/3560905.3568507},
abstract = {Visible Light Backscatter Communication (VLBC) presents an emerging ultra-low-power IoT connectivity solution with high spatial-spectral efficiency and intrinsic human-perceivable privacy advantages. However, research progress on enhanced data rate and sophisticated device coordination of state-of-the-art VLBC systems still cannot meet the low-latency requirement (sub-second level for an IoT network) for massive connections.In this paper, we present the design, implementation and evaluation of RetroMUMIMO, the first visible light backscatter network that enables physical-layer concurrency to minimize network latency. We propose a pulse feature extraction scheme to enable concurrent transmissions with the unexplored pulse diversity of tags. We design a low-latency demodulation algorithm assisted by such features to demodulate the concurrent symbols efficiently and effectively. Based on the physical-layer concurrency, we further design a MAC layer with contention-based transmission and minimal protocol overhead for low-latency networking. Our evaluation shows that the prototype system achieves up to 8 concurrent VLBC uplinks with real-time demodulation and up to 92.0\% latency reduction compared with the state-of-the-art VLBC systems.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {448–461},
numpages = {14},
keywords = {backscatter communication, multi-user MIMO, pulse-division concurrent transmission, visible light backscatter networking},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568528,
author = {Li, Dong and Liu, Jialin and Lee, Sunghoon Ivan and Xiong, Jie},
title = {Room-Scale Hand Gesture Recognition Using Smart Speakers},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568528},
doi = {10.1145/3560905.3568528},
abstract = {Acoustic signal has been recently adopted for contact-free hand gesture recognition due to its fine-grained sensing granularity and wide availability of microphone and speaker in consumer-grade electronic devices such as smartphones. However, a very limited sensing range constrains acoustic sensing to application scenarios where users interact with devices in close proximity. In this paper, we improve the range of acoustic sensing and demonstrate the feasibility of enabling room-scale hand gesture recognition using commodity smart speakers. We develop a series of novel signal processing techniques and implement our system on two commodity smart speaker prototypes with different numbers of microphones. Extensive evaluations are performed in three different environments with 1440 gestures collected from 16 participants. Experiment results show that our system can significantly increase the sensing range from 1 m to 4--5 m. In the challenging scenario where the user is 4 m away from the smart speaker and there is strong interference, the achieved gesture recognition accuracy is still higher than 90\%.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {462–475},
numpages = {14},
keywords = {contact-free acoustic sensing, room-scale hand gesture recognition, smart speaker},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568499,
author = {Sun, Yimiao and Wang, Weiguo and Mottola, Luca and Wang, Ruijin and He, Yuan},
title = {AIM: Acoustic Inertial Measurement for Indoor Drone Localization and Tracking},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568499},
doi = {10.1145/3560905.3568499},
abstract = {We present Acoustic Inertial Measurement (AIM), a one-of-a-kind technique for indoor drone localization and tracking. Indoor drone localization and tracking are arguably a crucial, yet unsolved challenge: in GPS-denied environments, existing approaches enjoy limited applicability, especially in Non-Line of Sight (NLoS), require extensive environment instrumentation, or demand considerable hardware/software changes on drones. In contrast, AIM exploits the acoustic characteristics of the drones to estimate their location and derive their motion, even in NLoS settings. We tame location estimation errors using a dedicated Kalman filter and the Interquartile Range rule (IQR). We implement AIM using an off-the-shelf microphone array and evaluate its performance with a commercial drone under varied settings. Results indicate that the mean localization error of AIM is 46\% lower than commercial UWB-based systems in complex indoor scenarios, where state-of-the-art infrared systems would not even work because of NLoS settings. We further demonstrate that AIM can be extended to support indoor spaces with arbitrary ranges and layouts without loss of accuracy by deploying distributed microphone arrays.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {476–488},
numpages = {13},
keywords = {acoustic signal, drone, indoor tracking},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568510,
author = {Luo, Wenjie and Song, Qun and Yan, Zhenyu and Tan, Rui and Lin, Guosheng},
title = {Indoor Smartphone SLAM with Learned Echoic Location Features},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568510},
doi = {10.1145/3560905.3568510},
abstract = {Indoor self-localization is a highly demanded system function for smartphones. The current solutions based on inertial, radio frequency, and geomagnetic sensing may have degraded performance when their limiting factors take effect. In this paper, we present a new indoor simultaneous localization and mapping (SLAM) system that utilizes the smartphone's built-in audio hardware and inertial measurement unit (IMU). Our system uses a smartphone's loud-speaker to emit near-inaudible chirps and then the microphone to record the acoustic echoes from the indoor environment. Our profiling measurements show that the echoes carry location information with sub-meter granularity. To enable SLAM, we apply contrastive learning to construct an echoic location feature (ELF) extractor, such that the loop closures on the smartphone's trajectory can be accurately detected from the associated ELF trace. The detection results effectively regulate the IMU-based trajectory reconstruction. Extensive experiments show that our ELF-based SLAM achieves median localization errors of 0.1 m, 0.53 m, and 0.4m on the reconstructed trajectories in a living room, an office, and a shopping mall, and outperforms the Wi-Fi and geomagnetic SLAM systems.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {489–503},
numpages = {15},
keywords = {acoustic sensing, simultaneous localization and mapping},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568515,
author = {Wang, Weiguo and Mottola, Luca and He, Yuan and Li, Jinming and Sun, Yimiao and Li, Shuai and Jing, Hua and Wang, Yulei},
title = {MicNest: Long-Range Instant Acoustic Localization of Drones in Precise Landing},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568515},
doi = {10.1145/3560905.3568515},
abstract = {We present MicNest: an acoustic localization system enabling precise landing of aerial drones. Drone landing is a crucial step in a drone's operation, especially as high-bandwidth wireless networks, such as 5G, enable beyond-line-of-sight operation in a shared airspace and applications such as instant asset delivery with drones gain traction. In MicNest, multiple microphones are deployed on a landing platform in carefully devised configurations. The drone carries a speaker transmitting purposefully-designed acoustic pulses. The drone may be localized as long as the pulses are correctly detected. Doing so is challenging: i) because of limited transmission power, propagation attenuation, background noise, and propeller interference, the Signal-to-Noise Ratio (SNR) of received pulses is intrinsically low; ii) the pulses experience non-linear Doppler distortion due to the physical drone dynamics while airborne; iii) as location information is to be used during landing, the processing latency must be reduced to effectively feed the flight control loop. To tackle these issues, we design a novel pulse detector, Matched Filter Tree (MFT), whose idea is to convert pulse detection to a tree search problem. We further present three practical methods to accelerate tree search jointly. Our real-world experiments show that MicNest is able to localize a drone 120 m away with 0.53\% relative localization error at 20 Hz location update frequency.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {504–517},
numpages = {14},
keywords = {acoustic localization, drone, microphone array},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568535,
author = {Jung, Woosub and Cui, Kailai and Koltermann, Kenneth and Wang, Junjie and Xin, ChunSheng and Zhou, Gang},
title = {Light Auditor: Power Measurement Can Tell Private Data Leakage through IoT Covert Channels},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568535},
doi = {10.1145/3560905.3568535},
abstract = {Despite many conveniences of using IoT devices, they have suffered from various attacks due to their weak security. Besides well-known botnet attacks, IoT devices are vulnerable to recent covert-channel attacks. However, no study to date has considered these IoT covert-channel attacks. Among these attacks, researchers have demonstrated exfiltrating users' private data by exploiting the smart bulb's capability of infrared emission.In this paper, we propose a power-auditing-based system that defends the data exfiltration attack on the smart bulb as a case study. We first implement this infrared-based attack in a lab environment. With a newly-collected power consumption dataset, we pre-process the data and transform them into two-dimensional images through Continous Wavelet Transformation (CWT). Next, we design a two-dimensional convolutional neural network (2D-CNN) model to identify the CWT images generated by malicious behavior. Our experiment results show that the proposed design is efficient in identifying infrared-based anomalies: 1) With much fewer parameters than transfer-learning classifiers, it achieves an accuracy of 88\% in identifying the attacks, including unseen patterns. The results are similarly accurate as the sophisticated transfer-learning CNNs, such as AlexNet and GoogLeNet; 2) We validate that our system can classify the CWT images in real time.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {518–532},
numpages = {15},
keywords = {IoT privacy, convolutional neural networks, covert channel, power auditing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568539,
author = {Zhang, Yan and Zhu, Yi and Liu, Zihao and Miao, Chenglin and Hajiaghajani, Foad and Su, Lu and Qiao, Chunming},
title = {Towards Backdoor Attacks against LiDAR Object Detection in Autonomous Driving},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568539},
doi = {10.1145/3560905.3568539},
abstract = {Due to the great advantage of LiDAR sensors in perceiving complex driving environments, LiDAR-based 3D object detection has recently drawn significant attention in autonomous driving. Although many advanced LiDAR object detection models have been developed, their designs are mainly based on deep learning approaches, which are usually data-hungry and expensive to train. Thus, it is common for some LiDAR perception system developers or self-driving car companies to collect training data from different sources (e.g., self-driving car users) or outsource the training work to a third party. However, these practices provide opportunities for backdoor attacks, where the attacker aims to inject a hidden trigger pattern into the victim detection model by poisoning its training set and let the model fail to detect objects when the trigger presents in the inference phase. Although backdoor attacks have posed serious security concerns, the vulnerability of LiDAR object detection to such attacks has not yet been studied. To fill the research gap, in this paper, we present the first study on backdoor attacks against LiDAR object detection in autonomous driving. Specifically, we propose a novel backdoor attack strategy based on which the attacker can achieve the attack goal by poisoning a small number of point cloud samples. In addition, the proposed attack strategy is physically realizable, and it allows the attacker to easily perform the attack using some common objects as the triggers. To make the poisoned samples difficult to be detected, we also design a stealthy attack strategy by creating some fake vehicle point clusters to hide the injected points in the point cloud. The desirable performance of our attacks is demonstrated through both simulation and real-world case study.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {533–547},
numpages = {15},
keywords = {LiDAR object detection, autonomous driving, backdoor attack},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568521,
author = {Yang, Zeyu and He, Liang and Yu, Hua and Zhao, Chengcheng and Cheng, Peng and Chen, Jiming},
title = {Reverse Engineering Physical Semantics of PLC Program Variables Using Control Invariants},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568521},
doi = {10.1145/3560905.3568521},
abstract = {Semantic attacks have incurred increasing threats to Industrial Control Systems (ICSs), which manipulate targeted system modules by identifying the physical semantics of variables in Programmable Logic Controllers (PLCs) programs, i.e., the sensing/actuating modules represented by the variables. This is usually (and inefficiently) achieved via manual examination of system documents and long-term observation of system behavior. In this paper, we design ARES, a method that Automatically Reverse Engineers the Semantics of variables in PLC programs without requiring any domain knowledge. ARES is built on the fact that the Supervisory Control And Data Acquisition (SCADA) system monitors the behavior of PLC using a fixed mapping between the variables of program code and data log, and the data log variables are marked with physical semantics. By identifying the mapping between PLC code and SCADA data (i.e., the code-data mapping), ARES reverse engineers the physical semantics of program variables. ARES also sheds light on the preferred practices in implementing control rules that improve the resistance of PLC programs to semantic attacks. We have experimentally evaluated ARES and the recommended implementation practices on two ICS platforms.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {548–562},
numpages = {15},
keywords = {control invariants, physical semantics, programmable logic controller},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568517,
author = {Ji, Sijie and Xie, Yaxiong and Li, Mo},
title = {SiFall: Practical Online Fall Detection with RF Sensing},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568517},
doi = {10.1145/3560905.3568517},
abstract = {Falls are one of the leading causes of death in the elderly people aged 65 and above. In order to prevent death by sending prompt fall detection alarms, non-invasive radio-frequency (RF) based fall detection has attracted significant attention, due to its wide coverage and privacy preserving nature. Existing RF-based fall detection systems process fall as an activity classification problem and assume that human falls introduce reproducible patterns to the RF signals. We, however, argue that the fall is essentially an accident, hence, its impact is uncontrollable and unforeseeable. We propose to solve the fall detection problem in a fundamentally different manner. Instead of directly identifying the human falls which are difficult to quantify, we recognize the normal repeatable human activities and then identify the fall as abnormal activities out of the normal activity distribution. We implement our idea and build a prototype based on commercial Wi-Fi. We conduct extensive experiments with 16 human subjects. The experiment results show that our system can achieve high fall detection accuracy and adapt to different environments for real-time fall detection.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {563–577},
numpages = {15},
keywords = {adaptive segmentation, device-free, fall detection, real-time system, self-supervised learning, wireless sensing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568516,
author = {Xia, Xianjin and Chen, Qianwu and Hou, Ningning and Zheng, Yuanqing},
title = {HyLink: Towards High Throughput LPWANs with LoRa Compatible Communication},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568516},
doi = {10.1145/3560905.3568516},
abstract = {This paper presents the design and implementation of HyLink which aims to fill the gap between limited link capacity of LoRa and the diverse bandwidth requirements of IoT systems. At the heart of HyLink is a novel technique named parallel Chirp Spread Spectrum modulation, which tunes the number of modulated symbols to adapt bit-rates according to channel conditions. Over strong link connections, HyLink fully exploits the link capability to transmit more symbols and thus transforms good channel SNRs to high link throughput. While for weak links, it conservatively modulates one symbol and concentrates all transmit power onto the symbol to combat poor channels, which can achieve the same performance as legacy LoRa. HyLink addresses a series of technical challenges on encoding and decoding of multiple payloads in a single packet, aiming at amortizing communication overheads in terms of channel access, radio-on power, transmission air-time, etc. We perform extensive experiments to evaluate the effectiveness of HyLink. Evaluations show that HyLink produces up to 10\texttimes{} higher bit rates than LoRa when channel SNRs are higher than 5 dB. HyLink inter-operates with legacy LoRa devices and can support new emerging traffic-intensive IoT applications.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {578–591},
numpages = {14},
keywords = {LPWAN, LoRa, adaptive data rate, internet of things, throughput},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568503,
author = {Deng, Yongheng and Chen, Weining and Ren, Ju and Lyu, Feng and Liu, Yang and Liu, Yunxin and Zhang, Yaoxue},
title = {TailorFL: Dual-Personalized Federated Learning under System and Data Heterogeneity},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568503},
doi = {10.1145/3560905.3568503},
abstract = {Federated learning (FL) enables distributed mobile devices to collaboratively learn a shared model without exposing their raw data. However, heterogeneous devices usually have limited and different available resources, i.e., system heterogeneity, for model training and communicating, while the diverse data distribution among devices, i.e., data heterogeneity, may result in significant performance degradation. In this paper, we propose TailorFL, a dual-personalized FL framework, which tailors a submodel for each device with personalized structure for training and personalized parameters for local inference. To achieve this, we first excavate the personalization principle for data heterogeneous FL via in-depth empirical studies, and based on which, we propose a resource-aware and data-directed pruning strategy that makes each device's submodel structure match its resource capability and correlate with its local data distribution. To aggregate the submodels while preserving their dual personalization properties, we design a scaling-based aggregation strategy that scales parameters with the pruning rate of submodels and aggregates the overlapped parameters. Moreover, to further promote beneficial and restrain detrimental collaborations among devices, we propose a server-assisted model-tuning mechanism, which dynamically tunes device's submodel structure at the server side with the global view of device's data distribution similarities. Extensive experiments demonstrate that compared to the status quo approaches, TailorFL achieves an average of 22\% increase in inference accuracy, and reduces the memory, computation, and communication costs for model training simultaneously.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {592–606},
numpages = {15},
keywords = {federated learning, heterogeneity, personalization, pruning},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568511,
author = {Fu, Ziyan and Ren, Ju and Liu, Yunxin and Cao, Ting and Zhang, Deyu and Zhou, Yuezhi and Zhang, Yaoxue},
title = {Hyperion: A Generic and Distributed Mobile Offloading Framework on OpenCL},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568511},
doi = {10.1145/3560905.3568511},
abstract = {Despite the significant development of mobile device SoCs, they are still inefficient in computing computation-intensive workloads, such as high-resolution image processing and AR/VR applications. Offloading offers a promising way to leverage cloud or edge servers for acceleration, but existing offloading is limited to specific tasks or specific hardware/software platforms, resulting in significant engineering overhead. To address this problem, we focus on the underlying layer of these applications (i.e., OpenCL) and propose Hyperion, a generic and distributed mobile offloading framework built on OpenCL. To achieve high-performance distributed execution for Hyperion, we first take a deep insight into the OpenCL data structures and design regularity-aware kernel analyzer to analyze the data dependency of work-groups and identify the essential data to offload. Then, context-aware execution time predictor is proposed to estimate the computing time of a given partitioned kernel workload that is highly impacted by many runtime factors. These techniques are integrated into pipeline-enabled and network-adaptive scheduler to make scheduling decisions, which coordinates the kernel partition and workload scheduling to form pipeline processing between data transmission and distributed execution with flexible adaptability to network dynamics. Extensive experimental results demonstrate that Hyperion achieves superior performance with an average 3.80\texttimes{} speedup compared with the best baseline and flexible adaptation to dynamic network conditions and available computing resources.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {607–621},
numpages = {15},
keywords = {OpenCL, distributed computing, edge computing, mobile offloading, online scheduling},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568530,
author = {Fu, Yongjian and Wang, Shuning and Zhong, Linghui and Chen, Lili and Ren, Ju and Zhang, Yaoxue},
title = {SVoice: Enabling Voice Communication in Silence via Acoustic Sensing on Commodity Devices},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568530},
doi = {10.1145/3560905.3568530},
abstract = {Silent Speech Interface (SSI) has been proposed as a means of reconstructing audible speech from silent articulatory gestures for covert voice communication in public and voice assistance for the aphasic. Prior arts of SSI, either relying on wearable devices or cameras, may lead to extended contact requirements or privacy leakage risks. The recent advances in acoustic sensing have brought new opportunities for sensing gestures, but their original intention is to infer speech content for classification instead of audible speech reconstruction, resulting in the loss of some important speech information (e.g., speech rate, intonation, and emotion). In this paper, we propose, the first system that supports accurate audible speech reconstruction by analyzing the disturbance of tiny articulatory gestures on the reflected ultrasound signal. The design of introduces a new model that provides the unique mapping relationship between ultrasound and speech signals, so that the audible speech can be successfully reconstructed from the silent speech. However, establishing the mapping relationship depends on plenty of training data. Instead of the time-consuming collection of massive amounts of data for training, we construct an inverse task that constitutes a dual form with the original task to generate virtual gestures from widely available audio (e.g., phone calls) for facilitating model training. Furthermore, we introduce a fine-tuning mechanism using unlabeled data for user adaptation. We implement using a portable smartphone and evaluate it in various environments. The evaluation results show that can reconstruct speech with a (Character Error Rate) CER as low as 7.62\%, and decrease the CER from 82.77\% to 9.42\% on new users with only 1 hour of ultrasound signals provided, which outperforms state-of-the-art acoustic-based approaches while preserving rich speech information.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {622–636},
numpages = {15},
keywords = {acoustic sensing, cGAN, silent speech, transformer},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568522,
author = {Han, Feiyu and Yang, Panlong and Du, Haohua and Li, Xiang-Yang},
title = {Accuth: Anti-Spoofing Voice Authentication via Accelerometer},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568522},
doi = {10.1145/3560905.3568522},
abstract = {Most existing voice-based user authentication systems mainly rely on microphones to capture the unique vocal characteristics of an individual, which makes these systems vulnerable to various acoustic attacks and suffer high-security risks. In this work, we present Accuth, a novel authentication system that takes advantage of a low-cost accelerometer to verify the user's identity and resist spoofing acoustic attacks. Accuth captures unique sound vibrations during the human pronunciation process and extracts multi-level features to verify the user's identity. Specifically, we analyze and model the differences between the physical sound field of human beings and loudspeakers, and extract a novel sound-field-level liveness feature to defend against spoofing attacks. Accuth is an effective complement to existing authentication approaches as it only leverages a ubiquitous, low-cost, and small-size accelerometer. In real-world experiments, Accuth achieves over 90\% identification accuracy among 15 human participants and an average equal error rate (EER) of 3.02\% for spoofing attack detection.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {637–650},
numpages = {14},
keywords = {accelerometer, biometrics, sound vibration, voice authentication},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568541,
author = {Luo, Zhicheng and Huang, Qianyi and Wang, Rui and Chen, Hao and Tao, Xiaofeng and Chen, Guihai and Zhang, Qian},
title = {WISE: Low-Cost Wide Band Spectrum Sensing Using UWB},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568541},
doi = {10.1145/3560905.3568541},
abstract = {Spectrum sensing plays a crucial role in spectrum monitoring and management. However, due to the expensive cost of high-speed ADCs, wideband spectrum sensing is a long-standing challenge. In this paper, we present how to transform Ultra-wideband (UWB) devices into a spectrum sensor which can provide wideband spectrum monitoring at a low cost. Compared with the expensive high-speed ADCs which cost at least hundreds of dollars, a UWB device is only several dollars. As the low-cost UWB technology is not originally designed for spectrum sensing, we address the inherent limitations of low-cost devices such as limited memory, low SPI speed and low accuracy, and show how to obtain spectrum occupancy information from the noisy and spurious UWB channel impulse response. In this paper, we present WISE, which not only can give accurate channel occupancy information, but also can precisely estimate the signal power and bandwidth. WISE can also detect fleeting radar signals. We implement WISE and perform extensive evaluations with both controlled experiments and field tests. Results show that WISE can sense up to 900MHz bandwidth and the power estimation error is less than 3dB. WISE can also accurately detect busy 5G channels. We believe that WISE provides a new paradigm for low-cost wideband spectrum sensing, which is critical for large-scale fine-grained spectrum monitoring.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {651–666},
numpages = {16},
keywords = {UWB, low-cost, spectrum sensing, wideband},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568506,
author = {Shi, Zhenguo and Gu, Tao and Zhang, Yu and Zhang, Xi},
title = {mmBP: Contact-Free Millimetre-Wave Radar Based Approach to Blood Pressure Measurement},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568506},
doi = {10.1145/3560905.3568506},
abstract = {Blood pressure (BP) measurement is an indispensable tool in diagnosing and treating many diseases such as cardiovascular failure and stroke. Traditional direct measurement can be invasive, and wearable-based methods may have limitations of discomfort and inconvenience. Contact-free BP measurement has been recently advocated as a promising alternative. In particular, Millimetre-wave (mmWave) sensing has demonstrated its promising potential, however it is confronted with several challenges including noise and vulnerability to human's tiny motions which may occur intentionally and inevitably. In this paper, we propose mmBP, a contact-free mmWave-based BP measurement system with high accuracy and motion robustness. Due to the high frequency and short wavelength, mmWave signals received in the time domain are dramatically susceptible to ambient noise, and deteriorating signal quality. To reduce noise, we propose a novel delay-Doppler domain feature transformation method to exploit mmWave signal's characteristics and features in the delay-Doppler domain to significantly improve signal quality for pulse waveform construction. We also propose a temporal referential functional link adaptive filter leveraging on the periodic and correlation characteristics of pulse waveform signals to alleviate the impact of human's tiny motions. Extensive experiment results achieved by the leave-one-out cross-validation (LOOCV) method demonstrate that mmBP achieves the mean errors of 0.87mmHg and 1.55mmHg for systolic blood pressure (SBP) and diastolic blood pressure (DBP), respectively; and the standard deviation errors of 5.01mmHg and 5.27mmHg for SBP and DBP, respectively.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {667–681},
numpages = {15},
keywords = {blood pressure, contact-free sensing, mmWave},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568514,
author = {Liu, Suyuan and Zhang, Lan and Yu, Haikuo and Hou, Jiahui and Guo, Kaiwen and Li, Xiang-Yang},
title = {HideSeeker: Uncover the Hidden Gems in Obfuscated Images},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568514},
doi = {10.1145/3560905.3568514},
abstract = {Obfuscation technologies have been well established for on-device image privacy protection, including pixelization, blurring, scribbling, sticker-covering, and inpainting. Despite their remarkable resistance to human observation, recent studies find that some of them are vulnerable to attacks by neural network-based recognition methods. In this work, we reveal the risk of privacy re-disclosure post image protection. Given an obfuscation-protected image, the privacy information includes 1) where the obfuscated region is and 2) what the hidden privacy-related objects are. Thus we focus on uncovering categories of privacy-related objects to evaluate the effectiveness of obfuscation technologies. Under severe obfuscation, unfortunately, even powerful object recognition models can hardly infer hidden privacy information.Inspired by the human observation process, we carefully craft a scheme HideSeeker, composed of feature-extraction, relation-graph-learning, and object-inference, to explore the contextual information of obfuscated regions and their relationships. HideSeeker can efficiently and effectively uncover the categories of hidden private objects in obfuscated images. We conduct comprehensive evaluations over two datasets containing 14206 images in total: laboratory-generated and publicly available obfuscated images. Our results demonstrate that HideSeeker successfully uncovers privacy-related objects with inference accuracy of up to 82.17\%, and 77.72\% on average no matter which obfuscation was applied, while the SOTA method can achieve an average accuracy of 42.3\%. For images protected by inpainting, accuracy is improved from 24.67\% to 78.16\%.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {682–695},
numpages = {14},
keywords = {image obfuscation, on-device privacy evaluation, privacy object inference, relation graph},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568532,
author = {Gao, Ming and Zhang, Lingfeng and Shen, Leming and Zou, Xiang and Han, Jinsong and Lin, Feng and Ren, Kui},
title = {KITE: Exploring the Practical Threat from Acoustic Transduction Attacks on Inertial Sensors},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568532},
doi = {10.1145/3560905.3568532},
abstract = {In cyber-physical systems, inertial sensors are the basis for identifying motion states and making actuation decisions. However, extensive studies have proved the vulnerability of those sensors under acoustic transduction attacks, which leverage malicious acoustics to trigger sensor measurement errors. Unfortunately, the threat from such attacks is not assessed properly because of the incomplete investigation on the attack's potential, especially towards multiple-degree-of-freedom systems, e.g., drones. To thoroughly explore the threat of acoustic transduction attacks, we revisit the attack model and design a new yet practical acoustic modulation-based attack, named KITE. Such an attack enables stable and controllable injections, even under frequency offset based distortions that limit the effect of prior attacking approaches. KITE exploits the potential threat of transduction attacks without the need of strengthening attackers' abilities. Furthermore, we extend the attack surface to multiple-degree-of-freedom systems, which are more widely deployed but ignored by prior work. Our study also covers the scenario of attacking moving targets. By revealing the practical threat from acoustic transduction attacks, we appeal for both the attention to their harm and necessary countermeasures.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {696–709},
numpages = {14},
keywords = {IoT security, acoustic transduction attacks, cyber-physical system, inertial sensors, spoofing attacks},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568518,
author = {Chen, Qianniu and Chen, Meng and Lu, Li and Yu, Jiadi and Chen, Yingying and Wang, Zhibo and Ba, Zhongjie and Lin, Feng and Ren, Kui},
title = {Push the Limit of Adversarial Example Attack on Speaker Recognition in Physical Domain},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568518},
doi = {10.1145/3560905.3568518},
abstract = {The integration of deep learning on Speaker Recognition (SR) advances its development and wide deployment, but also introduces the emerging threat of adversarial examples. However, only a few existing studies investigate its practical threat in physical domain, which either evaluate its feasibility only by directly replaying generated adversarial examples, or explore the partial channel interference for robustness improvement. In this paper, we propose a physical adversarial example attack, PhyTalker, which could generate and inject perturbations on voices in a live-streaming manner on attacking various SR models in different physical channels. Compared with the typical adversarial example for digital attacks, PhyTalker generates a subphoneme-level perturbation dictionary to decouple the perturbation optimization and injection. Moreover, we introduce the channel augmentation to compensate both device and environmental distortions, as well as model ensemble to improve the perturbation transferability. Finally, PhyTalker recognizes and localizes the latest recorded phoneme to determine the corresponding perturbations for real-time broadcasting. Extensive experiments are conducted with a large-scale corpus in real physical scenarios, and results show that PhyTalker achieves an overall Attack Success Rate (ASR) of 85.5\% in attacking mainstream SR systems and Mel Cepstral Distortion (MCD) of 2.45dB in human audibility.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {710–724},
numpages = {15},
keywords = {adversarial example attack, live-streaming, physical domain, speaker recognition},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568509,
author = {Zhu, Fengyuan and Feng, Luwei and Jin, Meng and Tian, Xiaohua and Wang, Xinbing and Zhou, Chenghu},
title = {Towards Ultra-Low Power OFDMA Downlink Demodulation},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568509},
doi = {10.1145/3560905.3568509},
abstract = {OFDMA downlink design allowing parallel processing OFDM subcarriers is adopted by a number of commercial wireless standards such as LTE, 5G, and 802.11ax. However, the widespread adoption of OFDMA downlink on low-end IoT devices is stymied due to the existing digital receiver framework's ≈100mW power consumption, which is mainly incurred by LO+mixer, ADC, and complex digital processing. In this paper, we present an ultra-low-power OFDMA downlink demodulation design, which achieves ≈100 μW receiving power. Our basic idea is to transform the current digital demodulation approach into the analog one based on filtering, which avoids those power-hungry components. We achieve this by proposing a series of novel RF front-end hardware designs: 1) a μW-level two-stage mixing scheme that enables adjustable and precise subcarrier filtering, 2) a quartz crystal-based filter circuit incurring negligible insertion loss, and 3) a passive phase-to-envelope conversion technique enabling low-power non-coherent phase demodulation. We build a prototype to verify the proposed schemes. Experimental and IC simulation results show that: our new design can achieve 130 -- 1500 times power savings depending on the number of subcarriers that need to be processed in parallel, compared with the traditional all-digital design.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {725–739},
numpages = {15},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568505,
author = {Jin, Meng and Yao, Shun and Li, Kexin and Tian, Xiaohua and Wang, Xinbing and Zhou, Chenghu and Cao, Xinde},
title = {A Passive Eye-in-Hand "Camera" for Miniature Robots},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568505},
doi = {10.1145/3560905.3568505},
abstract = {We in this paper present TiSee, an RFID-based sensing system that supports miniature robots to perform agile tasks in everyday environments. TiSee's unique capability is that it uses a single arbitrarily-deployed antenna to locate a target with sub-cm-level accuracy and identify its orientation to within few degrees. Compared with existing solutions which rely on either antenna arrays or multiple RFID readers, TiSee is cheap, compact, and applicable to miniature robots.The idea of TiSee is to stick an RFID tag on the robot (or its gripper) and use it as a moving "antenna" to locate another tag (the target). The core of this design is a novel technique which can build a "channel" between two commercial RFID tags. Such an inter-tag channel is proved to be highly sensitive to the change in inter-tag distance and is resistant to multipath. By leveraging this channel and the mobility of the robot, we emulate an antenna array and use it for fine-grained localization and orientation estimation. Our experiments show that TiSee achieves a median accuracy of 9.5mm and 3.1° in 3D localization and orientation estimation. TiSee brings an eye-in-hand "camera" to miniature robots, supporting them to perform agile tasks in dark, cluttered, and occluded settings.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {740–753},
numpages = {14},
keywords = {RFID, robotics, wireless sensing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568047,
author = {Chandel, Vivek and Ghose, Avik},
title = {NNTrak: Real-Time Wrist Tracking Using Smartwatch with CNN},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568047},
doi = {10.1145/3560905.3568047},
abstract = {In this work, we demonstrate a radically novel approach towards inertial-only tracking of wrist in real-time on a smartwatch for air-writing tasks. Deriving motion trajectories from commercial-grade Inertial Measurement Units (IMU) has always been a challenging task due to inherent sensor errors and associated trajectory drift. Computationally expensive solutions offered in literature cannot be used for a fully real-time tracking while also maintaining acceptable accuracy. This work presents 'NNTrak', marking our attempt to address these issues using a Convolutional Neural Network (CNN), which is trained to learn various strokes of the wrist and efficiently generates motion trajectory in real-time for air-writing. For this demonstration, we show computationally constrained Raspberry Pi 3B running our solution and a smartwatch worn while drawing a gesture in air with the trajectory being displayed in true real-time.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {754–755},
numpages = {2},
keywords = {gesture recognition, inertial sensors, neural networks, wearable},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568081,
author = {Mukhopadhyay, Shalini and Dey, Swarnava and Ghose, Avik and Tyagi, Aakash},
title = {Automated Generation of Tiny Model for Real-Time ECG Classification on Tiny Edge Devices},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568081},
doi = {10.1145/3560905.3568081},
abstract = {Continuous monitoring of cardiac health through single-lead wearable Electrocardiogram (ECG), is important for paroxysmal Atrial Fibrillation (AF) detection. Wearable ECG straps, watches, and implantable loop recorders (ILR) are based on this paradigm. These devices are used by medical professionals to view data from multiple patients, perform continuous monitoring and analysis to provide immediate care to patients. These monitoring devices display simple health screening alerts to the subjects and generate distress signals for people working outdoors or in isolated environments with intermittent Internet connectivity. Hence, low-memory, low-power, low-latency on-device inference becomes very important. This work aims at realizing such solutions by providing a framework to generate tiny (less than 256 KB) Deep Neural Networks customized for typical microcontrollers (MCU) used in those devices.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {756–757},
numpages = {2},
keywords = {ECG, arrhythmia classification, wearable health},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568049,
author = {Rubino, Matthew and Weng, Michelle and Chen, Jiasheng and Saptarshi, Shardul and Francisco, Marcus and Francisco, Alex and Zhou, Chi and Sun, Hongyue and Xu, Wenyao},
title = {A Campus Prototype of Interactive Digital Twin in Cyber Manufacturing},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568049},
doi = {10.1145/3560905.3568049},
abstract = {Smart manufacturing and Industry 4.0 are bringing disruptive changes to the manufacturing sector. Smart manufacturing increases productivity, creates safer conditions for workers, and simplifies product customization, all while decreasing business expenses [2]. To this end, we have created a flexible three-component architecture for remote machine management, using it to build a digital twin prototype of a Creality Ender-3 Pro 3D printer located on the University at Buffalo campus. This twin provides users with the ability to monitor and control the machine from anywhere in the world through a web interface. Our system improves upon existing technologies, such as Octoprint [1], through the addition of twin views. It also relies upon cheaper components, using the Arduino and ESP32 rather than the Raspberry Pi. Finally, existing technologies tend to focus on one specific type of machine. In contrast, our framework is flexible, capable of supporting many different machines.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {758–759},
numpages = {2},
keywords = {IoT, cloud computing, digital manufacturing, industry 4.0, virtual engineering},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568058,
author = {Luo, Zhicheng and Huang, Qianyi and Wang, Rui and Chen, Hao and Tao, Xiaofeng and Chen, Guihai and Zhang, Qian},
title = {A Low-Cost Wide Band Spectrum Sensing System with UWB},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568058},
doi = {10.1145/3560905.3568058},
abstract = {Spectrum sensing plays a crucial role in spectrum monitoring and management. However, Due to the expensive cost of high-speed ADCs, wideband spectrum sensing is a long-standing challenge. In this demo, we present how to transform the low-cost Ultrawideband (UWB) devices into a spectrum sensor and showcase WISE, a low-cost wideband spectrum sensing system, which not only can give accurate channel occupancy information, but also can precisely estimate the signal power and bandwidth. Our demo will show that WISE can sense up to 900MHz bandwidth and the power estimation error is less than 3dB. WISE can also accurately detect busy 5G channels and fleeting radar signals. We believe that WISE provides a new paradigm for low-cost wideband spectrum sensing, which is critical for large-scale fine-grained spectrum monitoring.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {760–761},
numpages = {2},
keywords = {UWB, low-cost, spectrum sensing, wideband},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568082,
author = {Hou, Kaiyuan and Xia, Stephen and Wu, Junyi and Zhao, Minghui and Bejerano, Emily and Jiang, Xiaofan},
title = {AI Stethoscope for Home Self-Diagnosis with AR Guidance},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568082},
doi = {10.1145/3560905.3568082},
abstract = {Cardiopulmonary ailments are a major cause of mortality. Stethoscopes are one of the most important tools that healthcare professionals use to screen patients for a variety of ailments, especially those related to the heart and lungs. Despite the growth of digital stethoscopes on the market, it takes years of training to properly use stethoscopes to listen for abnormal sounds within the body. In this demonstration, we present an intelligent stethoscope platform that makes stethoscopes more accessible to the general population. Our platform utilizes augmented reality (AR) to provide real-time guidance on where to properly place the stethoscope on the body, enabling the general population to screen themselves for ailments.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {762–763},
numpages = {2},
keywords = {digital stethoscope, human computer interaction, smart home},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568074,
author = {Nie, Jingping and Zhao, Minghui and Xia, Stephen and Sun, Xinghua and Shao, Hanya and Fan, Yuang and Preindl, Matthias and Jiang, Xiaofan},
title = {AI Therapist for Daily Functioning Assessment and Intervention Using Smart Home Devices},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568074},
doi = {10.1145/3560905.3568074},
abstract = {In this demonstration, in collaboration with licensed therapists, we introduce an AI therapist that takes advantage of the smart-home environment to screen day-to-day functioning and infer mental wellness of an occupant. Our system can assess a user's daily functioning and mental wellness based on a combination of direct conversation with users and information obtained from smart home devices using psychological rubrics proposed in [1]. We demonstrate that our system can converse with a user in a natural way (through a smartphone or smart speaker) and analyze a user's response semantically and sentimentally. In addition, we show that our system can provide preliminary interventions to help improve the user's wellness. In particular, when abnormal behavior is detected during the conversation or by smart home devices, the system provides psychotherapeutic consolations during the conversation and will check on the occupant's condition by actuating a home robot.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {764–765},
numpages = {2},
keywords = {artificial intelligence, edge computing, mental health, smart homes},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568087,
author = {Liu, Jingyu and Xiao, Xinrui and Zhao, Yang and Liu, Jie},
title = {Containerized Mobile Sensing Simulation Framework for Smart Agriculture},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568087},
doi = {10.1145/3560905.3568087},
abstract = {We present a containerized mobile sensing simulation (CMOS) framework developed for smart agriculture applications. This framework includes 1) 3D environment and object modeling, 2) mobile platform motion planning and control, and 3) optical sensing simulation, all implemented and connected within containers. Specifically, we build a user-friendly interface for 3D modeling, e.g., cornfield modeling using Blender. We use an unmanned aerial vehicle (UAV) as our mobile sensing platform and integrate UAV 3D model, flight path planning and control with robot operating system (ROS) packages and the Gazebo simulator. We also implemented optical sensing, e.g., collecting RGB image data from cameras in our simulation framework. This framework can be used not only in leaf area index correction and other analytical support for agriculture operations, but also as a synthetic data annotation tool for leaf segmentation and other smart agriculture applications. We demonstrate the major components of the CMOS framework, and how to use it to automatically annotate image data for the leaf segmentation application.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {766–767},
numpages = {2},
keywords = {mobile sensing, robotics, simulation},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568065,
author = {Liu, Yuxuan and Liu, Xinyu and Man, Fanhang and Wu, Chenye and Chen, Xinlei},
title = {Fine-Grained Air Pollution Data Enables Smart Living and Efficient Management},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568065},
doi = {10.1145/3560905.3568065},
abstract = {Fine-grained air pollution data is essential for smart living and efficient city management. However, it is arduous to obtain accurate air pollution data with high spatial and temporal resolutions via mobile crowdsensing (MCS) under limited budgets. Thus, we propose FAD, a system fully using fine-grained air pollution data to provide diverse services. Moreover, a low-cost yet highly accurate portable sensing device is designed for MCS applications to enhance data resolutions. Finally, we demonstrate various FAD-based services for citizens and governments in the real world.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {768–769},
numpages = {2},
keywords = {city management, fine-grained air pollution data, mobile crowdsensing (MCS), service system, smart living},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568066,
author = {Ren, Hongyi and Feng, Dayu and Mukherjee, Mithun and Pan, Zhigeng and Guo, Mian and Yang, Wenzhen and Matam, Rakesh},
title = {GUFFLE: A Design of Lightweight Pressure Interface for Near-to-Real-Time Perceptual Tactile Sensation},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568066},
doi = {10.1145/3560905.3568066},
abstract = {In this demonstration, we present a wearable haptic system to realize the perceptual illusion in a virtual environment. We collect the pressure data from sensors attached with the fingertip, and after passing through a classifier, we render the sensation of pressure. We mainly focus on designing a lightweight and wearable haptic interface with fast rendering. At last, we implement the proposed interface on Raspberry Pi and present preliminary results with various test objects.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {770–771},
numpages = {2},
keywords = {augmented reality, haptic/tactile communications, perceptual illusions, pressure sensors, remote rehabilitation},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568052,
author = {Jung, Woosub and Koltermann, Kenneth and Helm, Noah and Blackwell, GinaMari and Pretzer-Aboff, Ingrid and Cloud, Leslie and Zhou, Gang},
title = {IMU Sensing Data-Based Kinetic Tremor Detection in Parkinson's Disease Patients},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568052},
doi = {10.1145/3560905.3568052},
abstract = {Tremor is a common symptom among Parkinson's disease (PD) patients at all stages. To measure tremor, we utilized IMU sensing data from the wrists while PD patients were drawing. With 30 patients' IMU sensing data obtained from standard tremor rating scale activities, we conducted data analysis for identifying any tremor episodes and extracting tremor amplitude. In this demo, we demonstrate that our preliminary analysis and results show the potential of measuring kinetic tremors effectively using these methods.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {772–773},
numpages = {2},
keywords = {FAHN, IMU dataset, UPDRS, parkinson's disease, tremor detection},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568086,
author = {Jin, Tao and Dasari, Mallesham and Smith, Connor and Apicharttrisorn, Kittipat and Rowe, Anthony and Seshan, Srinivasan},
title = {Live 3D Scene Capture for Virtual Teleportation},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568086},
doi = {10.1145/3560905.3568086},
abstract = {It has long been a goal of immersive telepresence to capture and stream 3D spaces such that a remote viewer can watch from any location or angle within the scene. This demonstration presents Mosaic, a new distributed 3D scene capture system that uses textured mesh data representation for streaming a 3D volumetric video of a space to remote viewers. Compared to more common point cloud based methods, we show that textured mesh data requires less bandwidth and yields the same visual quality. However, textured mesh reconstruction is compute and memory intensive, mesh simplification is not easily parallelizable, and texture maps lacks spatial and temporal coherence. Mosaic tackles these challenges by examining each computational stage and determines how they can be efficiently distributed across multiple compute nodes to reduce overall latency, minimize bandwidth, and maintain quality. We then provide an end-to-end latency and bandwidth breakdown that can be used to target future acceleration work.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {774–775},
numpages = {2},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568061,
author = {Rohal, Shubham and Ruiz, Carlos and Zhang, Yue and Pan, Shijia},
title = {MOOCA: Muira-Ori Origami-Based Configurable Shelf-Liner for Autonomous Retail},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568061},
doi = {10.1145/3560905.3568061},
abstract = {Current autonomous checkout is often enable by the use of multiple overhead cameras and/or load sensors on shelf, which is limited by the occlusion and dense deployment. We present MOOCA, an origami-inspired low-cost configurable surface structure as the smart shelf liner. MOOCA leverage conductive threads and copper wires integrated in to the origami structure to detect and recognize pick-up and put-down products. We build our prototype with 3D printed structure using elastic resin. We will demonstrate MOOCA's functionality of predicting the item that is picked up from it.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {776–777},
numpages = {2},
keywords = {configurable smart structure, item classification, load sensing, smart retail},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568070,
author = {Zhu, Yue and Li, Xin and Liang, Junrui},
title = {Motion-Powered Gameboy},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568070},
doi = {10.1145/3560905.3568070},
abstract = {Energy harvesting technology enables the battery-free realization of some sensing, computing, and connectivity functions. However, its promotion in battery-free human-computer interaction is relatively slow in comparison. There is a critical energy gap around interactive devices which are screen-focused and usually power-hungry. This energy gap can be narrowed down and filled up by selecting a proper display and taking a sophisticated hardware and software co-design. Motion-powered gameboy, the first robust personal mobile gaming device, is manufactured by combining the features of a bistable E-ink display and a quasi-static toggling motion energy harvester. With the hardware-software co-design, the amount of energy generated by the player's pinch action can adequately guarantee successful user interaction and preferable user experience. The design methodology of the motion-powered game-boy provides a valuable example for the development of motion-powered human-computer interactive devices.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {778–779},
numpages = {2},
keywords = {battery-free IoT, human-computer interaction, motion energy harvesting},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568096,
author = {Liu, Miaomiao and Yang, Sikai and Chomsin, Wyssanie and Du, Wan},
title = {Real-Time Tracking of Smartwatch Orientation and Location by Multitask Learning},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568096},
doi = {10.1145/3560905.3568096},
abstract = {In this demo, we present RTAT, a real-time arm tracking system that tracks both orientation and location of a smartwatch simultaneously by a multitask learning neural network. We incorporate an attention layer and design a dedicated loss for the multitask neural network to learn the dynamic relationships among Inertial Measurement Unit (IMU) sensors. RTAT supports real-time tracking by performing deep learning inference on a smartphone. Finally, to train RTAT, we develop an easy-to-use labeled data collection system that uses a low-cost virtual reality system to measure the ground truth orientation and location of the smartwatch. Extensive experiments show RTAT outperforms significantly the state-of-the-art solutions in inference accuracy and latency.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {780–781},
numpages = {2},
keywords = {arm tracking, inertial measurement unit, location, mobile sensing, multitask learning, orientation},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568085,
author = {Bellon, Alex and Yen, Alex and Pannuto, Pat},
title = {TagAlong: A Free, Wide-Area Data-Muling Service Built on the AirTag Protocol},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568085},
doi = {10.1145/3560905.3568085},
abstract = {We demonstrate how to leverage Apple's Find My protocol, most well known as the underlying protocol of the AirTag, for arbitrary data-muling. This provides a new "infrastructure-free" deployment option, where areas with frequent human activity can take advantage of this zero-cost backhaul network. While there are severe limitations (e.g. no acknowledgement channel back to the sending device), Find My-based networking could still be a highly reliable backhaul with sufficient transmission redundancy and knowledge of deployment context.In this demo, we allow users to send arbitrary data to devices that will forward the data to the Find My network. The data is then recovered from Apple's servers and displayed on a status page. Critically, we will not deploy any of our own intermediate infrastructure and will instead rely on a sufficient density of iPhones and other Apple devices from the demo audience to backhaul data from our demo.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {782–783},
numpages = {2},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568067,
author = {Eom, Sangjun and Hadziahmetovic, Majda and Pajic, Miroslav and Gorlatova, Maria},
title = {Through an AR Lens: Augmented Reality Magnification through Feature Detection and Matching},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568067},
doi = {10.1145/3560905.3568067},
abstract = {Sensing and Augmented Reality (AR) can benefit a wide range of applications that involve the use of magnifying lenses. Recent developments in AR magnification provide a direct overlay of the magnified scenes in AR. However, instrumentation tasks that require high precision and visual acuity need to selectively magnify a region of interest while maintaining the visual perception of the rest of the environment. In this demo, we present AR-Magnifier, an AR magnification system through feature detection and matching. We propose a general framework based on an edge-computing architecture that can be applied to various types of instrumentation tasks. A pipeline is developed for detecting feature points and computing the homography matching to identify the magnified region of an object. We showcase how selective magnification in AR through sensing can assist the user in complex instrumentation tasks by providing visualization-based guidance.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {784–785},
numpages = {2},
keywords = {augmented reality, edge computing, feature detection, magnification},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568060,
author = {Wang, Ziqi and Sarker, Ankur and Wu, Jason and Hua, Derek and Dong, Gaofeng and Singh, Akash Deep and Srivastava, Mani},
title = {Towards Real-Time Rich Scene Analysis Using Vision-Guided Wireless Vibrometry},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568060},
doi = {10.1145/3560905.3568060},
abstract = {Intelligent systems commonly employ vision sensors like cameras to analyze a scene. Recent work has proposed a wireless sensing technique, wireless vibrometry, to enrich the scene analysis generated by vision sensors. Wireless vibrometry employs wireless signals to sense subtle vibrations from the objects and infer their internal states. However, it is difficult for pure Radio-Frequency (RF) sensing systems to obtain objects' visual appearances (e.g., object types and locations), especially when an object is inactive. Thus, most existing wireless vibrometry systems assume that the number and the types of objects in the scene are known. The key to getting rid of these presumptions is to build a connection between wireless sensor time series and vision sensor images. We present Capricorn, a vision-guided wireless vibrometry system. In Capricorn, the object type information from vision sensors guides the wireless vibrometry system to select the most appropriate signal processing pipeline. The object tracking capability in computer vision also helps wireless systems efficiently detect and separate vibrations from multiple objects in real time.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {786–787},
numpages = {2},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568093,
author = {Liu, Xu and Zhang, Hongliang and Di, Boya and Song, Lingyang},
title = {Ubiquitous Deployed Meta-Material Sensors for Structural Monitoring of Buildings},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568093},
doi = {10.1145/3560905.3568093},
abstract = {Obtaining fine-grained structural information about building through ubiquitous sensors is crucial for assessing their aging and damage. However, due to the energy requirements, traditional sensors deployed in the building structure need frequent maintenance works which are easy to produce irreversible damage to the building. Besides, the larger volume of sensors also brings the difficulty of deployment in buildings with complex structures. To solve these problems, we propose a novel sensing system to obtain fine-grained structural information based on ubiquitous deployed meta-material sensors. Specifically, meta-material sensors are small pieces of PCB printed with metal structure, which work without a power supply and suit wide deployment. The experiment realizes the humidity sensing with a spatial resolution of 0.5m, while existing methods for dispersing sensors achieve space intervals of 10m at the same cost. With this framework, the need of providing information support for assessing structural failure can be met.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {788–789},
numpages = {2},
keywords = {internet of things, meta-material, structural monitoring},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568062,
author = {Sen, Pritam and Jiang, Xiaopeng and Wu, Qiong and Talasila, Manoop and Hsu, Wen-Ling and Borcea, Cristian},
title = {Indoor Place Prediction on Smart Phones},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568062},
doi = {10.1145/3560905.3568062},
abstract = {High-accuracy and low-latency indoor place prediction for mobile users is crucial to enable applications for assisted living, emergency services, smart homes, and augmented reality. Previous studies on indoor place prediction use complex infrastructure with multiple visual/wireless anchors or multiple wireless access points. These localization techniques are difficult to deploy, may negatively impact user privacy through location tracking, and their data collection is not suitable for personalized place prediction. To solve these challenges, this paper proposes GoPlaces, a novel app that fuses inertial sensor data with WiFi-RTT estimated distances to predict the future indoor places visited by a user. GoPlaces does not require any infrastructure, except for one cheap off-the-shelf WiFi access point that supports ranging with RTT. In addition, it enables personalized place naming and prediction through its on-the-phone data collection and protects users' location privacy because user's data never leaves the phone. GoPlaces uses an attention-based bidirectional long short-term memory model to detect user's current trajectory, which is then used together with historical information stored in a prediction tree to infer user's future places. We implemented GoPlaces in Android and evaluated it in several indoor spaces. The experimental results demonstrate prediction accuracy as high as 92\%, low latency, and low resource consumption on the phones.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {790–791},
numpages = {2},
keywords = {deep learning, human mobility, indoor place prediction, sensor fusion, smart phones, time series analysis, wifi-RTT},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568094,
author = {Nigam, Nitika and Dutta, Tanima},
title = {A Fast, Multi-Camera, and Intelligent System for Exact Stampede Detection in Large Crowds},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568094},
doi = {10.1145/3560905.3568094},
abstract = {With the increasing population, events with large crowds also increased. It often leads to uncontrolled stampede situations, causing several deaths. Deployment of intelligent systems with the quick alert feature may reduce the impact of stampedes. Researchers utilized traditional deep learning models on a centralized server for stampede detection. These models have high time, computational complexity, unaddressed public privacy concerns, and misclassification due to less inter-class variance. We thus propose a low-cost, fast, and intelligent system named StampSys, for accurate stampede detection over large crowds in multi-camera environment. To address complexity and privacy issues, we introduce a novel light-weight multi-modal federated learning setup. We include a novel multi-label fuzzy classifier to improve the global decision. We create a new annotated dataset, entitled CrowdStampede with 6K images. The experimentation results show that our system accurately classifies stampede situations on our dataset.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {792–793},
numpages = {2},
keywords = {federated learning, fuzzy, stampede detection},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568088,
author = {Sitar, Edward M and Sur, Sanjib},
title = {A Millimeter-Wave Wireless Sensing Approach for Sleep Posture Classification},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568088},
doi = {10.1145/3560905.3568088},
abstract = {We spend one-third of our lives sleeping, and sleep quality plays an important role in our overall health. Sleep posture monitoring can help medical professionals prevent negative health outcomes associated with certain sleep postures. In this work, we propose using millimeter-wave wireless signals to classify the sleep posture using a supervised deep learning model and preliminarily evaluate the performance for 7 volunteers and 5 broad classes of postures.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {794–796},
numpages = {3},
keywords = {deep learning, millimeter-wave, sleep posture recognition},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568076,
author = {Jung, Hyunwoo and Yi, Juheon and Lee, Youngki},
title = {A Study on Thermal Issues in Mobile Extended Reality Applications},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568076},
doi = {10.1145/3560905.3568076},
abstract = {In this work, we show the severity of the thermal issue in mobile Extended Reality (XR) applications. We implement three XR applications and run the applications on a mobile device. We compare the device temperature running benchmark and XR applications. We find that long-term multi-DNN inference execution is the main cause of the thermal issue.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {797–799},
numpages = {3},
keywords = {extended reality, mobile thermal management},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568068,
author = {Ren, Yili and Wang, Yichao and Chen, Yingying and Yang, Jie},
title = {A Vision-Based Approach for Commodity WiFi Sensing},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568068},
doi = {10.1145/3560905.3568068},
abstract = {The ubiquitous WiFi signals provide us the opportunity to sense human activities and the physical environment. In this work, we take a layered approach to design a vision-based method for commodity WiFi sensing. Specifically, the next-generation WiFi supports a larger number of antennas that can provide spatial information of the signal reflections, which enables a vision-based approach for WiFi sensing. To better leverage the spatial formation of the signal reflections and fulfill emerging applications, we provide a holistic layered framework including hardware, physical, deep learning, and application layers as well as a case study. The proposed layered approach could enlighten the research on future WiFi sensing.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {800–801},
numpages = {2},
keywords = {channel state information (CSI), wifi sensing, wifi vision},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568050,
author = {Zhao, Zhihe and Ling, Neiwen and Guan, Nan and Xing, Guoliang},
title = {Aaron: Compile-Time Kernel Adaptation for Multi-DNN Inference Acceleration on Edge GPU},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568050},
doi = {10.1145/3560905.3568050},
abstract = {AI applications powered by deep learning are increasingly running on edge devices. Meanwhile, many real-world IoT applications demand multiple real-time tasks to run on the same device, for example, to achieve both object tracking and image segmentation simultaneously on an augmented reality glass. However, the current solutions can not yet support such multi-tenant real-time DNN inference on edge devices. Techniques such as on-device model compression trade inference accuracy for speed, while traditional DNN compilers mainly focus on single-tenant DNN model optimization. To fill this gap, we propose Aaron, which leverages DNN compiling techniques to accelerate multi-DNN inference on edge GPU based on compile-time kernel adaptation with no accuracy loss. Aaron integrates both DNN graph and kernel optimization to maximize on-device parallelism and minimize contention brought by concurrent inference.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {802–803},
numpages = {2},
keywords = {DNN compiler, efficient DNN processing, real-time system},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568057,
author = {Baran, Bart\l{}omiej and W\'{o}jcik, Dariusz and Oleszek, Micha\l{} and Vejar, Andres and Rymarczyk, Tomasz},
title = {BETS: A Bladder Monitoring System Using Electrical Impedance Tomography: poster},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568057},
doi = {10.1145/3560905.3568057},
abstract = {In this study are presented the results of our ongoing research on an original concept for visualizing and tracking the state of the urinary bladder. We have developed a measuring device based on electrical impedance tomography (EIT). Using electrical current stimulation and measuring the resulting voltages on a patient's body surface, we can visualize the bladder's position and shape, allowing us to analyze its filling level. The project also involves the development of diagnostic methods for functional disorders of the lower urinary tract. In addition, the device will measure muscle tension by electromyography, with the possibility of incorporating electrostimulation therapy. This approach can be used to monitor and support the treatment of patients with various health conditions related to the urinary bladder.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {804–805},
numpages = {2},
keywords = {electrical impedance tomography, medical imaging, medical monitoring, non-invasive method},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568051,
author = {Huang, Wenhao and Tsuge, Akira and Chen, Yin and Okoshi, Tadashi and Nakazawa, Jin},
title = {Bus Crowdedness Sensing System Based on Carbon Dioxide Concentration},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568051},
doi = {10.1145/3560905.3568051},
abstract = {Crowdedness sensing of buses is playing an important role in the disease control of COVID-19 and bus resource scheduling. This research analyzes the relationship between carbon dioxide concentration, bus environment and the number of passengers by linear regression. Our prototype system collects the data of bus environment and carbon dioxide concentration to estimate the number of passengers in real time. By collecting the sensing data from a shuttle bus of university campus, we experimentally evaluate the feasibility and sensing performance of the crowdedness estimation model.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {806–807},
numpages = {2},
keywords = {carbon dioxide sensor, crowdedness sensing, smart cities, ubiquitous computing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568072,
author = {Molteni, Davide and Picco, Gian Pietro and Trobinger, Matteo and Vecchia, Davide},
title = {Cloves: A Large-Scale Ultra-Wideband Testbed},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568072},
doi = {10.1145/3560905.3568072},
abstract = {Research advances in low-power wireless systems have greatly benefited from the availability of public testbeds. However, none is currently available for the increasingly popular ultra-wideband (UWB) radios enabling communication and localization. We present Cloves, the first public large-scale testbed supporting UWB.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {808–809},
numpages = {2},
keywords = {experimental testbed, ultra-wideband (UWB)},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568054,
author = {Xu, Liqiang and Nishiyama, Yuuki and Shimosaka, Masamichi and Tsubouchi, Kota and Sezaki, Kaoru},
title = {Convolutional Compressed Sensing for Smartphone Acceleration Data Compression},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568054},
doi = {10.1145/3560905.3568054},
abstract = {As intelligent sensing and smartphone technologies have progressed, a huge amount of highly heterogeneous data have come to be stored in smartphones and uploaded to servers for analysis on a daily basis. This has led to vast storage overheads for users and companies. Hence, data compression becomes the most efficient strategy for suppressing the increase in storage overhead. Compressed sensing (CS) technology is one approach to compressing data, but traditional CS-based algorithms are significantly time-consuming and have low reconstruction performance. In light of these drawbacks, this paper proposes a compressed sensing framework that instead takes advantage of the low time cost and adaptive learning capability of deep learning methods, wherein a convolutional neural network (CNN) is used for compressing and reconstructing acceleration data. Our experiments with actual smartphone acceleration data show that the proposed method dramatically improves the reconstruction performance with very little reconstruction time compared with traditional compressed sensing methods.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {810–811},
numpages = {2},
keywords = {acceleration data, compressed sensing, convolutional neural network, smartphone sensor},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568100,
author = {Mackey, Steven and Zhao, Tianya and Wang, Xuyu and Mao, Shiwen},
title = {Cross-Domain Adaptation for RF Fingerprinting Using Prototypical Networks},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568100},
doi = {10.1145/3560905.3568100},
abstract = {Radio frequency (RF) fingerprinting is a hardware feature used in Internet of Things (IoT) applications to identify wireless devices. In this paper, we propose few-shot learning (FSL) and prototypical networks (PTNs) to create a new model that can adapt to a new domain with very few labeled examples. The proposed model can mitigate the domain shift caused by changing RF environments. Experimental results show the proposed method can improve the performance of RF fingerprinting over different domains.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {812–813},
numpages = {2},
keywords = {RF fingerprinting, few-shot learning, prototypical networks},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568055,
author = {Ikeuchi, Yuichi and Tsubouchi, Kota and Nishio, Nobuhiko},
title = {Estimation of Precise Heading by Segmenting the Motion of Individual Steps and LSTM},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568055},
doi = {10.1145/3560905.3568055},
abstract = {Precise estimation of heading, which is a key component of pedestrian dead reckoning for indoor positioning methods, is needed. We propose a new method that improves the accuracy of the heading estimation by processing data at a resolution finer than one step. First, the sensor data are divided into segments finer than a step by using the norm of the acceleration vectors. Then, features to predict the heading are automatically extracted from the segments by using a neural network based on long short term memory, instead of using the statistics of steps as features as is done conventionally. Our method is more accurate than the conventional one for walking in straight lines and walking on curved trajectories.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {814–815},
numpages = {2},
keywords = {IMU, PDR, heading estimation, neural networks},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568063,
author = {Zhang, Xiao and Klevering, Griffin and Xiao, Li},
title = {Exploring Rolling Shutter Effect for Motion Tracking with Objective Identification},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568063},
doi = {10.1145/3560905.3568063},
abstract = {Sensing-based user interfaces hold enormous potential for smart homes, medical equipment, educational systems, AR/VR/MR, etc. However existing hand and body gesture recognition systems are mostly based on frame-level computer vision approaches, which have limitations such as the inability to operate in the environment with low brightness, short detection distance, without the objective identification ability, and coarse-grained tracking when the objectives are in high-speed motion. Therefore, in this paper, we propose to attach active LED elements on objectives and utilize rolling shutter effect to enhance the gesture recognition and achieve the fine-grained motion tracking with objective identification.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {816–817},
numpages = {2},
keywords = {gesture recognition, optical labeling and identification, rolling shutter camera, visible light sensing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568077,
author = {Yuan, Kuang and Gadre, Akshay and Kumar, Swarun},
title = {Exploring Time-Series Telemetry from CubeSats},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568077},
doi = {10.1145/3560905.3568077},
abstract = {With increasing numbers of nano-satellites (CubeSats) being launched into space in recent years, monitoring their health and debugging become crucial problems. In traditional systems such as big satellites, time-series telemetry is widely used by users to monitor the state of the satellite from the ground stations. However, today smaller CubeSats do not enjoy the benefits of live telemetry due to low throughput and lack of coverage from ground station infrastructure. In this poster, we conduct a motivation study based on data collected from public satellites in low-earth orbit to demonstrate the potential bottlenecks in obtaining live telemetry data from CubeSats. We then describe the design space of possible solutions and opportunities for researchers to improve time-series telemetry for CubeSats.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {818–819},
numpages = {2},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568089,
author = {Junker, Nicholas and Ge, Jinqun and Wang, Guoan and Sur, Sanjib},
title = {FlexVAA: A Flexible, Passive van Atta Retroreflector for Roadside Infrastructure Tagging and Identification},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568089},
doi = {10.1145/3560905.3568089},
abstract = {We propose FlexVAA, a system for identifying roadside infrastructure using flexible, passive wireless retroreflectors. FlexVAA can be easily attached to any surface, allowing roadside infrastructure to be upgraded for autonomous systems without impairing existing operations. Preliminary results show that attaching FlexVAA to a surface reflects more power than without FlexVAA attached. In the future, we plan to arrange multiple FlexVAA elements in order to embed data in the passively reflected signal, allowing identification for multiple unique tags.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {820–822},
numpages = {3},
keywords = {flexible electronics, road infrastructure, van atta array},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568095,
author = {Billah, Md Fazlay Rabbi Masum and Islam, Md Mofijul and Saoda, Nurani and Iqbal, Tariq and Campbell, Bradford},
title = {Fusing Computer Vision and Wireless Signal for Accurate Sensor Localization in AR View},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568095},
doi = {10.1145/3560905.3568095},
abstract = {Recent years have seen increasing traction to enable new applications that can localize sensors on the screen of an Augmented Reality (AR) device (e.g. smartphone, tablet) so that sensors can be controlled more intuitively. Despite recent advances in this area, both wireless signal dependent and computer vision based localization solutions have seen a slow acceptance due to signal noise, multipath effect, and limited AR device-sensor interactivity. In this paper, we propose a novel solution to combine the complementary advantages of wireless signal based localization solution with the computer vision based solution to track IoT devices and sensors more accurately. Experimental result shows that our system can accurately track IoT devices with an average pixel error of 34 pixels in a 1024 \texttimes{} 768 pixels image, which is a 75.8\% improvement from the state-of-the-art model.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {823–824},
numpages = {2},
keywords = {BLE, augmented reality, computer vision, sensor localization},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568083,
author = {Fan, Zipei and Zhang, Zhiwen and Wang, Hongjun},
title = {Generative Personalized Federated Learning Framework for Travel Time Estimation},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568083},
doi = {10.1145/3560905.3568083},
abstract = {Estimating the travel time of a given path is an important topic for the intelligent transportation system and serves as the foundation for various real-world applications. However, building an estimation model for such a data-driven task requires a large amount of mobile users' trajectory data which directly relates to their privacy and thus is less likely to be shared. Therefore, we propose GPF-TTE, Generative Personalized Federated Learning Framework for Travel Time Estimation (poster version of our previous work [1]) based on the issue of privacy protection for the mobile user group, in which 1) utilizes the federated learning approach, allowing private data to be kept on client devices while training, 2) apart from sharing a base model, we also adapt a fine-tuned personalized model for each client to study their personal driving habits, making up for the residual error caused by the prediction of the localized global model (the base model in local device), and 3) the cloud server aggregates localized models into the global model as a generative model to infer the future road traffic state.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {825–826},
numpages = {2},
keywords = {federated learning, ubiquitous, urban computing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568092,
author = {Qian, Xueteng and Guo, Xiuzhen and Yang, Yongjie and Fan, Xiaoran and Shangguan, Longfei},
title = {HeadFi II: Toward More Resilient Earable Computing Platform},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568092},
doi = {10.1145/3560905.3568092},
abstract = {Earables are embedded devices that can be placed in, on, or around the ear to sense human motions and physiological activities over an extended period of time. However, today's earable design principle heavily relies on dedicated sensors (e.g., accelerometer, gyroscope, proximity sensor), which inevitably adds cost, weight, and power consumption to earable devices, constituting a critical bottleneck in their wide adoption. Moreover, the tight coupling of sensors with onboard microcontrollers makes existing earables difficult to program, raising the barrier of entry to earable computing.In this poster, we describe HeadFi II, a stand-alone earable computing platform that integrates sensing and computing into a tiny hardware device with low power and computation footprint. We describe the design guideline and technical challenges as well as potential solutions. We believe this project would open up a new dimension of cutting-edge research and exciting educational opportunities. The developed solutions will lead to considerable advancements in both low-power hardware designs and efficient earable sensing algorithms, lowering the barrier of entry to earable computing by providing the research community with a versatile earable platform.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {827–828},
numpages = {2},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568048,
author = {Gomi, Hidehito and Tsubouchi, Kota and Teraoka, Teruhiko},
title = {Indoor Localization with Passerby Data in Parasitic Approach},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568048},
doi = {10.1145/3560905.3568048},
abstract = {We propose an innovative indoor localization approach to constructing user trajectories for indoor spaces where GPS signals are unavailable. The results of a simulation experiment demonstrate the effectiveness of the proposed approach and shed light on a new value for obtaining accurate positions indoors.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {829–830},
numpages = {2},
keywords = {indoor localization, location logging, mobile sensing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568064,
author = {Cui, Kaiyan and Yang, Qiang and Shen, Leming and Zheng, Yuanqing and Han, Jinsong},
title = {Integrated Sensing and Communication between Daily Devices and mmWave Radars},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568064},
doi = {10.1145/3560905.3568064},
abstract = {Millimeter wave (mmWave) radar has demonstrated excellent performance in object tracking and micro-displacement detection. Besides the powerful sensing function, this work brings the communication function, allowing daily devices to communicate with mmWave radars through vibrations. In this work, we present VibBeat, in which a daily device (e.g., smartphone and smartwatch) sends messages by modulating vibrations, while a mmWave radar receives the messages by detecting and decoding the vibrations with reflected mmWave signals. By doing so, the device (user) can not only be passively sensed by a mmWave radar, but also actively send messages to the radar for a personalized response. We implement our system using a COTS mmWave radar and smartphones without any hardware modification. Experimental results show that VibBeat supports multiple object communication and achieves a communication range of up to 5m.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {831–832},
numpages = {2},
keywords = {ISAC, mmWave communication, vibrations},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568099,
author = {Li, Guodong and Wu, Zhiyuan and Liu, Xinyu and Wang, Yue and Zhang, Lin},
title = {Multi-Task Learning Based Blind Calibration for Low-Cost Air Quality Sensor Deployments},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568099},
doi = {10.1145/3560905.3568099},
abstract = {Air pollution problem has caught much attention globally. In addition to the national air quality monitoring stations deployed by the government, the number of low-cost air quality sensors increases rapidly as a supplement to support fine-grained monitoring. In-field calibration methods are necessary for these low-cost sensor nodes to assure the data quality. However, it is costly to collect enough reference data after deployment to train the in-field calibration model and many sensors even have no synchronized reference in the real application scenarios. To address the above challenge, we propose a multi-task learning based blind calibraiton method for air quality sensors after deployments. Our method introduces not only the reference data of the target location to formulate calibration task, but also reference measurements collected from highly accurate stations already deployed by the government in other geographical locations to formulate prediction task. To utilize the reference measurements which are not in the same location with our target sensors, e.g., in other cities, we combine the proposed calibration task and prediction task under a multi-task learning scheme. The introduced references in other locations alleviate our few-reference challenge. Furthermore, we elaborate on the choices of different tasks to have better effect of the target calibraiton task. Evaluations on the real-world collected datasets show that our proposed algorithm has better calibraiton effect.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {833–834},
numpages = {2},
keywords = {air quality, blind calibration, multi-task learning},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568073,
author = {Gao, Jiechao and Tang, Mingyue and Wang, Tianhao and Campbell, Bradford},
title = {PFed-LDP: A Personalized Federated Local Differential Privacy Framework for IoT Sensing Data},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568073},
doi = {10.1145/3560905.3568073},
abstract = {Recent advancements in deep learning techniques have shown great potential for smart Internet of Things (IoT) applications. However, the edge devices of IoT applications often collect and store only limited data, which is insufficient for training modern deep learning models. Collaborative training methods such as cloud computing and federated learning set steps to build robust models for IoT applications, yet these methods bring the concern of data privacy (e.g., untrusted central server, model inversion). On the other hand, directly applying privacy-preserving techniques such as differential privacy can dramatically degrade the performance of IoT applications. Inspired by the development of model personalization, we aim to design a federated learning framework in a personalized fashion to reduce the accuracy loss caused by privacy-preserving techniques. In this paper, we present PFed-LDP, a private and accurate federated local differential privacy (LDP) framework for IoT sensing data. We first design a dynamic layer sharing mechanism to separate the local model into global layers and personalized layers. Second, we apply LDP noise to the global layers and transmit them to the federated learning framework for aggregation. Third, each local client updates their model with local personalized layers and aggregated global layers to perform IoT tasks. Our experiments on real-world datasets show that we only sacrifice 1.6\% of accuracy to achieve privacy-preserving IoT applications. We also observe that our method has the smallest accuracy range, which means we can achieve the best performance for the worst performed client.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {835–836},
numpages = {2},
keywords = {IoT, federated learning, privacy},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568097,
author = {Sukeda, Issey and Murakami, Hiroaki and Nishiyama, Yuuki and Kawahara, Yoshihiro},
title = {Recursive Queueing Estimation Using Smartphone-Based Acoustic Ranging},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568097},
doi = {10.1145/3560905.3568097},
abstract = {When customers wait their turn to place an order at a street vendor, they often form a spontaneous queue. Due to the presence of passers-by and people standing outside the queue, it is more difficult than one might think to distinguish between those in the queue and those not in the queue. In this paper, we consider a method that uses acoustic ranging to autonomously detect who is in line and in which order, under the condition that all customers have smartphones. The proposed method is unique in that it can distinguish whether a newly arrived user has joined the end of the queue or not by taking cues from the geometric properties of the queue. Our preparatory queueing simulations confirm that 92.5\% of the queuers are estimated correctly.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {837–838},
numpages = {2},
keywords = {acoustic sensing, mobile sensing, queueing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568098,
author = {Suzuki, Ryoto and Nishiyama, Yuuki and Murakami, Hiroaki and Kawahara, Yoshihiro and Sezaki, Kaoru},
title = {Room Scale Localization Improvement Utilizing Stay Time Characteristics of Each Room},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568098},
doi = {10.1145/3560905.3568098},
abstract = {Indoor localization technology is one of the most important topics in the fields of Internet of Things (IoT) and ubiquitous computing, and it has attracted much attention in recent years due to its ability to enable a variety of services. Localization methods using Bluetooth or Wi-Fi signal strength can introduce a low-cost location estimation system. However, due to the instability of the received signal strength and signals leaking from adjacent rooms, a simple method based on signal strength alone frequently results in misjudgment, depending on the signal propagation characteristics. In this paper, we propose a method to suppress misjudgment by considering the characteristics of stay time in different rooms. Our proposed method estimates the user state by fitting the distribution of time spent in each room to a Weibull distribution and applying survival analysis. The experimental results suggest that the method will provide more accurate information about the rooms in which users stay.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {839–840},
numpages = {2},
keywords = {bluetooth low energy, iBeacon, indoor localization, received signal strength indicator},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568080,
author = {Xie, Zongxing and Ye, Fan},
title = {Scaling Device-Free Indoor Tracking Based on Self Calibration},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568080},
doi = {10.1145/3560905.3568080},
abstract = {The democratization of indoor tracking systems lays the groundwork for a wide spectrum of smart home applications. While prior work on RF-based device-free localization/tracking have shown preferable features and promising results, they heavily relied on well-calibrated sensor placements, which require hours of intensive manual setup and respective expertise, making it prohibitively expensive to scale deployments to wide range (e.g., tens or hundreds of real homes). We propose SCALING, a plug-and-play indoor tracking system, of which the key enabler is a self calibrating algorithm that estimates the distributed sensor locations through their distance measurements to a person walking a trajectory, a trivial effort without taxing layman users physically or cognitively. We have experimentally evaluated SCALING via real world testbeds and shown an 80-percentile tracking accuracy of 40.5 cm, only 1\% degradation compared to the classical multilateration with known sensor locations (anchors), which costs hours of intensive calibrating effort.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {841–842},
numpages = {2},
keywords = {device-free, distributed monostatic radars, indoor tracking, local positioning system, radio frequency (RF) sensing, self calibration},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568090,
author = {Li, Huining and Zheng, Wenhan and Pandya, Aditya and Xu, Chenhan and Xia, Jun and Xu, Wenyao},
title = {Smartphone-Based Blood Perfusion Assessment for Ulcer Care},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568090},
doi = {10.1145/3560905.3568090},
abstract = {In this paper, we propose a transformative solution that uses a low-cost light sensor and commodity smartphone to support fast self-assessment of blood perfusion of ulcer regions in daily life. By harnessing the knowledge of light polarization, our system can "see-through" the skin to quantify the spatio-temporal properties of subdermal vasculature in terms of pulsation and hemoglobin. Our evaluation results show that our system can achieve 78.6\% accuracy to detect poor and good blood perfusion.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {843–844},
numpages = {2},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568091,
author = {Dhar, Argha Chandra and Roy, Arna and Biswas, Subrata and Islam, Bashima},
title = {Studying the Security Threats of Partially Processed Deep Neural Inference Data in an IoT Device},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568091},
doi = {10.1145/3560905.3568091},
abstract = {Partial computation offloading offers lower latency, privacy (by processing data close to the source), and higher performance. In partial offloading, some of the processing is performed on the less capable Internet-of-Things (IoTs), and more complex computation is performed in more capable cloud computers. Though many well-established security protocols are available to address external intrusion, it introduces significant overhead for large data sample. This overhead is becoming a challenging problem with the recent trend and promises of on-device deep neural network (DNN) inference. This paper studies how much prior data distribution knowledge is required by an intruder to retrieve the input from a partially computed vector. We explore simple and complex DNN tasks, which are unknown to the intruder. We show that for simple datasets, Auto-Encoder(AE) and Variational Auto Encoder(VAE) can retrieve the original input image with a 4\% accuracy drop on average. However, the same is not valid for complex data distribution.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {845–846},
numpages = {2},
keywords = {inverse deep neural network, mobile computing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568075,
author = {Zhang, Yuke and Takaki, Ken and Murakami, Hiroaki and Sasatani, Takuya and Kawahara, Yoshihiro},
title = {Toward Continuous Finger Positioning on Ear Using Bone Conduction Speaker},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568075},
doi = {10.1145/3560905.3568075},
abstract = {The advancement of semiconductor and battery technologies popularized tiny acoustic wearable devices such as bone conduction wireless headsets. However, this small form factor poses inconvenience when controlling these devices, as they cannot equip large footprint intuitive interfaces such as volume sliders and touch screens. This paper presents a technique using acoustic responses measured by a bone conduction speaker and a microphone to utilize the ear as a touch input interface. We discovered that a finger placed on different parts of the ear affects the acoustic radiation characteristic of the ear, modulating the leaked sound, and by leveraging this effect, the touch position can be estimated. Experimental results show that five distinct frequency responses with five different finger positions can be obtained, which indicates that our method could allow bone conduction headsets to capture continuous finger positions without additional hardware.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {847–848},
numpages = {2},
keywords = {acoustic sensing, bone conduction, human interface, positioning},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568078,
author = {Wang, Purui and Liang, Bo and Zhao, Renjie and Zhang, Pengyu and Zhang, Xinyu and Xu, Chenren},
title = {An RFID Localization System for Smart Logistics},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568078},
doi = {10.1145/3560905.3568078},
abstract = {In a modern logistics network, high-performance automation of inventory tracking and package management calls for a reliable, high-throughput and long range RFID localization system. We present RF-Chord, the first RFID localization system that simultaneously meets all these requirements. RF-Chord features a one-shot multisine-constructed wideband design that can process the RF signal with a 200 MHz bandwidth in real-time to facilitate one-shot localization at scale. In addition, multiple SINR enhancement techniques are designed for range extension. Finally, we propose a kernel-layer-based near-field localization and a multipath-suppression algorithm that reduces the 99\% long-tail errors.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {849–850},
numpages = {2},
keywords = {RFID, localization, logistics IoT, multisine, real-time},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568071,
author = {Krupp, Brian and Gersey, Julia and Fagert, Jonathon and Mlady, Tony},
title = {Towards Fine-Grained Air Quality Sensing in Urban Environments},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568071},
doi = {10.1145/3560905.3568071},
abstract = {This paper presents preliminary findings from a deployment of an Internet of Things (IoT) air quality sensor that can provide realtime and historical fine-grained air quality data. Current air quality data provided to communities may be inaccurate meaning that people are breathing air that is more polluted than what is reported. Through this research, we share our findings from testing in a controlled environment, a test deployment in an urban environment, and an enclosure for future deployments. From our test deployment we are able to determine that there is a significant difference between two locations that are less than 4 miles apart where the average particulate matter reading was more than double. These findings show that fine-grained air quality monitoring can provide the community with more meaningful data of the air they breathe.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {851–852},
numpages = {2},
keywords = {air pollution, sensing, urban air quality},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568084,
author = {Chen, Tao and Fan, Xiaoran and Yang, Yongjie and Shangguan, Longfei},
title = {Towards Remote Auscultation with Commodity Earphones},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568084},
doi = {10.1145/3560905.3568084},
abstract = {Virtual visits (a.k.a., telehealth) have been promoted in response to the COVID pandemic since early 2020. Despite its convenience, the current virtual visit practice barely relies on video observation and talking. The specialist, however, cannot accurately assess the patient's health condition by listening to acoustic cardiopulmonary signals emanating from the patient's heart with a stethoscope. In this poster, we explore the feasibility of remote auscultation in virtual visits settings by reusing the patient's earphones as a stethoscope. The proposed hardware-software system captures the minute heartbeats from the patient's ear canal. It then offloads these noisy cardiac signals to the pairing device (e.g., a smartphone or a laptop) to reconstruct fine-grained Phonocardiogram (PCG) signals. By listening to the reconstructed PCG signals, the specialist can easily assess the patient's health condition and make the most informed diagnosis. We describe the design challenges and explain our technical roadmap.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {853–854},
numpages = {2},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568079,
author = {Gupta, Pranjol and Talukder, Zahidur and Islam, Mohammad A. and Nguyen, Phuc},
title = {Towards Server-Level Power Monitoring in Data Centers Using Single-Point Voltage Measurement},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568079},
doi = {10.1145/3560905.3568079},
abstract = {Server-level power monitoring in data centers can significantly contribute to its efficient management. Nevertheless, due to the cost of a dedicated power meter for each server, most data center power management only focuses on UPS or cluster-level power monitoring. In this paper, we propose a low-cost novel power monitoring approach that uses only one sensor to extract power consumption information of all servers. We utilize the conducted electromagnetic interference of server power supplies to measure its power consumption from non-intrusive single-point voltage measurement. Using a pair of commercial grade Dell PowerEdge servers, we demonstrate that our approach can estimate each server's power consumption with ~3\% mean absolute percentage error.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {855–856},
numpages = {2},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568069,
author = {Zhao, Renjie and Zhang, Pengyu and Ma, Yunfei and Zhang, Xinyu},
title = {Ultra-Wideband Backscatter Towards General Passive IoT Localization},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568069},
doi = {10.1145/3560905.3568069},
abstract = {Typical passive internet of things (IoT) localization systems, such as those based on UHF RFID, adopt narrow bandwidth signal and bind the localization function with energy harvesting and communication waveform. Due to the signal bandwidth and waveform constraints, the systems can not meet crucial requirements of practical IoT use cases. In this poster, we identify the fundamental challenges and analyze why the existing systems fall short. Based on the analysis, we propose to adopt dual band backscatter design and identify different design choices on frequency band, waveform and tag modulation. Finally, we build an ultra-wideband FMCW signal based prototype UWB2 to verify the feasibility of our proposal. Our results show that the system can achieve low tail error and realize one shot localization even under harsh multipath scenarios.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {857–858},
numpages = {2},
keywords = {FMCW, RFID, UWB, internet of things, localization},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568056,
author = {Rymarczyk, Tomasz and K\l{}osowski, Grzegorz and Adamkiewicz, Przemys\l{}aw and Sty\l{}a, Micha\l{} and Kiczek, Bart\l{}omiej},
title = {Use of a Long Short-Term Memory Network in Radio Tomography to Track People Indoors},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568056},
doi = {10.1145/3560905.3568056},
abstract = {The aim of the research is to develop a system enabling effective and efficient tracking of people inside buildings using radio waves. The presented concept uses radio tomography imaging (RTI) as a passive analysis of radio wave interference as well as active connections with transmitting and receiving devices---mainly smartphones. A long short-term memory (LSTM) neural network was used to solve the inverse tomographic problem of converting measurements into images. The presented concept uses a proprietary design of transducers, which are transmitting and receiving devices that can exchange information with each other and establish connections with other devices. The novelty is the hybrid nature of the people location system, using both device-free and device-based methods. Another new approach is using the LSTM network to solve the inverse problem in RTI. Both solutions make the location system much more flexible, which makes imaging much more accurate and reliable.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {859–860},
numpages = {2},
keywords = {indoor localization, long short-term memory networks, radio tomographic imaging, wireless networks},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568059,
author = {K\l{}osowski, Grzegorz and Rymarczyk, Tomasz and Niderla, Konrad},
title = {Use of the Two-Stage Neural System in Electrical Impedance Tomography for Imaging Moisture inside Walls},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568059},
doi = {10.1145/3560905.3568059},
abstract = {Damp walls of buildings are a serious problem due to the social and economic consequences. Moisture causes accelerated wear of facades, paint coatings, weakening of the wall structure, and high maintenance and renovation costs. The growth of fungi and bacteria worsens the indoor microclimate [1]. Effective identification of moisture inside the walls enables effective preventive actions. The paper presents an algorithmic concept that increases the quality of tomographic images showing the distribution of moisture inside the walls. The method solves the problem of monitoring the dampness of historical buildings and walls susceptible to moisture. The research focuses on solving the inverse problem of converting electrical measurements into spatial images. The study used a proprietary electrical impedance tomography system with specially designed electrodes. The measurement vector is converted to images in two stages. In the first stage, the Long Short-Term Memory (LSTM) neural network was used, which generates raw reconstructions. The task of the second LSTM network is to convert the raw images obtained in the first stage into enhanced images. The application of the presented method is not limited to one type of narrow-sphere tomography. The two-stage approach can be easily adapted to, e.g., medical and industrial or process tomography. Therefore, it is a generic, universal method with great implementation potential, which is its great advantage.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {861–862},
numpages = {2},
keywords = {electrical impedance tomography, long short-term memory networks, machine learning, moisture imaging},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568053,
author = {Ishioka, Riku and Tsubouchi, Kota and Nishiyama, Yuuki and Sezaki, Kaoru},
title = {UV Index Estimation Leveraging GNSS Sensors on Smartphones},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568053},
doi = {10.1145/3560905.3568053},
abstract = {Monitoring the amount of UV irradiance to which individuals are exposed and ensuring that every individual receives the optimal amount has been the subject of extensive research. In previous research, the UV index was estimated using cell phone cameras, light sensors on smartphones, or wearable UV sensors. We propose a method for estimating the UV index using the widespread global navigation satellite system (GNSS) sensors available on smart-phones. In contrast to approaches that require the sensor to be exposed continuously to the irradiance, this method, which leverages GNSS sensors, has the potential advantage of enabling UV index measurement simply by carrying the phone as usual. As a first step in measuring the index using GNSS sensors, GNSS data were collected from cell phones placed at three locations in a single area; the OpenUV API was utilized as a baseline. The proposed method achieved a mean absolute error of 0.1523, which significantly outperformed the baseline.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {863–864},
numpages = {2},
keywords = {GNSS, UV index estimation, passive mobile sensing, smartphone},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568101,
author = {Sutton, Felix},
title = {The Design of a Battery-Less Wireless Condition Monitoring System for Industrial Circuit Breakers},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568101},
doi = {10.1145/3560905.3568101},
abstract = {Circuit breakers are a fundamental safety device in all residential and industrial electrical distribution installations. The harsh environmental conditions of industrial circuit breakers can lead to unwanted resistance, i.e., due to the build-up of dirt, between the circuit breaker terminals and the conducting metal bars that supply power from the grid. This can lead to excessive heat through the circuit breaker mechanics, which over time, may degrade the lifetime of the circuit breaker. In order to mitigate this, a monitoring system is needed to remotely monitor the temperature of the circuit breaker contact terminals, thus improving scheduled maintenance and minimizing downtime.We present the system design of a battery-less wireless temperature sensor for industrial circuit breakers. We follow well established embedded system design principles, and advocate a refinement to existing design methodologies specific to low-power energy harvesting wireless embedded systems. In this work, we detail each step in the proposed design methodology and present an evaluation of the system prototype in an industrial environment.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {865–870},
numpages = {6},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568102,
author = {Phan, Tra Nguyen and Oelmann, Bengt and Bader, Sebastian},
title = {Towards Automated Design Optimization of Electromagnetic Energy Harvesting Transducers},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568102},
doi = {10.1145/3560905.3568102},
abstract = {A new scheme for the automated design and optimization of electromagnetic energy harvesters is presented. The proposed method aims to deal with the limitations of current design techniques and to improve the efficiency of the design process. Most of the current design approaches require significant user experience and knowledge to make informed design decisions, which means that a large amount of time is needed to obtain the optimized design. Additionally, the design solution is suitable only for a specific application, which makes it difficult to adopt it to other application demands. In the proposed method, the development cycle has been sped up significantly by minimizing human efforts and utilizing a generic model for the design process. The method is based on a generic template based on specific resources and requirements, which is processed by a black-box optimization algorithm to come up with a number of promising configuration suggestions. The method's effectiveness and its autonomous operation are demonstrated based on the design optimization of an electromagnetic pick-up unit for vibration energy harvesters using a Halbach array.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {871–877},
numpages = {7},
keywords = {design automation, electromagnetic transduction, energy harvesting, modeling, optimization},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568104,
author = {Longman, Edward and El-Hajjar, Mohammed and Merrett, Geoff V.},
title = {Multihop Networking for Intermittent Devices},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568104},
doi = {10.1145/3560905.3568104},
abstract = {Energy harvesting (EH) devices without batteries can enable the Internet of Things (IoT) to reach new and challenging scenarios. Multihop routing is needed to extend the range but, when low EH causes intermittency, it has been overlooked and is not possible with existing protocols. Also, whilst wake-up receivers (WuRxs) have been used to enable star networks, the cost of another EH node sending wake-ups, required for multihop communication, has not been considered. This paper adapts the opportunistic RPL (ORPL) protocol to make possible multihop routing between intermittently-powered devices. Furthermore, the benefit of using WuRx to enable networks is measured, considering different sensitivity devices and associated range. Comparing ORPL to RPL, we show that opportunistic routing enables multihop communication where RPL cannot. If WuRx are used for routing towards a central hub, the more sensitive WuRx perform better, but routing cross-network benefits from lower sensitivity, lower power WuRx.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {878–884},
numpages = {7},
keywords = {batteryless sensors, intermittently-powered, wake-up receiver},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568107,
author = {Mosavat, Sayedsepehr and Golkar, Pedram and Zella, Matteo and Marr\'{o}n, Pedro Jos\'{e}},
title = {PROGNOES: Prediction of Harvestable Solar Energy Based on Sun Irradiation and Weather Conditions},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568107},
doi = {10.1145/3560905.3568107},
abstract = {Energy harvesting, batteryless devices can mitigate many shortcomings of battery-operated devices in the coming years, particularly in the area of the Internet of Things. Solar energy is an accessible and effective source of power for such devices. However, the uncontrollable nature of solar energy makes the task of designing and evaluating energy harvesting devices a challenging one. In this work, we propose PROGNOES, a tool that allows the user to forecast the harvestable solar energy by a particular solar cell at a specific time and location. To carry out the forecasts, various algorithms and models are used not only to provide the theoretical solar irradiation but also to provide the weather condition data corresponding to the time and location of the forecasting. PROG-NOES can generate forecasts in the form of IV curves, similar to those generated by physical solar cells. Such IV curves can then be emulated with suitable tools to provide energy traces to the energy harvesting devices at design time, therefore facilitating the task of designing robust, reliable energy harvesting, batteryless devices. In our experiments, we find that the energy forecasts carried out by PROGNOES can reach a mean absolute error of 7.16 mW.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {885–891},
numpages = {7},
keywords = {PV cell, design support, energy harvesting, energy management, energy prediction, solar cell},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568108,
author = {Brunner, Hannah and Boano, Carlo Alberto and R\"{o}mer, Kay},
title = {Leakage-Aware Lifetime Estimation of Battery-Free Sensor Nodes Powered by Supercapacitors},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568108},
doi = {10.1145/3560905.3568108},
abstract = {Battery-free sensor nodes rely solely on energy harvested from the environment and thus employ supercapacitors as energy storage to allow perpetual operation in absence of ambient energy. To guarantee that the sensor nodes can survive in periods where no harvested energy is available, it is crucial to accurately estimate the lifetime of these devices. However, as we show experimentally in this paper, an accurate lifetime estimation is non-trivial due to the supercapacitors' complex discharge characteristics (e.g., leakage currents) and large capacitance tolerances. After showing that empirical data capturing the supercapacitors' characteristics is essential towards an accurate estimation of the system's lifetime, we introduce an enhanced leakage model that is computationally lightweight and evaluate its accuracy experimentally.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {892–898},
numpages = {7},
keywords = {battery-free systems, leakage, sensor nodes, supercapacitors},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568109,
author = {Menon, Rohan and Gujarathi, Rohit and Saffari, Ali and Smith, Joshua R.},
title = {Wireless Identification and Sensing Platform Version 6.0},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568109},
doi = {10.1145/3560905.3568109},
abstract = {Connected devices are becoming more ubiquitous, but powering them remains a challenge. The Wireless Identification and Sensing Platform (WISP) is a fully programmable device capable of energy harvesting and backscatter communication. It can accommodate a variety of sensing modalities and operate without batteries or a wired power supply, making it a suitable device for ubiquitous computing. A new version of WISP is presented. WISP-6.0 is designed to be low-power, modular, and enable dual energy harvesting from sources like a solar panel. Additionally, an upgraded cross-platform host application is built using the latest web technologies. Compared to its predecessor, WISP-5.1, WISP-6.0 consumes 13.62\% and 6.29\% less power in active accelerometer and active acknowledgment modes respectively. Furthermore, WISP-6.0 is better able to harvest RF energy collected from its antenna, with the greatest improvements at higher input powers.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {899–905},
numpages = {7},
keywords = {WISP, battery-free camera, battery-free microphone, battery-free sensor, energy harvesting, internet of things, sensor platforms, wireless sensor networks},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568110,
author = {Madden, John and Marcano, Gabriel and Taylor, Stephen and Pannuto, Pat and Josephson, Colleen},
title = {Hardware to Enable Large-Scale Deployment and Observation of Soil Microbial Fuel Cells},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568110},
doi = {10.1145/3560905.3568110},
abstract = {Soil microbial fuel cells are a promising source of energy for outdoor sensor networks. These biological systems are sensitive to environmental conditions, therefore more data is needed on their behavior "in the wild" to enable the creation of an energy system capable of being widely deployed. Prior work on early characterization of microbial fuel cells relied on extremely accurate, but expensive, logging hardware. To scale up the number of deployment sites, we present custom logging hardware, specially designed to accurately monitor the behavior of microbial fuel cells at low cost. This paper describes the design and evaluation of the board, which is open source and freely available on GitHub.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {906–912},
numpages = {7},
keywords = {microbial fuel cell, power harvesting, power monitoring, sensor networks},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568111,
author = {Liaqat, Rao Muzamal and Branch, Philip and But, Jason},
title = {LoRa Based Linear Network Applications, Design Considerations and Open Challenges: A Review},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568111},
doi = {10.1145/3560905.3568111},
abstract = {Wireless sensor networks (WSNs) have emerged as an increasingly important technology with wide application in fields such as industrial automation, transportation, smart cities, and similar areas. LoRa based LPWAN provides long range, robust, economical, and reliable communication with high link budget compared to other LPWAN technologies. However, LoRa based networks are usually deployed using a star topology (LoRaWAN). This type of network topology is not suitable for long range wireless communication and is also subject to single point of failure at the LoRaWAN gateway. In this study we evaluate the potential of LoRa as links in linear networks. We have addressed the potential applications, design considerations and current challenges in adaptation of LoRa technology for linear networks. This survey presents a detailed analysis of LoRa technology as a linear network and provides recommendations to researchers and practitioners to explore LoRa technology as a linear network technology for various IoT applications.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {913–917},
numpages = {5},
keywords = {LoRa, LoRa challenges, LoRa linear networks, LoRa survey},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568112,
author = {Koch, Daniel Jay and Shahid, Muhammad Osama and Krishnaswamy, Bhuvana},
title = {Spreading Factor Detection for Low-Cost Adaptive Data Rate in LoRaWAN Gateways},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568112},
doi = {10.1145/3560905.3568112},
abstract = {In order to meet the capacity needs of LoRa networks, Adaptive Data Rate (ADR) has been proposed and implemented in LoRaWANs. The network server running ADR determines the optimum data-rate and hence spreading factor setting for each LoRa device in a network. This in turn requires the gateway to be capable of receiving all possible spreading factors. Existing gateways achieve this by using multiple RF front ends, increasing their overall cost and complexity. In this work, we propose a Discrete Wavelet Transform based spreading factor detection algorithm that is agnostic to transmitter settings. This computationally light-weight algorithm can be implemented on any off-the-shelf SDR, bringing down the cost and ease of LoRaWAN gateway implementations. Using experimental, real-world datasets, we show that the proposed algorithm can detect the spreading factor of over 99.5\% of the received packets at SNRs down to -10dB.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {918–924},
numpages = {7},
keywords = {LPWAN, LoRa, adaptive data rate, discrete wavelet transform},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568103,
author = {Tobias, Nicole and Sorber, Jacob},
title = {Old Dog, New Tricks: Seeking Metrics for Energy Harvesters as Sensors},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568103},
doi = {10.1145/3560905.3568103},
abstract = {Designing batteryless sensors presents many challenges, starting with selecting the right components for a particular application. Every new sensor added to a device can be costly, both monetarily and in energy expense. Recent research has begun to look at using the very harvesters that are already on the device as sensors for various applications. Unfortunately, not all harvesters are created equal and it is not as simple as just looking up current standards in a component's datasheet. In this paper, we propose that new metrics for energy harvesters are needed by the community to reduce complexities in the design process of selecting the optimal harvester to use as a sensor. Using a sampling of 9 solar harvesters, we ran 270 experiments to profile and compare how each reacted to a simple motion event. We also propose and explore a few sample metrics useful in selecting solar harvesters as sensors and discuss their potential impact on different applications.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {925–927},
numpages = {3},
keywords = {batteryless, energy as data, energy harvesting, multipurpose harvester, signal processing},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568105,
author = {Wymore, Mathew L. and Duwe, Henry},
title = {A Tale of Two Intermittencies},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568105},
doi = {10.1145/3560905.3568105},
abstract = {Two classes of intermittency have emerged in the batteryless intermittent research community: hard intermittency and soft inter-mittency. While conceptually similar, these two intermittencies represent very different approaches to the intermittency problem. In this position paper, we examine these two intermittencies in detail. We discuss the tradeoffs and evaluate the performance potential of the two intermittencies in the context of communication between intermittent nodes. Finally, we conclude that both types of intermittency have merits under different conditions and application requirements, and we argue for greater understanding of how these two disparate classes of intermittencies may interact and coexist within a single network.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {928–930},
numpages = {3},
keywords = {batteryless, communication, energy-harvesting, intermittency},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568106,
author = {Arora, Nivedita and Iyer, Vikram and Oh, Hyunjoo and Abowd, Gregory D. and Hester, Josiah D.},
title = {Circularity in Energy Harvesting Computational "Things"},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568106},
doi = {10.1145/3560905.3568106},
abstract = {We have witnessed explosive growth in computing devices at all scales, in particular with small wireless devices that can permeate most of our physical world. The IoT industry is helping to fuel this insatiable desire for more and more data. We have to balance this growth with an understanding of its environmental impact. Indeed, the ENSsys community must take leadership in putting sustainability up front as a primary design principle for the future of IoT and related areas, expanding the research mandate beyond the intricacies of the computing systems in isolation to encompass and integrate the materials, new applications, and circular lifecycle of electronics in the IoT. Our call to action is seeded with a circularity-focused computing agenda that demands a cross-stack research program for energy-harvesting computational things.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {931–933},
numpages = {3},
keywords = {circular electronics, intermittent computing, recycle, sustainability, sustainable HCI, transient electronics, upcycle},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568300,
author = {Moss, Arthur and Lee, Hyunjong and Xun, Lei and Min, Chulhong and Kawsar, Fahim and Montanari, Alessandro},
title = {Ultra-Low Power DNN Accelerators for IoT: Resource Characterization of the MAX78000},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568300},
doi = {10.1145/3560905.3568300},
abstract = {The development of edge devices with dedicated hardware accelerators has pushed the deployment and inference of Deep Neural Network (DNN) models closer to users and real-world sensory systems than ever before (e.g., wearables, IoT). Recently, a further subset of these devices has emerged: ultra-low power DNN accelerators. These microcontrollers possess a dedicated hardware accelerator and are able to operate with only μJ's of energy in milliseconds of time. With their small form-factor, such devices could be used for battery-powered machine learning (ML) applications. In this work, we take a close look at one such device: the MAX78000 by Maxim Integrated. We characterize the device's performance by running five DNN models of various sizes and architectures, and analyze its operational latency, power consumption, and memory footprint. To better understand the performance characteristics, we take a step further and investigate how different layer types (operation type, kernel size, number of input and output channels) and the selection of accelerator processors affect the execution time.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {934–940},
numpages = {7},
keywords = {edge accelerators, neural networks, resource characterisation},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568296,
author = {Qian, Chao and Einhaus, Lukas and Schiele, Gregor},
title = {ElasticAI-Creator: Optimizing Neural Networks for Time-Series-Analysis for on-Device Machine Learning in IoT Systems},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568296},
doi = {10.1145/3560905.3568296},
abstract = {Deep learning (DL) is quickly becoming a core technology to process sensor data from IoT devices. Nowadays, data is usually sent to remote Cloud services where GPU-based ML platforms process it. In contrast, our vision is to have IoT devices with local, on-device DL. This can increase privacy and accessibility as well as reduce processing costs. To do so, specialized hardware accelerators are needed to perform ML operations efficiently without high performance CPUs. In this paper we introduce our approach for a generator for ML hardware accelerators in the IoT. We focus specifically on the inference of ML algorithms for a typical class of IoT use cases, i.e., processing time-series data under real-time constraints. Additionally our optimization techniques rely on the co-design of hardware and ML algorithms to explore the most specialized and efficient corners of the design space. In this work we analyze the requirements for our generator, discuss optimization stages and techniques and show a case study based on an LSTM model for traffic flow prediction.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {941–946},
numpages = {6},
keywords = {IoT, code generator, embedded FPGA, energy-efficiency, machine learning},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568298,
author = {Katsidimas, Ioannis and Kotzakolios, Thanasis and Nikoletseas, Sotiris and Panagiotou, Stefanos H. and Tsakonas, Constantinos},
title = {Smart Objects: Impact Localization Powered by TinyML},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568298},
doi = {10.1145/3560905.3568298},
abstract = {Growing momentum in embedded systems and the wide use of sensors in everyday life, have motivated significantly, novel research in Internet of Things (IoT) systems and on-device Machine Learning (TinyML) processing. However, limitations in the energy stock and the computational capabilities of resource-scarce devices prevent the implementation of complex ML algorithms in IoT devices, which typically have limited computing power, small memory, and generate large amounts of data. This paper, aims to research and exploit the TinyML emerging technology for embedding intelligence in low-power devices, towards next generation IoT paradigm and smart sensing, in the context of SHM. In particular, the purpose is to provide integrated SHM functionality in plastic structures and thus make them "conscious" and self-explanatory (smart objects), by being able to localize any occurring impacts on the structure. We implement and benchmark Random Forest and Shallow Neural Network models on Arduino NANO 33 BLE, using an experimental dataset of piezoelectric sensor measurements concerning impact events in a thin plastic plate. The classification and model footprint results, 98.71\% - 8KB and 95.35\% - 12KB of accuracy and flash memory size for each model respectively, are very promising and constitute a solid baseline for motivating our concept.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {947–953},
numpages = {7},
keywords = {TinyML, extreme edge, intelligent IoT, piezoelectric transducers, structural health monitoring},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568299,
author = {Hussain, Hanan and Tamizharasan, P. S},
title = {The Impact of Cascaded Optimizations in CNN Models and End-Device Deployment},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568299},
doi = {10.1145/3560905.3568299},
abstract = {Optimization techniques are vital in deploying CNN models to resource-constrained devices like IoT or handheld devices. The classic optimization techniques like quantization, pruning, and clustering have proved their impact on model compression by trading off the overall accuracy. However, the performance of cascaded optimizations like (i) sparsity preserving clustering (PC), (ii) sparsity preserving quantization (PQ), (iii) cluster preserving quantization (CQ), and (iv) sparsity and cluster preserving quantization (PCQ) techniques remain unexplored. This paper studies the inference efficiency of CNN models when optimization techniques are performed in a cascaded way and individually. The feasibility of the optimization techniques was tested on both NVIDIA GTX1650 GPU and Raspberry pi-4 by considering five factors: performance metrics like (a) inference latency and (b) accuracy and (c) computational complexity of the model, resource utilization metrics like (d) energy consumption during the inference and (e) memory requirement to store the model. The results show that among all the models generated from the optimized techniques, the fully cascaded (PCQ) outperforms in terms of accuracy, latency and memory requirement metrics.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {954–961},
numpages = {8},
keywords = {GPU and performance metrics, convolution neural network, efficient models, optimization techniques, raspberry Pi},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568297,
author = {Pasandi, Hannaneh B. and Pasandi, Haniyeh B.},
title = {Evaluation of ASR Systems for Conversational Speech: A Linguistic Perspective},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568297},
doi = {10.1145/3560905.3568297},
abstract = {Automatic speech recognition (ASR) meets more informal and free-form input data as voice user interfaces and conversational agents such as the voice assistants such as Alexa, Google Home, etc., gain popularity. Conversational speech is both the most difficult and environmentally relevant sort of data for speech recognition. In this paper, we take a linguistic perspective, and take the French language as a case study toward disambiguation of the French homophones. Our contribution aims to provide more insight into human speech transcription accuracy in conditions to reproduce those of state-of-the-art ASR systems, although in a much focused situation. We investigate a case study involving the most common errors encountered in the automatic transcription of French language.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {962–965},
numpages = {4},
keywords = {ASR systems, homophones, natural language processing, voice assistant},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568304,
author = {Hu, Zhizhang and Yu, Tong and Zhang, Ruiyi and Pan, Shijia},
title = {CIPhy: Causal Intervention with Physical Confounder from IoT Sensor Data for Robust Occupant Information Inference},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568304},
doi = {10.1145/3560905.3568304},
abstract = {Occupant information inference with IoT sensor data enables many smart applications, such as patients'/older adults' in-home monitoring. The difficulty of collecting labeled real-world IoT sensor data often leads to reliability and scalability issues for those systems. Extensive prior works (e.g., domain adaptation) focus on the domain shift issues, i.e., the inconsistent data feature and label relationship, and dataset bias is often neglected. Dataset bias is commonly caused by limited and varied accessibility to labeled data for each class, and it is inevitable for real-world datasets. The model trained with a biased dataset fits into the bias, hence cannot further generalize to the testing data for accurate inference.We propose CIPhy, a causal intervention scheme with physical confounders measured from the sensor data to achieve robust occupant information inference. We model the dataset bias as a confounding problem. There exists a confounder directly impacts both data feature and label, and each class's accessibility to labeled data varies when the confounder's condition changes. The model trained with biased data learns a spurious feature-label correlation conditioned on the confounder's condition in the training data. When testing data has a different condition, i.e., confounding shift, this correlation can not be applied. By using the causal intervention, e.g., backdoor adjustment, the confounding shift's negative impact on the data-driven models can be mitigated. The CIPhy decouples the sensor data to measure the confounder, then conducts the causal intervention for a de-biased occupant information inference. We use a public dataset on occupant identification as a case study, to investigate the feasibility of applying causal intervention to resolve the dataset bias issue. From the experiment, CIPhy achieves up to 11.42\% identification accuracy improvement compared to baselines given the biased training data and confounding shift.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {966–972},
numpages = {7},
keywords = {causal intervention, dataset bias, occupant information inference},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568303,
author = {Pattnaik, Naibedya and Vemula, Uday Sai and Kumar, Kriti and Kumar, A. Anil and Majumdar, Angshul and Chandra, M. Girish and Pal, Arpan},
title = {CycleGAN Based Unsupervised Domain Adaptation for Machine Fault Diagnosis},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568303},
doi = {10.1145/3560905.3568303},
abstract = {Fault diagnosis plays a vital role in ensuring the normal operation of the machine and safe production. In recent years, data-driven techniques have gained a lot of popularity for machine fault diagnosis. But most of these techniques assume the training and test data have the same distribution. However, in most practical application scenarios, domain discrepancy can be observed between the training (source) and test (target) data due to different factors like changes in the operating conditions, different sensor locations, etc. Classical approaches fail to address such domain discrepancy, which leads to poor performance. The problem becomes more challenging when the target is completely unlabeled. To address this scenario, domain adaptation techniques are used to transfer the knowledge learned from the labeled source domain to the unlabeled target domain. Recently, adversarial network based domain adaptation has been extensively explored for fault diagnosis. But the adversarial loss alone does not guarantee the translation of the source to the desired target domain (class consistent). Here, we propose to use cycle-consistency loss employing 1D-CycleGAN for learning the source to target mapping for unsupervised adaptation for bearing fault diagnosis. The proposed method is evaluated for two different scenarios, with the source and target from (i) same machine but different working conditions and (ii) different but related machines. Experimental results show that while the proposed method performs comparable to the best-performing benchmark for the first case, it significantly outperforms all the state-of-the-art methods for the challenging second case.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {973–979},
numpages = {7},
keywords = {CycleGAN, domain adaptation, machine fault diagnosis, unsupervised learning},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568305,
author = {Selialia, Khotso and Chandio, Yasra and Anwar, Fatima M.},
title = {Federated Learning Biases in Heterogeneous Edge-Devices: A Case-Study},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568305},
doi = {10.1145/3560905.3568305},
abstract = {Critical machine learning applications (medical image guidance, task prediction, anomaly detection) require large amounts of data that could not be sufficiently supplied from a single entity, so multiple edge devices collaboratively train their collected data. But this raises privacy and overhead concerns. Federated learning (FL) can be a promising solution to enable these applications while preserving data privacy and mitigating communication overhead. However, an FL model originating from edge deployments with heterogeneous resources may be biased towards a set of devices. We observe that existing bias mitigation techniques in FL focus mainly on the bias that originates from label heterogeneity (due to the skewed distribution of data). We argue that sample feature heterogeneity due to different feature representations at devices is a major contributor to bias in FL. In this paper, we present an analysis of the bias that arises from sampling feature heterogeneity, and analyze the potential of existing performance enhancing techniques (normalization) to overcome bias. Our results demonstrate that normalization techniques do not eliminate bias and motivate the need for dedicated bias mitigation techniques in FL.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {980–986},
numpages = {7},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568302,
author = {Khan, Momin Ahmad and Shejwalkar, Virat and Houmansadr, Amir and Anwar, Fatima M.},
title = {Security Analysis of SplitFed Learning},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568302},
doi = {10.1145/3560905.3568302},
abstract = {Split Learning (SL) and Federated Learning (FL) are two prominent distributed collaborative learning techniques that maintain data privacy by allowing clients to never share their private data with other clients and servers, and find extensive IoT applications in smart healthcare, smart cities and smart industry. Prior work has extensively explored the security vulnerabilities of FL in the form of poisoning attacks. To mitigate the effect of these attacks, several defenses have also been proposed. Recently, a hybrid of both learning techniques has emerged (commonly known as SplitFed) that capitalizes on their advantages (fast training) and eliminates their intrinsic disadvantages (centralized model updates).In this paper, we perform the first empirical analysis of SplitFed's robustness to strong model poisoning attacks. We observe that the model updates in SplitFed have significantly smaller dimensionality as compared to FL that is known to have curse of dimensionality. We show that large models that have higher dimensionality are more susceptible to privacy and security attacks, whereas the clients in SplitFed do not have the complete model and have lower dimensionality, making them more robust to existing model poisoning attacks. Our results show that the accuracy reduction due to the model poisoning attack is 5x lower for SplitFed compared to FL.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {987–993},
numpages = {7},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568301,
author = {William, Jannik and Santos, Matuzal\'{e}m Muller dos and de Brito, Maiquel and H\"{u}bner, Jomi Fred and Vachtsevanou, Danai and Gomez, Andres},
title = {Increasing the Intelligence of Low-Power Sensors with Autonomous Agents},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568301},
doi = {10.1145/3560905.3568301},
abstract = {Low-power sensors are becoming ever more powerful, increasing both their energy efficiency as well as their processing capabilities. Much work in recent years has focused on optimizing machine learning models to low-power systems, typically to locally process sensor data. Significantly less attention has been paid to other artificial intelligence fields such as knowledge representation and automated reasoning, which may contribute to building autonomous devices. In this work, we present a low-power sensor node with an autonomous belief-desire-intention agent. This kind of agent simplifies the implementation of both proactive and reactive behaviors, promoting autonomy in our target applications. It does so by locally perceiving and reasoning, and then wirelessly broadcasting an intention, which can be forwarded to an actuator. The capabilities of the autonomous agent are demonstrated with a light-control application. Experiments demonstrate the feasibility of running intelligent agents in low-power platforms with little overhead.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {994–999},
numpages = {6},
keywords = {autonomous agents, low-power systems, reasoning systems},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3578264,
author = {Chung, Ming-Kuang and Ching, Fu-Shiang and Chen, Ling-Jyh},
title = {From Participatory Sensing to Public-Private Partnership: The Development of AirBox Project in Taiwan},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3578264},
doi = {10.1145/3560905.3578264},
abstract = {A complete sensor network should include sensors, data processing, and data services. However, to establish the legitimacy of sensor data for urban governance, sensor networks should go beyond simple deployment of sensors in the built environment and strive for deeper integration of data services within civil society. This paper presents the Taiwan AirBox Project as an exemplary case of practical deployment of a sensor network to discuss the topics of open data, value-added services, and joint calibration services; as well as how these services generate productive public-private partnerships.The AirBox project adopted a strategy of combining open-source hardware, flexible database API, multiple value-added data services, and open-joint calibration to gradually enhance the data quality. The results suggested that: 1. open hardware and open source software are keys to expanding the deployment of the sensor network; 2. open data and diverse value-added services enhance the public's environmental awareness and advocacy; 3. the open joint-calibration system helps connect government policy formulation with public environmental awareness.In addition, the AirBox project demonstrates the feasibility of a democratized deployment strategy. "Openness" serves as the foundation for mutual trust, communication, cooperation, and co-creation among stakeholders involved in the deployment process.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1000–1006},
numpages = {7},
keywords = {AirBox, open joint-calibration system, participatory sensing, sensor network deployment},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567772,
author = {Ling, Neiwen and He, Yuze and Guan, Nan and Fu, Heming and Xing, Guoliang},
title = {An Indoor Smart Traffic Dataset and Data Collection System: Dataset},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567772},
doi = {10.1145/3560905.3567772},
abstract = {Smart traffic is an emerging research area gaining more attention due to a class of emerging applications such as autonomous driving. Most smart traffic scenarios are outdoors, which are hard to collect traffic data and build demanding sensing systems. In this work, an indoor smart traffic testbed with an F1TENTH autonomous driving vehicle is built, allowing the collection of traffic datasets under different scenarios and performing various smart traffic tasks. This novel data collection system and collected dataset can help research teams build various smart traffic systems and evaluate indoor smart traffic datasets. The collected traffic light dataset is publicly available at the link1.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1007–1010},
numpages = {4},
keywords = {F1TENTH, autonomous driving, dataset, smart traffic},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567771,
author = {Teo, Yi Ting and Quintana, Matias and Sabarudin, Muhammad Zikry Bin and Tan, Charlene and Chong, Adrian and Miller, Clayton},
title = {Green Mark Certified Buildings Metadata from Singapore: Dataset},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567771},
doi = {10.1145/3560905.3567771},
abstract = {In many countries, there are local efforts and incentives to further increase the adoption of greener buildings. This highlights the critical need for buildings to be green and for tools to facilitate their transformation for new and existing building owners. Thus, this work curates a dataset regarding the actions and features implemented by building stakeholders to attain the Green Mark (GM) certification which promotes the adoption of numerous green building technologies. Public data from 3,583 entries over 17 years was extracted and pre-processed. Green features of each certified entry were identified and labeled accordingly using a list of keywords created from the GM certification assessment criteria. We present an overview of the dataset and key insights into the building retrofitting landscape. The dataset is available at https://zenodo.org/record/7198276},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1011–1013},
numpages = {3},
keywords = {energy-efficient, green features, primary space usage, retrofitting},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567763,
author = {Chandio, Yasra and Bashir, Noman and Anwar, Fatima M.},
title = {HoloSet - A Dataset for Visual-Inertial Pose Estimation in Extended Reality: Dataset},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567763},
doi = {10.1145/3560905.3567763},
abstract = {There is a lack of datasets for visual-inertial odometry applications in Extended Reality (XR). To the best of our knowledge, there is no dataset available that is captured from an XR headset with a human as a carrier. To bridge this gap, we present a novel pose estimation dataset --- called HoloSet --- collected using Microsoft Hololens 2, which is a state-of-the-art head mounted device for XR. Potential applications for HoloSet include visual-inertial odometry, simultaneous localization and mapping (SLAM), and additional applications in XR that leverage visual-inertial data.HoloSet captures both macro and micro movements. For macro movements, the dataset consists of more than 66,000 samples of visual, inertial, and depth camera data in a variety of environments (indoor, outdoor) and scene setups (trails, suburbs, downtown) under multiple user action scenarios (walk, jog). For micro movements, the dataset consists of more than 12,000 samples of additional articulated hand depth camera images while a user plays games that exercise fine motor skills and hand-eye coordination. We present basic visualizations and high-level statistics of the data and outline the potential research use cases for HoloSet.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1014–1019},
numpages = {6},
keywords = {AR/VR, SLAM, computer vision, dataset, deep learning, extended reality, hololens, navigation, odometry, tracking},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567764,
author = {Katsidimas, Ioannis and Kotzakolios, Thanasis and Nikoletseas, Sotiris and Panagiotou, Stefanos H. and Timpilis, Konstantinos and Tsakonas, Constantinos},
title = {Impact Events for Structural Health Monitoring of a Plastic Thin Plate: Dataset},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567764},
doi = {10.1145/3560905.3567764},
abstract = {Nowadays, more and more datasets are published towards research and development of systems and models, enabling direct comparisons, continuous improvement of solutions, and researchers engagement with experimental, real life data. However, especially in the Structural Health Monitoring (SHM) domain, there are plenty of cases where new research projects have a unique combination of structure design and implementation, sensor selection and technological enablers that does not fit with the configuration of relevant individual studies in the literature. Thus, we share the data from our case study to the research community as we did not find any relevant repository available. More specifically, in this paper, we present a novel time-series dataset for impact detection and localization on a plastic thin-plate, towards Structural Health Monitoring applications, using ceramic piezoelectric transducers (PZTs) connected to an Internet of Things (IoT) device. The dataset was collected from an experimental procedure of low-velocity, low-energy impact events that includes at least 3 repetitions for each unique experiment, while the input measurements come from 4 PZT sensors placed at the corners of the plate. For each repetition and sensor, 5000 values are stored with 100 KHz sampling rate. The system is excited with a steel ball, and the height from which it is released varies from 10 cm to 20 cm. The dataset is available in GitHub (https://github.com/Smart-Objects/Impact-Events-Dataset).},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1020–1025},
numpages = {6},
keywords = {PZT sensor data, dataset, impact events, microcontroller, structural health monitoring, thin plate},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567761,
author = {Garrido-Hidalgo, Celia and F\"{u}rst, Jonathan and Cheng, Bin and Roda-Sanchez, Luis and Olivares, Teresa and Kovacs, Ern\"{o}},
title = {Interlinking the Brick Schema with Building Domain Ontologies},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567761},
doi = {10.1145/3560905.3567761},
abstract = {In the building context, there is a growing requirement for numerous data models and ontologies to coexist as a means to cover different perspectives and communities. While there are some well-known efforts, such as the Brick schema, to create an overall usable ontology, interlinking available ontologies and data models is still a challenge that can provide significant benefits towards interoperability of Building Information Models. To shed light on this matter, we provide a review of some of the most important ontologies in the building context, which we then match against Brick as a means to provide an interlinked data model. For finding matches, we propose TrioNet, an interactive ontology matcher utilizing weak supervision and active learning, which we compare in terms of precision and recall with two well-known state-of-the-art ontology matchers: AgreementMakerLight (AML) and LogMap. TrioNet outperforms them in finding more verified matches with only a few domain expert annotations, making it an ideal tool for the creation of interlinked data models to improve interoperability. With this paper, we contribute the following datasets: (i) the overall Brick data model interlinked to five other ontologies; (ii) the discovered pairwise ontology alignments; and (iii) the manually-annotated matches used for evaluation.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1026–1030},
numpages = {5},
keywords = {building, dataset, interactive matching, ontology matching},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567773,
author = {Saoda, Nurani and Billah, Md Fazlay Rabbi Masum and Sobral, Victor Ariel Leal and Campbell, Bradford},
title = {SolarWalk Dataset: Occupant Identification Using Indoor Photovoltaic Harvester Output Voltage},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567773},
doi = {10.1145/3560905.3567773},
abstract = {Occupant identification is paramount for many building applications. Regardless, several practical concerns limit existing solutions to be ubiquitously deployed. Current systems are either intrusive, privacy-invasive, or require obtrusive, maintenance-heavy, and special-purpose infrastructure. As an alternative, the shadow pattern of a person reflected in the output voltage of a photovoltaic harvester power supply in many energy-harvesting devices can be used as a unique person identifying feature. In this paper, we present the first dataset containing the time-series open circuit output voltage traces of indoor photovoltaic cell corresponding to occupant door crossing events to perform occupant identification in smart homes. We collect shadow patterns of five participants from two different doors in two rooms of a building. The dataset consists of a total of 900 door entry and exit events during different hours of the day. We sample the voltage at 50 hz and provide the raw timestamped data. We also pre-process the data to filter the event of interest and label the data with associated occupant id and type of door events. Moreover, we provide insights into future research directions using the dataset. The dataset is available at https://doi.org/10.5281/zenodo.7195748},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1031–1034},
numpages = {4},
keywords = {occupant identification, photovoltaic harvesters},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567766,
author = {Zachariah, Thomas and Klugman, Noah and Dutta, Prabal},
title = {ThingSpeak in the Wild: Exploring 38K Visualizations of IoT Data},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567766},
doi = {10.1145/3560905.3567766},
abstract = {Cloud services are vital tools for storing, analyzing, and responding to data collected by sensors in the Internet of Things (IoT). With ThingSpeak, a popular web platform that provides these services, users can easily create cloud "channels" to receive, host, and visualize sensor data. In this study, we scrape public channels from 6,511 users to construct a comprehensive picture of both the ThingSpeak developer community and their applications. We release this data to support future work. From this data, we examine 37,989 visualizations and uncover relationships between application domains and visualization techniques utilized. Further, we investigate how ThingSpeak's interface impacts user design choices. To learn which channels most successfully disseminate information, we explore design patterns on channels "liked" on Facebook or discussed in ThingSpeak forums. Finally, we briefly comment on how services like ThingSpeak can better support users' needs moving forward.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1035–1040},
numpages = {6},
keywords = {PaaS, analysis, cloud, dataset, internet of things, visualization},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567770,
author = {Fang, Shiwei and Sarker, Ankur and Wang, Ziqi and Srivastava, Mani and Marlin, Benjamin and Ganesan, Deepak},
title = {Design and Deployment of a Multi-Modal Multi-Node Sensor Data Collection Platform},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567770},
doi = {10.1145/3560905.3567770},
abstract = {Sensing and data collection platforms are the crucial components of high-quality datasets that can fuel advancements in research. However, such platforms usually are ad-hoc designs and are limited in sensor modalities. In this paper, we discuss our experience designing and deploying a multi-modal multi-node sensor data collection platform that can be utilized for various data collection tasks. The main goal of this platform is to create a modality-rich data collection platform suitable for Internet of Things (IoT) applications with easy reproducibility and deployment, which can accelerate data collection and downstream research tasks.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1041–1046},
numpages = {6},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567759,
author = {Saganowski, Stanis\l{}aw and Miszczyk, Jan and Kunc, Dominika and Lisouski, Dzmitry and Kazienko, Przemys\l{}aw},
title = {Lessons Learned from Developing Emotion Recognition System for Everyday Life},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567759},
doi = {10.1145/3560905.3567759},
abstract = {Recognizing emotions in everyday life requires a user-friendly and reliable system based on a smartphone and wearables. For over a year, we have been developing the Emognition system, which enables collecting emotionally annotated physiological signals in real-life scenarios. In this work, we describe the system architecture, the components and libraries used, as well as the development, testing, and implementation strategies. We explain in detail the integration with wearables - smartwatch Samsung Galaxy Watch 3 and chest strap Polar H10. The encountered problems and developed solutions are thoroughly discussed. We also provide the advantages and limitations of several frameworks for embedding machine learning models into a resource-restricted mobile application.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1047–1054},
numpages = {8},
keywords = {emognition system, emotional data, emotionally annotated physiology, wearables},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567768,
author = {Yuan, Shiji and Sun, Ying and Wang, Shuai and Chen, Xinlei and Ding, Ying and Zheng, Dezhi and Fan, Shangchun},
title = {Non-Acoustic Speech Sensing System Based on Flexible Piezoelectric},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567768},
doi = {10.1145/3560905.3567768},
abstract = {Speech is one of the most important biological signals to complement human-human and human-computer interaction. Traditional speech datasets were collected by air microphones, but using these datasets in noisy environments such as factories is practically challenging. Therefore, speech recognition in noisy environments poses higher requirements. The non-acoustic speech dataset plays a significant role in robust speech recognition under high background noise. Existing datasets suffered from dull sound, low intelligibility and poor recognition accuracy due to hardware and computer technology limitations. This paper presents a non-acoustic speech sensing system based on flexible piezoelectric. The system collected vibration signals from the jaws of six males and five females, and the corpus contained ten different control commands at 90 dB of background noise. The dataset is reliable with high intelligibility and capable of achieving 93.7\% recognition accuracy by calculation. With the aforementioned benefits, this dataset is an essential tool for studying human-computer interaction in high-noise environments, analyzing human acoustic properties, and aiding medical rehabilitation.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1055–1060},
numpages = {6},
keywords = {flexible piezoelectric sensor, non-acoustic speech, speech command data},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567767,
author = {Jung, Hyunwoo and Kim, Wootack and Seo, Hyuna and Lee, Youngki},
title = {Simultaneous Sporadic Sensor Anomaly Detection for Smart Homes},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567767},
doi = {10.1145/3560905.3567767},
abstract = {Dissemination of sensors and advances in techniques (e.g., network) has led to the opportunity for smart home. However, sensor malfunctions and difficult-to-diagnose characteristics hinder robust sensor system operation. Sensor anomaly detection systems for smart home have been proposed, but they target only a few specific types of sensor anomalies of a single sensor. In this work, we propose a sensor anomaly detection method based on Deep Neural Network (DNN), which automatically extracts critical features to detect the anomalies, even for simultaneous sporadic anomalies with complex data patterns. We leverage Hypersphere Classification (HSC) [14], the state-of-the-art DNN-based supervised outlier exposure method. We evaluate our proposed method on a public smart home sensor dataset. Our results show that the performances of the baselines drop up to 54.4\% while ours drops up to 1.1\%.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1061–1066},
numpages = {6},
keywords = {anomaly detection, deep learning, smart home, unsupervised outlier exposure},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567760,
author = {Leprince, Julien and Miller, Clayton and Madsen, Henrik and Basu, Kaustav and van der Vlist, Rik and Zeiler, Wim},
title = {Grey-Brick Buildings, an Open Data Set of Calibrated RC Models of Dutch Residential Building Heat Dynamics},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567760},
doi = {10.1145/3560905.3567760},
abstract = {Building thermal modeling is the founding stone upon which numerous carbon reduction strategies in the building sector are built. Yet, as of today, little to no interpretable and calibrated models founded on real-world measurements have been open-sourced. This work attempts to remedy this deficiency and renders public improved results of a recently published stochastic model identification of building heat dynamics study evaluated over 225 Dutch residential buildings. Calibrated lumped resistance-capacity models are made available, along with thermal characterizations of the buildings and reported meta-data. The paper discusses how open-access building thermal models support a collection of building service applications such as building performance benchmarks, model-based control, demand-side management, policy impact assessment, and data augmentation. Insights provided present a starting point for open access benchmarks of building thermal dynamics, paving the way toward new scientific discoveries from common standards.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1067–1071},
numpages = {5},
keywords = {buildings, demand-side management, grey-box modeling, heat dynamics, open data, performance benchmark},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567765,
author = {Tran, Vinh Q. C. and Le, Duc V. and Yntema, Doekle R. and Havinga, Paul J. M.},
title = {Testbed Hardware Design to Collect Data for Underground PVC Water Pipe Crack Detection: Challenges and Solutions},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567765},
doi = {10.1145/3560905.3567765},
abstract = {A premature crack is a significant indicator for early failure detection for underground polyvinyl chloride (PVC) water pipes. Using an array of strain gauges mounted on a pipe surface to monitor the strain of adjacent areas of a premature crack is a novel technology that has not been explored. To reduce the risks and up-front investments, we need a testbed to investigate, verify, and validate the innovative technology. However, establishing such a pipe monitoring testbed that covers completely realistic underground situations is challenging. The main reason lies in three main challenges: (i) mimicking the natural changes of water flowing in pipes; (ii) identifying the proper placement of strain gauges and detectable crack sizes; (iii) simulating the crucial underground conditions such as temperature and external stress. To this end, in this paper, we present a testbed to get more insights into the effects of different crack types on the pressure-strain characteristic in realistic conditions. In particular, we use pressure meters and water pumps to control the water flow (for challenge (i)); deploy various strain gauges types and induce cracks with different sizes (for challenge (ii)); fill the pipe with water at various temperatures and underground-like external stress (for challenge (iii)); Analyzing experimental results reveals useful hints for designing a realistic testbed, including but not limited to, the required distance among strain gauges, the influence of temperature and pipe axial stress. The dataset and analytic results of this work would provide more insights into how to design a realistic testbed for underground PVC water pipe crack detection.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1072–1076},
numpages = {5},
keywords = {pipe crack, pressure strain characteristic, strain gauge, testbed},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567769,
author = {Sun, Yifei and Liu, Yuxuan and Wang, Ziteng and Qu, Xiaolei and Zheng, Dezhi and Chen, Xinlei},
title = {C-RIDGE: Indoor CO2 Data Collection System for Large Venues Based on prior Knowledge},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567769},
doi = {10.1145/3560905.3567769},
abstract = {CO2 concentration data with high resolution in large venues is highly required during indoor sport events for in-time environment adjustment to guarantee the athlete performances and audience experience. However, the limited battery energy of the wireless sensors cannot support high data resolution and long time coverage simultaneously. Besides, there also lacks effective embedded methods to clean anomaly data caused by the human and environmental factors probably occurring in large venues. Thus, in this paper, we propose C-RIDGE, a low-power sensing system for high resolution CO2 data collection in large venues. Based on prior knowledge, firstly, an adaptive sampling rate adjustment policy is developed for lower energy consumption to extend the time coverage of data. Secondly, CO2 physical property (CPP) aided data cleaning algorithm is designed to improve data quality as well, using Pearson Correlation Coefficient (PCC) and standard deviation with sliding windows. C-RIDGE has been deployed in one venue during a world-class event. The experiments and collected data have shown the system power consumption can be reduced by 36.1\%, with measurement error less than 10.2\%. The outliers and anomaly trends can also be detected and calibrated effectively via CPP algorithm. The dataset is available at https://doi.org/10.5281/zenodo.7160830.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1077–1082},
numpages = {6},
keywords = {CO2 sensing, data analysis, data collection, low power system},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3567762,
author = {Tawakuli, Amal and Kaiser, Daniel and Engel, Thomas},
title = {Transforming IoT Data Preprocessing: A Holistic, Normalized and Distributed Approach},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3567762},
doi = {10.1145/3560905.3567762},
abstract = {Data preprocessing is an integral part of Artificial Intelligence (AI) pipelines. It transforms raw data into input data that fulfill algorithmic criteria and improve prediction accuracy. As the adoption of Internet of Things (IoT) gains more momentum, the data volume generated from the edge is exponentially increasing that far exceeds any expansion of infrastructure. Social responsibilities and regulations (e.g., GDPR) must also be adhered when handling IoT data. In addition, we are currently witnessing a shift towards distributing AI to the edge. The aforementioned reasons render the distribution of data preprocessing to the edge an urgent requirement. In this paper, we introduce a modern data preprocessing framework that consists of two main parts. Part1 is a design tool that reduces the complexity and costs of the data preprocessing phase for AI via generalization and normalization. The design tool is a standard template that maps specific techniques into abstract categories and highlights dependencies between them. In addition, it presents a holistic notion of data preprocessing that is not limited to data cleaning. The second part is an IoT tool that adopts the edge-cloud collaboration model to progressively improve the quality of the data. It includes a synchronization mechanism that ensures adaptation to changes in data characteristics and a coordination mechanism that ensures correct and complete execution of preprocessing plans between the cloud and the edge. The paper includes an empirical analysis of the framework using a developed prototype and an automotive use-case. Our results demonstrate reductions in resource consumption (e.g., energy, bandwidth) while maintaining the value and integrity of the data.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1083–1088},
numpages = {6},
keywords = {IoT, data cleaning, data preprocessing, data quality, edge-cloud collaborative systems},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568414,
author = {Boubin, Jayson and Zhang, Zichen and Chumley, John and Stewart, Christopher},
title = {Adaptive Deployment for Autonomous Agricultural UAV Swarms},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568414},
doi = {10.1145/3560905.3568414},
abstract = {Unmanned aerial vehicles (UAV) play a critical role in many edge computing deployments and applications. UAV are prized for their maneuverability, low cost, and sensing capacity, facilitating many applications that would otherwise be prohibitively expensive or dangerous without them. UAV are cheaper than alternative aerial analysis methods, but still incur costs from expensive human piloting and workloads which necessitate high-resolution coverage of large areas. Recently, autonomous UAV swarms have emerged to increase the speed of deployments, decrease the cost and scope of human piloting, and improve the quality of autonomous decision-making through data sharing. Autonomous UAV deployments, however, suffer from external factors. UAV are inherently power-constrained, with low onboard battery lives and limited ability to siphon power from the edge systems that support them. Certain environmental conditions, like inclement weather, wind, extreme heat, and low light also affect UAV power consumption, sensed data quality, and ultimately mission success. In this paper, we present an empirically based model for efficient autonomous swarm deployment. We built and deployed a real autonomous UAV swarm to map leaf defoliation in soybeans. Using this deployment, we determined environmental conditions which led to malfunctions, inefficient edge energy usage, and mispredictions. Using these findings, we developed a deployment model for UAV swarms that decreases malfunctions and data irregularities by 4.9X and decreases edge energy consumption by 45\%, while increasing deployment times by only 4\%.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1089–1095},
numpages = {7},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568415,
author = {Zhang, Yue and Benitez, Abdias Tellez and Ehsani, Reza and Pan, Shijia},
title = {DaQual: Data Quality Assessment for Tree Trunk Relative Water Content Sensors in a Pomegranate Orchard},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568415},
doi = {10.1145/3560905.3568415},
abstract = {High-fidelity sensor data quality is the fundamental base of smart agriculture. Since crop information inference and cultivating strategy optimization mainly depend on data-driven methods; the data quality assessment is essential to ensure the reliability of the IoT systems for smart agriculture. The traditional data quality assessment methods focus on sensor data consistency with the costly reference truth, which is often not scalable for agricultural applications.We present DaQual, a data-driven data quality assessment scheme for tree trunk relative water content sensors in a pomegranate orchard. The objective is to leverage the neural network architecture to learn the underlying relationship between sensors deployed on the same farm and utilize the quantified associated relationship between sensors to assess its reliability. DaQual first builds a prediction model for each sensor with all other sensors' data as input. Then, the trained network's parameter values (weights) are used to quantify the contribution of the sensor - the higher the contribution, the higher its data quality. We evaluate DaQual via a real-world tree trunk relative water content sensor dataset with nine sensors deployed in a pomegranate orchard, and our scheme demonstrates up to 1.8\texttimes{} improvements when used to select a subset of sensors with high data quality.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1096–1101},
numpages = {6},
keywords = {data quality, quality assessment, smart agriculture},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568416,
author = {Dong, Yiwen and Codling, Jesse R and Rohrer, Gary and Miles, Jeremy and Sharma, Sudhendu and Brown-Brandl, Tami and Zhang, Pei and Noh, Hae Young},
title = {PigV2: Monitoring Pig Vital Signs through Ground Vibrations Induced by Heartbeat and Respiration},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568416},
doi = {10.1145/3560905.3568416},
abstract = {Pig vital sign monitoring (e.g., estimating the heart rate (HR) and respiratory rate (RR)) is essential to understand the stress level of the sow and detect the onset of parturition. It helps to maximize peri-natal survival and improve animal well-being in swine production. The existing approach mainly relies on manual measurement, which is labor-intensive and only provides a few points of information. Other sensing modalities such as wearables and cameras are developed to enable more continuous measurement, but are still limited due to animal discomfort, data transfer, and storage challenges. In this paper, we introduce PigV2, the first system to monitor pig heart rate and respiratory rate through ground vibrations. Our approach leverages the insight that both heartbeat and respiration generate ground vibrations when the sow is lying on the floor. We infer vital information by sensing and analyzing these vibrations. The main challenge in developing PigV2 is the overlap of vital- and non-vital-related information in the vibration signals, including pig movements, pig postures, pig-to-sensor distances, and so on. To address this issue, we first characterize their effects, extract their current status, and then reduce their impact by adaptively interpolating vital rates over multiple sensors. PigV2 is evaluated through a real-world deployment with 30 pigs. It has 3.4\% and 8.3\% average errors in monitoring the HR and RR of the sows, respectively.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1102–1108},
numpages = {7},
keywords = {heart rate, pig, precision livestock farming, respiratory rate, structural vibration, vital signs},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568417,
author = {Wang, Yucheng and Gu, Mengmeng and Zhou, Mingyuan and Qian, Xiaoning},
title = {Attention-Based Deep Bayesian Counting For AI-Augmented Agriculture},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568417},
doi = {10.1145/3560905.3568417},
abstract = {Object counting in images has been studied extensively, in particular using deep network models recently. The existing counting models typically output the point estimates of the object counts in given images. However, none of these can provide reliable uncertainty quantification of the derived count estimates, which is critical for consequent decision making when adopting these counting models in real-world applications. In this paper, we propose a novel deep counting model in a Bayesian framework. With the designed Bayesian attention module and Bayesian counting loss function, our deep Bayesian counting model not only improves the accuracy of count estimates with varying object and background appearance; but also enables their uncertainty quantification. We specifically focus on plant counting, which plays important roles in AI-augmented agriculture, for example crop yield estimates and farm management. Our ablation studies and experiments with the real-world agriculture data in the Global Wheat dataset have demonstrated that our deep Bayesian counting model obtains high count estimation accuracy as well as reliable uncertainty quantification. In addition, with the integrated Bayesian attention modules, it may help improve the interpretability of the derived count estimates, especially when the distribution of the interested plants in images is heterogeneous.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1109–1115},
numpages = {7},
keywords = {bayesian attention, object counting, uncertainty quantification},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568418,
author = {Luong, Tyler and Thomas, Stewart J.},
title = {Towards the Plant-Based Sensor: Agricultural Energy Harvesting and Sensing Experiments},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568418},
doi = {10.1145/3560905.3568418},
abstract = {With an ongoing search for alternative energy sources, plants may serve as a viable means for operating low-power digital circuits. Biopotential, the electrical signals found within the body due to electrochemical activity, can be monitored and harnessed within plants and vegetables. Measuring plant biopotential, in combination with electrogenic microbial fuel cell (MFC) technology [14], suggests that a self-sufficient and micro-power generation system can be made using a microbial fuel cell in tandem with a living plant [18]. This research presents ongoing work in proposed sub-systems within this power generation system and their compatibility with low-power electronics, a project inspired from works focused on converting plants into batteries [7, 8]. The power harvesting aspect of the project consists of long deployment experiments with mud based MFCs using MudWatt kits, as well as a plant based MFC. The plant sensing aspect of the project is depending on thigmonastic reactions from the plant specie Mimosa pudica.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1116–1122},
numpages = {7},
keywords = {bioelectricity, energy harvesting, plant monitoring},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568419,
author = {Kaur, Upinder and Voyles, Richard M.},
title = {CASPER: Criticality-Aware Self-Powered Wireless in-vivo Sensing Edge for Precision Animal Agriculture},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568419},
doi = {10.1145/3560905.3568419},
abstract = {The promise of individualized care for improving animal welfare demands real-time continuous monitoring of animals. While technology has helped crop agriculture realize the goals of precision care, animal agriculture is still lacking domain-adapted technology. In this work, we present a novel Criticality-Aware Self-Powered in-vivo sensing Edge for pRecision animal agriculture, CASPER. Enabling real-time monitoring of a suite of biomarkers while scavenging power from both thermal and physiological sources, CASPER promises unprecedented adaptability, range, and life-cycle for such an edge node. Field deployments show that CASPER generates 30mW of power with a surplus of 9.08mW, during the ultra-low power mode. The criticality-aware control is proven to capture deviation in trends of biomarker activity that would be missed in fixed-interval transmission. Hence proving the validity and effectiveness of CASPER.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1123–1129},
numpages = {7},
keywords = {IoT, precision animal agriculture, self-powered, sensor, wireless edge},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568420,
author = {Saffari, Ali and Iyer, Vikram and Kapetanovic, Zerina and Ranganathan, Vaishnavi},
title = {Smart Pallets: Toward Self-Powered Pallet-Level Environmental Sensors for Food Supply Chains},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568420},
doi = {10.1145/3560905.3568420},
abstract = {This work highlights the need for a low-cost and low-overhead solution to monitor pallet-level environment in the food supply chain to create traceability, accountability and reduce wastage. We identify post-harvest sensing through the supply chain as a key need to reduce food waste. Toward this end, we develop initial prototypes of two different wireless environmental sensing architectures. The first leverages an ultra-low power timer with a current consumption of 35 nA to power gate and periodically wake up the system. The second mode explores a sparse event driven sensing model leveraging the threshold detection features of low power sensors to log events of interest. We demonstrate a millimeter scale prototypes that can read and backscatter temperature and humidity data with as little as 3.2 μW of power.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1130–1135},
numpages = {6},
keywords = {RFID, WISP, backscatter, environmental sensors, food supply chain, smart agriculture, smart pallet, wireless sensors},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568430,
author = {Zhang, Lei and Gao, Guanyu and Zhang, Huaizheng},
title = {Towards Data-Efficient Continuous Learning for Edge Video Analytics via Smart Caching},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568430},
doi = {10.1145/3560905.3568430},
abstract = {Continuous learning (CL) has recently been adopted into edge video analytics, gaining huge success in maintaining high accuracy without constantly retraining DNN models by human intervention. Though existing solutions offer optimized processing pipelines, the cost brought by CL should not be neglected. This vision paper starts an investigation by exploring two kinds of cost, human labeling and edge storage. The former comes from the need for CL's automatically tuning, and the latter is due to an exemplar pool (including both drift and historical data) maintained to prevent catastrophic forgetting caused by naive retraining. To alleviate the costs, we propose a new CL-based edge video analytics system by incorporating an active learner mechanism. Specifically, we revisit the current CL video system design and develop an active CL pipeline atop them. The pipeline first accepts the drift data stored in drift pool and utilizes an active learner to sample a small partition of them for labeling. Then it mixes up both small labeled drifted data and some historical data to send them to an exemplar pool for CL. Our preliminary benchmark studies exhibit that the new system can achieve competitive accuracy by spending only 30\% labeling and storage cost compared to other baselines, showing a promising research direction for future study.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1136–1140},
numpages = {5},
keywords = {active learning, continual learning, video analytics},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568431,
author = {Hou, James and Xu, Susu},
title = {Near-Real-Time Seismic Human Fatality Information Retrieval from Social Media with Few-Shot Large-Language Models},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568431},
doi = {10.1145/3560905.3568431},
abstract = {Real-time disaster-induced human fatality information is critical for rapid and accurate disaster impact and loss estimation and effective emergency response. Systems like PAGER incorporate online reported death tolls and loss projection models trained on significant historical earthquake events and ground shaking data to provide projected final seismic loss estimations. However, the input reported death toll data are mainly retrieved from news platforms manually, which is time-consuming and may have a large time bias. In recent years, platforms such as Facebook and Twitter have become hot spots for witness reporting and communication during disaster events, producing large volumes of immediate fatality information without the hindrances of official channels. Though lucrative, social media data is very noisy both in syntax and accuracy, necessitating robust solutions. In this work, we design and deploy a new online system that automatically extracts near-realtime multi-lingual human fatality information including death tolls and injury tolls, from a variety of information sources immediately after an earthquake occurs. Past studies have proposed to use popular machine learning methods such as SVMs, CNNs and Logistic Regression in conjunction with word embeddings to classify the relevancy of each social media message. However, these techniques suffer from impeding requirements of annotated data, which are unavailable at the onset of natural disasters, and cannot directly extract disaster information, instead relying on statistical analysis on their classification results. To address such challenges, we propose a Large Language Model-based approach that leverages its robust language understanding and few-shot learning abilities. In combination with our novel multilingual Hierarchical Event Classifier, another contribution, we achieve effective automatic earthquake casualty information retrieval from social media, which we test by deploying our framework to two recent earthquakes.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1141–1147},
numpages = {7},
keywords = {earthquake, few-shot learning, large language models, near-realtime information retrieval, rapid disaster response},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568432,
author = {Wang, Haoyang and Chen, Xuecheng and Cheng, Yuhan and Wu, Chenye and Dang, Fan and Chen, Xinlei},
title = {H-SwarmLoc: Efficient Scheduling for Localization of Heterogeneous MAV Swarm with Deep Reinforcement Learning},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568432},
doi = {10.1145/3560905.3568432},
abstract = {Emergency rescue scenarios are considered to be high-risk scenarios. Using a micro air vehicle (MAV) swarm to explore the environment can provide valuable environmental information. However, due to the absence of localization infrastructure and the limited on-board capabilities, it's challenging for the low-cost MAV swarm to maintain precise localization. In this paper, a collaborative localization system for the low-cost heterogeneous MAV swarm is proposed. This system takes full advantage of advanced MAV to effectively achieve accurate localization of the heterogeneous MAV swarm through collaboration. Subsequently, H-SwarmLoc, a reinforcement learning-based planning method is proposed to plan the advanced MAV with a non-myopic objective in real-time. The experimental results show that the localization performance of our method improves 40\% on average compared with baselines.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1148–1154},
numpages = {7},
keywords = {heterogeneous MAV swarm, localization, reinforcement learning},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568433,
author = {Bae, Andrew and Xu, Susu},
title = {Discovering and Understanding Algorithmic Biases in Autonomous Pedestrian Trajectory Predictions},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568433},
doi = {10.1145/3560905.3568433},
abstract = {Pedestrian trajectory prediction is an important module in autonomous vehicles (AVs) to ensure safe and effective motion planning. Recently, many deep learning algorithms that achieve near real-time trajectory predictions have been developed. However, people in the artificial intelligence (AI) ethics community have raised critical concerns about the bias and fairness of many general deep learning algorithms. For example, most pedestrian trajectory data is collected from majority populations, and models learned from this data may not generalize well to the heterogeneous needs and behavior patterns of different pedestrian groups, especially for vulnerable pedestrians like the disabled, the elderly, and children. Biases present in trajectory prediction algorithms could mean that pedestrians from certain vulnerable demographics are more likely to be involved in vehicle crashes. In this work, we test two state-of-the-art pedestrian trajectory prediction models for age and gender biases across three different datasets. We design and utilize novel evaluation metrics for comparing model performance. We find that both models perform worse on children and the elderly compared to adults. However, their performance is similar between men and women. We identify potential sources of these biases, as well as discuss several limitations of our study. Our future work will consist of testing more models, refining our evaluation metrics, further differentiating the dataset bias from the algorithmic bias, and mitigating the algorithmic biases.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1155–1161},
numpages = {7},
keywords = {algorithm evaluation, bias, fairness, trajectory prediction},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568434,
author = {Hui, Qianxin and Liu, Xiaolin and Li, Yang and Xu, Susu and Zhang, Shuailei and Sun, Ying and Wang, Shuai and Chen, Xinlei and Zheng, Dezhi},
title = {Riemannian Geometric Instance Filtering for Transfer Learning in Brain-Computer Interfaces},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568434},
doi = {10.1145/3560905.3568434},
abstract = {Due to the inter-subject variability of Electroencephalogram(EEG) signals, a long calibration time is required to collect a large number of labeled trials to calibrate classifier parameters before using the Brain-computer Interface(BCI). This challenge greatly limits the practical roll-out of BCIs. To address this problem, we propose a novel instance-based transfer learning framework named Riemannian Geometric Instance Filtering (RGIF) to reduce calibration time without sacrificing accuracy. A new inter-subject similarity metric based on Riemannian geometry is proposed to measure the similarity between a few trials from the target subject and adequate trials from source subjects. The classification model for the target subject is then trained with the help of abundant trials from similar source subjects with high similarity to the target subject. We evaluate our method on two open-source EEG datasets. The results show that our approach improves significantly compared with other baselines. Furthermore, compared with using all source subjects data, our method reduces the training time by at least half and achieves slightly better accuracy.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1162–1167},
numpages = {6},
keywords = {brain-computer interface, inter-subject similarity, motor imagery, riemannian geometry, transfer learning},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568435,
author = {Dong, Yiwen and Liu, Jingxiao and Noh, Hae Young},
title = {GaitVibe+: Enhancing Structural Vibration-Based Footstep Localization Using Temporary Cameras for in-Home Gait Analysis},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568435},
doi = {10.1145/3560905.3568435},
abstract = {In-home gait analysis is important for providing early diagnosis and adaptive treatments for individuals with gait disorders. Existing systems include wearables and pressure mats, but they have limited scalability due to dense deployment and device carrying/charging requirements. Recently, vision-based systems have been developed to enable scalable, accurate in-home gait analysis, but it faces privacy concerns due to the exposure of people's appearances and daily activities. To overcome these limitations, our prior work developed footstep-induced structural vibration sensing for in-home gait monitoring, which is device-free, wide-ranged, and perceived as more privacy-friendly. Although it has succeeded in temporal parameter estimation, it shows limited performance for spatial gait parameter estimation due to the low accuracy in footstep localization. In particular, the localization error mainly comes from the estimation error of the wave arrival time at the vibration sensors and its error propagation to wave velocity estimations. To this end, we present GaitVibe+, a vibration-based footstep localization method fused with temporarily installed cameras for in-home gait analysis. Our method has two stages: fusion and operating stages. In the fusion stage, both cameras and vibration sensors are installed to record only a few trials of the subject's footstep data, through which we characterize the uncertainty in wave arrival time and model the wave velocity profiles for the given structure. In the operating stage, we remove the camera to preserve privacy at home. The footstep localization is conducted by estimating the time difference of arrival (TDoA) over multiple vibration sensors, whose accuracy is improved through the reduced uncertainty and velocity modeling during the fusion stage. We evaluate GaitVibe+ through a real-world experiment with 50 walking trials. With only 3 trials of multi-modal fusion, our approach has an average localization error of 0.22 meters, which reduces the spatial gait parameter error by 4.1x (from 111.4\% to 27.1\%) compared to the existing work.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1168–1174},
numpages = {7},
keywords = {computer vision, in-home gait analysis, localization, multi-modal fusion, spatial gait parameter, vibration},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568436,
author = {Zhao, Yuqing and Saxena, Divya and Cao, Jiannong},
title = {Memory-Efficient Domain Incremental Learning for Internet of Things},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568436},
doi = {10.1145/3560905.3568436},
abstract = {In Internet of Things (IoT) scenarios such as smart homes, autonomous vehicles, and wearable devices, data pattern changes over time due to changing environments and user requirements, known as domain shifts. When encountering domain shifts, deep neural network models in IoT suffers from performance degradation and need to retrain from scratch to adapt to domain shifts incrementally. Therefore, incremental learning is needed to adapt a model to domain shifts without retraining. Existing methods using the parameter isolation technique perform well in incremental learning of new domains without performance degradation. However, they cannot be directly adopted in IoT applications as they store masks and require users to label the task to indicate task-specific parameters during inference, which is memory inefficient and cumbersome. In this paper, we propose a memory-efficient method for IoT to incrementally adapt to domain shifts in a fixed neural network, named E-DomainIL. Our method freezes learned parameters and allows reusing them later in training to avoid interference between different domains. E-DomainIL does not require task labels or storing masks as it uses all parameters during inference. We use data-driven pruning to adjust the parameter ratio according to the dataset, thus maintaining the balance between accuracy and parameter efficiency. Experimental results on image classification benchmarks demonstrate our method's efficiency and accuracy.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1175–1181},
numpages = {7},
keywords = {catastrophic forgetting, data-driven pruning, domain incremental learning, domain shift, internet of things},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568437,
author = {Yin, Xiangyu and Huang, Kai and Forno, Erick and Chen, Wei and Huang, Heng and Gao, Wei},
title = {Out-Clinic Pulmonary Disease Evaluation via Acoustic Sensing and Multi-Task Learning on Commodity Smartphones},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568437},
doi = {10.1145/3560905.3568437},
abstract = {Pulmonary diseases, such as asthma and Chronic Obstructive Pulmonary Disease (COPD), constitute a major public health challenge. The disease symptoms, including airway obstruction and inflammation, usually result in changes in airway mechanical properties, such as the caliber and impedance of the airway. To measure such airway properties for disease evaluation and diagnosis purposes, pulmonary function tests (PFT) has been widely adopted. However, most existing PFT systems require expensive and cumbersome hardware that are impossible to be used out of clinic. To allow out-clinic continuous pulmonary disease evaluation, in this paper we present AWARE, a new sensing and AI system that supports accurate and reliable PFT using commodity smartphones. AWARE uses a smartphone to transmit acoustic signals and reconstructs the profile of human airway based on the analysis of reflected acoustic waves captured from the smartphone's microphone. The subject's pulmonary condition is then evaluated by a multi-task learning model that integrates both the airway measurements and the subject's lung function records as the ground truth. Evaluations on 75 human subjects demonstrate that AWARE has the capability to achieve 80\% accuracy on distinguishing between humans with healthy pulmonary function and with asthma symptoms.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1182–1188},
numpages = {7},
keywords = {acoustic sensing, multitask learning, pulmonary disease evaluation, smartphone},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568438,
author = {Bandyopadhyay, Soma and Datta, Anish and Pal, Arpan and Gadepally, Srinivas Raghu Raman},
title = {Intelligent Continuous Monitoring to Handle Data Distributional Changes for IoT Systems},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568438},
doi = {10.1145/3560905.3568438},
abstract = {Intelligent continuous monitoring of an IoT system to identify the operational changes, encompassing both normal and abnormal scenarios, with drift in sensing device is a challenging problem. It demands capability of learning continuously with multiple interventions or shifts, without forgetting past events information. However, forgetting the past learned knowledge, known as catastrophic forgetting, impacts significantly on the performance of continuous monitoring. In this work, we propose a generative neural network based model to handle various operational changes. Here, one objective is to learn continually by capturing past data distributional knowledge, while adapting new data signatures. Other objective, is to handle changes in data distribution like, to identify drifts, as well as, variations in diverse operational conditions of the system. We have experimented using vibration sensor based public real-world bearing data and performed extensive analysis incorporating synthetic drifts. Proposed method outperforms existing benchmark performances with clear separation of drift in learned representation.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1189–1195},
numpages = {7},
keywords = {continual learning, machine vibration, sensor drift},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568176,
author = {Pillai, Babu and H\'{o}u, Zh\'{e} and Biswas, Kamanashis and Bui, Vinh and Muthukkumarasamy, Vallipuram},
title = {Blockchain Interoperability: Performance and Security Trade-Offs},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568176},
doi = {10.1145/3560905.3568176},
abstract = {Blockchain technology is becoming a promising technological solution for enterprise applications with the rise of interoperable solutions. A cross-chain architecture facilitates interoperability, thus improves its chain efficiency, reduces fragmentation, and allows users and features to flow more freely across multiple blockchains. However, enabling interoperability in silo networks will make a significant functional trade-off on the security and performance of the system. This paper review trade-offs in blockchain technologies related to interoperability.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1196–1201},
numpages = {6},
keywords = {blockchain, decentralisation, interoperability, interoperability trade-off},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568177,
author = {R, Gaushik M and R, Jivtesh M and P, Adarsh and B, Sai Shibu N and Rao, Sethuraman N},
title = {A Prototype Design for Gamified Blood Donation App Using Blockchain Technology, IPFS and NFTs},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568177},
doi = {10.1145/3560905.3568177},
abstract = {Donating blood is a common practice that has a positive effect on the lives of several individuals. Daily, the number of people in urgent need of blood continues to rise substantially. It is often challenging to find a suitable donor in case of emergency. The situation is worse if it is a rare blood group. This paper introduces a blockchain-based decentralised application (DApp) to match recipients with blood donors during an emergency. Personal information such as name, location, blood group, and donation history is stored securely in the blockchain distributed ledger through IPFS. The donors' lack of awareness and motivation are the primary reasons for people not coming forward for blood donations. We propose to gamify the blood donation process by issuing NFT badges as a reward for donors. This paper explains the design of smart contracts for storing donor and recipient data on the ledger and issuing NFTs to donors. The article also briefly discusses the process of designing the DApp.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1202–1207},
numpages = {6},
keywords = {NFTs, blockchain, blood donation, gamification, smart contracts},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568179,
author = {Vangala, Anusha and Das, Ashok Kumar},
title = {Privacy-Preserving Blockchain-Based Authentication in Smart Energy Systems},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568179},
doi = {10.1145/3560905.3568179},
abstract = {Smart Energy Systems (SES) are the need of the hour, given the looming dangers of power crises amid changing climatic conditions. However, sensitive data play a critical role in such systems deserving high privacy and security protection. This paper proposes a novel blockchain-based authentication scheme that preserves privacy using the zero-knowledge protocol. During informal analysis, the proposed scheme shows resistance to various attacks such as man-in-the-middle attacks, replay attacks, impersonation attacks, privileged insider attacks, and ephemeral secret leakage attacks. The formal security verification using AVISPA regards the scheme as safe. In addition, the scheme supports critical features such as anonymity and untraceability within limited computational and communicational costs. A simulation of blockchain using Node.js shows only a linear increase in computation time with an increase in the number of blocks, and transactions, and an exponential increase with the number of nodes.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1208–1214},
numpages = {7},
keywords = {authentication, blockchain, internet of things (IoT), security, smart energy systems},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568180,
author = {Niranga, G. D Heshan and Nair, Vidya S and B, Sai Shibu N},
title = {Design of a Secured Medical Data Access Management Using Ethereum Smart Contracts, Truffle Suite and Web3},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568180},
doi = {10.1145/3560905.3568180},
abstract = {Securing and managing medical data in hospitals is one of the significant challenges still existing in healthcare. There can be different kinds of patients staying in hospitals with various diseases. All these medical data records need to be secured appropriately for future use and verification. In the hospital, there will be essential documents such as criminal cases and postmortem reports, although it is unclear if they are being handled properly or not. Even the hospital staff can alter these data. This paper proposes a blockchain-based secured medical data management system to manage access to each medical record in a network of hospitals. The proposed system has three main access management categories: one for securing general (fever or cold) medical report, category 2 for postmortem or crime reports security and category 3 for securing cancer /brain death /genetic disorder reports. Sensitive clinical data should not be visible to patients with cancer or genetic disorders as these patients have a higher rate of suicide attempts. Hence, the data is accessible only to doctors, family members, and researchers. The data related to the crime or postmortem reports have only limited access for those with legal permission to access and verify these types of reports. So through blockchain distributed ledger technology and smart contracts, we could store the data in a tamper-proof manner and manage the user access to these data.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1215–1221},
numpages = {7},
keywords = {access management, blockchain, distributed ledger technology, medical data, smart contract},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568181,
author = {Geng, Tieming and Njilla, Laurent and Huang, Chin-Tser},
title = {A Survey of Blockchain-Based Electronic Voting Mechanisms in Sensor Networks},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568181},
doi = {10.1145/3560905.3568181},
abstract = {Electronic voting technology has the ability to accelerate the counting of ballots, reduce the cost of voting, and offer convenience for remote voters. Meanwhile, the efficiency of voting can be improved. Immutability, verifiability, and distribution are the main features blockchain can provide. Building an electronic voting system based on the blockchain can help to mitigate the security issues such as single-point failure and data manipulation. However, some blockchain systems are not feasible in the environment of sensor networks. In this paper, we propose a comparative analysis of blockchain-based electronic voting systems from the perspective of blockchain type, cryptography techniques, counting method, and security requirements. We also identify a possible new direction for the design of blockchain-based electronic voting systems for the reference of future research.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1222–1228},
numpages = {7},
keywords = {blockchain, electronic voting, sensor network},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568175,
author = {Rossini, Martina and Zichichi, Mirko and Ferretti, Stefano},
title = {Smart Contracts Vulnerability Classification through Deep Learning},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568175},
doi = {10.1145/3560905.3568175},
abstract = {We investigate the use of deep learning to classify smart contract code vulnerabilities. We use different variants of Convolutional Neural Networks (CNNs) and a Long Short-Term Memory (LSTM) neural network. Five classes of vulnerabilities were employed. Our results suggest that the CNNs are able to provide a good level of accuracy, thus showing the viability of the proposed approach.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1229–1230},
numpages = {2},
location = {Boston, Massachusetts},
series = {SenSys '22}
}
@inproceedings{10.1145/3560905.3568178,
author = {R, Jivtesh M and Samuel, Rohit Mathew and R, Gaushik M and Menon, Siddhi and B, Sai Shibu N and Rao, Sethuraman N},
title = {Electric Vehicle as a Virtual Mobile Power Plant for Smart Grid: A Blockchain and Cryptocurrency-Based Proof of Concept System},
year = {2023},
isbn = {9781450398862},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3560905.3568178},
doi = {10.1145/3560905.3568178},
abstract = {Blockchain is the underlying technology for cryptocurrencies. Reliable machine-to-machine automatic transactions, such as auctions, bidding, and payments, utilise the immense potential of blockchain technology. Researchers are exploring blockchain-based applications for automobiles and transportation, such as electric vehicle (EV) charging and highway user fee payment. The use of blockchain eliminates the need for third parties in transactions. This paper presents a proof of concept for using EVs as energy storage in a smart grid system. Generators, consumers, and distributed energy resources (DER), such as solar and wind, make up the elements of a smart grid. We propose storing the surplus power generated by DER in the electric vehicle's battery. When the generation is less, or there is high demand, these EVs can supply the stored energy back to the grid. We use blockchain smart contracts and Ethereum cryptocurrency to monitor and monetise the process. We also make a cost comparison of conventional internal combustion engine (ICE) vehicles and EVs, analysing the financial benefits of employing the suggested method in EV charging instead of more conventional charging methods.},
booktitle = {Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems},
pages = {1231–1232},
numpages = {2},
keywords = {EV, blockchain, charging station, energy sharing, energy trading},
location = {Boston, Massachusetts},
series = {SenSys '22}
}