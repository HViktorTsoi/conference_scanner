@inproceedings{10.1145/2742647.2742659,
author = {Chen, Dongyao and Cho, Kyong-Tak and Han, Sihui and Jin, Zhizhuo and Shin, Kang G.},
title = {Invisible Sensing of Vehicle Steering with Smartphones},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742659},
doi = {10.1145/2742647.2742659},
abstract = {Detecting how a vehicle is steered and then alarming drivers in real time is of utmost importance to the vehicle and the driver's safety, since fatal accidents are often caused by dan- gerous steering. Existing solutions for detecting dangerous maneuvers are implemented either in only high-end vehicles or on smartphones as mobile applications. However, most of them rely on the use of cameras, the performance of which is seriously constrained by their high visibility requirement. Moreover, such an over/sole-reliance on the use of cameras can be a distraction to the driver.To alleviate these problems, we develop a vehicle steering detection middleware called V-Sense which can run on commodity smartphones without additional sensors or infrastructure support. Instead of using cameras, the core of V-Sense/ senses a vehicle's steering by only utilizing non-vision sensors on the smartphone. We design and evaluate algorithms for detecting and differentiating various vehicle maneuvers, including lane-changes, turns, and driving on curvy roads. Since V-Sense does not rely on use of cameras, its detection of vehicle steering is not affected by the (in)visibility of road objects or other vehicles. We first detail the design, implementation and evaluation of V-Sense and then demonstrate its practicality with two prevalent use cases: camera-free steering detection and fine-grained lane guidance. Our extensive evaluation results show that V-Sense is accurate in determining and differentiating various steering maneuvers, and is thus useful for a wide range of safety-assistance applications without additional sensors or infrastructure.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {1–13},
numpages = {13},
keywords = {camera-free sensing, driving assistant application, smartphone, vehicle steering detection},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742662,
author = {Yun, Sangki and Chen, Yi-Chao and Qiu, Lili},
title = {Turning a Mobile Device into a Mouse in the Air},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742662},
doi = {10.1145/2742647.2742662},
abstract = {A mouse has been one of the most successful user interfaces due to its intuitive use. As more devices are equipped with displays and offer rich options for users to choose from, a traditional mouse that requires a surface to operate is no longer sufficient. While different types of air mice are available in the market, they rely on accelerometers and gyroscopes, which significantly limit the accuracy and ease of use.In this paper, we develop a system that can accurately track hand movement to realize a mouse. A unique advantage of our scheme is that it achieves high tracking accuracy using the existing hardware already available in the mobile devices (e.g., smart phones and smart watches) and equipment to be controlled (e.g., smart TVs). More specifically, our approach sends inaudible sound pulses at a few selected frequencies, and uses the frequency shifts to estimate the speed and distance traveled. We then develop techniques to quickly calibrate the distance between speakers and narrow down the device's initial position using its movement trajectory. Based on the information, we continuously track the device's new position in real time. This is feasible because many devices, such as smart TVs, PCs, and laptops, already have multiple speakers. When only one speaker is available, we can leverage the frequency shift of sound along with the phase of received WiFi signal to enable tracking. Our evaluation and user study demonstrate that our system achieves high tracking accuracy (e.g., median error of around 1.4 cm) and ease of use.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {15–29},
numpages = {15},
keywords = {accelerometer, doppler effect, gyroscope, tracking},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742673,
author = {Chen, Bo and Yenamandra, Vivek and Srinivasan, Kannan},
title = {Tracking Keystrokes Using Wireless Signals},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742673},
doi = {10.1145/2742647.2742673},
abstract = {We implement a passive remote keystroke detection mechanism using only changes in the wireless channel. The detection algorithm does not require the user to wear any active devices nor does it require a change in the user's wireless transmission technique. The receiver system is implemented with five antennas. We cancel the signals received on multiple antennas. The key insight to realizing a fine-grained localization system is to exploit the extremely high sensitivity of cancellation performance (interference cancellation in full-duplex for example) to exact amplitude and phase matching. The receiver design introduces a delay mismatch between the received signal streams to guarantee imperfect cancellation across the transmission bandwidth except at one in-band frequency resulting in a trough in the cancellation spectrum. We detect keystrokes by forming an array of observed trough frequency across different antenna pairs.We implement our receiver system on the NI-based SDR platform. With full-training the receiver detects a keystroke within one key offset with an accuracy of 91.8\%. With a short ≈ 10 character training input, this accuracy drops to 85\%.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {31–44},
numpages = {14},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742674,
author = {Nandakumar, Rajalakshmi and Gollakota, Shyamnath and Watson, Nathaniel},
title = {Contactless Sleep Apnea Detection on Smartphones},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742674},
doi = {10.1145/2742647.2742674},
abstract = {We present a contactless solution for detecting sleep apnea events on smartphones. To achieve this, we introduce a novel system that monitors the minute chest and abdomen movements caused by breathing on smartphones. Our system works with the phone away from the subject and can simultaneously identify and track the fine-grained breathing movements from multiple subjects. We do this by transforming the phone into an active sonar system that emits frequency-modulated sound signals and listens to their reflections; our design monitors the minute changes to these reflections to extract the chest movements. Results from a home bedroom environment shows that our design operates efficiently at distances of up to a meter and works even with the subject under a blanket.Building on the above system, we develop algorithms that identify various sleep apnea events including obstructive apnea, central apnea, and hypopnea from the sonar reflections. We deploy our system at the UW Medicine Sleep Center at Harborview and perform a clinical study with 37 patients for a total of 296 hours. Our study demonstrates that the number of respiratory events identified by our system is highly correlated with the ground truth and has a correlation coefficient of 0.9957, 0.9860, and 0.9533 for central apnea, obstructive apnea and hypopnea respectively. Furthermore, the average error in computing of rate of apnea and hypopnea events is as low as 1.9 events/hr.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {45–57},
numpages = {13},
keywords = {contactless breathing monitoring, mobile health, phone sonar, sleep apnea},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742653,
author = {Nath, Suman},
title = {MAdScope: Characterizing Mobile In-App Targeted Ads},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742653},
doi = {10.1145/2742647.2742653},
abstract = {Advertising is the primary source of revenue for many mobile apps. One important goal of the ad delivery process is targeting users, based on criteria like users' geolocation, context, demographics, long-term behavior, etc. In this paper we report an in-depth study that broadly characterizes what targeting information mobile apps send to ad networks and how effectively, if at all, ad networks utilize the information for targeting users. Our study is based on a novel tool, called MadScope, that can (1) quickly harvest ads from a large collection of apps, (2) systematically probe an ad network to characterize its targeting mechanism, and (3) emulate user profiles of specific preferences and interests to study behavioral targeting. Our analysis of 500K ad requests from 150K Android apps and 101 ad networks indicates that apps do not yet exploit the full potential of targeting: even though ad controls provide APIs to send a lot of information to ad networks, much key targeting information is optional and is often not provided by app developers. We also use MadScope to systematically probe top 10 in-app ad networks to harvest over 1 million ads and find that while targeting is used by many of the top networks, there remain many instances where targeting information or behavioral profile does not have a statistically significant impact on how ads are chosen. We also contrast our findings with a recent study of targeted in-browser ads.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {59–73},
numpages = {15},
keywords = {in-app advertising, measurement, mobile advertising, targeted advertising, user profiles},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742676,
author = {Li, Wenhao and Li, Haibo and Chen, Haibo and Xia, Yubin},
title = {AdAttester: Secure Online Mobile Advertisement Attestation Using TrustZone},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742676},
doi = {10.1145/2742647.2742676},
abstract = {Mobile advertisement (ad for short) is a major financial pillar for developers to provide free mobile apps. However, it is frequently thwarted by ad fraud, where rogue code tricks ad providers by forging ad display or user clicks, or both. With the mobile ad market growing drastically (e.g., from $8.76 billion in 2012 to $17.96 billion in 2013), it is vitally important to provide a verifiable mobile ad framework to detect and prevent ad frauds. Unfortunately, this is notoriously hard as mobile ads usually run in an execution environment with a huge TCB.This paper proposes a verifiable mobile ad framework called AdAttester, based on ARM?s TrustZone technology. AdAttester provides two novel security primitives, namely unforgeable clicks and verifiable display. The two primitives attest that ad-related operations (e.g., user clicks) are initiated by the end user (instead of a bot) and that the ad is displayed intact and timely. AdAttester leverages the secure world of TrustZone to implement these two primitives to collect proofs, which are piggybacked on ad requests to ad providers for attestation. AdAttester is non-intrusive to mobile users and can be incrementally deployed in existing ad ecosystem. A prototype of AdAttester is implemented for Android running on a Samsung Exynos 4412 board. Evaluation using 182 typical mobile apps with ad frauds shows that AdAttester can accurately distinguish ad fraud from legitimate ad operations, yet incurs small performance overhead and little impact on user experience.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {75–88},
numpages = {14},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742668,
author = {Liu, Bin and Liu, Bin and Jin, Hongxia and Govindan, Ramesh},
title = {Efficient Privilege De-Escalation for Ad Libraries in Mobile Apps},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742668},
doi = {10.1145/2742647.2742668},
abstract = {The proliferation of mobile apps is due in part to the advertising ecosystem which enables developers to earn revenue while providing free apps. Ad-supported apps can be developed rapidly with the availability of ad libraries. However, today?s ad libraries essentially have access to the same resources as the parent app, and this has caused signi?cant privacy concerns. In this paper, we explore ef?cient methods to de-escalate privileges for ad libraries where the resource access privileges for ad libraries can be different from that of the app logic. Our system, PEDAL, contains a novel machine classi?er for detecting ad libraries even in the presence of obfuscated code, and techniques for automatically instrumenting bytecode to effect privilege de-escalation even in the presence of privilege inheritance. We evaluate PEDAL on a large set of apps from the Google Play store and demonstrate that it has a 98\% accuracy in detecting ad libraries and imposes less than 1\% runtime overhead on apps.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {89–103},
numpages = {15},
keywords = {ad libraries, app instrumentation, mobile apps, previlege de-escalation, static analysis},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742660,
author = {Zhang, Nairan and Lee, Youngki and Radhakrishnan, Meera and Balan, Rajesh Krishna},
title = {GameOn: p2p Gaming On Public Transport},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742660},
doi = {10.1145/2742647.2742660},
abstract = {Mobile games, and especially multiplayer games are a very popular daily distraction for many users. We hypothesise that commuters travelling on public buses or trains would enjoy being able to play multiplayer games with their fellow commuters to alleviate the commute burden and boredom. We present quantitative data to show that the typical one-way commute time is fairly long (at least 25 minutes on average) as well as survey results indicating that commuters are willing to play multiplayer games with other random commuters. In this paper, we present GameOn, a system that allows commuters to participate in multiplayer games with each other using p2p networking techniques that reduces the need to use high latency and possibly expensive cellular data connections. We show how GameOn uses a cloud-based matchmaking server to eliminate the overheads of discovery as well as show why GameOn uses Wi-Fi Direct over Bluetooth as the p2p networking medium. We describe the various system components of GameOn and their implementation. Finally, we present numerous results collected by using GameOn, with three real games, on many different public trains and buses with up to four human players in each game play.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {105–119},
numpages = {15},
keywords = {mobile gaming, p2p games, public transportation},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742657,
author = {Cuervo, Eduardo and Wolman, Alec and Cox, Landon P. and Lebeck, Kiron and Razeen, Ali and Saroiu, Stefan and Musuvathi, Madanlal},
title = {Kahawai: High-Quality Mobile Gaming Using GPU Offload},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742657},
doi = {10.1145/2742647.2742657},
abstract = {This paper presents Kahawai1, a system that provides high-quality gaming on mobile devices, such as tablets and smartphones, by offloading a portion of the GPU computation to server-side infrastructure. In contrast with previous thin-client approaches that require a server-side GPU to render the entire content, Kahawai uses collaborative rendering to combine the output of a mobile GPU and a server-side GPU into the displayed output. Compared to a thin client, collaborative rendering requires significantly less network bandwidth between the mobile device and the server to achieve the same visual quality and, unlike a thin client, collaborative rendering supports disconnected operation, allowing a user to play offline - albeit with reduced visual quality.Kahawai implements two separate techniques for collaborative rendering: (1) a mobile device can render each frame with reduced detail while a server sends a stream of per-frame differences to transform each frame into a high detail version, or (2) a mobile device can render a subset of the frames while a server provides the missing frames. Both techniques are compatible with the hardware-accelerated H.264 video decoders found on most modern mobile devices. We implemented a Kahawai prototype and integrated it with the idTech 4 open-source game engine, an advanced engine used by many commercial games. In our evaluation, we show that Kahawai can deliver gameplay at an acceptable frame rate, and achieve high visual quality using as little as one-sixth of the bandwidth of the conventional thin-client approach. Furthermore, a 50-person user study with our prototype shows that Kahawai can deliver the same gaming experience as a thin client under excellent network conditions.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {121–135},
numpages = {15},
keywords = {code offload, computer games, gpu, mobile devices},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742649,
author = {Gordon, Mark S. and Hong, David Ke and Chen, Peter M. and Flinn, Jason and Mahlke, Scott and Mao, Zhuoqing Morley},
title = {Accelerating Mobile Applications through Flip-Flop Replication},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742649},
doi = {10.1145/2742647.2742649},
abstract = {Mobile devices have less computational power and poorer Internet connections than other computers. Computation offload, in which some portions of an application are migrated to a server, has been proposed as one way to remedy this deficiency. Yet, partition-based offload is challenging because it requires applications to accurately predict whether mobile or remote computation will be faster, and it requires that the computation be large enough to overcome the cost of shipping state to and from the server. Further, offload does not currently benefit network-intensive applications.In this paper, we introduce Tango, a new method for using a remote server to accelerate mobile applications. Tango replicates the application and executes it on both the client and the server. Since either the client or the server execution may be faster during different phases of the application, Tango allows either replica to lead the execution. Tango attempts to reduces user-perceived application latency by predicting which replica will be faster and allowing it to lead execution and display output, leveraging the better network and computation resources of the server when the application can benefit from it. It uses techniques inspired by deterministic replay to keep the two replicas in sync, and it uses flip-flop replication to allow leadership to float between replicas. Tango currently works for several unmodified Android applications. In our results, two computation-heavy applications obtain up to 2-3x speedup, and five network applications obtain from 0 to 2.6x speedup.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {137–150},
numpages = {14},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742656,
author = {Lee, Kyungmin and Chu, David and Cuervo, Eduardo and Kopf, Johannes and Degtyarev, Yury and Grizan, Sergey and Wolman, Alec and Flinn, Jason},
title = {Outatime: Using Speculation to Enable Low-Latency Continuous Interaction for Mobile Cloud Gaming},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742656},
doi = {10.1145/2742647.2742656},
abstract = {Gaming on phones, tablets and laptops is very popular. Cloud gaming - where remote servers perform game execution and rendering on behalf of thin clients that simply send input and display output frames - promises any device the ability to play any game any time. Unfortunately, the reality is that wide-area network latencies are often prohibitive; cellular, Wi-Fi and even wired residential end host round trip times (RTTs) can exceed 100ms, a threshold above which many gamers tend to deem responsiveness unacceptable.In this paper, we present Outatime, a speculative execution system for mobile cloud gaming that is able to mask up to 120ms of network latency. Outatime renders speculative frames of future possible outcomes, delivering them to the client one entire RTT ahead of time, and recovers quickly from mis-speculations when they occur. Clients perceive little latency. To achieve this, Outatime combines: 1) future state prediction; 2) state approximation with image-based rendering and event time-shifting; 3) fast state checkpoint and rollback; and 4) state compression for bandwidth savings.To evaluate the Outatime speculation system, we use two high quality, commercially-released games: a twitch-based first person shooter, Doom 3, and an action role playing game, Fable 3. Through user studies and performance bench- marks, we find that players strongly prefer Outatime to traditional thin-client gaming where the network RTT is fully visible, and that Outatime successfully mimics playing across a low-latency network.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {151–165},
numpages = {15},
keywords = {cloud gaming, network latency, speculation},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742651,
author = {Lee, Hui-Yu and Lin, Hao-Min and Wei, Yu-Lin and Wu, Hsin-I and Tsai, Hsin-Mu and Lin, Kate Ching-Ju},
title = {RollingLight: Enabling Line-of-Sight Light-to-Camera Communications},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742651},
doi = {10.1145/2742647.2742651},
abstract = {Recent literatures have demonstrated the feasibility and applicability of light-to-camera communications. They either use this new technology to realize specific applications, e.g., localization, by sending repetitive signal patterns, or consider non-line-of-sight scenarios. We however notice that line-of-sight light-to-camera communications has a great potential because it provides a natural way to enable visual association, i.e., visually associating the received information with the transmitter's identity. Such capability benefits broader applications, such as augmented reality, advertising, and driver assistance systems. Hence, this paper designs, implements, and evaluates RollingLight, a line-of-sight light-to-camera communication system that enables a light to talk to diverse off-the-shelf rolling shutter cameras. To boost the data rate and enhance reliability, RollingLight addresses the following practical challenges. First, its demodulation algorithm allows cameras with heterogeneous sampling rates to accurately decode high-order frequency modulation in real-time. Second, it incorporates a number of designs to resolve the issues caused by inherently unsynchronized light-to-camera channels. We have built a prototype of RollingLight with USRP-N200, and also implemented a real system with Arduino Mega 2560, both tested with a range of different camera receivers. We also implement a real iOS application to examine our real-time decoding capability. The experimental results show that, even to serve commodity cameras with a large variety of frame rates, RollingLight can still deliver a throughput of 11.32 bytes per second.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {167–180},
numpages = {14},
keywords = {camera communications, frequency shift keying, rolling shutter, smartphones, visible light communications},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742652,
author = {Wang, Anran and Li, Zhuoran and Peng, Chunyi and Shen, Guobin and Fang, Gan and Zeng, Bing},
title = {InFrame++: Achieve Simultaneous Screen-Human Viewing and Hidden Screen-Camera Communication},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742652},
doi = {10.1145/2742647.2742652},
abstract = {Recent efforts in visible light communication over screen-camera links have exploited the display for data communication. Such practices, albeit convenient, have led to contention between space allocated for users and content reserved for devices, in addition to their visual anti-aesthetics and distractedness. In this paper, we propose INFRAME++, a system that enables concurrent, dual-mode, full-frame communication for both users and devices. INFRAME++ leverages the spatial-temporal flicker-fusion property of human vision system and the fast frame rate of modern display. It multiplexes data onto full-frame video contents through novel complementary frame composition, hierarchical frame structure, and CDMA-like modulation. It thus ensures opportunistic and unobtrusive screen-camera data communication without affecting the primary video-viewing experience for human users. Our prototype and experiments have confirmed its effectiveness of delivering data to devices in its visual communication with imperceptible video artifacts for viewers. INFRAME++ is able to achieve 150-240 kbps at 120FPS over a 24? LCD monitor with one data frame per 12 display frames. It supports up to 360kbps while data:video is 1:6.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {181–195},
numpages = {15},
keywords = {dual-mode visible communication, full-frame video, hidden visible communication, inframe++, screen-camera communication},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742667,
author = {Li, Tianxing and An, Chuankai and Xiao, Xinran and Campbell, Andrew T. and Zhou, Xia},
title = {Real-Time Screen-Camera Communication Behind Any Scene},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742667},
doi = {10.1145/2742647.2742667},
abstract = {We present HiLight, a new form of real-time screen-camera communication without showing any coded images (e.g., barcodes) for off-the-shelf smart devices. HiLight encodes data into pixel translucency change atop any screen content, so that camera-equipped devices can fetch the data by turning their cameras to the screen. HiLight leverages the alpha channel, a well-known concept in computer graphics, to encode bits into the pixel translucency change. By removing the need to directly modify pixel RGB values, HiLight overcomes the key bottleneck of existing designs and enables real-time unobtrusive communication while supporting any screen content. We build a HiLight prototype using off-the-shelf smart devices and demonstrate its efficacy and robustness in practical settings. By offering an unobtrusive, flexible, and lightweight communication channel between screens and cameras, HiLight opens up opportunities for new HCI and context-aware applications, e.g., smart glasses communicating with screens to realize augmented reality.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {197–211},
numpages = {15},
keywords = {alpha channel, screen-camera communication, visible light communication},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742663,
author = {LiKamWa, Robert and Zhong, Lin},
title = {Starfish: Efficient Concurrency Support for Computer Vision Applications},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742663},
doi = {10.1145/2742647.2742663},
abstract = {Emerging wearable devices promise a multitude of computer vision-based applications that serve users without active engagement. However, vision algorithms are known to be resource-hungry; and modern mobile systems do not support concurrent application use of the camera. Toward supporting efficient concurrency of vision applications, we report Starfish, a split-process execution system that supports concurrent vision applications by allowing them to share computation and memory objects in a secure and efficient manner. Starfish splits the vision library from an application into a separate process, called the Core, which centrally serves all vision applications. The Core shares library call results among applications, eliminating redundant computation and memory use. Starfish supports unmodified applications and unmodified libraries without needing their source code, and guarantees correctness to the applications. In doing so, Starfish improves both the performance and energy efficiency of concurrent vision applications. Using a prototype implementation on Google Glass, we experimentally demonstrate that Starfish reduces the time spent processing repeated vision library calls by 71\% - 97\%. When running two to ten concurrent face recognition applications at 0.3 frames per second, Starfish reduces CPU utilization by more than 42\% - 80\%. Notably, this keeps CPU utilization below 13\%, even as the number of applications increases. This reduces system power consumption by 19\% - 58\%, as Starfish maintains a power consumption at approximately 1210 mW while running the concurrent application workloads.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {213–226},
numpages = {14},
keywords = {computer vision, memoization, mobile computing, vision library},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742665,
author = {Nirjon, Shahriar and Gummeson, Jeremy and Gelb, Dan and Kim, Kyu-Han},
title = {TypingRing: A Wearable Ring Platform for Text Input},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742665},
doi = {10.1145/2742647.2742665},
abstract = {This paper presents TypingRing, a wearable ring platform that enables text input into computers of different forms, such as PCs, smartphones, tablets, or even wearables with tiny screens. The basic idea of TypingRing is to have a user wear a ring on his middle finger and let him type on a surface - such as a table, a wall, or his lap. The user types as if a standard QWERTY keyboard is lying underneath his hand but is invisible to him. By using the embedded sensors TypingRing determines what key is pressed by the user. Further, the platform provides visual feedback to the user and communicates with the computing device wirelessly. This paper describes the hardware and software prototype of TypingRing and provides an in-depth evaluation of the platform. Our evaluation shows that TypingRing is capable of detecting and sending key events in real-time with an average accuracy of 98.67\%. In a field study, we let seven users type a paragraph with the ring, and we find that TypingRing yields a reasonable typing speed (e.g., 33-50 keys per minute) and their typing speed improves over time.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {227–239},
numpages = {13},
keywords = {ring, typing, wearable},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742655,
author = {Santagati, G. Enrico and Melodia, Tommaso},
title = {U-Wear: Software-Defined Ultrasonic Networking for Wearable Devices},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742655},
doi = {10.1145/2742647.2742655},
abstract = {Wearable medical sensing devices with wireless capabilities have become the cornerstone of many revolutionary digital health applications that promise to predict and treat major diseases by acquiring and processing health information. Existing wireless wearable devices are connected through radio frequency (RF) electromagnetic wave carriers based on standards such as Bluetooth or WiFi. However, these solutions tend to almost-blindly scale down traditional wireless technologies to the body environment, with little or no attention to the peculiar characteristics of the human body and the severe privacy and security requirements of patients. We contend that this is not the only possible approach, and we present U-Wear, the first networking framework for wearable medical devices based on ultrasonic communications.U-Wear encloses a set of physical, data link and network layer functionalities that can flexibly adapt to application and system requirements to efficiently distribute information between ultrasonic wearable devices. U-Wear also offers reconfiguration functionalities at the application layer to provide a flexible platform to develop medical applications. We design two prototypes that implement U-Wear and operate in the near-ultrasonic frequency range using commercial-off-the-shelf (COTS) speakers and microphones. Despite the limited bandwidth, i.e., about 2 kHz, and COTS audio hardware components not optimized for operating at high frequency, our prototypes (i) achieve data rates up to 2.76 kbit/s with bit-error-rate lower than 10-5 using a transmission power of 20 mW; (ii) enable multiple nodes to share the medium; and (iii) implement reconfigurable data processing to extract medical parameters from sensors with high accuracy.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {241–256},
numpages = {16},
keywords = {acoustic communications, body area networks, digital health, wearable devices},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742669,
author = {Jain, Shubham and Borgiattino, Carlo and Ren, Yanzhi and Gruteser, Marco and Chen, Yingying and Chiasserini, Carla Fabiana},
title = {LookUp: Enabling Pedestrian Safety Services via Shoe Sensing},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742669},
doi = {10.1145/2742647.2742669},
abstract = {Motivated by safety challenges resulting from distracted pedestrians, this paper presents a sensing technology for fine-grained location classification in an urban environment. It seeks to detect the transitions from sidewalk locations to in-street locations, to enable applications such as alerting texting pedestrians when they step into the street. In this work, we use shoe-mounted inertial sensors for location classification based on surface gradient profile and step patterns. This approach is different from existing shoe sensing solutions that focus on dead reckoning and inertial navigation. The shoe sensors relay inertial sensor measurements to a smartphone, which extracts the step pattern and the inclination of the ground a pedestrian is walking on. This allows detecting transitions such as stepping over a curb or walking down sidewalk ramps that lead into the street. We carried out walking trials in metropolitan environments in United States (Manhattan) and Europe (Turin). The results from these experiments show that we can accurately determine transitions between sidewalk and street locations to identify pedestrian risk.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {257–271},
numpages = {15},
keywords = {inertial sensing, localization, pedestrian safety, smartphone, accelerometer, gps, gyroscope},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742672,
author = {Lane, Nicholas D. and Georgiev, Petko and Mascolo, Cecilia and Gao, Ying},
title = {ZOE: A Cloud-less Dialog-enabled Continuous Sensing Wearable Exploiting Heterogeneous Computation},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742672},
doi = {10.1145/2742647.2742672},
abstract = {The wearable revolution, as a mass-market phenomenon, has finally arrived. As a result, the question of how wearables should evolve over the next 5 to 10 years is assuming an increasing level of societal and commercial importance. A range of open design and system questions are emerging, for instance: How can wearables shift from being largely health and fitness focused to tracking a wider range of life events? What will become the dominant methods through which users interact with wearables and consume the data collected? Are wearables destined to be cloud and/or smartphone dependent for their operation?Towards building the critical mass of understanding and experience necessary to tackle such questions, we have designed and implemented ZOE - a match-box sized (49g) collar- or lapel-worn sensor that pushes the boundary of wearables in an important set of new directions. First, ZOE aims to perform multiple deep sensor inferences that span key aspects of everyday life (viz. personal, social and place information) on continuously sensed data; while also offering this data not only within conventional analytics but also through a speech dialog system that is able to answer impromptu casual questions from users. (Am I more stressed this week than normal?) Crucially, and unlike other rich-sensing or dialog supporting wearables, ZOE achieves this without cloud or smartphone support - this has important side-effects for privacy since all user information can remain on the device. Second, ZOE incorporates the latest innovations in system-on-a-chip technology together with a custom daughter-board to realize a three-tier low-power processor hierarchy. We pair this hardware design with software techniques that manage system latency while still allowing ZOE to remain energy efficient (with a typical lifespan of 30 hours), despite its high sensing workload, small form-factor, and need to remain responsive to user dialog requests.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {273–286},
numpages = {14},
keywords = {continuous sensing, dialog system, mobile sensing, wearable},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742661,
author = {Nguyen, David T. and Zhou, Gang and Xing, Guoliang and Qi, Xin and Hao, Zijiang and Peng, Ge and Yang, Qing},
title = {Reducing Smartphone Application Delay through Read/Write Isolation},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742661},
doi = {10.1145/2742647.2742661},
abstract = {The smartphone has become an important part of our daily lives. However, the user experience is still far from being optimal. In particular, despite the rapid hardware upgrades, current smartphones often suffer various unpredictable delays during operation, e.g., when launching an app, leading to poor user experience. In this paper, we investigate the behavior of reads and writes in smartphones. We conduct the first large-scale measurement study on the Android I/O delay using the data collected from our Android application running on 2611 devices within nine months. Among other factors, we observe that reads experience up to 626\% slowdown when blocked by concurrent writes for certain workloads. Additionally, we show the asymmetry of the slowdown of one I/O type due to another, and elaborate the speedup of concurrent I/Os over serial ones. We use this obtained knowledge to design and implement a system prototype called SmartIO that reduces the application delay by prioritizing reads over writes, and grouping them based on assigned priorities. SmartIO issues I/Os with optimized concurrency parameters. The system is implemented on the Android platform and evaluated extensively on several groups of popular applications. The results show that our system reduces launch delays by up to 37.8\%, and run-time delays by up to 29.6\%.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {287–300},
numpages = {14},
keywords = {application launch, application response time, flash disk i/o optimizations, smartphone application performance},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742658,
author = {Zhang, Li and Pathak, Parth H. and Wu, Muchen and Zhao, Yixin and Mohapatra, Prasant},
title = {AccelWord: Energy Efficient Hotword Detection through Accelerometer},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742658},
doi = {10.1145/2742647.2742658},
abstract = {Voice control has emerged as a popular method for interacting with smart-devices such as smartphones, smartwatches etc. Popular voice control applications like Siri and Google Now are already used by a large number of smartphone and tablet users. A major challenge in designing a voice control application is that it requires continuous monitoring of user?s voice input through the microphone. Such applications utilize hotwords such as "Okay Google" or "Hi Galaxy" allowing them to distinguish user?s voice command and her other conversations. A voice control application has to continuously listen for hotwords which significantly increases the energy consumption of the smart-devices.To address this energy efficiency problem of voice control, we present AccelWord in this paper. AccelWord is based on the empirical evidence that accelerometer sensors found in today?s mobile devices are sensitive to user?s voice. We also demonstrate that the effect of user?s voice on accelerometer data is rich enough so that it can be used to detect the hotwords spoken by the user. To achieve the goal of low energy cost but high detection accuracy, we combat multiple challenges, e.g. how to extract unique signatures of user?s speaking hotwords only from accelerometer data and how to reduce the interference caused by user?s mobility.We finally implement AccelWord as a standalone application running on Android devices. Comprehensive tests show AccelWord has hotword detection accuracy of 85\% in static scenarios and 80\% in mobile scenarios. Compared to the microphone based hotword detection applications such as Google Now and Samsung S Voice, AccelWord is 2 times more energy efficient while achieving the accuracy of 98\% and 92\% in static and mobile scenarios respectively.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {301–315},
numpages = {15},
keywords = {accelerometer, accelword, energy, hotword detection, measurement},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742648,
author = {Yang, Zhice and Wang, Zeyu and Zhang, Jiansong and Huang, Chenyu and Zhang, Qian},
title = {Wearables Can Afford: Light-weight Indoor Positioning with Visible Light},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742648},
doi = {10.1145/2742647.2742648},
abstract = {Visible Light Positioning (VLP) provides a promising means to achieve indoor localization with sub-meter accuracy. We observe that the Visible Light Communication (VLC) methods in existing VLP systems rely on intensity-based modulation, and thus they require a high pulse rate to prevent flickering. However, the high pulse rate adds an unnecessary and heavy burden to receiving devices. To eliminate this burden, we propose the polarization-based modulation, which is flicker-free, to enable a low pulse rate VLC. In this way, we make VLP light-weight enough even for resource-constrained wearable devices, e.g. smart glasses. Moreover, the polarization-based VLC can be applied to any illuminating light sources, thereby eliminating the dependency on LED.This paper presents the VLP system PIXEL, which realizes our idea. In PIXEL, we develop three techniques, each of which addresses a design challenge: 1) a novel color-based modulation scheme to handle users? mobility, 2) an adaptive downsampling algorithm to tackle the uneven sampling problem of wearables? low-cost camera and 3) a computational optimization method for the positioning algorithm to enable real-time processing. We implement PIXEL?s hardware using commodity components and develop a software program for both smartphone and Google glass. Our experiments based on the prototype show that PIXEL can provide accurate realtime VLP for wearables and smartphones with camera resolution as coarse as 60 pixel x 80 pixel and CPU frequency as low as 300MHz.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {317–330},
numpages = {14},
keywords = {indoor localization, mobile devices, polarization, visible light communication, wearables},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742666,
author = {Jain, Puneet and Manweiler, Justin and Roy Choudhury, Romit},
title = {OverLay: Practical Mobile Augmented Reality},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742666},
doi = {10.1145/2742647.2742666},
abstract = {The idea of augmented reality - the ability to look at a physical object through a camera and view annotations about the object - is certainly not new. Yet, this apparently feasible vision has not yet materialized into a precise, fast, and comprehensively usable system. This paper asks: What does it take to enable augmented reality (AR) on smartphones today? To build a ready-to-use mobile AR system, we adopt a top-down approach cutting across smartphone sensing, computer vision, cloud offloading, and linear optimization. Our core contribution is in a novel location-free geometric representation of the environment - from smartphone sensors - and using this geometry to prune down the visual search space. Metrics of success include both accuracy and latency of object identification, coupled with the ease of use and scalability in uncontrolled environments. Our converged system, OverLay, is currently deployed in the engineering building and open for use to regular public; ongoing work is focussed on campus-wide deployment to serve as a "historical tour guide" of UIUC. Performance results and user responses thus far have been promising, to say the least.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {331–344},
numpages = {14},
keywords = {augmented reality, gyroscope, localization, mobile, tagging},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742671,
author = {Wang, He and Bao, Xuan and Roy Choudhury, Romit and Nelakuditi, Srihari},
title = {Visually Fingerprinting Humans without Face Recognition},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742671},
doi = {10.1145/2742647.2742671},
abstract = {This paper develops techniques using which humans can be visually recognized. While face recognition would be one approach to this problem, we believe that it may not be always possible to see a person?s face. Our technique is complementary to face recognition, and exploits the intuition that human motion patterns and clothing colors can together encode several bits of information. Treating this information as a "temporary fingerprint", it may be feasible to recognize an individual with reasonable consistency, while allowing her to turn off the fingerprint at will.One application of visual fingerprints relates to augmented reality, in which an individual looks at other people through her camera-enabled glass (e.g., Google Glass) and views information about them. Another application is in privacy-preserving pictures ? Alice should be able to broadcast her "temporary fingerprint" to all cameras in the vicinity along with a privacy preference, saying "remove me". If a stranger?s video happens to include Alice, the device can recognize her fingerprint in the video and erase her completely. This paper develops the core visual fingerprinting engine ? InSight ? on the platform of Android smartphones and a backend server running MATLAB and OpenCV. Results from real world experiments show that 12 individuals can be discriminated with 90\% accuracy using 6 seconds of video/motion observations. Video based emulation confirms scalability up to 40 users.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {345–358},
numpages = {14},
keywords = {augmented reality, matching, smartphones, visual fingerprinting},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742650,
author = {Lerner, Adam and Saxena, Alisha and Ouimet, Kirk and Turley, Ben and Vance, Anthony and Kohno, Tadayoshi and Roesner, Franziska},
title = {Analyzing the Use of Quick Response Codes in the Wild},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742650},
doi = {10.1145/2742647.2742650},
abstract = {One- and two-dimensional barcodes, including Quick Response (QR) codes, have become a convenient way to communicate small amounts of information from physical objects to mobile devices. While there is much discussion, awareness, and proposed use of such barcodes, both in aca-demia and in industry, to our knowledge there has not been a systematic and in-depth analysis of the actual ecosystem surrounding these codes. To fill this gap, we analyze a log of all scans performed by users of a popular QR and barcode scanning app available for Android, iPhone, and Windows Phone. Our dataset includes over 87 million scans performed over a 10-month period from May 2013 to March 2014. We examine general use patterns of QR and barcodes in the wild and identify common and uncommon uses and misuses. We see the presence of both conventional (e.g., web) and emerging (e.g., Bitcoin) uses of QR codes, and develop an informed understanding of the types of QR codes being created and how users interact with QR and barcodes in the wild.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {359–374},
numpages = {16},
keywords = {barcodes, empirical studies, mobile computing, mobile malware, qr codes, ubiquitous computing},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742675,
author = {Vallina-Rodriguez, Narseo and Sundaresan, Srikanth and Kreibich, Christian and Weaver, Nicholas and Paxson, Vern},
title = {Beyond the Radio: Illuminating the Higher Layers of Mobile Networks},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742675},
doi = {10.1145/2742647.2742675},
abstract = {Cellular network performance is often viewed as primarily dominated by the radio technology. However, reality proves more complex: mobile operators deploy and configure their networks in different ways, and sometimes establish network sharing agreements with other mobile carriers. Moreover, regulators have encouraged newer operational models such as Mobile Virtual Network Operators (MVNOs) to promote competition. In this paper we draw upon data collected by the ICSI Netalyzr app for Android to characterize how operational decisions, such as network configurations, business models, and relationships between operators introduce diversity in service quality and affect user security and privacy. We delve in detail beyond the radio link and into network configuration and business relationships in six countries. We identify the widespread use of transparent middleboxes such as HTTP and DNS proxies, analyzing how they actively modify user traffic, compromise user privacy, and potentially undermine user security. In addition, we identify network sharing agreements between operators, highlighting the implications of roaming and characterizing the properties of MVNOs, including that a majority are simply rebranded versions of major operators. More broadly, our findings highlight the importance of considering higher-layer relationships when seeking to analyze mobile traffic in a sound fashion.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {375–387},
numpages = {13},
keywords = {android, cellular networks, dns, http header injection, http proxy, measurement, middleboxes, mobile networks, mobile traffic, pep, privacy},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742670,
author = {Nikravesh, Ashkan and Yao, Hongyi and Xu, Shichang and Choffnes, David and Mao, Z. Morley},
title = {Mobilyzer: An Open Platform for Controllable Mobile Network Measurements},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742670},
doi = {10.1145/2742647.2742670},
abstract = {Mobile Internet availability, performance and reliability have remained stubbornly opaque since the rise of cellular data access. Conducting network measurements can give us insight into user-perceived network conditions, but doing so requires careful consideration of device state and efficient use of scarce resources. Existing approaches address these concerns in ad-hoc ways.In this work we propose Mobilyzer, a platform for conducting mobile network measurement experiments in a principled manner. Our system is designed around three key principles: network measurements from mobile devices require tightly controlled access to the network interface to provide isolation; these measurements can be performed efficiently using a global view of available device resources and experiments; and distributing the platform as a library to existing apps provides the incentives and low barrier to adoption necessary for large-scale deployments. We describe our current design and implementation, and illustrate how it provides measurement isolation for applications, efficiently manages measurement experiments and enables a new class of experiments for the mobile environment.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {389–404},
numpages = {16},
keywords = {cellular networks, measurement tool, mobile web, network performance, video},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742654,
author = {Zhang, Chi and Zhang, Xinyu and Chandra, Ranveer},
title = {Energy Efficient WiFi Display},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742654},
doi = {10.1145/2742647.2742654},
abstract = {WiFi Display, also called Miracast, is an emerging technology that allows a mobile device (source) to duplicate its screen content to an external display (sink) via a peer-to-peer WiFi link. Despite its diverse application scenarios and growing popularity, Miracast consumes substantial power due to a combination of video encoding/decoding and transmission. In this paper, we first conduct a measurement study to quantify and model key parameters that scale Miracast's power consumption. We then propose a set of optimization mechanisms to bypass redundant codec operations, reduce video tail traffic, and relocate the Miracast channel dynamically to maximize transmission efficiency. We have implemented this energy-efficient Miracast framework on an Android smartphone. Experimental results show that the legacy Miracast system costs 1.3 to 2.4 Watts. Our framework reduces the power consumption by 29\% to 61\%, depending on the Miracast application's video traffic patterns. Our optimization mechanisms do not affect the video quality, and can even reduce the latency of certain Miracast applications.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {405–418},
numpages = {14},
keywords = {energy efficiency, miracast, mobile phones, wifi direct, wifi display},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2742664,
author = {Moon, YoungGyoun and Kim, Donghwi and Go, Younghwan and Kim, Yeongjin and Yi, Yung and Chong, Song and Park, KyoungSoo},
title = {Practicalizing Delay-Tolerant Mobile Apps with Cedos},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2742664},
doi = {10.1145/2742647.2742664},
abstract = {Delay-tolerant Wi-Fi offloading is known to improve overall mobile network bandwidth at low delay and low cost. Yet, in reality, we rarely find mobile apps that fully support opportunistic Wi-Fi access. This is mainly because it is still challenging to develop delay-tolerant mobile apps due to the complexity of handling network disruptions and delays.In this work, we present Cedos, a practical delay-tolerant mobile network access architecture in which one can easily build a mobile app. Cedos consists of three components. First, it provides a familiar socket API whose semantics conforms to TCP while the underlying protocol, D2TP, transparently handles network disruptions and delays in mobility. Second, Cedos allows the developers to explicitly exploit delays in mobile apps. App developers can express maximum user-specified delays in content download or use the API for real-time buffer management at opportunistic Wi-Fi usage. Third, for backward compatibility to existing TCPbased servers, Cedos provides D2Prox, a protocol-translation Web proxy. D2Prox allows intermittent connections on the mobile device side, but correctly translates Web transactions with traditional TCP servers. We demonstrate the practicality of Cedos by porting mobile Firefox and VLC video streaming client to using the API. We also implement delay/disruption-tolerant podcast client and run a field study with 50 people for eight weeks. We find that up to 92.4\% of the podcast traffic is offloaded to Wi-Fi, and one can watch a streaming video in a moving train while offloading 48\% of the content to Wi-Fi without a single pause.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {419–433},
numpages = {15},
keywords = {delay-tolerant networking, mobility, wi-fi offloading},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2749242,
author = {Jain, Shubham and Borgiattino, Carlo and Ren, Yanzhi and Gruteser, Marco and Chen, Yingying and Chiasserini, Carla Fabiana},
title = {Video: LookUp!: Enabling Pedestrian Safety Services via Shoe Sensing},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2749242},
doi = {10.1145/2742647.2749242},
abstract = {This video is a demonstration of the work discussed in our full paper available in the MobiSys'15 proceedings. The video illustrates a sensing technology for fine-grained location classification in an urban environment, for enhancing pedestrian safety. Our system seeks to detect the transitions from sidewalk locations to in-street locations, to enable applications such as alerting texting pedestrians when they step into the street. Existing positioning technologies are not sufficiently precise to allow distinguishing a position on the sidewalk from a position in the street, as explored in our previous work. To this end, we use shoe-mounted inertial sensors for location classification based on surface gradient profile and step patterns. This approach is different from existing shoe sensing solutions that focus on dead reckoning and inertial navigation. The shoe sensors relay inertial sensor measurements to a smartphone, which extracts the step pattern and the inclination of the ground a pedestrian is walking on. This allows detecting transitions such as stepping over a curb or walking down sidewalk ramps that lead into the street. We carried out walking trials in metropolitan environments in United States (Manhattan) and Europe (Turin). The results from these experiments show that we can accurately determine transitions between sidewalk and street locations to identify pedestrian risk.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {435},
numpages = {1},
keywords = {accelerometer, gps, gyroscope, inertial sensing, localization, pedestrian safety, smartphone},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2749243,
author = {Wang, Zeyu and Yang, Zhice and Zhang, Jiansong and Huang, Chenyu and Zhang, Qian},
title = {Video: Lightweight Visible Light Communication for Indoor Positioning},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2749243},
doi = {10.1145/2742647.2749243},
abstract = {Visible light positioning (VLP) is an emerging positioning technique that utilizes indoor light sources to broadcast archer locations through visible light communication (VLC). Benefited by the densely deployed light lamps, VLP holds the promise for more accurate positioning accuracy than RF based approaches, and thus enables interesting applications such as retail navigation and shelf-level advertising in supermarkets and shopping malls.However, we observe that in existing VLP systems, receiving devices are heavily burdened in handling light flickering for VLC. In order to prevent human from being disturbed, the VLC transmitter lamps have to transmit pulses in a high rate (over 1kHz). Since the pulse rate far exceeds the cameras' sampling capability (30fps), receiver design either requires customized light sensor with cumbersome calibration on receiving signal strength [2] or processing high resolution images to leverage rolling shutter effect of the CMOS camera to decode message [1].The heavy burden on receiving devices motivated us to try getting rid of light flickers. Since human eyes normally can not perceive changes in polarization, the idea is to modulate polarization instead of intensity for communication. In this demo, we demonstrate the VLC system in our VLP design [3] which realizes this idea. It enables lightweight VLC that is even affordable in wearables (Google Glass), without incurring hardware modification or computation off-loading. Moreover, it also makes other types of illuminating light beyond LED light (even sun light) possible to construct communication, therefore eliminates the barrier for deploying future VLC-based applications.As detailed in the full paper [3], our design was inspired by the liquid crystal display (LCD), from which we borrowed polarizer and liquid crystal. Liquid crystal has the property to change the polarization of bypassing polarized light according to the applied voltage. We use polarizer to polarize illuminating light and leverage liquid crystal to modulate bits through changing the light's polarization. The receiver can thus detect changes in polarization with a polarizing film, through which different polarizations result in different intensities. Since the SNR of such communication channel may significantly vary with the mobility of receiving device, we propose to add a dispersion filter to the transmitter. The dispersion filter can cast different frequency of lights into different polarization directions so that SNR in different receiving directions are evened. With the above techniques, VLC transmitter generates signal in low baud rate and mobile devices can perform VLC through camera directly. The communication is long in distance and lightweight enough for resource-constrained devices since the information is carried in intensity changes rather than certain image patterns in rolling shutter approaches.In this demo, we will illustrate the prototype implementation of the VLC communication system. We use incandescent lamps as illuminating light sources. The transmitter consists of a polarizing film, a liquid crystal layer, a dispersor and a control board. The receiver is demonstrated in Android smartphone with polarizing film in front of the camera.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {437},
numpages = {1},
keywords = {pixel, polarization, visible light communication, wearables},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745925,
author = {Alessandroni, Giacomo and Bogliolo, Alessandro and Carini, Alberto and Delpriori, Saverio and Freschi, Valerio and Klopfenstein, Lorenz and Lattanzi, Emanuele and Luchetti, Gioele and Paolini, Brendan and Seraghiti, Andrea},
title = {Demo: Mobile Crowdsensing of Road Surface Roughness},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745925},
doi = {10.1145/2742647.2745925},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {439},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745920,
author = {Benbadis, Farid and Rebecchi, Filippo and Cosnier, Florian and Sammarco, Matteo and Dias de Amorim, Marcelo and Conana, Vania},
title = {Demo: D2D Rescue of Overloaded Cellular Channels},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745920},
doi = {10.1145/2742647.2745920},
abstract = {Mobile data traffic is set to triple in three years from now according to Cisco. This trend is a real challenge for operators since wireless capacity is bounded.To boost network capacity further, operators think about paradigm-shifting solutions to relieve their infrastructures. Recently, data offloading received increasing attention from the research community. Operators may leverage unused bandwidth across different technologies to shift part of the traffic onto less critical infrastructure (e.g., through Wi-Fi access points). In a further evolution, they can also benefit from the widespread diffusion of smart mobile devices with multiple communication interfaces. Users become the heart of the offloading strategy by employing multi-hop opportunistic communications to improve content dissemination, while reducing the load on the wireless infrastructure.We propose an architecture that takes advantage of the latest advances in opportunistic networking to achieve efficient traffic offloading. In this approach, terminals are under continuous control of the operator - the cellular infrastructure serves as a control channel to track data dissemination. The demonstration builds on DROiD [2] as injection strategy, and Epics [1] to distribute data opportunistically.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {441},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745923,
author = {Degtyarev, Yury and Cuervo, Eduardo and Chu, David},
title = {Demo: Irides: Attaining Quality, Responsiveness and Mobility for Virtual Reality Head-mounted Displays},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745923},
doi = {10.1145/2742647.2745923},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {443},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745932,
author = {Faye, S\'{e}bastien and Frank, Raphael},
title = {Demo: Using Wearables to Learn from Human Dynamics},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745932},
doi = {10.1145/2742647.2745932},
abstract = {Recent technological advances have allowed the development of miniaturized sensors and the emergence of a wide range of connected objects. Whether it's smartphones or in the broader sense wearables, the diversity of these devices and their accessibility opens up new fields for applications in the computer sciences [2, 3]. Smartwatches, which are experiencing a boom on the market, will be integral to the research that will shape the Internet in the years to come, namely big data, sensing systems and human behavior. Our demonstration falls within this context and aims to demonstrate the potential of these emerging technologies to respond to problems and to way of thinking introduced by industry and the scientific community, which are generally limited to smartphone sensing frameworks [1]. Further, we plan to present our research platform, SWIPE, which is dedicated to collecting, studying and learning about human dynamics by means of an ecosystem of wearables. A short presentation video is available online at http://swipe.sfaye.com/mobisys15/.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {445},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745917,
author = {Feij\'{o} Filho, Jackson and Valle, Thiago and Prata, Wilson},
title = {Demo: Breathing-Based Text Input for Mobile Phones},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745917},
doi = {10.1145/2742647.2745917},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {447},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745919,
author = {Feij\'{o} Filho, Jackson and Prata, Wilson and Valle, Thiago},
title = {Demo: Continuous Emotional Status in Mobile-Mediated Communications},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745919},
doi = {10.1145/2742647.2745919},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {449},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745926,
author = {Feij\'{o} Filho, Jackson and Prata, Wilson and Valle, Thiago},
title = {Demo: Mobile Software Emotions Logging: Towards an Automatic Usability Evaluation},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745926},
doi = {10.1145/2742647.2745926},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {451},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745930,
author = {Lam, Yawhuei and Varga, Virag and Kriara, Lito and Gross, Thomas and Mangold, Stefan},
title = {Demo: TouchCom - Creating Real Excalibur Experience with Body Touch Communication},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745930},
doi = {10.1145/2742647.2745930},
abstract = {The TouchCom project aims to gain a thorough understanding of the transmission channel and to implement higher layer protocols to support Human-Computer Interaction applications and multi-hop body-to-body communication. Finally, we built a prototype of a transmitter and receiver device to demonstrate a real life application.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {453},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745929,
author = {Li, Tianxing and An, Chuankai and Xiao, Xinran and Campbell, Andrew T. and Zhou, Xia},
title = {Demo: Real-Time Screen-Camera Communication Behind Any Scene},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745929},
doi = {10.1145/2742647.2745929},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {455},
numpages = {1},
keywords = {screen-camera link, visible light communication},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745921,
author = {Mujibiya, Adiyan and Torii, Junji},
title = {Demo: Energy Harvesting Using Everyday Objects},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745921},
doi = {10.1145/2742647.2745921},
abstract = {We present an energy harvesting technique that leverages readily available time-varying ambient electric field (EF) as source, and explore the utilization of surrounding everyday objects that are constructed from conductive materials. In this abstract, we describe the general concept and the circuit model of our approach. We showed that by incorporating energy store and release circuitry, we were able to deliver power to a usable level. To thoroughly test the technique, we developed Wireless Logger hardware module and conduct extensive one week-long power harvesting experiment. We show our ambient electric field profiler tool that checks the electrical properties of an environment. This tool is useful to obtain parameters to know whether our technique is feasible for a given environment. We highlight limitations that encourage us to refine our design, explore other grounding strategies, and implement techniques to extract the maximum harvestable energy in the future iterations of this strategy. We believe that the perpetual issue in Internet-of-Things is electrical power, and this research contributes as a simple, lightweight, thus usability-wise, a powerful solution for this issue.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {457},
numpages = {1},
keywords = {capacitive reactance, electric field, electromagnetic inductance, iot, power harvesting, wireless sensor network},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745928,
author = {Pamboris, Andreas and B\'{a}guena, Miguel and Wolf, Alexander L. and Manzoni, Pietro and Pietzuch, Peter},
title = {Demo: NOMAD: An Edge Cloud Platform for Hyper-Responsive Mobile Apps},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745928},
doi = {10.1145/2742647.2745928},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {459},
numpages = {1},
keywords = {edge cloud platform, low-latency backend services},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745918,
author = {Varga, Virag and Kriara, Lito and Vukadinovic, Vladimir and Gross, Thomas and Mangold, Stefan},
title = {Demo: Bringing the Internet of Toys to Life},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745918},
doi = {10.1145/2742647.2745918},
abstract = {The Internet of Things (IoT) will connect not only Zigbee-enabled devices but also Wi-Fi-enabled consumer electronics, given the recent rise of IPv6. We developed a power saving communication protocol for low-complexity IPv6-connected devices that can support multiple applications. We demonstrate here in an entertainment-related application scenario how to use that protocol to bring what we refer to as the Internet of Toys to life (Fig. 1).We demonstrate a real-time Internet of Toys system using the Multi-Hop Power Saving Mode (MH-PSM) protocol developed for Wi-Fi enabled IPv6-connected devices on the Contiki OS embedded open source platform [1]. MH-PSM enables low-latency ad hoc communication using 802.11 over multiple hops [2]. The software system includes the RRPL dynamic routing [3] and Constrained Application Protocol (CoAP). The hardware platform is based on low-complexity Arduino Due boards.The system setup includes a gateway, which is an Internet-connected laptop running a CoAP border-router. The toys and gateway create an 802.11 IBSS (ad hoc) network using IPv6. We have implemented an application that enables toys to speak together in coordination (i.e., to engage in a dialog according to a scripted story). The coordination requires signaling between toys. The gateway runs a web server allowing some features of the application to be controlled by a web browser on a phone. The web application creates signaling traffic between the phone and toy(s) which traverses the gateway. The toys can also be monitored and controlled remotely from anywhere in the Internet using CoAP.Fig. 2 shows experimental results when ten toys are active simultaneously transmitting one packet per second to all the other nodes. Such a setup creates a congested environment, with the topology including up to five-hop routes. Comparing the demo setup with an earlier testbed that used MH-PSM [2] with static routes, we note an increase of the delay due to the routing overhead of RRPL. For similar reasons, the packet delivery ratio is also on average 5\% lower in the real-time system compared to an earlier evaluation in a testbed. The real-time application clearly introduces new challenges that must be addressed compared to an evaluation in a testbed with predetermined routing tables. However, this application scenario can handle the extra work and the real-time system demonstrates that MH-PSM with RRPL and CoAP can efficiently support a wide range of IoT applications, with packet delivery ratio over 90\%. Currently, we are working on moving this platform to support more powerful OpenWrt-enabled devices.In our demonstration, participants can experience the Internet of Toys and use an iPhone (provided) to select a story for the toys to narrate.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {461},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745916,
author = {Wang, Anran and Li, Zhuoran and Fang, Gan and Peng, Chunyi and Shen, Guobin and Zeng, Bing},
title = {Demo: Achieving Simultaneous Screen-Human Viewing and Hidden Screen-Camera Communication},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745916},
doi = {10.1145/2742647.2745916},
abstract = {We present and demonstrate INFRAME++, a novel system that enables concurrent, dual-mode, full-frame communication for both users and devices. It achieves unobtrusive screen-camera data communication without affecting the primary video-viewing experience for human users. It leverages the capability discrepancy and distinctive features of the human vision system and devices (modern display and camera). We have implemented INFRAME++ as a PC-phone application. Both communication will be realized through multiplexed videos frames which will be displayed on a modern monitor (120FPS) and captured by a smartphone camera for data decoding. In this demonstration (Figure 1), we will show that INFRAME++ can yield normal video-viewing experience for humans, and high-rate data communication for devices (up to 300 kbps). User participation will be welcome in this live demo.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {463},
numpages = {1},
keywords = {dual-mode visible communication, full-frame video, hidden visible communication, inframe++, screen-camera communication},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745924,
author = {Wang, Zeyu and Yang, Zhice and Zhang, Jiansong and Huang, Chenyu and Zhang, Qian},
title = {Demo: Lightweight Visible Light Communication forIndoor Positioning},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745924},
doi = {10.1145/2742647.2745924},
abstract = {Visible light positioning (VLP) is an emerging positioning technique that utilizes indoor light sources to broadcast archer locations through visible light communication (VLC). Benefited by the densely deployed light lamps, VLP holds the promise for more accurate positioning accuracy than RF based approaches, and thus enables interesting applications such as retail navigation and shelf-level advertising in supermarkets and shopping malls.However, we observe that in existing VLP systems, receiving devices are heavily burdened in handling light flickering for VLC. In order to prevent human from being disturbed, the VLC transmitter lamps have to transmit pulses in a high rate (over 1kHz). Since the pulse rate far exceeds the cameras' sampling capability (30fps), receiver design either requires customized light sensor with cumbersome calibration on receiving signal strength [2] or processing high resolution images to leverage rolling shutter effect of the CMOS camera to decode message [1].The heavy burden on receiving devices motivated us to try getting rid of light flickers. Since human eyes normally can not perceive changes in polarization, the idea is to modulate polarization instead of intensity for communication. In this demo, we demonstrate the VLC system in our VLP design [3] which realizes this idea. It enables lightweight VLC that is even affordable in wearables (Google Glass), without incurring hardware modification or computation off-loading. Moreover, it also makes other types of illuminating light beyond LED light (even sun light) possible to construct communication, therefore eliminates the barrier for deploying future VLC-based applications.As detailed in the full paper [3], our design was inspired by the liquid crystal display (LCD), from which we borrowed polarizer and liquid crystal. Liquid crystal has the property to change the polarization of bypassing polarized light according to the applied voltage. We use polarizer to polarize illuminating light and leverage liquid crystal to modulate bits through changing the light's polarization. The receiver can thus detect changes in polarization with a polarizing film, through which different polarizations result in different intensities. Since the SNR of such communication channel may significantly vary with the mobility of receiving device, we propose to add a dispersion filter to the transmitter. The dispersion filter can cast different frequency of lights into different polarization directions so that SNR in different receiving directions are evened. With the above techniques, VLC transmitter generates signal in low baud rate and mobile devices can perform VLC through camera directly. The communication is long in distance and lightweight enough for resource-constrained devices since the information is carried in intensity changes rather than certain image patterns in rolling shutter approaches.In this demo, we will illustrate the prototype implementation of the VLC communication system. We use incandescent lamps as illuminating light sources. The transmitter consists of a polarizing film, a liquid crystal layer, a dispersor and a control board. The receiver is demonstrated in Android smartphone with polarizing film in front of the camera. The following demo scenarios are planed to show our design (the demo space higher than 2.4m is preferred): Polarization based VLC modulation can solve the flickering problem. The modulated light provides normal illumination. When viewing the modulated light through a polarizing film, people can feel strong intensity changes.Dispersor and binary color shift keying (BCSK). Transmitter without dispersor results in bad SNR in certain receiving angles. For normal transmitters, color changes can always be observed in different angles.End-to-end VLC communication system. Smartphones with a polarizing film in front of the camera can receive and show transmitted messages from VLC transmitters.The VLC method enables accurate indoor positioning. After successfully receiving location beacons from VLC transmitters, smartphone performs location estimation.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {465},
numpages = {1},
keywords = {pixel, polarization, visible light communication, wearables},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745927,
author = {Xu, Shichang and Nikravesh, Ashkan and Yao, Hongyi and Choffnes, David and Mao, Z. Morley},
title = {Demo: Mobilyzer: Mobile Network Measurement Made Easy},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745927},
doi = {10.1145/2742647.2745927},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {467},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745931,
author = {Yun, Sangki and Chen, Yi-Chao and Mao, Wenguang and Qiu, Lili},
title = {Demo: Turning a Mobile Device into a Mouse in the Air},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745931},
doi = {10.1145/2742647.2745931},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {469},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745922,
author = {Zhao, Yixin and Pathak, Parth H. and Xu, Chao and Mohapatra, Prasant},
title = {Demo: Finger and Hand Gesture Recognition using Smartwatch},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745922},
doi = {10.1145/2742647.2745922},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {471},
numpages = {1},
keywords = {gesture recognition, wearables},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745903,
author = {Berning, Matthias and Budde, Matthias and Riedel, Till and Beigl, Michael},
title = {Poster: bPart - A Small and Versatile Bluetooth Low Energy Sensor Platform for Mobile Sensing},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745903},
doi = {10.1145/2742647.2745903},
abstract = {This work presents the bPart, a highly integrated autonomous sensor platform for use with mobile phones and devices. It consists of a Bluetooth Low Energy (BLE) radio and several MEMS sensors, all integrated in a volume of less than 1cm³, including the battery. Aside from the wireless transceiver, the bPart features sensors for ambient illumination, 3D-acceleration, temperature and relative humidity. In addition, there is a button and a magnetic switch for binary input and a RGB-LED for user feedback. A secondary LED in the infrared spectrum enables camera-assisted identification and tracking of the node. Runtimes of several years are possible on the included CR2023 lithium coin cell, through the low energy radio, onboard power-conversion and low-power sleep modes. The latter is rated below 2µW and a single data packet consumes about 75µWs. Its low energy consumption makes the bPart suitable for operation with energy harvesting, which we have validated with a 33cm² solar cell in indoor lighting conditions.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {473},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745907,
author = {Bisio, Igor and Delfino, Alessandro and Lavagetto, Fabio},
title = {Poster: Detecting if a Smartphone is Indoors or Outdoors with Ultrasounds},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745907},
doi = {10.1145/2742647.2745907},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {475},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745914,
author = {Chung, Albert Y. and Jung, Jongtack and Kim, Kangho and Lee, Hyung Kyu and Lee, Jiyeon and Lee, Suk Kyu and Yoo, Seungho and Kim, Hwangnam},
title = {Poster: Swarming Drones Can Connect You to the Network},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745914},
doi = {10.1145/2742647.2745914},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {477},
numpages = {1},
keywords = {aerial network infrastructure, multirotor, uav},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745904,
author = {Eldaw, Muawya Habib Sarnoub and Levene, Mark and Roussos, George},
title = {Poster: Constructing a Unique Profile for Mobile User Identification in Location Recommendation Systems},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745904},
doi = {10.1145/2742647.2745904},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {479},
numpages = {1},
keywords = {fingerprint, location recommendation, mobility traces},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745908,
author = {Hosseinmardi, Homa and Mattson, Sabrina Arredondo and Rafiq, Rahat and Han, Richard and Lv, Qin and Mishra, Shivakant},
title = {Poster: Detection of Cyberbullying in a Mobile Social Network: Systems Issues},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745908},
doi = {10.1145/2742647.2745908},
abstract = {Cyberbullying is a major problem affecting more than half of all American teens, and has been attributed to suicidal behavior among teens. Instagram, a media-based mobile social network, is one of the most popular social networks used for cyberbullying. In this paper, we describe the development of classifiers to detect cyberbullying in Instagram. We identify systems issues that need to be considered in the design of a cyberbullying detection system.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {481},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745910,
author = {Kriara, Lito and Corbellini, Giorgio and Vukadinovic, Vladimir and Kaelin, Ruben and Frigg, Roman and Mangold, Stefan},
title = {Poster: A Hybrid Indoor Audio Localization System},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745910},
doi = {10.1145/2742647.2745910},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {483},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745915,
author = {Li, Wenhao and Liang, Liang and Ma, Mingyang and Xia, Yubin and Chen, Haibo},
title = {Poster: TVisor - A Practical and Lightweight Mobile Red-Green Dual-OS Architecture},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745915},
doi = {10.1145/2742647.2745915},
abstract = {Mobile and embedded system software designer are often torn between choosing security and functionality. In particular, the security of out-of-band execution environment is sensitive to rich functionality. ARM TrustZone has been used to develop a Trusted Execution Environment (TEE), which runs in parallel with rich functionality commodity OS and provides an isolated and tamper-resistant execution context for trusted applications. ARM TrustZone splits access of the processor, memory and peripherals into two different worlds, namely normal world and secure world. The secure world is more privileged and the recommended context to implement TEE. However, despite the security of TrustZone TEE, the functionality is very limited.Hardware virtualization could balance the tradeoff between security and functionality by creating two VMes atop of the hardware. However, most of embedded and mobile devices lack hardware virtualization support, which makes it hard to deploy.Red-green dual-OS design, which provides a highly-protected and constrained trusted environment ("green" OS) to perform secure sensitive tasks and a general purpose environment ("red" OS) for all other tasks and applications, is an attractive design to achieve both security and functionality. Red-green dual-OS architecture uses resources partition instead of virtualization to achieve its goal and has been deployed in many mobile devices by running the red OS in normal world and the green OS in secure world of ARM TrustZone. However, even red-green dual-OS provides an isolated environment and rich functionality, the two OSes are not created equally: a compromise of the green OS would also result in the compromise of the red OS since secure world is more privileged.We show that how TVisor, a lightweight dual-OS architecture that creates two born-equal OS and each of them could still use the secure services of TEE in secure world, balances security and functionality for mobile devices. TVisor could be deployed to many low-cost embedded and mobile devices which are equipped with ARM TrustZone but without hardware virtualization support.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {485},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745906,
author = {Peng, Ge and Nguyen, David T. and Zhou, Gang and Wang, Shuangquan},
title = {Poster: A Continuous and Noninvasive User Authentication System for Google Glass},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745906},
doi = {10.1145/2742647.2745906},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {487},
numpages = {1},
keywords = {continuous authentication, google glass},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745913,
author = {Rege, Manoj R. and Handziski, Vlado and Wolisz, Adam},
title = {Poster: A Context Simulation Harness for Realistic Mobile App Testing},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745913},
doi = {10.1145/2742647.2745913},
abstract = {Accurate performance testing of mobile apps require comprehensive simulation of real world context in a mobile emulator viz. location, sensor values, network conditions etc. Existing mobile emulators support such simulation, however they lack the capability for automated generation of realistic, correlated, and dependent context traces. As a result, the burden of their generation and injection is left to the developers who have to create their own traces. This is not straightforward: there are heterogenous remote databases of traces, mathematical models and trace files can be used as well, but the trace values should be correlated, and traces have to be converted to a common format. We are developing ContextMonkey - a framework that addresses these concerns by leveraging context traces from databases such as FourSquare [1], OpenSignal [2], Google Street View [3]. It acts as a harness to mobile emulators, and aims at improving the efficiency of mobile app performance tests.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {489},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745911,
author = {Vigil, Morgan and Johnson, David and Belding, Elizabeth},
title = {Poster: Localized Content for Village Schools},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745911},
doi = {10.1145/2742647.2745911},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {491},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745905,
author = {Xu, Shichang and Nikravesh, Ashkan and Yao, Hongyi and Choffnes, David and Mao, Z. Morley},
title = {Poster: Context-Triggered Mobile Network Measurement},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745905},
doi = {10.1145/2742647.2745905},
abstract = {While the availability and accessibility of cellular network connectivity have improved in recent years, our ability to diagnose and debug network problems in this environment has not. One key challenge is that many of the network problems occur near the edge of the network where only mobile devices can perceive them, but network and battery resources to conduct measurements from these mobile devices are scarce. Traditional network measurement approaches that use continuous, periodic, or random measurements are either infeasible or ineffective in this environment.In this work, we propose an alternative approach: triggering measurements based on relevant device context such as signal strength and historical performance data, which can inform decisions for when to measure current network performance. This context can be collected locally on the device as well as aggregated at a global scale to schedule measurement based on data collected from multiple devices. By carefully selecting when to conduct a measurement, and using prediction to improve the likelihood that triggered measurements will succeed, we can more reliably measure important network phenomena with less overhead. Using Mobilyzer [3] as a platform for evaluation, we propose an architecture that is sufficiently general to support a wide range of triggered measurement experiments. We demonstrate the use of this framework for measurements on mobile platforms that are traditionally difficult to capture, e.g., handoff measurement. Further, we can use the global scheduler to predict which devices will likely satisfy the preconditions for the triggered measurement to improve the measurement success rate.Compared to previous work [2, 1, 4], ours is the first to propose a general framework to enable context-triggered mobile measurement, leveraging both local and global visibility into context while ensuring low overhead.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {493},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745909,
author = {Yus, Roberto and Mena, Eduardo},
title = {Poster: Emergency Management Using SHERLOCK},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745909},
doi = {10.1145/2742647.2745909},
abstract = {Emergency management has attracted the focus of mobile computing research in the last years due to the flexibility that it provides in critical scenarios. The lack of a pre-existing infrastructure or even a communication breakdown are important issues that mobile computing can deal with. In addition, Semantic Web techniques to handle the data in these scenarios, such as knowledge representation and reasoning, have been proven useful.In the SHERLOCK project [1] we are developing a general system to provide users with interesting Location-Based Services (LBSs) that can help in emergency management. SHERLOCK executes on mobile devices and leverages their communication mechanisms to exchange information among them. The system uses: 1) ontologies and semantic reasoners to handle knowledge about LBSs and interesting objects, and 2) mobile agents to balance CPU consumption and communication load.},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {495},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}
@inproceedings{10.1145/2742647.2745912,
author = {Zeng, Kexiong (Curtis) and Dou, Yanzhi and Yang, Yaling and Chandra, Ranveer},
title = {Poster: Location Verification and Recovery for Mobile In-Vehicle Applications},
year = {2015},
isbn = {9781450334945},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2742647.2745912},
doi = {10.1145/2742647.2745912},
booktitle = {Proceedings of the 13th Annual International Conference on Mobile Systems, Applications, and Services},
pages = {497},
numpages = {1},
location = {Florence, Italy},
series = {MobiSys '15}
}